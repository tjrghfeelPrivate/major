<!DOCTYPE html>
<html>
<head>
	<meta charset="UTF-8">
	<title>major page</title>
	<style>
		body{
			background-color: #212121;
			color: #d3d3d3; 
		}
		button{
			font-size:0.7vw;
			font-weight:bolder;
			background-color:#555555;
			color:white;
			border:0px solid black;
			border-radius:7px;
			margin-left:0.5vw;
			padding:0.1vw 0.5vw;
		}
		pre{
			margin:0px auto;
		}
		img{
			height:300px;
		}
	</style>
</head>
<body>
	<button id="showAll">모두 펼치기</button><br><br>

	<br>컴퓨터 기본 <button>더보기</button>
	<pre>
		ㅡ CSAPP <button>more</button>
		<pre>
			ㄴ 
			ㄴ chapter 04. Processor Architecture <button>more</button>
			<pre>
				ㄴ processor family 
					ㄴ Intel IA32, IBM, ARM processor 등과 같은 프로세서의 종류. 
					ㄴ 한 패밀리 안에서도 여러 processor model이 존재. 
						시간이 지남에 따라 발전하되, 같은 패밀리 내에서는 호환성을 보통 유지하도록 개발. 
				ㄴ instruction-set architectur (ISA) 
					ㄴ 특정 processor family가 지원하는 머신레벨 명령어 집합. 
					ㄴ 컴파일러 개발자와 프로세서 설계자 사이에 있는 일종의 추상적 계층역할을 한다할 수 있음? 
						컴파일러 개발자들은 고수준언어를 머신레벨로 변환할 때, ISA에 따라 어떤 머신레벨 명령어로 변환해야 할지, 어떻게 인코딩해야할지 등을 고려하고, 
						프로세서 설계자는 프로세서가 ISA에서 지원하는 명령어를 실행할 수 있도록 설계해야함 ? 
				ㄴ 이 장에서 이야기할 샘플 프로세서인 Y86 
					ㄴ ??? 'sequentail operation' 기반? 
					ㄴ 매 clock cycle 마다 하나의 명령어를 완전히 수행? 
					ㄴ ??? 한 clock cycle은 일련의 액션이 완전히 끝날 수 있을만큼 충분히 느리게 진행? 
					ㄴ ???~~~
					ㄴ 예외 발생시, 프로그램 실행이 그냥 중단되는 것으로 가정. 
						ㄴ 원래는 다양한 예외 handler가 실행됨. 
				ㄴ ??? ~~~ 335, 336p 
				ㄴ Programmer-Visible state 
					ㄴ 머신레벨, 어셈블리 언어단에서 접근 및 수정 가능한 프로세서의 state? 
					ㄴ program register, condition code, program counter, memory, program status 등. 
					ㄴ 여기서 말하는 'programmer'란, 어셈블리 코드로 프로그램을 작성하는 사람 또는 컴파일러(머신레벨 코드를 생성하므로). 
					ㄴ 목록 
						ㄴ program register 
							ㄴ %eax, %ecx, %edx, %ebx, %esi, %edi, %ebp, %esp 
								ㄴ %esp 
									ㄴ stack pointer로서 사용. 스택에 대한 push, pop, call, return 등의 명령어에서 사용.
								ㄴ 그 외 
									ㄴ 정해진 사용처 없음. 
							ㄴ 'word'를 저장. 
							ㄴ 각 레지스터들은 'register ID'를 가짐. 0~7까지. 
							ㄴ ??? CPU내의 'register file'에 저장되어 있음?
								ㄴ ???register file은 ID값이 주소값처럼 사용되는 random-access memory? 
							ㄴ register ID 'F' 
								ㄴ ??? 레지스터가 없음을 나타내어야 할때 사용되는 register id? 
						ㄴ condition code 
							ㄴ 세가지 코드값 존재. 
								ㄴ ZF, SF, OF 
							ㄴ 가장 최근의 논리 | 산술 연산에 대한 정보를 저장. 
						ㄴ program counter 
							ㄴ 현재 실행되는 명령어의 주소값 저장. 
						ㄴ memory 
							ㄴ 대용량 바이트의 배열. 
							ㄴ ??? virtual address로 사용됨. 
						ㄴ program status 
							ㄴ 전반적 프로그램 실행 상태를 나타내는 코드. 
							ㄴ normar 상태 또는 어떤 예외상태를 나타냄. 
							ㄴ 코드 목록 
								ㄴ code: 1 / name: AOK / 정상 실행 상태. 
								ㄴ code: 2 / name: HLT / 프로그램이 halt명령어를 실행한 상태. 
								ㄴ code: 3 / name: ADR / 명령어 fetch 또는 데이터 읽기 쓰기 중에 잘못된 주소값에 대한 읽기/쓰기 시도 오류. 
								ㄴ code: 4 / name: INS / 잘못된 명령어 실행시도. 
							ㄴ 
				ㄴ Y86 의 명령어 목록 (책 내용상 임의로 정의한 프로세서. 명령어는 IA32와 유사하다고는함)
					ㄴ movl 명령어들 
						ㄴ irmovl, rrmovl, mrmovl, rmmovl 
						ㄴ 명령어 이름에서 'movl'제외 앞 두개의 문자는 source type, desctimation type을 의미. 
							ㄴ i : immediate, r : register, m : memory
					ㄴ integer 연산 명령 
						ㄴ ??? OPL ? 
						ㄴ aadl, subl, andl, xorl 
					ㄴ jump 연산 명령어 
						ㄴ jmp, jle, jl, je, jne, jge, jg
					ㄴ conditional move 연산 명령어 
						ㄴ cmovle, cmovl, cmove, cmovne, cmovge, cmovg
						ㄴ rrmovl와 형식이 같지만, 조건이 만족할때만 move. 
					ㄴ call 명령어 
						ㄴ ??? 
					ㄴ pushl, popl 
					ㄴ halt 명령어 
						ㄴ 명령어 실행을 멈춤. 
						ㄴ 
					ㄴ 위 명령어들의 구조. 
						ㄴ <img src="image/CSAPP_Y86_sample_instruction_structure.png"/> 
							ㄴ 명령어들과 각 명령어들의 머신레벨 인코딩값. 
						ㄴ 각 명령어들은 인코딩값에서 첫번째 byte로 instruction type 값을 가짐. 
						ㄴ instruction type은 두개의 4bit 값으로 나뉘고, 
							첫번째 4bit는 code, 두번째 4bit는 function. 
							ㄴ 두번째 4bit인 function값은 여러 관련있는 명령어들이 첫번째 4bit인 code값을 공통으로 가지는 경우에만 의미 있음. 
								ㄴ ex ) addl 명령어(60), subl(61), andl(62), xorl(63) 등. 
								ㄴ 즉, 정수 연산인 OPL 내에서 여러 정수연산 명령어들이 있고, 이 명령어들이 두번째 4bit인 function값에 따라 구분되는식. 
								ㄴ function값에 따른 명령어 ex 
									ㄴ <img src="image/CSAPP_ch04_function_value_for_Y86_instruction.png"/>
							ㄴ 위 명령어들의 경우, code값은 0xB까지만 존재. 
							ㄴ 이렇게 첫번째 바이트가 명령어를 유일하게 식별하여 바이트코드만으로 그 일련의 바이트가 어떤 명령어인지 프로세서가 명확하게 판단 가능. 
						ㄴ register specifier byte  
							ㄴ 명령어 구조에서 레지스터를 명시하는 바이트 부분을 나타내는 말. 
							ㄴ 1개 또는 2개가 올 수 있음. 
								ㄴ 1개만 사용되는 경우, 나머지 한쪽은 F 레지스터로 표현됨. 
							ㄴ rA 또는 rB로 불림. 
							ㄴ 예제에서 볼 수 있듯, 명령어에 사용될 데이터 소스 또는 목적지로 해당 레지스터가 사용되거나 계산 대상이 될 수 있음. 
						ㄴ 명령어 인자로서 'constant word'가 올 수 있음. 
							ㄴ immediate data. 
							ㄴ 예제에서 'V', 'D', 'Dest' 부분. 
					ㄴ 연습문제 4.1 
					ㄴ 연습문제 4.2 
						A. 30f3fcffffff40630008000000 
						B. 
							a0 6f ) pushl %esi 
							80 08020000 ) 00000208 / call 16^2*2+8   
							00 ) halt 
							30 f3 0a000000 ) 0000000a / irmovl 10 %ebx  
							90 ) ret 
						C. 50540700000010f0b01f
							50 54 07000000 ) 00000007 / mrmovl 7(%esp) %ebp 
							10 ) nop 
							??? f0b01f  0f 에 해당하는 명령어 없음? 
						D. 6362a0f0 
							61 13 ) subl %ecx %ebx 
							73 00040000 ) 00000400 / je 16^2*4   
							00 ) halt 
						E. 
							63 62 ) xorl %esi %edx 
							??? a0 f0 ) pushl f가 와야하는 레지스터 바이트와 아닌 바이트가 뒤바뀌엇다? 
					ㄴ 
					
					

				ㄴ Y86의 완전한 프로그램 어셈블리 코드 ex  
					ㄴ 책에 나온 C언어 코드 예제를 어셈블리코드로 구현하여 보여준 예제. 
					ㄴ assembler directive 
						ㄴ ??? 어셈블러에게 코드 생성하는 주소를 조정하거나 특정 데이터를 삽입하라고 지시하는 지시자? 
						ㄴ 어셈블리코드에서 도트(.)으로 시작하는 명령어들? 
				ㄴ ??? Y86의 instruction set simulator (YIS) 
					ㄴ 머신레벨코드를 실행시키는 프로그램? 책에서 임의로 있다고 가정하는 프로그램? 
					ㄴ 디버깅할 때 쓰임? 실행 중간에서의 'programmer-visible state'들의 값들 확인 가능? 
						ㄴ <img src="image/CSAPP_ch04_YIS_debugging_ex.png"/>  
				ㄴ pushl %esp 명령시 동작 방식 
					ㄴ pushl 명령 수행시, 스택포인터가 하나 줄고 스택에 데이터를 추가하게 되는데, 
						pushl %esp 같은경우, 스택포인터인 %esp가 하나 줄고 줄어든 값을 스택에 넣을지, 기존 %esp값을 넣고 스택포인터가 하나 줄어들지 애매. 
						IA32 프로세서의 경우, 기존 %esp값을 넣고 스택포인터가 하나 줄어드는 방식. 
				ㄴ ??? Login design? 
					ㄴ hardware design? 
						ㄴ 컴퓨터 하드웨어를 설계하는 것? 전자 회로를 설계? 
						ㄴ 과거엔 종이에 그려서, 현대엔 'hardware description language'(HDL)을 사용하여 설계. 
					ㄴ logic gate 
						ㄴ 디지털 회로에서 가장 기본적 컴퓨팅 요소. 
						ㄴ 입력으로 들어온 비트에 대해 boolean함수같은 연산을 하여 출력을 내보냄. 
						ㄴ <img src="image/CSAPP_ch04_logic_gate_type.png"/>
						ㄴ 인풋은 단일 비트여야함. 
						ㄴ 인풋은 n개일 수 있음. 꼭 2개일 필요 없음. 
						ㄴ ??? HCL상에서 각각 &&, ||, ! 로 표현됨? 
					ㄴ 조합 회로 (combinational circuit) 
						ㄴ 여러 logic gate들을 연결, 조합하여 ??? network로 만들 수 있다. 
						ㄴ 이를 통하여 'combinational circuit'를 만들 수 있음.
						ㄴ ex ) 
							<img src="image/CSAPP_ch04_combinational_circuit_ex.png"/> 
						ㄴ 이러한 구성에 조건 존재 
							ㄴ ??? The outputs of two or more logic gates cannot be connected together. Other-wise, the two could try to drive the wire in opposite directions, possibly causing an invalid voltage or a circuit malfunction. 
							ㄴ network에 순환 경로가 있어선 안된다. 즉, 경로상의 loop가 존재해선 안됨. 
						ㄴ HDL 표현 
							ㄴ 위 예제 그림의 combinational circuit를 HDL로 다음과 같이 표현 가능. 
								bool eq = (a && b) || (!a && !b); 
							ㄴ 형식은 c언어 문법과 유사하나, c언어에서처럼 연산을 수행한다기보다 'eq'란 이름의 조합회로를 정의하는 의미. 
							ㄴ c언어에서의 논리 expression과의 차이점. 
								ㄴ ??? Since a combinational circuit consists of a series of logic gates, it has the property that the outputs continually respond to changes in the inputs. If some input to the circuit changes, then after some delay, the outputs will change accordingly. In contrast, a C expression is only evaluated when it is encountered during the execution of a program. 
								ㄴ c에선 bool값 외에 정수값도 논리표현식에 사용될 수 있지만, logic gate에선 bit값만 가능. 
								ㄴ c에선 '부분 판별'이 가능. 즉, 논리표현식 중 일부만 수행해도 결과를 알 수 있으면 나머지는 평가되지 않음. (short-circuit evaluation)
									logic gate에선 그런거 없이 모두 계산됨. 
						ㄴ 종류 
							ㄴ single-bit multiplexor 
								ㄴ 'MUX'라고도 표현. 
								ㄴ <img src="image/CSAPP_ch04_combinational_circuit_multiplexor.png"/>
								ㄴ input bit로 a, b. control signal로 s를 받음. 
									s가 1이면 output은 a, s가 0이면 output은 b.
								ㄴ HDL 표현 
									ㄴ bool out = (s && a) || (!s && b); 
						ㄴ word-level combinational circuit 
							ㄴ 일반적으로 조합회로는 'word'란 데이터에 대해 연산을 수행하도록 만들어짐. 
								ㄴ word란, 알고있는대로 데이터 단위. 이전챕터에서 나온 word. 
							ㄴ ???word의 각 비트에 대해 연산하는 logic gate들로 구성? 
							ㄴ ex ) 
								ㄴ 값 동일 여부 체크 회로 
									ㄴ <img src="image/CSAPP_ch04_word_lv_combinational_circuit_ex.png"/>
									ㄴ 인풋의 두 word의 각 비트들에 대해 동일성 체크하여 모두 같으면 1, 하나라도 다르면 0 출력. 
									ㄴ HDL 표현 
										ㄴ bool Eq = (A == B);
					
				ㄴ Hardware Control Language (HCL) 
					ㄴ 
				ㄴ ~~~
			</pre>

			ㄴ chapter 09. Virtual Memory <button>more</button>
			<pre>
				ㄴ 프로세스는 CPU와 메인메모리를 다른 프로세스들과 공유. 
					프로세스가 많아져 필요한 CPU사용 요구량이 많아짐에 따라 프로세스들은 느려질 수 있음. 
					근데 메모리가 부족해지는 경우, 아예 실행이 불가하거나 치명적 에러 발생할 수 있음. 
					이러한 이유로, 현대 시스템들은 메모리를 잘 관리하기 위해 'virtual memory'라는 메인메모리의 추상계층을 사용. 
				ㄴ ~~~

			</pre>

			ㄴ chapter 12. Concurrent Programming <button>more</button>
			<pre>
				ㄴ '병렬성' 개념은 커널 레벨에서뿐 아니라 어플레벨에서도 많이 사용. 
					ㄴ 어플레벨에서 'concurrency'를 사용하는 어플을 'concurrent program'이라함. 
				ㄴ 어플 레벨에서의 병렬성 사용 예 
					ㄴ I/O 장치에 대한 접근 
						ㄴ I/O 장치는 일반적으로 속도가 느리고, 이런 io장치에 접근하여 응답을 기다리는동안 커널은 cpu가 다른 작업을 수행하게함. 
					ㄴ 유저와의 상호작용 관련 
						ㄴ 윈도우에서 인터넷 서핑을 하면서 문서를 출력하는 등, 동시에 여러 작업을 수행해야 하는 기능이 필요. 
					ㄴ ??? Reducing latency by deferring work. Sometimes, applications can use concur-rency to reduce the latency of certain operations by deferring other operations and performing them concurrently. For example, a dynamic storage allocator might reduce the latency of individual free operations by deferring coalesc-ing to a concurrent “coalescing” flow that runs at a lower priority, soaking up spare CPU cycles as they become available. 
					ㄴ serving multiple clients
					ㄴ multi-core machine에서의 'parallel'실행. 
				ㄴ 어플 레벨 concurrency 구현 방법 
					ㄴ process <button>more</button>
					<pre>
						ㄴ 각 프로세스가 하나의 실행 흐름이되고, 커널에 의해 스케줄링 및 관리됨. 
						ㄴ 프로세스들은 각각의 가상주소공간을 가지므로, 실행흐름들도 별도의 가상주소 공간을 가짐. 
						ㄴ 가장 간단한 방법. 
						ㄴ fork, exec, waitpid 등의 함수 이용. 
						ㄴ 예 ) concurrent server 
							ㄴ 프로세스에서 클라이언트의 request를 받고, 이를 처리하는 child 프로세스를 생성하여 처리하는 방식. 
						ㄴ ~~~???

					</pre>

					ㄴ I/O Multiplexing <button>more</button>
					<pre>
						ㄴ??? 하나의 프로세스 내에서 어플리케이션에 의해 명시적으로 실행흐름들이 스케줄링되는 방식. 
						ㄴ 하나의 프로세스만 사용하기 때문에, 실행흐름들이 주소공간 공유. 
						ㄴ 필요 케이스 
							ㄴ 책에서의 임시 예제 
								ㄴ 서버로서, 여러 클라이언트의 요청을 리슨하고 있으면서 동시에 사용자 키보드 입력에 반응해야 하는 경우. 
									ㄴ 최상위 프로세스가 클라이언트 요청에 리슨하고 있으면 사용자 키보드 입력에 반응을 못할 것이고, 
										그 반대도 마찬가지. 
						ㄴ select 함수 
							ㄴ ??? 커널 함수? 
							ㄴ ??? i/o이벤트 발생시 프로세스를 중단시키고 실행흐름 컨트롤을 어플에게 넘겨주는 함수? 
							ㄴ i/o 이벤트 예 
								ㄴ ??? 특정 descriptor가 읽기 가능해졌을 때, 쓰기 가능해졌을 때, 에러가 발생했을 때 등. 
						ㄴ ~~~???

					</pre>

					ㄴ thread <button>more</button>
					<pre>
						ㄴ thread를 이용. 
						ㄴ thread <button>more</button>
						<pre>
							ㄴ 하나의 프로세스 내에서 실행되는 실행흐름. 
							ㄴ 커널에 의해 알아서 스케줄링됨. 
							ㄴ thread context 
								ㄴ 스레드별로 각자 가지는 컨텍스트. 
								ㄴ unique한 thread id (TID), stack, stack pointer, program counter, general-purpose register, condition code 등 포함. 
							ㄴ 한 프로세스 내에서 실행되는 스레드들은 프로세스와 동일한 가상주소공간을 공유. 
								ㄴ 즉, code, data, heap, shared libraries, open file 등 공유. 
							ㄴ 공유되는 데이터들에 대해선 어떤 스레드든 read/write 가능. 
								스레드별로 가지는 컨텍스트에 대해선 read/write 불가. 
								ㄴ ??? 단, thread stack에 대해선 예외. 
									ㄴ ???가상주소공간상 stack 영역에 위치하는데, 스레드별로 stack을 별도로 가지기는 하나, 
										다른스레드가 접근하는게 막혀있지는 않아서 주소값만 알면 다른 스레드가 read/write가능? 
										ㄴ ??? global, static 변수 등에 stack에 위치한 데이터의 주소값을 저장하고 이 global변수 등을 다른 스레드에서 사용하는 식으로 가능? 
									ㄴ ??? 다른 thread context내 자원에 대해선 원천적으로 읽기쓰기가 안되는데 stack만 가능? 왜? 
									ㄴ threaded c 프로그램에서의 변수의 메모리 결정 방식
										ㄴ 변수 유형에 따라 가상메모리상에 매핑 결정? 
										ㄴ global 
											ㄴ 가상메모리의 read/write 영역에 유일하게 하나의 인스턴스 생성. 
											ㄴ 모든 스레드가 접근 가능. 
										ㄴ local automatic 변수 
											ㄴ 함수 내에 'static'키워드 없이 선언된 변수. 
											ㄴ 런타임시, 각 스레드가 각각의 local automatic 변수 인스턴스를 가짐. 
												ㄴ 여러 스레드가 동일한 routine을 실행하더라도 각자 가짐. 
										ㄴ local static 변수 
											ㄴ 함수 내에 'static'키워드로 선언된 변수.
											ㄴ 'global'변수와 동일하게, 가상메모리의 read/write 영역에 유일하게 하나의 인스턴스 존재. 
												당연히 모든 스레드가 공유. 
									ㄴ ??? thread 프로그램에서의 공유 변수 
										ㄴ 변수 v가 있을 때, v의 인스턴스들 중 하나가 여러 스레드에 의해 참조될 때, v를 shared variable이라 함.
										ㄴ 실습 12.6  
										ㄴ ??? stack영역은 주소만 알면 다른스레드가 얼마든지 참조 가능하다했는데 
											ㄴ 참조 가능 여부가 아니라, 코드상에서 참조되고 있는지를 묻는 것? 
							ㄴ thread 실행 방식 
								ㄴ 프로세스는 처음 하나의 스레드(main thread)로 실행을 시작, 
									이후 자식 스레드(peer thread)를 생성하게 되고, 
									메인 스레드가 잠깐 sleep등을 하게 되면 'context switch'에 의해 컨트롤이 자식 스레드로 넘어가고 이 자식 스레드가 실행됨. 
									실행 흐름이 다시 넘어갈때까지. 	
							ㄴ thread context는 process context보다 매우 작아, context swtich에 드는비용이 적어 빠르다. 
							ㄴ 스레드들은 프로세스처럼 엄격한 계층관계를 가지지 않음. 
								프로세스에 의해 생성된 스레드이기만 하면 'thread pool'로서 동등하게 함께 취급. 어떤 스레드에서 어떤 스레드가 생성되었는지 등 상관 없이. 
								ㄴ??? 메인 스레드 역시, 프로세스 내에서 가장 먼저 시작하는 스레드라는 것을 제외하고는 다른 스레드들과 동등한 취급. 
						</pre>
						ㄴ Posix thread (Pthreads) <button>more</button> 
						<pre>
							ㄴ c언어에서 스레드를 다루는데 사용되는 표준 인터페이스. 
								스레드 생성, kill, reap, 스레드간 데이터 공유, 시스템 상태값에 대한 변화 알림 등의 기능. 
							ㄴ int pthread_create(pthread_t *tid, pthread_attr_t *attr, func *f, void *arg); 
								ㄴ 새 스레드 생성 & 생성된 스레드 context 내에서 함수 f 실행. 
								ㄴ ??? attr을 통해 새 스레드의 디폴트 속성 변경. ?책에선 다루지 않음? 
								ㄴ return시, tid에 새 스레드의 id 저장.
								ㄴ ??? The new thread can determine its own thread ID by calling the pthread_self function. 
							ㄴ 스레드 종료 
								ㄴ ??? 스레드는 top-level thread의 routine 종료시 종료됨?  
								ㄴ 스레드에서 pthread_exit() 호출시 명시적으로 종료. 
									ㄴ 메인스레드가 이를 호출한 경우, 모든 peer thread가 종료될때까지 대기 후, 모두 종료되면 메인스레드와 프로세스 종료. 
								ㄴ peer 스레드 중 하나에서 Unix의 exit를 호출한 경우. 
									ㄴ 이 함수는 프로세스를 종료시킴. 따라서 관련된 스레드들도 모두 종료됨. 
								ㄴ 제 3의 peer thread가 pthread_cancel()로 현재의 스레드를 종료시킨 경우.
							ㄴ 종료된 스레드 수거 
								ㄴ int pthread_join(pthread_t tid, void **thread_return); 
									ㄴ 스레드 tid가 종료될때까지 대기 
										& ??? 해당 스레드 종료시, 그 스레드 루틴이 반환한 generic pointer를 thread_return에 저장? 
										& ??? 종료된 스레드가 가지고 있던 메모리 리소스를 reap? 커널이 알아서?  
									ㄴ 임의의 스레드가 종료될떄까지가 아닌, 특정 스레드가 종료될때까지 기다리는 것. 
							ㄴ joinable thread, detached thread 
								ㄴ joinable thread 
									ㄴ 다른 스레드에 의해서 수거되고 kill될 수 있는 스레드. 
									ㄴ 다른 스레드가 수거하기 전까지 메모리 리소스가 free되지 않음. 
									ㄴ ??? 스레드의 디폴트? 
								ㄴ detached thread
									ㄴ join되는 스레드와 대조적으로 detached thread는 메모리가 자동으로 수거되지 않고 다른 스레드가 kill할 수도 없다. 
										리소스는 종료시 시스템이 알아서 수거해감. 
								ㄴ 메모리 누스 방지를 위해, 스레드는 다른 스레드에 의해 수거되거나 
									pthread_detach()를 통해 detached thread로 만들어져야함.  
								ㄴ int pthread_detach(pthread_t tid); 
									ㄴ 스레드 tid를 detached상태로 만듦. 
									ㄴ 인자에 pthread_self()를 넣어 스스로를 detached로 만들 수 있음. 
								ㄴ 사용 예 
									ㄴ??? 웹 서버에서 여러 클라이언트 연결에 대해 스레드를 생성하여 요청을 처리하는 경우, 
										새로 생성하는 스레드는 detached 스레드로 만든다? 
										각 스레드별로 요청을 각자 처리하기 때문에 서버가 이 스레드들이 종료될때까지 대기할 이유가 없기때문에? 
										??? 어떻게 돌아가길래 detached 스레드가 아니면 서버가 대기해야하는지? joinable 스레드로는 대기 없게 못하나? 
							ㄴ ??? thread 초기화? 
								ㄴ ???~~~
							ㄴ 스레드 기반 웹 서버 코드 예 
								ㄴ ???~~~ 
						</pre>
						ㄴ thread의 synchronization error <button>more</button>
						<pre>
							ㄴ 기계어 명령어가 한번에 한 명령어씩 실행된다고 할때, (즉, 한 명령어가 완료되어야 다른 명령어 실행가 실행됨)
								여러 스레드가 실행되는 경우, os가 스레드들의 실행 전환을 알아서 하기때문에 
								각 스레드의 명령어가 이상적으로 순차적으로 실행되지 않고 서로 섞여서 실행 될 수 있음. 
								가령, thread A의 명령어 A1, A2, A3,... thread B의 명령어 B1, B2, B3...가 있을 때, 
								이상적으론 A1, A2, A3, B1, B2, B3... 순으로 실행되어야 하나, 
								실제로는 A1, B1, A2, B2, A3, B3... 순으로 실행될 수 있음. 
								이런 경우, 명령어에 공유 변수를 업데이트하는 로직이 있는 경우, 해당 변수에 대한 로직이 꼬일 수 있음. 
								ㄴ ex ) 
									<img src="image/CSAPP_ch11_synchronization_error_ex_code.png"/>
								ㄴ 어셈블리 명령어 
									<img src="image/CSAPP_ch11_synchronization_error_ex.png"/>
							ㄴ progress graph 
								ㄴ 여러 스레드가 실행되는 경우, 스레드들의 실행을 모델링하는 방법. 
								ㄴ <img src="image/CSAPP_ch11_progress_graph_ex.png"/>
								ㄴ 방법 
									ㄴ 스레드 n개인 경우, n차원 좌표. 
									ㄴ 각 축은 thread 1, 2, ..., n을 의미. 
									ㄴ 각 축의 한 칸은 스레드의 명령어 하나를 의미. 
										한칸가면 첫번째 명령어 실행된 것 이런식. 
										(1, 2)이런식이면 1번스레드는 첫번째 명령어까지 실행, 2번째는 두번쨰 명령어까지 실행된 상태 이런식. 
									ㄴ 한칸씩 이동하는게 실행흐름이 진행되는 것. 예제와 같이 화살표로 표시. 
								ㄴ unsafe region 
									ㄴ 위 예제 코드상에서, 어셈블리 명령어 L, U, S부분이 공유 변수로 인해 로직이 꼬일 수 잇는 부분. 
										'critical section'이다. 
										즉, 스레드가 이 부분에 있을 때, 다른 스레드가 동일하게 이 부분을 실행하여 방해받아서는 안되는 영역. 
										즉, 어떤 스레드가 이 부분을 실행하고 있을때는 문제가 될 수 있는 공유변수 접근에 대해서 스레드들이 '상호 배타성(mutually exclusion)'을 가져야함.  
									ㄴ <img src="image/CSAPP_ch11_unsafe_region.png"/> 
										ㄴ 위 그림과 같이 progress graph상에서의 critical section의 교차영역을 unsafe region이라 함.
										ㄴ 영역 둘레를 타고 실행흐름이 이동하는 것까지는 safe, 영역에 들어가게되면 unsafe. 
										ㄴ safe 이동이면 공유변수로 인한 synchronization error가 없다 볼 수 있으며, 
											unsafe 이동이면 synchronization error가 발생할 수 있음. 
							ㄴ unsafe region 해결책 
								ㄴ 
								ㄴ 목록 	
									ㄴ semaphore 
										ㄴ semaphore라는 특별한 변수를 이용하는 방식. 
										ㄴ semaphore 변수 
											ㄴ global변수 
											ㄴ 음수가 아닌 정수. 
											ㄴ P, V 라는 연산에 의해서만 조작됨. 
												ㄴ P 
													ㄴ s (semaphore변수)가 0이 아닌 경우, s를 감소시키고 return. 
													ㄴ s가 0인 경우, s가 0이 아니게 되고, V연산에 의해 ???프로세스가 재시작 될때까지 스레드 중단
														재시작되고나면, P연산이 마저 진행(즉, s를 감소시키고 return)
													ㄴ s가 0이 아님을 확인하는 과정과 s를 감소시키는 과정은 atomic하게 실행. 즉, 과정 중 중간에 끊기는 일은 없음. 
													ㄴ ???  If s is zero, then suspend the thread until s becomes nonzero and the process is restarted by a V operation. After restarting, the P operation decrements s and returns control to the caller. 
												ㄴ V 
													ㄴ s를 1 증가. 
													ㄴ P연산에 의해 중단된 스레드가 있으면, 이중 '단 하나'를 재시작시킴. 
													ㄴ s를 1 증가시키는 과정은 atomic하게 실행. 즉, s를 로드하고 증가시키고 다시 저장하는 과정은 중간에 끊기는 일이 없음. 
													ㄴ 대기중인 스레드 중 어떤 스레드가 재시작할지에 대한 순서는 정해진게 없음. 즉, 예측할 수 없음. 
											ㄴ P, V 연산 규칙에 의해, semaphore는 절대 음수가 되지 않음. 
												ㄴ 이를 'semaphore invariant'라함. 
										ㄴ 상호배타에 적용 
											ㄴ binary semaphore <button>more</button>
											<pre>
												ㄴ s를 초기 1로 설정 & 'critical section'부분을 P, V연산으로 감쌈. P연산 -> critical section -> V연산 
													그럼 critical section을 실행하기 전에 P연산에 의해 s가 0이 되고 V연산이 실행되기 전에 
													다른 스레드가 critical sectino을 실행할 수 없음(이 부분 실행 전 P연산에서 s가 0이라 중단되기 때문) 
													V가 실행된 이후에서야 대기 중인 스레드 중 하나가 중단이 풀려 P연산을 마저 완료하고 critical section을 실행. 
													ㄴ 이를 통해, 
														여러 스레드가 cirtical section을 동시에 실행하는 것이 막힘. 
														즉, critical section에 대한 mutually exclusive access가 보장됨. 
												ㄴ ex ) 
													for (i=0; i< niters; i++){
														P(&mutex); 
														cnt++;
														V(&mutex); 
													}
												ㄴ semaphore값이 0 또는 1만 가능하기 때문에 'binary' semaphore라 불림. 
												ㄴ 'mutex' 
													ㄴ binary semaphore를 'mutex'라고도 부름. 
													ㄴ 이 경우, P연산 수행을 'locking mutex', V연산 수행을 'unlocking mutex'이라 표현. 
												ㄴ progress graph 상에서의 표현 
													ㄴ <img src="image/CSAPP_ch11_binary_semaphore_in_progress_graph.png"/>
													ㄴ 이전의 예제상에서 L, U, S 명령어 부분이 critical section이었고, 이 부분 앞뒤로 P, V연산을 추가한것을 
														progress graph로 표현한 것. 좌표상의 값이 semaphore값. 
													ㄴ P연산 후에 s값이 0이 되고, 이상태에서 다른 스레드가 P연산 수행시 -1이 되고 
														이렇게 s값이 음수인 부분들이 unsafe region이 됨.  
											</pre>
											ㄴ 공유 자원에 대한 스케줄링??? <button>more</button>
											<pre>
												ㄴ semaphore를 이용하여 스레드들의 '상호배타'뿐 아니라, 공유자원에 대한 스케줄링에도 적용 가능. 
												ㄴ ??? 스레드가 semaphore를 이용해 다른 스레드에게 어떤 조건이 충족됨을 알리는 방식을 사용? 
												ㄴ 두가지 대표적 시나리오. 'producer-consumer', 'readers-writers' 
												ㄴ producer-consumer <button>more</button>
												<pre>
													ㄴ producer 스레드와 consumer스레드는 'bounded buffer'를 공유 
														& producer는 반복적으로 버퍼에 새 item을 생성하여 추가 & consumer는 반복적으로 버퍼에서 item을 제거함으로서 소비. 
													ㄴ 상세 
														ㄴ producer, consumer는 n slot짜리 'bounded buffer'를 공유. 
														ㄴ buffer는 공유 자원이므로, 이에 대한 접근시 상호배타락 필요. 
														ㄴ 또한, 버퍼의 슬롯이 full이면 producer는 버퍼에 빈 공간이 생길 때까지 대기해야 하며, 
															버퍼가 비어있으면 consumer는 버퍼에 item이 생길 때까지 대기해야함. 
													ㄴ 구현 예시 <button>more</button>
													<pre>
														ㄴ buffer 구조체 
															typedef struct { 
																int *buf;	/* Buffer array */ 
																int n;	/* Maximum number of slots */ 
																int front;	/* buf[(front+1)%n] is first item. 버퍼의 첫번째 item가리킴.  */ 
																int rear;	/* buf[rear%n] is last item. 버퍼의 마지막 item가리킴. */ 
																sem_t mutex; 	/* Protects accesses to buf */ 
																sem_t slots; 	/* 이용가능한 slot개수에 대한 semaphore */ 
																sem_t items; 	/* 이용가능한 item 개수에 대한 semaphore. */ 
															} sbuf_t; 
														ㄴ 동작 코드 
															#include "csapp.h"
															#include "sbuf.h"
															
															/* Create an empty, bounded, shared FIFO buffer with n slots */
															void sbuf_init(sbuf_t *sp, int n) {
																sp->buf = Calloc(n, sizeof(int));  // 버퍼에 메모리 할당. 
																sp->n = n; /* Buffer holds max of n items */
																sp->front = sp->rear = 0; /* front, rear 설정. */

																// 3가지 세마포어 초기화. 
																Sem_init(&sp->mutex, 0, 1); /* Binary semaphore for locking */
																Sem_init(&sp->slots, 0, n); /* Initially, buf has n empty slots */
																Sem_init(&sp->items, 0, 0); /* Initially, buf has zero data items */
															}
															
															/* Clean up buffer sp */
															void sbuf_deinit(sbuf_t *sp) {
																Free(sp->buf);
															}
															
															/* Insert item onto the rear of shared buffer sp */
															void sbuf_insert(sbuf_t *sp, int item) {
																P(&sp->slots); /* 이용 가능한 슬롯 확인. 0이면 대기하게됨. */
																P(&sp->mutex); /* mutex lock. */
																sp->buf[(++sp->rear) % (sp->n)] = item; /* 버퍼에 item삽입. */
																V(&sp->mutex); /* mutex unlock. */
																/*
																item 개수 세마포어에 대해 V연산. item 개수 세마포어로 인해 대기중인 스레드가 실행됨. 
																이게 새 item에 대해 announce를 하는 역할인셈.
																*/
																V(&sp->items); 
															}
															
															/* Remove and return the first item from buffer sp */
															int sbuf_remove(sbuf_t *sp) {
																int item;
																P(&sp->items); /* 이용가능한 item확인. 0이면 대기하게됨. */
																P(&sp->mutex); /* Lock the buffer */
																item = sp->buf[(++sp->front) % (sp->n)]; /* Remove the item */
																V(&sp->mutex); /* Unlock the buffer */
																V(&sp->slots); /* Announce available slot */
																return item;
															}
													</pre>
													ㄴ 연습문제 12.9 <button>more</button>
													<pre>
														ㄴ A ) No, 
															p와 c의 item추가, 제거 코드 부분을 보면, p와 c가 공통적으로 변경 및 접근하는 변수가 없음. 
															p는 sp->rear에 접근 및 변경을 하고 c가 sp->front에 접근 및 변경을 하고 sp->n은 둘다 수정 없이 조회만함. 
															따라서, p, c가 각각 1나씩 있는 경우, 여러 스레드가 이 공유변수들에 대해 synchronization 오류를 일으킬 일은 없음. 
															ㄴ 정답 Yes, 
																ㄴ buf에 동시 접근이 가능하므로 mutex lock이 필요하다함. 
																ㄴ 피드백 
																	ㄴ 공유변수에 대한 동시 접근 상황이 있으면 로직상 문제가 될지 아닐지 일일히 케이스를 따져보기보단 그냥 lock? 
																		하나씩 따져보면 너무 복잡하다?  
														ㄴ B ) No, 
															ㄴ A와 마찬가지. 
															ㄴ 정답 No, 
																ㄴ n=1이면, 1개라도 item이 있으면 full인 상태이고 insert의 P($sp->slots)에서 막힐 것이고, 
																	0개이면 remove()에서 P(&sp->items)에서 막힐 것이므로, 결과적으로 insert()든, remove()든 
																	버퍼에 item추가, 제거 코드 부분을 실행할 수 있는건 한순간에 하나의 스레드일 것이므로 mutex lock이 필요치 않다함. 
																ㄴ 피드백 
																	ㄴ 삽입, 제거 코드 부분만 신경쓰고 그 이전 코드에 lock이 있는것 고려 못함. 
														ㄴ C ) Yes, 
															ㄴ p 스레드들이 sp->rear에 대해, c 스레드들이 sp->front에 대해 동시에 접근 및 변경을 시도할 수 있으므로 mutex lock 필요. 
															ㄴ 정답 No, 
																ㄴ B가 No인 것과 같은 이유. p, c 스레드가 여러개더라도 결국 insert()의 P(&sp->slots), remove()의 P(&sp->items)를 
																	통과하는건 한순간의 하나의 스레드이므로 mutex lock 필요치 않다고함. 
													</pre>
												</pre>
												ㄴ reader-writer <button>more</button>
												<pre>
													ㄴ 여러 스레드가 동시 실행되며 공유 자원에 접근한다고 할때, 
														공유자원에 대한 업데이트 작업을 하는 스레드를 'writer', 
														공유자원에 대한 읽기 작업만 하는 스레드는 'reader'라 할 수 있다. 
														writer는 공유자원에 대해 상호배타가 필요하지만, 
														reader는 다른 reader들과 동시에 공유자원에 접근하여도 문제 없다. 
														ㄴ ex ) 
															비행기표 예매 시스템에서, 남은 좌석 상태를 보낸 사람은 reader, 
															좌석을 예매 중인 사람은 writer라 할 수 있다. 
														ㄴ 일반적인 경우, reader와 writer의 수는 무한대로 존재할 수 있다 가정. 
													ㄴ ???두가지 유형 
														ㄴ first reader-writer 
															ㄴ reader가 우선권을 가지는 방식. 
																writer가 이미 공유자원 사용 권한을 가지고 있는게 아니라면 
																reader는 wait를 하지 않는다. 즉, reader가 먼저 사용한다? 
															ㄴ 구현 코드 예 <button>more</button>
															<pre>
																/* Global variables */
																int readcnt = 0; /* Initially = 0 */  // 현재 공유자원을을 읽고있는 reader의 수. 이또한 공유자원. 
																// binary semaphore. mutex는 readcnt에 대한 락으로 쓰이고, 
																// w는 reader쪽에서 writer의 접근을 막는데 쓰임. 
																sem_t mutex, w; /* Both initially = 1 */  
																
																void reader(void) {
																	while (1) {
																		P(&mutex);  // readcnt에 접근하기 위해 락. 
																		readcnt++;  // 현재 reader 스레드가 읽기 시작하므로 카운트 증가. 
																		/* 
																		P(&w)로 w에 대해 락을 걸음. 이를 통해, 좀 아래에서 V(&w)를 하기 전까지 writer는 대기해야함. 
																		또한, readcnt가 1일때만 w에 락을 걸음. 이러면 동시에 실행되는 많은 reader 스레드 중 첫번째 스레드만 
																		w에 락을 걸게되고, 그 이후 reader 스레드들은 이 부분을 그냥 건너뛰고 공유자원을 읽게됨. 
																		*/
																		if (readcnt == 1) /* First in */ 
																			P(&w);
																		V(&mutex);  // readcnt에 대한 작업이 마쳐, 락을 해제. 
																
																		/* Critical section */
																		/* 공유자원을 읽는 부분. */
																
																		P(&mutex);
																		readcnt--;  // 읽기를 마쳤으므로 카운트 감소. 
																		/*
																		V(&w)로 w에 대한 락을 해제. 이를 통해, writer는 쓰기작업을 할 수 있게됨. 
																		단, readcnt가 0인 경우에만 락을 해제하는데, 이는 동시에 실행되는 많은 reader 스레드들 중, 
																		가장 마지막 남은 스레드가 readcnt--을 실행해야 readcnt가 0이 될수밖에 없으므로, 
																		가장 마지막 reader 스레드가 읽기를 마쳐야, 즉, 모든 reader 스레드가 읽기작업을 마쳐야 
																		writer가 쓰기작업을 할 수 있게됨을 의미. 
																		*/
																		if (readcnt == 0) /* Last out */
																			V(&w);
																		V(&mutex);
																	}
																}
																
																void writer(void) {
																	while (1) {
																		P(&w);
																
																		/* Critical section */
																		/* 공유자원에 대하 write하는 부분. */
																
																		V(&w);
																	}
																}
																ㄴ 이런식으로 구현시, 여러 reader, writer 스레드들이 동시 실행되고 있다할때, 
																	writer는 한번에 한 스레드만 실행이 가능하고, writer가 하나 실행중이면 reader는 대기해야 하지만, 
																	한번 reader가 읽기를 시작하면, writer는 당연히 대기해야하고, 게다가 다른 reader들은 제한없이 동시에 읽기를 
																	수행할 수 있고 writer는 이 모든 reader들이 읽기를 마칠때까지 대기해야하는식. 
																ㄴ 이런식인 경우, writer가 거의 무기한으로 대기하게 되는 문제 발생. 
																	또한, writer가 연속적으로 작업을 하게되는 경우, reader들이 계속 대기하게 될 수도 있음. 
																	(우선순위가 '약하기' 때문)
															</pre>
														ㄴ second reader-writer 
															ㄴ writer가 우선권을 가지는 방식. 
																writer가 공유자원을 써야하는 상황이 되면 writer가 사용한다? 
																즉, reader는 대기해야 한다? 
												</pre>
												ㄴ ??? 활용? 
													<img src="image/CSAPP_ch11_procuder_consumer_ex_in_server.png"/>
													ㄴ ??? 이런 스케줄링 방식을 웹서버에 활용할 수 있다? 
														producer-consumer방식으로, 메인스레드가 클라이언트로부터 받은 요청을 공유버퍼에 추가하고, 
														worker 스레드들이 consumer로서 공유버퍼에서 요청을 가져와 처리하는 방식? 
													ㄴ ??? 무슨 이점? 
														ㄴ 매번 요청이 들어올 때마다 새 스레드를 생성하는 방식의 경우, 스레드 생성 비용이 만만치 않다? 
															producer-consumer방식 사용시, 이렇게 매번 스레드 생성할 필요 없으니 비용이 절약된다? 
											</pre>
													
						</pre>
						ㄴ multi-core 에서의 스레드 
							ㄴ 현대의 컴퓨터들은 multi-core인 경우가 많으며, 이런 경우, 멀티코어들이 여러 스레드들을 동시에 실행시키는 방식으로 동작. 
								ㄴ ??? 자세한 동작방식은 안나옴? 
							ㄴ 성능 
								ㄴ 일반적으로 코어의 개수 n개인 경우, 스레드를 n개까지 추가하게되면 성능이 증가하나, 그 이후부터는 크게 증가하지 않음. 
									당연히, n개 이상일 경우 동시에 실행할 코어가 남아있지 않기 때문. 
								ㄴ 측정 
									ㄴ 실제 실행 시간이 가장 확실하나, 몇가지 측정법 존재. 
									ㄴ speedup (strong scaling)
										ㄴ <img src="image/CSAPP_ch11_parallelism_thread_speedup.png"/>
											ㄴ p : 스레드 개수 
											ㄴ T(p) : p개의 스레드를 사용한 경우의 실행시간 
											ㄴ S(p) : p개의 스레드를 사용한 경우의 실행시간 증가율. 
										ㄴ T(1)가 concurrency 프로그램인 경우, S(p)를 'relative speedup', 
											T(1)가 실행흐름이 유일하게 하나 존재하는 프로그램인 경우, S(p)를 'absolute speedup'라 함. 
										ㄴ ralative speedup, absolute speedup 비교 
											ㄴ 'relative speedup'보단, 'absolute speedup'이 더 확실한 지표라함. 
												ㄴ concurrency프로그램은 코어가 하나여도 synchronization관련 오버헤드가 있기 때문에 T(1)값이 약간 증가하여 S(p)값이 늘어나기 때문이라함. 
											ㄴ absolute speedup은 측정하기 어렵. 
												ㄴ concurrency가 없는 T(1), T(p)를 측정하기 위해선, 프로그램의 concurrency가 없는 버전, 있는 버전이 필요하기 때문. 
									ㄴ efficiency 
										ㄴ 
					</pre> 

				ㄴ ~~~

			</pre>

			ㄴ ~~~
		</pre>

		ㅇ ??? 디스크? 
			ㄴ 성능 측정 
				ㄴ IOPS (Inout/Output operations Per Second) 
					ㄴ 초당 입출력 작업 수. 
					ㄴ 단순 작업의 수만을 나타내는 지표라 이것만으로 실제 성능 예측 어렵. 

		ㅇ 컴파일 언어, 인터프리터 언어<button>더보기</button>
		<pre>
			ㅡ 컴파일 언어 ) &lt;html&gt; 
				ㄴ 컴파일러에 의해 소스코드가 기계어로 번역이 되어 이를 저장해두었다가 실행시키는 언어를 컴파일언어라 한다.
				ㄴ
				ㄴ ex) c, java ...
			ㅡ 인터프리터 언어 )
				ㄴ 프로그램이 실행될때 소스코드가 인터프리터에 의해 번역이 되면서 바로 실행되는 언어를 인터프리터 언어라 한다.
				ㄴ javascript, html, 파이선, ruby ...
				ㄴ 스크립트
		</pre>

		ㅡ 컴파일, 링크, 로드? <button>more</button>
		<pre>
			ㄴ machine code
				ㄴ ??? cpu를 직접적으로 조작하는 명령어들로 이루어진 저수준 프로그래밍 언어?
			ㄴ lexical analysis, 어휘 분석
				ㄴ 프로그램, 웹페이지 등에 있는 문자열을 일련의 lexical token으로 변환하는 것.
				ㄴ lexical token이란 특정한 의미가 할당된 문자열. (토큰의 카테고리, 토큰값) 쌍으로 이루어짐.
				ㄴ 토큰 카테고리 목록
					ㄴ identifier. 프로그램 언어의 엔터티에 이름이 붙은 것. 언어의 엔터티는 변수, 데이터 타입, 라벨, 모듈 등이 포함.
						간단하게 프로그램 언어에서 사용자가 정의하는 이름들을 의미?
					ㄴ keyword. 프로그램 언어에서의 예약어들. if, return 등.
					ㄴ separator. 데이터, 문자열, 수학표현식 등의 안에서 분리된 영역, 독립된 영역의 경계을 나타내기 위해 사용되는
						하나 이상의 문자로 이루어진  문자열. ( ), { }, “ ”, csv의 컴마 등.
					ㄴ operator. 프로그래밍 언어에서 사용되는 연산자. +,* 등.
					ㄴ literal. 프로그래밍 언어의 리터럴
					ㄴ comment. 프로그래밍 언어의 주석.
			ㄴ Object code
				ㄴ 컴파일러에 의해 생성된 기계어.
				ㄴ 컴파일러의 목표 결과물이라 하여 'object' code.
			ㄴ Object file
				ㄴ object code를 포함하고 있는 파일.
				ㄴ 컴파일러나 어셈블러가 생성.
			ㄴ Linker
				ㄴ 컴퓨터 시스템 프로그램의 일종.
				ㄴ 하나 이상의 object file을 결합하여 하나의 실행파일(executable), 라이브러리 파일, object file을 만듦.
			ㄴ Linking
				ㄴ 여러 코드, 데이터를 모아 결합하여 load(메모리로 복사)되고 실행될 수 있는 하나의 실행 파일을 만드는 과정.
				ㄴ compile시, load시, runtime시에 수행 가능.
				ㄴ 과거엔 수작업으로 linking을 진행하였으나 현대엔 'linker'라는 프로그램을 사용하여 수행.
				ㄴ 장점, 의의
					ㄴ 모듈별로 분리하여 컴파일이 가능함으로서, 하나의 거대한 파일이 아닌 관리하기 쉬운 작은 단위의 파일들로서 사용 가능.
						특정 모듈 수행시 그 모듈만 재컴파일하고 다시 링킹만 하면 되는 등.
				ㄴ 작은 프로그램 개발시엔 큰 문제 없으나, 규모가 커질 경우 링킹과 관련된 이슈들이 발생.
					해결을 위해 링킹에 대한 이해가 필요.

			ㄴ Compiler Driver
				ㄴ preprocessor, compiler, assembler, linker를 호출하여 컴파일을 진행하는 컴포넌트.

			ㄴ ~~~
			ㄴ symbol resolution
				ㄴ 링커는 각각의 심볼 참조를 입력받은 relocatable obj file의 심볼테이블에 있는 딱 하나의 정의와 매핑.
				ㄴ 동일한 모듈 내에서 정의되고 참조되는 local symbol은 symbol resolution이 간단.
					ㄴ 컴파일러가 모듈당 각 local symbol이 하나의 정의만을 가지도록 하고,
						local symbol에 해당하는 local static 변수가 유일한 이름을 가지도록 하기 때문.
				ㄴ global symbol의 경우,
					ㄴ 컴파일러는 모듈내에 저으이가 없는 symbol 확인시, 다른 모듈에 정의가 있다 가정.
						심볼테이블에 해당 심볼에 대한 entry 추가 & 링커가 이를 처리하도록 냅둠.
					ㄴ 링커는 해당 심볼에 대한 정의를 다른 모듈들 안에서 찾지 못하면 에러 발생.
					ㄴ ??? 한 심볼이 다른 여러 obj file에서 정의된 경우, 링커는 에러를 발생시키거나 그 중 하나를 선택한다.
					ㄴ 컴파일러는 각각의 global symbol을 'strong' 또는 'weak' 심볼로서 어셈블러한테 export하면,
						어셈블러는 이 정보를 해당 relocatable obj file의 심볼테이블에 인코딩.
						ㄴ 함수, 초기화된 글로벌 변수는 'strong', 초기화되지 않은 글로벌 변수는 'weak'.
					ㄴ 링커는 글로벌 심볼 정의가 여러개 있는 경우, 다음 규칙에 따라 심볼 결정.
						ㄴ 'strong' 글로벌 심볼 정의가 여러개인 경우는 허용되지 않음. 에러 발생.
						ㄴ 'strong' 심볼과 여러 'weak' 심볼이 있는 경우, 'strong' 심볼로 결정.
						ㄴ 'weak' 심볼만 여러개 있는 경우, 아무거나 선택.
					ㄴ 선택되지 않은 다른 심볼 정의는 무시되므로, 해당 심볼 사용시 주의 필요. 버그의 소지 있음.

			ㄴ static library 링킹
				ㄴ 대부분의 컴파일 시스템은 관련있는 object 모듈들을 패키징하여 하나의 파일로 만드는 방식을 지원.
				ㄴ 이 하나의 파일을 'static library'라고 함.
				ㄴ static library는 링커에게 input으로 넘길 수 있음.
				ㄴ executable 파일 생성시, library에서 프로그램이 참조하는 모듈들만 복사.
				ㄴ ??? ANSI C의 경우, 문자열 조작, i/o 조작, 수학 관련 함수들 등 여러가지 라이브러리가 있고
					c 프로그램 어디서든 이 standard library를 사용할 수 있다.
				ㄴ ??? library 없이 컴파일러가 이러한 표준 기능들을 제공할 방법을 고려해보면,
					ㄴ ??? 컴파일러가 이 표준 함수들의 호출을 인식하고 적절한 코드를 직접 생성시키는 방법. (??? Pascal 처럼?)
						이러한 방법은 C에선 어렵. 표준 라이브러리가 너무 많아서.
						또한 표준 기능 변경시마다 컴파일러를 수정해야하고, 컴파일러에 너무 많은 복잡성을 주게됨?
						어플리케이션 개발자에겐 편리. 어디서든 표준 함수 사용이 가능해서.
					ㄴ ??? 또다른 방법은, 모든 표준 함수들을 하나의 relocatable object 파일에 넣는 것.
						ㄴ 표준함수의 구현과 컴파일러의 구현을 분리.
						ㄴ 이전 방법과 동일하게 어플리케이션 프로그래머는 편함.
						ㄴ 모든 executable 파일이 동일한 풀버전 표준함수 코드를 가지고 있게됨. (저장공간 낭비)
						ㄴ 모든 실행중인 프로그램은 이 표준 함수에 대한 코드를 메모리에 올려놓게됨. (메모리 낭비)
						ㄴ 표준함수에 대한 수정시, 모든 소스코드를 재컴파일해야함.
					ㄴ
		</pre>

		ㄴ Concurrency, Parallelism 
			ㄴ ~~~ 
			ㄴ thread, multi-processing, multi-io? 
				ㄴ thread 사용 적합 케이스 
					ㄴ ~~~
					ㄴ i/o 작업이 많은 비중을 차지하는 경우 
						ㄴ i/o작업 하는 동안 대기하고 다른 스레드가 cpu작업을 진행할 수 있기 때문에. 
						ㄴ single core에서 concurrent하게 동작하든, multi-core에서 parallel하게 동작하든 이득. 
					ㄴ 실제 io관련 작업이 얼마인지 정확히 파악 필요. 
						ㄴ 가령, db 쿼리 작업시, 패치해오는 데이터가 많은 경우, 쿼리실행 대기시간만큼이나 
							가져온 데이터를 처리하는 cpu-bound작업도 적지않음. 

		ㅇ statically typed language vs dynamically typed language<button>더보기</button>
		<pre>
			ㅡ statically typed )
				ㄴ 변수의 타입을 컴파일 시점에 알 수 있는 언어. java, c, c++ 등
			ㅡ dynamically typed )
				ㄴ 변수의 타입을 실행 시점에 알 수 있는 언어. js, python 등
				ㄴ 대부분의 스크립트 언어가 여기에 속한다. 컴파일러가 따로 없기때문.
					ㄴ 때문에, 인터프리터가 변수의 타입을 잘못 해석하여 버그가 발생하기는 하지만
					ㄴ 스크립트 언어는 규모가 크지않은 경우가 많기때문에 크게 문제가 되지 않는다.
		</pre>

		ㅇ WebDriver<button>더보기</button>
		<pre>
			ㅡ https://w3c.github.io/webdriver/webdriver-spec.html
			ㅡ w3c의 표준에는 'WebDriver'란 user agent(브라우저, 폰 등)을 컨트롤할 수 있게 해주는 'remote-control interface'라고 정의하고있다.
				ㄴ 브라우저를 클릭하거나 등.
				ㄴ 이런것들을 통하여 테스트를 자동화 하는듯함.
			ㅡ 웹 문서의 dom요소를 찾거나 조작하거나 user agent의 동작을 컨트롤하는 여러 인터페이스들을 제공.
			ㅡ 일반적으로 각 브라우저 밴더들이 표준에 맞게 구현하여 제공하고 있다고한다.
				ㄴ ex) chrome의 'Google chrome driver', 파이어폭스의 'geckodriver' 등
		</pre>

		ㅇ curl<button>more</button>
		<pre>

		</pre>

		ㅇ Sequence diagram<button>more</button>
		<pre>
			ㅡ 시간순으로 객체 사이의 상호작용을 다이어그램 형식으로 그린 것.
				ㄴ 객체 사이의 메세지 전달과 시나리오를 평행하는 수직선으로 표현한다.
			ㅡ 'event diagram', 'event scenarios'라고도 불린다.
			<img src="image/sequence_diagram.png" height="550"/>
			ㅡ 형식 )
				ㄴ 맨 위에 객체들이 존재
				ㄴ 각 객체 아래로 'lifeline'이 하나씩 존재. 아래로 갈 수록 시간이 지남을 나타낸다.
				ㄴ 'lifeline'에서 화살표를 다른 객체의 'lifeline'으로 연결하면서 객체간 '메시지' 상호작용을 나타낸다.
					ㄴ 채워진 화살표는 '동기'메시지를 의미, 점 화살표는 '비동기'메시지를 의미.
		</pre>

		ㅇ os  <button>more</button>
		<pre>
			ㅡ ~~~~~

			ㅡ 18. 가상 머신, virtual machine<button>more</button>
			<pre>
				ㄴ 하드웨어(cpu, 디스크, 메모리, 네트워크 등)를 추상화하여 한 컴퓨터에서 여러 개의 분리된 환경이 돌아가는 것처럼
					보이게 하는 것.

			</pre>

			ㄴ Linux<button>펼치기</button>
			<pre>
				ㄴ linux distribution (리눅스 배포판)
					ㄴ linux kernel을 포함하는 소프트웨어들로 만들어진 os. 
					ㄴ 각 배포판의 웹사이트를 통해 얻을 수 있는 경우 많음. 
					ㄴ 임베디드 장치, 서버, 개인컴퓨터 등 여러 곳에 사용 가능 및 배포판별로 기능이 특화되어 있음. 

				ㄴ Linux kernel 
					ㄴ 오픈소스인 UNIX-like kernel. 
					ㄴ Linus Torvalds(리눅스 토르발드)가 개발. 
					ㄴ ??? GNU os의 커널로 채택?

				ㄴ ~~~

				ㄴ FHS (=Filesystem Hierarchy Standard)
					ㄴ unix-like 시스템의 파일시스템 구조에 대한 컨벤션.
						ㄴ ex ) 맨 위에 root( / ), 그 아래 /etc, /bin 등등이 있는 구조를 말함.
				ㄴ Unix-like os의 파일 시스템
					ㄴ 가상 파일 시스템을 만든다.
					ㄴ 이 가상 파일 시스템에서는 단 하나의 루트 디렉토리가 존재하고 다른 모든 파일, 디렉토리들은 이 하위에 존재한다. (계층형)
					ㄴ 마운팅
						ㄴ 어떤 장치 안에 들어있는 파일들이 파일 시스템 상의 특정 위치에 보이도록하여 사용자가 접근할 수 있게 하는 기능.
						ㄴ ex ) usb의 파일들을 마운트하여 /media 위치에서 이 파일들에 접근할 수 있음.
						ㄴ 이때 파일들을 접근 가능하게 된 위치를 'mount point' 라고 함. ex ) /media

				ㄴ chroot
					ㄴ UNIX-like os에서 모든 프로세스는 root directory를 가짐. 대부분은 시스템의 루트 디렉토리와 동일.
					ㄴ chroot 명령어를 통해 이 루트 디렉토리를 변경할 수 있다.
					ㄴ 보통 고립된 환경을 세팅하기 위해 사용된다.
						??? 레거시 라이브러리를 필요로하는 소프트웨어 구동을 위해서 또는 소프트웨어 설치와 디버깅의 단순화?
					ㄴ 프로세스가 root directory 밖으로 탈출할 수 있기 때문에 보안용도로는 사용되지 않는다.

				ㄴ namespace
					ㄴ ???namespace라는 것을 두고, 프로세스들과 커널 자원들을 특정 네임스페이스에 속하게 하고
						각자가 속한 네임스페이스 내의 자원들만 '볼수???' 있도록하는 기능?
					ㄴ ??? '볼 수 없는 것'이란?
						ㄴ 이해 및 실습을 하지 않아 정확하지는 않지만, 글에서 현상적으로 보았을 때,
							그냥 해당 네임스페이스 안에 있으면 다른 볼 수 없는 네임스페이스(부모나 형제 네임스페이스)의
							자원들(프로세스, 네트워크 인터페이스, 마운트 포인트 등)이 존재하지 않는 것처럼 동작함. 인식이 안됨.
					ㄴ PaaS 등에서 컨테이너로서 사용되고,
						같은 os kernel 자원을 사용하고 있지만 마치 별도의 vm 위에 있는 것처럼 ns별로 독립적으로 할당받은 자원을 사용하는 것.
					ㄴ ???컨테이너 처럼 가두거나 할때 쓰이고?
					ㄴ ns는 프로세스당 최대 하나 할당 가능.
					ㄴ linux에서 보통 /proc/(*pid*)/ns 에 네임스페이스가 있다.
					ㄴ 새 프로세스 생성시, 모든 네임스페이스가 상속된다.
					ㄴ clone 또는 unshare syscall로 ns 생성 가능.
						ㄴ clone 사용시, 새로운 ns를 가진 프로세스 생성.
						ㄴ unshare 사용시, 새로운 ns를 생성하고 현재 프로세스를 이 ns로 이동.
					ㄴ 종류
						ㄴ PID namespace
							ㄴ process tree를 고립시킨다.
							* 리눅스 프로세스들은 계층형 트리 구조를 가진다.
								예전엔 리눅스는 단 하나의 프로세스 트리를 가졌다.
								이 프로세스 트리는 procfs라는 파일시스템에 의해 관리.
								pid 1번이 보통 프로세스 트리에서 root 프로세스가 되며, systemd인 경우가 많다.
							ㄴ pid namespace를 통하여 중첩 process tree 생성 가능.
								ㄴ 각 중첩 프로세스 트리의 루트 프로세스는 자신을 루트 프로세스로 인식 가능하며, 중첩 트리 안에서 pid=1
								ㄴ 중첩 프로세스 트리 내 다른 프로세스들도 중첩 프로세스 트리에 해당하는 pid들을 각각 가짐.
									즉, 한 프로세스가 여러개의 pid를 가질 수 있음.
								ㄴ 부모 pid namespace에선 루트 프로세스로부터 뻗어간 프로세스 트리가 모두 보이나,
									특정 pid namespace에선 해당 프로세스 트리 밖에 보이지 않으므로 보이지 않는 프로세스들과 상호작용할 수 없음.
							ㄴ ??? 다른 ns 종류들과 다르게, clone(), fork()를 통하여 새 프로세스가 생성될 때에만 생성가능.
						ㄴ mount namespace
						ㄴ network namespace
						ㄴ ~~~
					ㄴ 각 namespace 종류들에 대한 설명 및 실습 참고
						ㄴ https://medium.com/@saschagrunert/demystifying-containers-part-i-kernel-space-2c53d6979504
						ㄴ https://blog.quarkslab.com/digging-into-linux-namespaces-part-1.html
						ㄴ google 검색 키워드 : "how to work linux namespace"

				ㄴ SELinux
					ㄴ

				ㄴ RPM, RPM Package manger, Red Hat Package Manger
					ㄴ free opensource package 관리 시스템.
					ㄴ 파일 포멧 : .rpm
					ㄴ linux 배포판들에서 사용.
					ㄴ ~~~
					ㄴ front end
						ㄴ yum
							ㄴ Fedora Linux, Centos 5 이상, Red Hat Enterprise Linux 5 이상, Scientific Linux, Yellow Dog Linux, Oracle Linux 에서 사용.
							ㄴ ~~~
						ㄴ DNF
							ㄴ Fedora Linux 18 이상, Red Hat Enterprise 8 이상, AlmaLinux 8, CentOS Linux 8 에서 사용.
							ㄴ ~~~

				ㄴ 명령어들 <button>more</button>
				<pre>
					ㄴ du <button>more</button>
					<pre>
						ㄴ 형식 )
							du [OPTION]... [FILE]...
							du [OPTION]... --files0-from=F
						ㄴ 명시된 파일들의 디스크 용량 정보 제공.
						ㄴ ex )
							du /home /var/lib/pgsql     => /home, /var/lib/pgsql 에 대한 디스크 용량 정보 출력.
						ㄴ 디렉터리인 경우 하위로 recursive한다.
						ㄴ 옵션
							ㄴ --max-depth=N (-d)
								ㄴ 현재 위치에서 하위 N만큼 깊이까지의 디렉토리에 대해서만 확인.
								ㄴ 가령, 구조가
									/home
									/home/dir1
									/home/dir2
									/home/dir2/dir2_1
									/home/dir2/dir2_2
									/home/dir2/dir2_2/dir2_2_1
									/home/dir2/dir2_2/dir2_2_2
									위와 같고 현재위치가 /home이면,
									du --max-depth=0 => /home의 전체용량만 요약해서 나열.
										다음과 같이,

										256G    .

									du --max-depth=2 => /home 하위 2단계 깊이의 서브디렉토리까지의 전체 용량만 요약해서 나열하는식.
										다음과 같이,

										256G    .
										123G    ./dir1
										123G    ./dir2
										80G     ./dir2/dir2_1
										42G     ./dir2/dir2_2
							ㄴ --human-readable (-h) : 사람이 읽기 쉽게. 용량을 MB,GB등으로 변환해서 보여줌.
					</pre>
					ㄴ df <button>more</button>
					<pre>
						ㄴ df [OPTION]... [FILE]...
						ㄴ 해당 파일들을 포함하고 있는 파일시스템의 이용률을 보여줌.
							ㄴ ex )
								df /var/lib/pgsql   => pgsql이 저장되어있는 파일시스템(예를들어, /에 마운트된 /dev/xvdal)의 이용률 보여줌.

								Filesystem  1K-blocks   Used    Available   Use%    Mounted on
								/dev/xvdal  123123213   23123   12123213    13%     /

								df /var/lib/pgsql /dev  => pgsql과 /dev가 젖아되어있는 파일시스템의 이용률 보여줌.

								Filesystem  1K-blocks   Used    Available   Use%    Mounted on
								/dev/xvdal  123123213   23123   12123213    13%     /
								devtmpfs    123321      0       123321      0%      /dev

						ㄴ 파일을 명시하지 않으면, 마운트된 모둔 파일시스템을 보여줌.
					</pre>
					ㄴ ssh <button>more</button>
					<pre>
						ㄴ OpenSSH의 ssh client
						ㄴ ssh protocol을 이용하여 remote에 로그인 기능 제공.
						ㄴ ssh protocol 1,2 지원. 디폴트는 2.
						ㄴ 유저 인증
							ㄴ 사용 가능한 인증 방법 목록
								ㄴ GSSAPI 인증
								ㄴ host-based 인증
								ㄴ challenge-response 인증
								ㄴ password 인증
							ㄴ 위 인증 방법 목록의 위에서부터 순서대로 시도된다. ssh protocol 2의 경우 디폴트 설정가능하다함.
								(PreferredAuthentications 설정)
						ㄴ 인증 완료되면, remote는 ssh 명령어에 주어진 명령을 실행하거나
							인증된 유저를 remote에 로그인시키고 remote의 shell을 넘겨준다.
							이때 실행되는 명령어나 shell과의 통신은 암호화된다.
						ㄴ 옵션<button>more</button>
						<pre>
							ㄴ ~~~

						</pre>

						ㄴ 참고
							ㄴ https://linux.die.net/man/1/ssh
					</pre>
					ㄴ scp <button>more</button>
					<pre>
						ㄴ 네트워크 상으로 호스트간 파일 복사.
						ㄴ 데이터 전송과 인증을 위해 ssh 명령어를 사용한다함. ???내부적으로 알아서 사용하는듯?
					</pre>

					ㄴ top <button>more</button>
					<pre>
						ㄴ ??? ~~~
						ㄴ 결과창
							ㄴ ~~~
							ㄴ 요약 영역
								ㄴ ~~~
								ㄴ 메모리
									ㄴ 첫번째줄 : 메모리
										ㄴ total : 전체 메모리 크기
										ㄴ free
										ㄴ
										ㄴ buff/cache
									ㄴ 두번째 줄 : 스왑 메모리
							ㄴ 디테일 영역
								ㄴ 컬럼
									ㄴ ~~~
									ㄴ RES : 랩에서 사용 중인 메모리
									ㄴ SHR : 다른프로세스와의 공유 메모리
									ㄴ TIME+ : 프로세스가 사용한 토탈 cpu시간. 
						ㄴ 결과창에서의 명령어
							ㄴ M : 메모리 사용량 순으로 정렬
							ㄴ P : cpu 사용량 순으로 정렬
							ㄴ T : 프로세스 실행시간 순으로 정렬
							ㄴ N : pid 순으로 정렬
						ㄴ 참고 ) https://man7.org/linux/man-pages/man1/top.1.html

					</pre>

					ㄴ

				</pre>

				ㄴ 배포판 목록 
					ㄴ 목록 참고 
						ㄴ 전체 목록 계층구조 
							ㄴ https://upload.wikimedia.org/wikipedia/commons/1/1b/Linux_Distribution_Timeline.svg
						ㄴ 배포판 비교 참고 
							ㄴ https://en.wikipedia.org/wiki/Comparison_of_Linux_distributions
					ㄴ Debian 
						ㄴ debian project에 의해 개발. 
						ㄴ 다른 리눅스 배포판들의 기반으로 많이 사용. Proxmox, Ubuntu, Linux Mint, Pardus, Astra 등. 
						ㄴ fork 
							ㄴ Ubuntu 
							ㄴ Linux Mint 
					
					ㄴ Red Hat Linux 
						ㄴ Red Hat 사에서 만든 상업용 오픈소스 리눅스 배포판. 
						ㄴ Red Hat의  2004년에 지원 중단. 
						ㄴ 
						ㄴ 하위 목록 
							ㄴ Fedora linux 
								ㄴ Fedora Project가 개발한 리눅스 배포판
								ㄴ 중단된 Red Hat Linux를 이어개발하는 것으로 시작. 
								ㄴ Centos stream, Red Hat Enterprise linux의 upstream 역할. 
								ㄴ 하위 
									ㄴ Red Hat Enterprise Linux (RHEL)
										ㄴ ~~~
										ㄴ 하위 
											ㄴ Centos (7)<button>펼치기</button>
											<pre>
												...
						
												ㄴ 기본 명령어들 )
													ㄴ cp )
														ㄴ 복사 명령어
														ㄴ cp (*복사대상파일*) (*파일이름*) : 복사대상을 복사하여 두번째인자인 파일을 만든다.
														ㄴ cp (*복사대상파일*) (*디렉토리*) : 복사대상파일을 해당 디렉토리로 복사한다. (복사대상을 여러개 선택할수있다) ex) cp file1 file2 file3 (*디렉토리*)
													ㄴ rm )
														ㄴ 삭제명령어
														ㄴ rm (*파일*) : 해당 파일 삭제
															ㄴ ex) rm *.dat :  .dat으로 끝나는 모든 파일 삭제.
															ㄴ rm * : 모든파일삭제.
														ㄴ rm -r (*디렉토리*) : 디렉토리삭제. 안에파일이 있어도 삭제함.
													ㄴ pwd : print working directory. 현재 작업중인 디렉토리 위치 출력.
													ㄴ ??? route )
														ㄴ 라우팅 테이블 확인.
														ㄴ ex )
															Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
															default         gateway         0.0.0.0         UG    100    0        0 em4  # 디폴트 게이트웨이???
															192.168.0.0     0.0.0.0         255.255.255.0   U     100    0        0 em4
													ㄴ netstat
														ㄴ ~~~
														ㄴ output 요소
															ㄴ ~~~
															ㄴ local address
																ㄴ 소켓 연결에서 로컬 엔드포인트의 address:port.
															ㄴ foreign address
																ㄴ 소켓 연결에서 remote 엔드포인트의 address:port.
						
												ㄴ rpm
													ㄴ Redhat사에서 개발한 패키지 관리 프로그램.
													ㄴ Maven처럼 프로그램설치시 필요한 의존성이 있으면 자동으로 필요한 패키지들을 함께 설치해 준다.
													ㄴ ~~.rpm 형식의 파일이름을 가지며, 이름부분에는 정해진 규칙을 따르는 패키지명을 가진다.
														ㄴ (*패키지이름*)-(*소스버전*)-(*릴리즈버전*).(*배포관리버전*).(*아키텍쳐*).rpm
														ㄴ ex) mysql-connector-java-5.1.25-3.el7.noarch.rpm
													ㄴ 명령어 )
														ㄴ 기본형태 )  rpm [옵션] [rpm 패키지파일 또는 rpm 패키지이름]
														ㄴ 패키지 설치여부 조회 )
															ㄴ rpm -qa :
															ㄴ rpm -qa (*패키지이름*) : 해당 패키지 조회
															ㄴ rpm -qa | grep : 좀더 세밀한 조회
														ㄴ 설치명령어 )
															ㄴ rpm -Uvh (*패키지파일*) : 해당 패키지파일 설치명령어. -Uvh는 옵션. U는 패키지가 이미설치되어있으면 upgrade를 진행, v는 설치과정 출력, h는 진행률 출력.
														ㄴ 패키지 삭제 )
															ㄴ rpm -e (*패키지파일*)
						
												ㄴ yum
													ㄴ rpm의 대용으로 나온 패키지 관리 프로그램.
													ㄴ 명령어 )
														ㄴ yum install (*패키지명*)
														ㄴ yum groupinstall (*그룹명*)
														ㄴ yum check-update : 업데이트가 되어있는 패키지목록 확인
														ㄴ yum update : 설치된 패키지들을 최신버전으로 업데이트
														ㄴ yum update (*패키지명*) : 해당 패키지를 업데이트
														ㄴ yum list installed : 설치된 패키지 확인
														ㄴ yum list : 설치가능한 패키지 목록 확인
														ㄴ yum info (*패키지명*) : 패키지 정보보기
														ㄴ yum localinstall : local에 있는 rpm파일을 설치할때 사용된다.
						
												ㄴ inetd, xinetd
													ㄴ 개인적 개요 )
														ㄴ 리눅스의 인터넷 데몬같은것?
													ㄴ xinetd : extended inetd
													ㄴ 인터넷 서비스를 제공해주는 프로그램을 실행시킨다.
													ㄴ conf파일에 설정되어있는 모든 포트에 대해 listen을 하고 있다가 request가 도착하면 이에 맞는 적절한 서버를 실행시켜준다.
													ㄴ 'super server'라고도 불린다.
						
												ㄴ inetd 모드, standalone 모드
													ㄴ inetd 모드 : inetd를 통해서 서비스가 실행되는 모드를 말한다.
													ㄴ standalone 모드 : inetd없이도 혼자서 서비스가 실행되는 모드를 말한다.
						
												ㄴ vsftpd
													ㄴ ftp서버 프로그램.
													ㄴ ...
													ㄴ 사용법 )
														ㄴ  vsftpd.conf )
															ㄴ vsftpd에 관한 설정파일. https://linux.die.net/man/5/vsftpd.conf 참조.
															ㄴ anon_upload_enable : wirte_enable항목이 YES일때만 효과가 적용되며, 익명사용자가 업로드를 할수있게하는 항목.
															ㄴ write_enable :
															ㄴ userlist_file : userlist_enable항목이 활성화되어있을때 사용된다. 여기에 적힌 파일로부터 username list를 가져온게된다.
																디폴트는 /etc/vsftpd/user_list.
															ㄴ userlist_enable : 활성화되면, userlist_file에 적힌 파일로부터 user list를 가져와 이들이 로그인하는걸 막는다.
																(비번을 요구하기전에 거부된다). 디폴트는 NO이다.
															ㄴ userlist_deny : userlist_enable이 활성화되어있을때 사용된다. NO이면 userlist_file에 있는 유저만 접근이 가능하다.
																yes인경우 userlist_file에 있는 유저들의 접근을 거부한다. (비번을 요구하기전에 거부된다) 디폴트는 YES이다.
						
												ㄴ firewall 방화벽
													ㄴ iptables 명령어를 이용한 설정 : 이전버전에서 사용되었고 사용이 어렵다는 단점이 있다.
													ㄴ firewall-cmd, firewall-config
														ㄴ 새롭게 방화벽설정에 사용되는 명령어. 전자가 cmd환경에서, 후자가 gui환경에서 사용가능하다.
														ㄴ --permanent 옵션 )
															ㄴ firewall-cmd 명령어에 --permanent 옵션을 붙일 수 있다.
															ㄴ 이는 해당명령의 정책을 영구적으로 적용하라는 의미이다.
															ㄴ 이 옵션으로 정책설정후, firewall-cmd --reload 명령어를 입력하거나 재부팅을 해야 적용이된다. 그전엔 적용안됨.
															ㄴ 이게 없을시, 영구적용이 아닌 임시로 적용하게되며, 재부팅 또는 firewall-cmd --reload 명령시 리셋된다.
													ㄴ 사용법 )
														ㄴ firewall이 구동중인지 확인 : firewall-cmd --state
														ㄴ 설치 : yum install firewalld
														ㄴ firewall이 실행되도록 설정 )
															systemctl enable firewalld
															systemctl start firewalld
														ㄴ 특정 포트 및 서비스 방화벽 허용 )
															firewall-cmd --permanent --add-port=80/tcp
															firewall-cmd --permanent --add-service=http
															ㄴ --zone=(*zone이름*) 을 추가하여 네트워크zone을 설정할수도있다. 없으면 디폴트설정된걸로 설정.
														ㄴ 허용하고있는 port확인 )
															firewall-cmd --list-ports
						
												ㄴ centos7 mysql 설치 및 실행
													ㄴ 설치 )
														ㄴ rpm파일을 다운받는다.
														ㄴ yum install mysql-community-server로 mysql을 설치한다.
														ㄴ mysql을 실행한다. systemctl start mysqld
														ㄴ mysql을 처음설치하면 /var/log/mysqld.log안에 temporary password가 존재한다. 이를 이용하여 맨 처음 mysql에 접속할 수 있다.
															ㄴ 처음 접속한 뒤, 반드시 비밀번호를 변경해주어야한다. 안하면 아무 명령도 실행안됨.
															ㄴ  alter user 'root'@'localhost' identified by '(*새 비밀번호*)';
														ㄴ mysql에 접속한다. mysql -u root -p
															ㄴ 이거치면 비번입력하라뜨고 위의 temporary password로 입력하고 비번바꿔주면된다.
														ㄴ 이후 mysql을 사용하면된다.
													ㄴ 설정 )
														ㄴ centos에서는 mysql설정이 명령어 또는 전용 설정파일에서 가능하다.
														ㄴ 전용 설정파일은 여러종류가 있는듯하고 각각 적용범위에 차이가 있는듯하다.
														ㄴ my.cnf 설정 )
															ㄴ 전용 설정 파일들중 하나이다.
															ㄴ (*프로퍼티*) = (*값*) 형태로 설정내용들을 적는다.
															ㄴ 세세한 프로퍼티들은 다음을 참조. https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html
						
												ㄴ ip 설정<button>more</button>
												<pre>
													ㄴ ~~~
													ㄴ 고정 ip 설정<button>more</button>
													<pre>
														ㄴ /etc/sysconfig/network-script 위치에 'ifcfg-(*네트워크 인터페이스명?*)'과 같은 형식으로 각 네트워크 인터페이스의 설정파일들이 존재.
															ㄴ ex) ifcfg-em1
															ㄴ ex )
																TYPE="Ethernet"
																PROXY_METHOD="none"
																BROWSER_ONLY="no"
																BOOTPROTO="dhcp"
																DEFROUTE="yes"
																IPV4_FAILURE_FATAL="no"
																IPV6INIT="yes"
																IPV6_AUTOCONF="yes"
																IPV6_DEFROUTE="yes"
																IPV6_FAILURE_FATAL="no"
																IPV6_ADDR_GEN_MODE="stable-privacy"
																NAME="em4"
																UUID="87c24268-dc3a-437f-ba8b-8c758b841ea1"
																DEVICE="em4"
																ONBOOT="yes"
														ㄴ 파일 내의 다음 항목들을 수정하고 systemctl restart network 하여 적용 가능하다.
															ㄴ BOOTPROTO = "none"  # dhcp값이면 dhcp로 자동할당되므로 수정.
															ㄴ PIADDR = (*고정할 ip주소*)
															ㄴ PREFIX = (*넷마스크 prefix*)
															ㄴ GATEWAY = (*gateway ip*)
															ㄴ DNS1 = (*dns ip*)
															ㄴ DNS2 = (*dns ip*)
															ㄴ ONBOOT = "yes"  # yes 이어야 부트시 네트워크 설정이 진행.
														ㄴ 또는 nmtui 명령어로 설정 가능.
															ㄴ systemctl status NetworkManager 로 'NetworkManager'가 실행중인지 확인.
																ㄴ ??? NetworkManager란?
															ㄴ nmtui 명령어 입력하면 설정 gui창이 뜨고 ip설정이 가능하다.
													</pre>
												</pre>
						
											</pre>
											ㄴ Rocky Linux 
												ㄴ ~~~ 
												ㄴ version 
													ㄴ 9.x 
														ㄴ RHEL 9.x 버전을 기반으로 만들어짐. 

					ㄴ Centos Stream 
						ㄴ Red Hat Enterprise Linux와 Fedora linux 사이에 있는 midstream 리눅스 배포판. 
							fedora에서의 실험적인 기능들을 RHEL에 반영하기 전 중간에 한번 더 거치는 중간단계 역할. 

			</pre>

			ㄴ os 설치 
				ㄴ bootable usb
					ㄴ 
				ㄴ 기존 os 제거 후 재설치
					ㄴ bootable usb를 만들고 이 usb로 부팅 시작하면 알아서 기존 os 포멧 후 usb의 os를 설치. 

			ㅡ 무제<button>more</button>
			<pre>
				ㄴ corn
					ㄴ unix-like os의 스케줄러
			</pre>
		</pre>

		ㅇ 가상화<button>more</button>
		<pre>
			ㅡ ~~~
			ㅡ hardware virtualization
				ㄴ = platform virtualization, server virtualization
				ㄴ hypervisor에 의해 host의 hardware에서 가상화가 수행된다.
					가상의 컴퓨터 환경(virtual machine)을 만들어 낸다.
				ㄴ VM에서 돌아가는 소프트웨어들은 실제 하드웨어 위에서 돌아가는 것과 거의 동일하다.
				ㄴ 네트워크, display, keyboard, disk 등 물리적 시스템 자원에 대한 접근만 약간의 제한.
				ㄴ hypervisor 실행을 위한 리소스, VM에서의 감소된 리소스로 인해 성능 저하 경향 큼.
				ㄴ 사용 이유
					ㄴ 서버 통합시,
						작은 여러 서버들을 큰 하나의 서버로 통합하여 cpu, hard drive 등의 하드웨어 비용을 줄임.
						??? 하드웨어는 가상환경으로 통합되나, os는 그렇지 못하므로 이때 VM..?
					ㄴ

			ㅡ virtual machine, VM
				ㄴ ~~~
				ㄴ system virtual machine
					ㄴ full virtualization 라고도 함.
					ㄴ 완전한 컴퓨터 시스템 전체, 완전한 os의 실행을 제공하는 가상 머신.
					ㄴ ??? 기존의 아키텍처를 'emulate' 한다.
					ㄴ 실제 하드웨어에서 사용할 수 없는 프로그램을 실행할 플랫폼을 제공
					ㄴ 컴퓨터 자원을 효율적으로 활용하기 위해 여러 개의 가상 머신을 가지는 데 사용.

					ㄴ hypervisor가 'machine code'를 이용하여 하드웨어를 공유 및 관리하여
						하나의 물리 machine 위에서 서로 독립된 여러개의 환경이 존재하도록 한다.
				ㄴ process virtual machine
					ㄴ

			ㅡ OS-level virtualization, os 가상화
				ㄴ 커널이 여러개의 고립된 'user space'의 존재를 허용하는 os 패러다임?
					ㄴ 'user space'
						ㄴ os에서 가상 메모리는 보통 'user space'와 'kernel space'로 나뉨.
						ㄴ user space는 어플이나 드라이버가 실행되는 공간,
							kernel space는 os kerner, device 드라이버 등이 실행되는 공간.
						ㄴ 악성 소프트웨어로부터 메모리와 하드웨어를 보호하기 위함.
					ㄴ user space 호칭
						ㄴ container : LXC, Solaris containers, Docker, Podman
						ㄴ zones : Solaris containers
						ㄴ virtual private servers : OpenVZ
						ㄴ 등등..
				ㄴ 컴퓨터의 리소스 중 일부만이 할당된다.
				ㄴ 여러개가 존재할 수 있다.
				ㄴ 컨테이너 안에서 돌아가는 프로그램의 관점에선, 일반 os와 다를게 없다.
				ㄴ container engine (컨테이너 엔진)
					ㄴ ex ) docker engine, RKT, CRI-O, LXD
					ㄴ CLI 등으로 유저의 요청을 받아 컨테이너 관련 작업을 하는 소프트웨어.
						image를 pull하거나 등등의 작업 수행.
					ㄴ OCI표준을 따르는 image를 사용하여 동작?
				ㄴ container runtime
					ㄴ 컨테이너 엔진으로부터 필요한 정보를 받아 실질적으로 컨테이너를 실행하는 컴포넌트.
					ㄴ OCI의 표준 구현체는 'runc'. 그 외에도 crun, railcar 등의 다른 컨테이너 런타임도 존재.
					ㄴ 리눅스 커널과 실질적으로 상호작용하여 컨테이너 실행.
					ㄴ 컨테이너의 cgroup, selinux 설정 등도 맡음.
					ㄴ 도커 초기에 LXC가 컨테이너 런타임으로서 컨테이너를 실행. 후에 도커에서 libcontainer라는 라이브러리를 만들어 사용.
						더 이후, OCI 등장때 도커에서 이 lib을 기부, 이를 기반으로 runc 탄생했다함.
				ㄴ OCI (Open Container Initiative)
					ㄴ os-level 가상화 (특히, 리눅스 컨테이너)에 대한 표준.
					ㄴ https://opencontainers.org
					ㄴ container image 형식에 대한 표준, container runtime에 대한 표준 등이 있다.
					ㄴ ~~~

			ㅡ 클라우드 컴퓨팅<button>more</button>
			<pre>
				ㅡ ~~~
				ㅡ 서비스 모델
					ㄴ NIST에서 정한 세가지 표준 모델 존재.
						IaaS, Infrastructure as a service
						PaaS, Platform as a service
						SaaS, Software as a service
						ㄴ ??? 아래로 갈 수록 추상화 수준이 높아짐.
					ㄴ IaaS
						ㄴ infrastructure as a service.
							ㄴ infrastructure, 즉, 컴퓨터 하부 구조를 서비스로 제공하는 것???
						ㄴ vendor가 저장소, 네트워크, 서버, 가상화(하드웨어 emulatation)을 제공.
						ㄴ 이러한 리소스를 public cloud, private cloud 또는 이 둘의 혼합형 cloud를 통하여 제공한다.
						ㄴ ??? 네트워크 구조, 데이터 파티션, 보안, 스케일링, 물리적 컴퓨터 리소스 등 여러가지 low-level 상세 정보를
							high-level api를 통하여 유저가 양방향 참조할 수 있게 해준다?
						ㄴ ??? cloud os 안에 있는 hypervisor들로 수 많은 가상 머신들과 이들의 스케일링 조절이 가능하다.
						ㄴ OpenStack, Apache CloudStack, OpenNebula 등의 '클라우드 컴퓨팅 관련 기술'(??? cloud orchestration technology)을 사용한다.
							ㄴ vm의 생성, hypervisor 결정 ~~~ 등등의 기능.
						ㄴ ??? hypervisor 대신 리눅스 'container' 사용 가능.
							ㄴ 컨테이너는 하나의 커널 위에 고립된 파티션에서 실행됨.
							ㄴ 이때, 리눅스 'namespace', 'cgroup' 기술이 컨테이너를 고립, 보안처리, 관리하는데 쓰임.
							ㄴ hypervisor 실행을 위한 오버헤드가 없으므로 가상화보다 성능이 좋다.
						ㄴ 임의의 os나 어플리케이션을 배포하고 실행할 수 있는 저장소, 네트워크, 기타 기반 컴퓨팅 리소스 등을 사용자에게 제공하는 것.
							소비자는 cloud의 하부 구조를 관리하지 않지만 os, 저장소, 어플리케이션에 대한 권한과 네트워크에 대한 약간 제한된 권한을 가진다.
						ㄴ 저러한 리소스들을 주문 요청에 따라 제공해준다.
						ㄴ 사용자는 인터넷을 이용할 수도, os를 설치할 수도, 어플리케이션을 설치할 수도 있다.
					ㄴ Paas (= Platform as a service)
						ㄴ = application platform as a service (aPaaS)
						ㄴ 플랫폼을 서비스로 제공하는 것?
						ㄴ ??? ~~~
						ㄴ 세가지 방식으로 제공될 수 있다.
							ㄴ 클라우드 서비스에 의해 제공.
								ㄴ 사용자가 최소한의 설정으로 어플을 배포하면, 서비스 제공자가 네트워크, 서버, 저장소, os, db,
									미들웨어(java runtime 등) 등을 제공하는 것.
							ㄴ ??? As a private service (software or appliance) behind a firewall.
							ㄴ ??? As software deployed on public infrastructure as a service.
						ㄴ 사용자가 어플을 생성, 배포, 호스트할 환경을 제공해준다.
						ㄴ 이를 통해 환경 세팅(서버, db 세팅 등)의 작업을 없애준다. 어플에만 집중할 수 있게 해준다.
						ㄴ ??? 그 외에도 Paas가
							어플 디자인, 개발, 테스트, 배포, 웹서비스 통합, db통합, 보안, 스케일링, 어플 버전관리 등등의 여러 기능을 포함할 수 있다.
						ㄴ ??? 단점으로는 가격, 운영기능 부족, 제어 감소, 트래픽 라우팅 시스템의 어려움.
						ㄴ ~~~

				ㅇ AWS<button>more</button>
				<pre>
					ㅡ ~~~
						ㅡ 제공 서비스
							ㄴ ~~~
							ㄴ IAM (AWS Identity and Access Management) <button>more</button>
							<pre>
								ㄴ

							</pre>

							ㄴ ACM, AWS Certificate Manager
								ㄴ ssl, tls 인증서 및 키 관련 생성, 저장, 갱신 등의 작업을 대신 처리해주는 기능.
								ㄴ AWS의 Elastic load balancing, amazon CloudFront, amazon API Gateway, 등을 통해 배포된다.
									??? 직접 설치할 수는 없다고 한다.
								ㄴ

							ㄴ AWS Private CA (Certificate Authority)
								ㄴ ??? AWS cloud 내에서 Public Key Infrastructure (PKI)를 만들려 할 때 사용하는 서비스?

							ㄴ EC2 (Elastic Compute Cloud) <button>more</button>
							<pre>
								ㄴ ~~~ 다날림
								ㄴ key pair
									ㄴ ~~~
									ㄴ key pair 변경
										ㄴ
								ㄴ Amazon Machine Image (AMI)
									ㄴ ~~~
									ㄴ Amazon Linux
										ㄴ AWS에서 제공하는 리눅스 image
										ㄴ 종류
											ㄴ AL2023
											ㄴ Amazon Linux 2
											ㄴ Amazon Linux AMI
												ㄴ 2023.12 에 지원종료.
										ㄴ root에 대한 ssh, 패스워드 인증이 디폴트로 막혀잇음.
							</pre>

							ㄴ Amazon EBS<button>more</button>
							<pre>
								ㄴ ~~~
								ㄴ volume type <button>more</button>
								<pre>
									ㄴ Solid state drive (SSD) volume
										ㄴ SSDs를 이용한 volume.
										ㄴ use case
											ㄴ 작은 크기의 I/O에 대한 빈번한 read/write연산에 최적화 되어있다함.
											ㄴ ??? virtual desktop
											ㄴ 중간규모의 싱글 인스턴스 database.
											ㄴ 지연율이 중요한 상호작용하는 어플.
											ㄴ 개발, 테스트 환경.
											ㄴ ??? boot volume
											ㄴ  대부분의 경우에 적합하여 aws에서 추천하는 종류라함.
										ㄴ 종류
											ㄴ General Purpose SSD
												ㄴ gp3
													ㄴ general purporse SSD volume의 가장 최신 세대 볼륨.
													ㄴ volume 중 가장 비용효율적이고 저렴하다함.
													ㄴ gp2에 비해 20% 저렴.
												ㄴ gp2
											ㄴ Provisioned IOPS SSD
												ㄴ 퍼포먼스에 특화된 타입. 지연율, IOPS, throughput이 중요한 경우 사용.
												ㄴ io2 Block Express
												ㄴ io1
									ㄴ Hard disk drive (HDD) volume
										ㄴ ??? 크기가 큰 streaming workload에 최적화? 'throughput'이 중요한.
										ㄴ 종류
											ㄴ Throughput Optimized HDD volume
												ㄴ st1
											ㄴ Cold HDD volume
												ㄴ sc1
									ㄴ 그 외 이전 타입
										ㄴ Magnetic volume
											ㄴ magnetic drive를 이용한 옛날버전 volume.
											ㄴ use case
												ㄴ 데이터량이 작고, 주기적이지 않은 접속, 퍼포먼스가 중요치 않은 경우 적합.
											ㄴ size : 1GB ~ 1TB
											ㄴ IOPS : 40~200
											ㄴ throughput : 40 ~ 90 MB/s

								</pre>
								ㄴ volume 수정 <button>more</button>
								<pre>
									ㄴ 유의사항
										ㄴ 볼륨 수정 후, 동일한 볼륨을 다시 수정하려면 최소 6시간 대기 필요 & 해당 볼륨이
											'in-use' 또는 'available' 상태가 되어야함.
										ㄴ 볼륨 수정시, 몇분에서 몇시간 소요.
										ㄴ ~~~
									ㄴ 수정 방법
										ㄴ in console
											ㄴ ec2 페이지의 volume 부분들어가서 수정하면 성능, 사이즈 등을 수정하는 페이지 뜸.
												수정하고 확인 누르면됨.
										ㄴ 볼륨 사이즈를 늘렸다면, ??? 파티션,file system을 확장시켜야 한다?
											ㄴ https://docs.aws.amazon.com/ebs/latest/userguide/recognize-expanded-volume-linux.html
											ㄴ 방법
												ㄴ EBS volume를 resize한 후 상태값이 'optimizing'이 되면 수행 가능.
												ㄴ 사전 작업
													ㄴ ~~~
												ㄴ linux instance의 경우,
													ㄴ ??? Xen instance와 Nitro system instance인지에 따라 약간 상이.
														ㄴ aws ec2 describe-instance-types --instance-type (*???instance type*) --query "InstanceTypes[].Hypervisor"
														ㄴ 위명령어로 분별. 'nitro'는 Nitro-based instance, 'xen' | 'xen-on-nitro'는
															Xen-based instance.
													ㄴ 파티션 extend
														ㄴ volume에 partition 존재여부 확인. 없음 패스.
															ㄴ 'sudo lsblk' 명령어 사용.
															ㄴ ex )
																NAME    MAJ:MIN RM SIZE RO TYPE MOUNTPOINT
																xvda    202:0    0  16G  0 disk
																└─xvda1 202:1    0   8G  0 part /
																xvdf    202:80   0  24G  0 disk
															ㄴ 위와 같이 '└─' 모양으로 하위항목에 type이 'part', 즉 파티션임을 알수있다.
														ㄴ 파티션이 있다면, 파티션이 extend가 필요한지 확인한다. 필요없음 패스.
															ㄴ 위 lsblk 명령 결과에서 파티션의 size가 volume size보다 작으면 extend가 필요한것.
														ㄴ 파티션이 extend가 필요하다면, 'growpart' 명령어로 확장가능.
															ㄴ ex )
																Xen-instance인 경우,
																sudo growpart /dev/xvda 1  => ??? /dev/xvda의 1번 파티션을 extned?
															ㄴ lsblk명령어 다시 사용하여 volume과 파티션 크기가 같아졌늦지 확인.
													ㄴ file system extend
														ㄴ df -hT 명령어로 확장해야하는 파일시스템 정보 확인.
														ㄴ 확장해야하는 파일시스템의 'type'에 따라 다른명령어를 사용하여 extend.
															ㄴ 'xfs'인 경우,
																sudo xfs_growfs -d (*파일시스템의 마운트포인트*)
														ㄴ df -hT 명령어로 파일시스템의 크기가 확장되었는지 확인.
								</pre>

							</pre>

							ㄴ Elastic Load Balancing
								ㄴ 들어오는 트래픽을 지정한 타겟으로 분산시켜주는 기능.
									타겟들의 상태를 확인하여 양호한 상태의 타겟에게 트래픽을 라우팅한다.
									ㄴ 타겟이란 ec2 인스턴스, 컨테이너, ip 등.
								ㄴ 'Elastic' load balancer는 들어오는 트래픽의 양에 따라 load balancer의 scale을 자동으로 조절한다.
								ㄴ 다음의 load balancer를 지원한다.
									ㄴ Application Load Balancer
									ㄴ Network Load Balancer
									ㄴ Gateway Load Balancer
									ㄴ Classic Load Balancer
								ㄴ Application Load Balancer
									ㄴ 'Listener'
										ㄴ 설정에 따라 특정 프로토콜과 포트에서 클라이언트의 연결 request를 확인하고 있다가, 들어오면 설정한 'rule'에 따라 트래픽을 타겟으로 라우팅한다.
										ㄴ 'rule'은 우선순위, 하나 이상의 액션, 하나 이상의 조건으로 구성.
									ㄴ 'target group'
										ㄴ request를 포함하고 있는 target들에게 라우팅한다.
										ㄴ target에 대한 상태 체크를 설정할 수 있다. 모든 target에 대해 실행된다.
								ㄴ ec2와 함꼐 사용하는 경우,
									security group 설정에서, inbound는 0.0.0.0으로 해두고 outbound를 해당 ec2에게만 가도록 하는게 좋다.
									outbound rule에서 source를 ec2가 매핑된 security group으로 지정하면 됨.
									ec2쪽에서는 inboud에서 load balancer 에게만 받도록 load balancer와 매핑된 security group을 지정하는게 좋다.
									포트는 받으려는 포트와 loac balancer가 health check를 하는 포트를 받도록.

							ㄴ S3 (Simple Storage Service) <button>more</button>
							<pre>
								ㄴ ~~~
								ㄴ ??? 파일에 대한 접근 횟수, 지연율 등에 따라 다양한 storage class가 존재하여 이를 선택할 수 있다?
								ㄴ Bucket
									ㄴ ~~~
									ㄴ bucket address
										ㄴ
									ㄴ aws resource
								ㄴ 보안
									ㄴ ~~~
									ㄴ 관리 방식
										ㄴ 'Block public access'
											ㄴ bucket 레벨에서 bucket에 대한 모든 public access를 차단.
											ㄴ 모든 public 접근에 대한
											ㄴ 디폴트로 on. 명확하게 어떤 접근에 대해 허용해야 하는지 알지 못한다면 off하지 말라함.
											ㄴ??? off하여 모두 허용시켜 static website처럼 쓸거면 'AWS CloudFont' 사용하는게 낫다함???
										ㄴ AWS IAM
										ㄴ bucket policy
										ㄴ S3 access point
										ㄴ ACLs (Access control list)
										ㄴ S3 Object Ownership???
									ㄴ 접근 관리
										ㄴ ???디폴트로, S3 resource는 이를 생성한 소유자에게만 접근이 허용.
										ㄴ ???임의로 'access policy'를 설정하여 접근 권한을 변경 가능.
								ㄴ versioning
								ㄴ S3 object lock
								ㄴ S3 Replication
								ㄴ presigned URL
									ㄴ s3 object에 대한 권한이 없는 사용자가 object에 접근할 수 있도록
										권한이 있는 유저가 object에 대해 일시적으로 접근가능한 url을 생성하는 기능.
										이 url로 접근하여 파일을 다운받거나 업로드할 수 있다.
									ㄴ 제한
										ㄴ url에 대한 권한은 이 presigned url을 생성한 유저의 권한 내로 제한된다.
									ㄴ 방법
										ㄴ s3 console
										ㄴ AWS CLI
										ㄴ AWS SDKs
											ㄴ url의 최대 유효기간 7일.
											ㄴ python
												ㄴ
										ㄴ Visual Studio(Window) AWS Toolkit
										ㄴ Visual Studio Code AWS Toolkit

							</pre>


				</pre>

				ㄴ Google Cloud<button>more</button>
				<pre>
					ㄴ
					ㄴ 무제<button>more</button>
					<pre>
						ㄴ compute engine vm이 일반적인 가상머신인듯. aws ec2처럼.
						ㄴ 무료 사용
							ㄴ 일정 기간 무료체험판과 신규 가입시 크레딧 제공.
							ㄴ 일부 기능, 제한된 사용량에 대해 무료 제공 중.
								ㄴ https://cloud.google.com/free?hl=ko

					</pre>
				</pre>

			</pre>

			ㅇ 도커, Docker<button>more</button>
			<pre>
				ㄴ 개요 
					ㄴ ??? PaaS들의 집합?
					ㄴ OS-level 가상화를 사용하여 '컨테이너'라 부르는 것 안으로 소프트웨어들을 패키징한다.
					ㄴ 가상 컨테이너 안에 어플과 이의 의존성들을 패키지화 해준다.
					ㄴ '컨테이너'는 Linux, Window, mac에서 돌아갈 수 있다.
					ㄴ Linux kernel 기능(cgroup, namespace)과 'union mounting' 기능을 사용하여 자원을 고립한다.
					ㄴ macOs에선 리눅스 가상머신 기능으로 이를 동작시킨다.
					ㄴ 컨테이너가 가볍기 때문에 한 서버에서 동시에 여러개를 구동시킬 수 있다.
				ㄴ Docker engine에 대한 기술지원은 제공하지 않는다함. 
					대신 Docker Desktop을 제공. 간편하게 도커 사용 가능한 부분 유료 상품. 
				ㄴ license 
					ㄴ apache license 2.0 
				ㄴ 설치 
					ㄴ docker engine 
						ㄴ 공식페이지 따라하면됨. 
							ㄴ https://docs.docker.com/engine/install/ 
						ㄴ rocky linux의 경우, 전용 프로그램이 없어 centos로 사용. 
					ㄴ docker desktop 
						ㄴ in linux... 
							ㄴ 제공하는 배포판 한정? 
								ㄴ??? rocky는 안됨? 
				ㄴ 컨테이너란?
					ㄴ ??? 도커는 호스트 위에서 돌아가는 프로세스들의 집합???
						ㄴ ??? 이 프로세스들은 고립되어 있고, 몇 가지 공통적인 기능을 수행한다???
					ㄴ ??? 리눅스에서 프로세스들은 트리구조를 가지므로, 프로세스의 집합인 컨테이너는 항상 루트 프로세스를 가진다 할 수 있다???
					ㄴ chroot
						ㄴ 현재 프로세스의 루트 디렉토리를 변경하는 기능.
							ㄴ ??? 당연히 현재 프로세스의 자식 프로세스들의 루트 디렉토리도 같이 변경된다.

				ㄴ
					ㄴ 'container'라 불리는 느슨하게 고립된 환경 안에서 프로그램을 실행하고 패키지화 할 수 있다.
						ㄴ 프로그램 실행에 필요한 모든 것들을 포함하고 있어 이것들을 별도로 신경쓰지 않아도 된다.
						ㄴ 컨테이너는 다른 사람들과 공유가 가능.
						ㄴ 도커에서 컨테이너 관리 도구 및 플랫폼 제공.
							ㄴ ??? 어플 배포 및
					ㄴ 컨테이너라는 휴대성 좋은 단위를 기반으로 한 기술.
						스케일 변경과 구성 변경에 용이.
					ㄴ 가상머신보다 자원이 덜 들고 가볍고 빠르다.
					ㄴ 아키텍쳐
						ㄴ 클라이언트-서버 구조.
						ㄴ 서버가 컨테이너를 빌드, 실행, 배포.
						ㄴ 서버, 클라리언트는 같은 시스템 위에 있을 수도 떨어져 있을 수도 있다.
						ㄴ rest api, unix socket, network interface를 사용하여 통신.
					ㄴ 도커 데몬
						ㄴ dockerd
						ㄴ 도커 api request를 listen, 도커 이미지, 컨테이너, 네트워크, 볼륨 등의 도커 객체를 관리.
							타 도커 데몬과 통신.
					ㄴ 도커 클라이언트
						ㄴ docker
						ㄴ 유저가 실질적으로 도커를 사용하는데 쓰는 대상. ex ) docker run
						ㄴ 유저의 명령을 받거나 하면 docker 데몬에게 요청을 보내 작업을 수행하도록함.
						ㄴ 'docker api' 사용.
						ㄴ 하나 이상의 데몬과 통신 가능.
					ㄴ 도커 데스크탑
						ㄴ 도커를 좀 더 쉽게 사용할 수 있게 해주는 프로그램. mac, window, linux. 
						
					ㄴ 도커 registries
						ㄴ 'docker image' 저장소.
						ㄴ docker hub는 public docker registry.
							기본적으로 docker hub에서 image를 찾도록 디폴트 설정. 변경 가능.
					ㄴ 도커 object
						ㄴ docker image, container, network, volume, plugin 등을 통칭.
						ㄴ docker image
							ㄴ docker container 생성을 위한 명령어들로 이루어진 read-only template.
							ㄴ 또 다른 docker image를 기반으로 커스터파이징이 추가되어 생성되는 경우 잦음.
							ㄴ registry로부터 받아 사용하거나 직접 build할 수 있다.
								ㄴ 후자를 위해, 'Dockerfile'을 문법에 맞게 생성 필요.
									이 파일의 내용은 이미지를 생성하고 실행하는데 필요한 단계들을 정의, ??? 이미지의 layer를 정의.
									ㄴ Dockerfile
										ㄴ 확장자명이 없는 단순 텍스트 파일.
										ㄴ 도커 이미지 생성에 사용될 명령어 script들을 담고 있다.
								ㄴ 'Dockerfile' 수정 후 재빌드시, 변화가 있는 layer만 재빌드된다. 이로 인해 도커가 타 가상화 기술에 비해 가볍고 빠르다 한다.
							ㄴ ???컨테이너에게 고립된 파일 시스템을 제공한다?
								ㄴ 같은 이미지더라도 매번 새 컨테이너 생성시 각각의 고립된 파일시스템을 할당해준다.
								ㄴ 'container volume'을 통해 이를 수정할 수 있다.
							ㄴ ??? 정확히 명시된 내용을 확인하지 못한 추측이지만..
								build시, 컨테이너를 실행시키기 위해 필요한 모든 파일들을 생성하여 image에 넣어두고
								이후, 이 image로부터 필요한 모든 것들을 가져다가 컨테이너를 실행한다? 일종의 필요한 파일들의 압축 파일 형태?
								물론 필요한 파일들 뿐만 아니라 환경 변수 등의 여러가지 설정 데이터도 포함?
								ㄴ 도커가 image를 어떻게 만들고 컨테이너 실행에 사용하는지는 모르겠지만,
									대략적으로, 컨테이너 실행에 필요한 파일, 메타데이터 등을 특정 표준에 맞게 구조화하여 묶어 놓은 것이 image.
									컨테이너 실행시, 컨테이너 환경에서 이 이미지를 풀어 사용하여 원하는 컨테이너 환경을 구성.
									ㄴ https://developers.redhat.com/blog/2018/02/22/container-terminology-practical-introduction#
									ㄴ https://iximiuz.com/en/posts/you-need-containers-to-build-an-image/
						ㄴ docker container
							ㄴ 이미지의 실행 가능한 인스턴스.
							ㄴ Docker api, CLI를 통해 컨테이너를 생성, 시작, 정지, 이동, 삭제 할 수 있다.
								하나 이상의 network에 접속하거나 저장소를 붙이거나 컨테이너의 현재 상태를 기반으로 새 이미지를 만들 수 있다.
							ㄴ 디폴트로, 다른 컨테이너 및 host machine과 잘 고립되어 있는 편. 디테일한 설정 가능.
							ㄴ 기반 이미지와 컨테이너 생성, 시작시의 여러가지 설정으로 정의된다.
							ㄴ 어떤 os에서도 구동가능.
							ㄴ 다른 컨테이너들과 독립되어 있다.
							ㄴ ex )
								docker run -i -t ubuntu /bin/bash
								ㄴ 'ubuntu'란 이미지 없을시, registry로부터 pull. docker pull ubuntu 명령 수행시와 동일하게.
								ㄴ 컨테이너 생성. docker container craete 명령 수행시와 동일하게.
								ㄴ 컨테이너에 파일시스템 할당. ??? final layer에?
								ㄴ network interface 생성.
								ㄴ 컨테이너 실행 및 '/bin/bash' 명령 실행. '-i', '-t' 옵션으로 인해.
								ㄴ 이후 /bin/bash의 터미널 종료시, 컨테이너 '정지'. '삭제'되지 않음.
						ㄴ container Volume
							ㄴ 컨테이너의 파일시스템을 host machine의 특정 파일시스템 경로에 연결시켜주는 기능을 한다.
							ㄴ 여러 컨테이너가 동일한 위치를 사용할 수 있으며, 컨테이너들 사이에서 공유되는 효과가 있다.
							ㄴ docker run 명령어에 '-v' 옵션으로 volume 관련 설정 가능.
						ㄴ 도커는 'Go' 언어로 개발, 리눅스 커널의 기능 사용.
							'namespace' 라는 기술 사용하여 컨테이너의 고립된 작업 환경 기능 구현. 컨테이너 실행시, 해당 컨테이너에 대한 'namespace' set 생성하여 사용.
							컨테이너 내에서도 layer별로 namespace 고립.
							ㄴ 리눅스 kernel의 'namespace', 'cgroup'
								ㄴ ~~~
								ㄴ https://medium.com/@saschagrunert/demystifying-containers-part-i-kernel-space-2c53d6979504 참고
					ㄴ 기본 사용법 )
						ㄴ ~~~
						ㄴ 이미지 빌드
							ㄴ 'Dockerfile' 생성 및 명령어 작성.
							ㄴ docker build -t (*생성될 이미지의 태그명*) (*'Dockerfile'을 찾을 경로*)
								ㄴ (*'Dockerfile'을 찾을 경로*)에서 'Dockerfile'을 찾아 이미지 생성.
						ㄴ 컨테이너 실행
							ㄴ ex ) docker run -dp 3000:3000 getting-started
								ㄴ 'detached' 모드(백그라운드 실행)로, 3000번 포트 연결하여 실행.
						ㄴ 컨테이너 정지
							ㄴ ex )
								docker stop (*컨테이너id*)
						ㄴ 컨테이너 삭제
							ㄴ ex )
								docker rm (*컨테이너id*)
						ㄴ 업데이트
							ㄴ 기존 포트 사용하는 컨테이너 정지 후, 새로 빌드한 이미지를 실행시키면 됨.
						ㄴ container volume 설정
							ㄴ docker volume create (*volume명*)
							ㄴ docker run -dp 3000:3000 -v todo-db:/etc/todos getting-started
							ㄴ 해당 컨테이너 삭제 후 새 컨테이너를 -v todo-db:/etc/todos 옵션을 동일하게 주어 실행시, 데이터 유지.
							ㄴ docker volume inspect (*volume명*)
								ㄴ 해당 볼륨에 대한 정보 조히ㅗ.

					ㄴ Docker Build
						ㄴ docker build 명령어 : 가장 기본적인 빌드 방법.
						ㄴ docker BuildKit
							ㄴ 새롭게 추가된 빌드 컴포넌트.
						ㄴ docker Buildx
							ㄴ BuildKit에서 지원하는 모든 기능을 포함하면서 docker build 명령어를 상속하는 CLI plugin.
							ㄴ 'docker buildx build'
								ㄴ 'docker build' 명령어와 거의 동일한 UX로 사용된다.
						ㄴ Dockerfile
							ㄴ 특정 문법을 따르는 명령어 모은 텍스트 파일. 이미지를 구성할 때 필요하다.
							ㄴ 명령어
								ㄴ FROM (*image*)
									ㄴ base image 정의.
								ㄴ RUN (*명령어*)
									ㄴ ??? 현재 이미지의 최상 layer에서 해당 명령을 실행하고 결과를 커밋.
									ㄴ ??? 명령어 실행을 위한 shell form을 가지고 있다?
								ㄴ WORKDIR (*디렉터리*)
									ㄴ Dockerfile에서 뒤에 오는 모든 RUN, CMD, ENTRYPOINT, COPY, ADD 명령어를 위한
										working 디렉토리 설정.
								ㄴ COPY (*소스*) (*목적지*)
									ㄴ 파일이나 디렉토리 복사 붙여넣기.
								ㄴ CMD (*명령어*)
									ㄴ 해당 이미지를 기반으로하는 컨테이너 시작시 맨 처음 실행될 명령어 설정.
									ㄴ Dockerfile 당 하나 존재해야 하며, 여러개인 경우 마지막 것만 취급.
							ㄴ 디폴트 파일명은 'Dockerfile'
								ㄴ 디폴트 파일명인 경우, 'docker build' 명령시 별도의 파일명 플래그 필요 없음.
									디폴트가 아닌 경우, docker build --file (*파일명*)
								ㄴ 명시적 설정의 경우, '(*파일명*).Dockerfile' 이 관례.
						ㄴ 도커 이미지는 read-only layer들로 구성. 각각은 Dockerfile의 명령어의 결과.
						ㄴ ~~~

					ㄴ Docker Storage
						ㄴ 디폴트로, 컨테이너 안에서 생성되는 모든 파일들은 컨테이너 계층 안에서 저장되기 때문에,
							컨테이너가 존재하지 않게되면 영속되지 않고, 컨테이너 계층 바깥으로 꺼내기 어렵다.
						ㄴ ??? host machine과 강하게 결합되어 있어 꺼내거나 다른 곳으로 옮ㄱ기ㅣ 어렵다?
						ㄴ ??? 'storage driver'를 사용한다?
						ㄴ 컨테이너 계층이 아닌 host machine에 데이터를 저장하는 두가지 방법 존재. 'volume', 'bind mount'
							ㄴ 그 외에 host machine의 시스템 메모리에 파일을 저장하는 방법. 'tmpfs'(리눅스의 경우), 'named pipe'(윈도우의 경우)
								ㄴ 메모리에 저장하므로 당연히 영속되지 않는다.
						ㄴ volume
							ㄴ host의 파일시스템 중 일부가 도커에 의해 관리되면서 이곳에 데이터가 저장되는 방식.
							ㄴ 도커가 아닌 프로세스가 이 부분을 수정할 수 없다.
							ㄴ 'docker volume create'를 통해 명시적 생성 또는 컨테이너, 서비스 생성시 도커에 의해 자동 생성.
							ㄴ 여러 컨테이너한테 동시 마운팅 가능.
							ㄴ volume을 사용중인 실행 중인 컨테이너가 없어도 없어지지 않는다.
							ㄴ 'docker volume prune'으로 제거 가능.
							ㄴ 좋은 사용 예 )
								ㄴ 여러 컨테이너들 사이에서 데이터 공유가 필요한 경우.
								ㄴ 호스트가 해당 디렉터리 구조를 가지는지가 불분명한 경우. 호스트에서의 설정과 컨테이너의 실행을 분리해준다.
								ㄴ ??? 컨테이너의 데이터를 로컬이 아닌 remote host나 cloud provider에 저장하고 싶을떄?
								ㄴ ??? 데이터를 한 호스트에서 다른 호스트로 백업, restore, migrate하고자 할떄?
								ㄴ 'docker desktop'에서 높은 i/o 성능을 필요로 할때. volume이 호스트에서 linux VM에 저장되기 때문에 읽기쓰기 성능이 더 좋다.
								ㄴ ??? 'docker desktop'에서 어플이 완벽하게 native filesystem 처럼 동작해야 할때. volume이 linux VM에 저장되기때문에 이를 보장해준다.
						ㄴ bind mount
							ㄴ host의 어디든 저장소로 사용될 수 있다.
							ㄴ 컨테이너나 host의 도커가 아닌 프로세스가 수정할 수 있다.
							ㄴ host의 파일이나 디렉토리가 컨테이너에 마운트된다.
								ㄴ 전체 경로가 제공되고
								ㄴ 해당 파일이나 디렉토리가 없으면 자동 생성.
							ㄴ ??? 도커 CLI command로 bind mount를 관리할 수 없다?
							ㄴ 좋은 사용 예 )
								ㄴ 설정 파일이나 배포를 위한 소스코드, 빌트 artifact 등을 호스트와 컨테이너가 공유해야 할 때.
								ㄴ 컨테이너가 마운트하여 사용할 호스트의 파일 또는 디렉토리 구조 부분이 일관성을 보장할 수 있을 때.
						ㄴ tmpfs
							ㄴ host의 메모리에만 저장되며 host의 파일시스템에 write되지 않는다.
							ㄴ 좋은 사용 예 )
								ㄴ 데이터를 영구적으로 저장할 필요가 없을 때.
									ㄴ 보안상의 이유이거나
									ㄴ 저장하지 않을 대용량의 데이터를 write 해야하는 경우에 성능상의 이유 등.
						ㄴ 컨테이너 상에서 이미 파일, 디렉토리가 존재하는 위치에 빈 volume을 마운트할 경우,
							기존에 존재하던 파일, 디렉토리들이 volume으로 복사된다.
						ㄴ ??? 컨테이너 상에서 이미 파일, 디렉토리가 존재하는 위치에 비어있지 않은 volume을 마운트하거나 bind mount를 할 경우,
							기존에 존재하던 파일, 디렉토리들이 리눅스의 /mnt에 저장되는 것처럼 가려진다.
							~~~

					ㄴ networking
						ㄴ 도커 network driver
							ㄴ 도커의 네트워크 관련 subsystem은 driver를 이용하여 pluggable하다.
							ㄴ 종류 )
								ㄴ bridge network )
									ㄴ 디폴트 network driver.
									ㄴ 소프트웨어적인 bridge. 같은 bridge에 연결된 컨테이너들이 통신할 수 있도록.
										다른 bridge에 속한 컨테이너들과는 네트워크 고립.
									ㄴ 같은 docker daemon host 위에 있는 컨테이너들에 적용 가능.
									ㄴ 도커 실행시, default bridge network 생성.
										컨테이너 실행시, network관련 아무 명시가 없으면 컨테이너를 이 디폴트 bridge에 연결.
									ㄴ 사용자 정의 bridge network 생성 가능.
									ㄴ 디폴트 bridge대신 사용자 정의 bridge 사용 권장.
									ㄴ standalone container 내의 어플에 대한 통신이 필요할 때 사용.
									ㄴ 디폴트 bridge 사용시, 관련 없는 대상이 네트워크 연결될 수 있다.
										사용자 정의 브릿지를 통하여 확실히 관련있는 대상들만 연결되도록 하는 것이 낫다.
									ㄴ ???사용자 정의 브릿지 사용시, 컨테이너 재시작 필요 없이 bridge 연결을 끊거나 연결할 수 있다.
										디폴트 브릿지는 재시작해야함.
									ㄴ 사용자 정의 브릿지마다 필요한 설정을 따로 하여 적용 가능.
									ㄴ ??? 여러 컨테이너가 환경변수를 공유할 방법은 디폴트 브릿지로 연결하여야지만 가능하지만 다른 방식으로 해겨 ㄹ가능.
										ㄴ docker volume에서 mount를 통하여 파일을 공유
										ㄴ docker-compose에서 compose파일 내에 변수 정의
										ㄴ swarm service
									ㄴ 'docker network create (*사용자 정의 브릿지 네트워크명*)' 을 통하여 사용자 정의 브릿지 생성 가능.
										ㄴ 여러 옵션들로 네트워크 설정 가능.
									ㄴ 'docker network rm' 으로 브릿지 네트워크 삭제.
										ㄴ 사전에 브릿지에 연결된 컨테이너 disconnect 필요.
									ㄴ 같은 bridge 내의 컨테이너들은 서로 모든 포트 접근 가능.
									ㄴ

								ㄴ host network
									ㄴ 컨테이너의 네트워크가 고립되지 않고 host의 네트워크 네임스페이스를 공유한다.
									ㄴ 컨테이너가 별도의 ip주소를 가지지 않는다.
									ㄴ 컨테이너에 대한 port mapping은 무시된다.
										ㄴ -p, --publish, -P, --publish-all 옵션이 무시됨.
									ㄴ 성능 최적화,
										컨테이너가 많은 포트를 사용해야 할 때, (???'network address translation'이 필요치 않음)
										??? 'userland-proxy'가 포트별로 없을 때?
										유용하다.
									ㄴ 리눅스 호스트일때만 지원.
										Window, Mac의 Docker Desktop과 Docker EE에선 지원 x.
									ㄴ ???swarm service에 사용 가능.
										ㄴ 'docker service create'에 '--network host'옵션을 통하여.
										ㄴ ??? swarm 서비스들의 트래픽은 overlay network를 통하여 전달되지만,
											각각의 swarm service container들은 호스트의 네트워크를 통하여 데이터를 보냄.
								ㄴ overlay network
									ㄴ 여러 docker daemon host를 연결하여 네트워크를 만들거나
										'docker swarm service'들이 서로 통신할 수 있게한다.
										ㄴ swarm service와 standalone container 사이의 통신,
											서로 다른 daemon의 standalone container끼리의 통신도 가능하다.
										ㄴ 하여, os-level routing을 대체할 수 있다.
									ㄴ ??? This network sits on top of (overlays) the host-specific networks, allowing containers connected to it (including swarm service containers) to communicate securely when encryption is enabled.
									ㄴ ??? ~~~
								ㄴ ipvlan
									ㄴ ???IPv4, IPv6 addressing을 관리할 수 있게한다.
									ㄴ ~~~
								ㄴ macvlan
									ㄴ 컨테이너의 MAC address를 할당할 수 있게한다.
									ㄴ ~~~
								ㄴ none
									ㄴ 컨테이너의 네트워크를 diable한다.
									ㄴ swarm service에선 사용불가.
								ㄴ 그 외 plugin
									ㄴ third-party 네트워크 플러그인을 설치하여 사용 가능.
									ㄴ Docker Hub나 third-party vendor들로부터 받을 수 있다.

						ㄴ port publish
							ㄴ 도커 컨테이너의 특정 포트를 외부로 노출시켜(publish) 접근할 수 있도록 하는 것.
							ㄴ ??? --publish(= -p) 플래그 사용.
						ㄴ CLI > docker run 네트워크 관련 옵션
							ㄴ --network 옵션
								ㄴ ex ) docker run --network="bridge" ~~~
								ㄴ 인자값
									ㄴ "bridge"
										ㄴ 디폴트값.
										ㄴ
									ㄴ "host"
										ㄴ 컨테이너가 호스트의 네트워크 스택을 사용.
									ㄴ "container:(*컨테이너 이름 또는 id*)"
										ㄴ 컨테이너가 다른 컨테이너의 네트워크 스택을 사용.
									ㄴ "(*user 생성 docker network명*)"
										ㄴ 'docker network create' 를 통해 생성한 사용자 생성 네트워크를 사용.
									ㄴ "none" : 컨테이너 네트워크가 disable.

							ㄴ --dns
								ㄴ 컨테이너의 dns서버는 디폴트로 호스트와 동일.
								ㄴ 이 옵션으로 컨테이너 dns서버 지정 가능.
							ㄴ --mac-address
								ㄴ 컨테이너 mac address 지정 가능.
						ㄴ ??? docker proxy server 설정
							ㄴ ~~~
						ㄴ ~~~





					ㄴ mount 방식 유형
						ㄴ bind mount
							ㄴ host machine의 파일 또는 폴더를 직접 사용하는 것.
						ㄴ named volume
							ㄴ 도커에 의해 생성되고 관리되며, host machine, 다른 container 사이에서 공유될 수 있다.
						ㄴ tmpfs
							ㄴ ~~~
						ㄴ named pipe
							ㄴ ~~~

					ㄴ Docker Compose
						ㄴ multi-container 도커 어플을 정의 및 실행해주는 도구.
						ㄴ YAML 파일로 관련 설정들을하고, 이를 실행하는 방식으로 동작.
						ㄴ 3가지 단계로 사용 절차 구성
							ㄴ 'Dockerfile' 정의.
							ㄴ 'docker-compose.yml'에 어플을 구성할 서비스들 정의.
							ㄴ docker compose 실행.
						ㄴ docker-compose.yml
							ㄴ ex )
								version: "3.9"  # optional since v1.27.0
								services:
								web:  # 실행할 컨테이너를 지칭. 임의 명칭?
									build: .  # 이 위치에서 빌드하여 이미지로 사용할 것.
									ports:  # 포트 바인드.
									- "8000:5000"
									volumes:
									- .:/code
									- logvolume01:/var/log
									depends_on:
									- redis
								redis:
									image: redis  # 'redis'란 이미지 사용. hub에서 가져올 수도 있다.
								volumes:
								logvolume01: {}

					ㄴ Docker CLI
						ㄴ run
							ㄴ ~~~
							ㄴ option
								ㄴ --add-host
									ㄴ
								ㄴ --network
									ㄴ ex ) docker run --network=my-net (*container name*)
						ㄴ ~~~

					ㄴ Orchestration
						ㄴ ???도커 컨테이너처럼 '컨테이너화된 어플리케이션'을 관리(배포, 스케일링, 유지보수 등)하는 도구를 의미.
						ㄴ ex ) Kubernetes, Docker Swarm

			</pre>

		</pre>

		ㅇ email (메일, Electronic mail) <button></button>
		<pre>
			ㄴ ??? 전기 장치를 사용하는 사람들 사이의 메세지(mail) 교환 방법?
				ㄴ 물리적인 mail만 존재하던 때에 이에 상응하는 전기적 mail이라 하여 붙여진 이름?
			ㄴ ??? email 시스템은 보통 'store-and-forward' 모델을 따른다?
			ㄴ FQDA
				ㄴ email 주소를 나타내는 문자열.
				ㄴ ex ) localpart@mailhost.example.com
				ㄴ @ 앞부분 : local part. 보통 username.
				ㄴ @ 뒷부분 : 메일의 호스트, 도메인명.
			ㄴ MX record
				ㄴ ??? 도메인명을 대신하여 이메일을 받을 메일 서버를 명시하는 record?
					ㄴ ex ) 대략적 형식
						Domain			TTL   Class    Type  Priority      Host
						example.com.		1936	IN	MX	10         onemail.example.com.
						example.com.		1936	IN	MX	10         twomail.example.com.
				ㄴ ??? DNS 내부에 있는 데이터?
					ㄴ 도메인명과 메일서버 도메인명이 우선순위 값과 함께 매핑되어 있다.
					ㄴ MTA가 DNS에게 이메일 수령 주소의 도메인명에 대한 MX records를 요청하면
						DNS는 MX records에서 이와 매핑되어 있는 메일서버 도메인명 목록을 반환해준다.
					ㄴ MTA는 이 메일서버의 호스트명으로 SMTP 연결을 진행한다?
			ㄴ 전송 흐름 
				<img src="image/email_transfer.png"/>
				<img src="image/email_transfer2.png"/>
				ㄴ 대략, 
					end user -> MUA -> MSA -> MTA -> MTA -> ... -> MTA -> MDA -> MUA -> end user 
			ㄴ mailbox 
				ㄴ ??? 이메일이 최종적으로 전달되야할 목적지를 개념적으로 지칭하는말? 
					ㄴ 꼭 파일 스토리지에 메일을 저장하는 곳을 의미하지는 않는다함. 
					ㄴ 근데 그냥 메일이 저장되는 스토리지라고 생각하는게 이해하기 편할듯. 
				ㄴ 보통 이메일 주소에 따라 유일하게 식별되나 아닌 경우도 있다함. 
				ㄴ 스토리지 
					ㄴ 실제 메일이 저장되는 곳이 어디가 돼야하는지 정해진건 없다함. 
						단지 많이 사용되는 방식이 있다함. 
					ㄴ 저장방식 
						ㄴ mbox 
							ㄴ 모든 메세지를 하나의 파일에 저장하는 방식. 
							ㄴ 모든 메세지 내용이 plain str형태로 concatenated되어 저장됨. 
								각 메세지는 'From'뒤에 한칸 공백을 두는 것으로 시작하는식 
							ㄴ ~~~ 
						ㄴ Maildir 
							ㄴ ??? 메세지들이 유일한 이름의 파일로서 저장되고, 이메일마다 폴더가 생겨 그 안에 이 메일파일들이 저장되는 방식. 
							ㄴ ~~~  
			ㄴ MUA (mail user agent, email client, email reader) 
				ㄴ end user가 이메일을 읽고, 쓰고, 관리할 수 있게 해주는 컴포넌트를 의미. 
				ㄴ ex ) Outlook, apple mail, gmail 등, 관련 기능을 하는 웹페이지, 데스크탑 프로그램, 하드웨어 등. 
				ㄴ 메일 access  
					ㄴ MTA, MDA 등과 상호작용하여 유저의 mailbox에 있는 메일들을 가져옴. 
						ㄴ 일반적으로 유저의 mailbox는 remote에 있음. 
						ㄴ 이 때, POP, IMAP 등의 프로토콜이 사용됨. 이 프로토콜 방식에 따라 메일들을 가져오는 것. 
				ㄴ 메일 전송 
					ㄴ 메일 전송 기능도 당연 있고, MUA가 MTA, MDA 등과 통신하여 알아서 메일을 보내는 식. 
			ㄴ MSA (mail submission agent)
				ㄴ 이메일 전달하는 애? MUA로부터 메세지를 받아 MTA와 상호작용하는 프로그램 또는 에이전트.
				ㄴ ??? SMTP의 변형인 ESMTP 프로토콜 사용?
				ㄴ 많은 경우, MTA가 MSA의 역할도 수행한다함. 당연히, MSA로서의 기능만 수행하는 프로그램도 있음. 
				ㄴ 역사적으로는 MSA, MTA 모두 port 25를 사용하나, MSA의 공식적 port는 587.
			ㄴ MDA (message delivery agent) 
				ㄴ 메일을 MAT로부터 받아 로컬에 있는 수신인의 mailbox에 저장하는 소프트웨어. 
				ㄴ ex ) maildrop 
			ㄴ MTA (Message transfer agent, mail transfer agent, mail relay)
				ㄴ SMTP 프로토콜을 사용하여 한 컴퓨터에서 다른 컴퓨터로 메일을 전달하는 소프트웨어. 
				ㄴ ex ) sendmail, Postfix, EXim  
				ㄴ 문맥에 따라 mail server, mail exchanger, MX host 라고도 불린다.
				ㄴ MTA 또는 MSA 또는 MUA로부터 메일을 받는다.
				ㄴ ??? 이메일 수신시마다, 메세지 헤더 top에 'Received' trace header 필드를 추가하여, MTA들의 처리 기록을 만든다?
				ㄴ 메세지를 수신할 mailbox가 local에 없으면, 메세지는 다른 MTA로 전달된다(relayed)
					ㄴ ??? 즉, 메일이 해당 로컬에 대한 메일이 아니면 다른 MTA로 전달된다? 
				ㄴ 로컬이 수신자라면 MTA는 메일을 MDA로 전달하고 MDA가 메일을 mail box에 넣는다? 
					ㄴ ??? 이 과정에서 메세지 헤더에 'Return-Path' 값이 설정된다? 
				ㄴ 다른 MTA로 전달될 때마다, 메일의 헤더에 trace 기록이 남는다함. 
				ㄴ 다음 MTA가 결정되는 방식은 SMTP 프로토콜에 정의되어 있다함. 
					ㄴ 변경도 가능하다함. 
				ㄴ 메세지를 MDA에게 전달.
				ㄴ relay server, filtering server는 이메일을 간략하게 저장하나, 다른 경우, mailbox를 두어 이메일 전체를 저장하며,
					이 경우, end user가 MUA나 email client를 통해 이메일에 접근할 수단을 지원한다.
					ㄴ POP3, IMAP, proprietary system(MAPI 등).
				ㄴ 이메일에 대한 user의 접근은 보통 webmail이나 email client에 의해 이루어진다.
				ㄴ ??? mail client에 의한 새 이메일 전송은 SMTP, port 587이나 465을 통해 이루어지나,
					현재는 사용자가 ISP와 같은 계정을 가진 경우로 제한되는 경향이 있다.
					일종의 정책이며, 사용자가 스팸이나 이메일 남용하는 것에 대한 책임을 묻기 위함이라 한다.
				ㄴ 유형 
					ㄴ??? client-based MTA 
						ㄴ email에 접근하기 위해 별도 소프트웨어를 설치해야 하는 경우. 
						ㄴ ex ) Outlook, Thunderbird
					ㄴ ???web-based MTA 
						ㄴ email에 접근하기 위해 웹 브라우저를 사용하는 경우.
						ㄴ ex ) Gmail, Yahoo! Mail
				ㄴ MTA 비교 
					ㄴ 
				ㄴ MTA 목록 
					ㄴ Postfix <button>more</button>
					<pre>
						ㄴ 3.5 기준. 
						ㄴ 개요 
							ㄴ  
						ㄴ ??? 대략적 동작 방식? 
							ㄴ 여러 데몬들로 구성. 
							ㄴ 처음 메일을 받는건 smtpd, qmqpd, sendmail. 
							ㄴ 이곳들로부터 메일을 받아, cleanup 수행 후, queue(qmgr)에 저장. 
							ㄴ 큐에서 active queue는 전송 대기중인 메일들 큐. 
							ㄴ 전송 실패시, 메일은 deferred queue에 들가고, 일정시간 후 다시 active queue로 전달되어 재전송되게됨.  
						ㄴ 기본 사용법 
							ㄴ rock linux 환경 
								ㄴ postfix 설치 
								ㄴ systemctl start postfix 
								ㄴ postfix가 시작하며 postfix의 프로세스들이 실행. 
								ㄴ postfix서버로 메일 요청 전송시 postfix가 이를 처리하여 메일 전송. 
									ㄴ ex ) 
										mail -s "test title" tjrghfeel@kaimobile.com 
										test mail content 

										ctrl+D 입력. 

										목적지 이메일의 수신함에 메일 도착. 
										postfix가 디폴트 설정상태이면 아마 정크메일로 분류되어 있거나 아예 수신되지 않을 것. 
						ㄴ 아키텍쳐 
							<img src="image/POSTFIX_architecture.png"/> 
							ㄴ master 
								ㄴ postfix 메일 시스템의 총관리 서버. 
								ㄴ 시스템 부팅시 'postfix start' 명령어로 시작. 시스템 종료시까지 계속 실행 상태. 
								ㄴ postfix의 프로세스들을 실행시키고, 어떤 문제로 인해 조기종료된 경우 재실행시킴. 
								ㄴ ??? 서버 프로세스 개수를 제한함. master.cf에 설정된 대로. 
							ㄴ postdrop 
								ㄴ??? postfix의 mail posting 기능? 
								ㄴ ??? 'maildrop' directory에 파일을 생성하고, standard input을 그 파일로 복사함. 
							ㄴ cleanup 
								ㄴ ??? cleanup daemon process? postfix의 요소? 아님 리눅스 자체 요소? 
								ㄴ ??? 들어오는 메일을 처리 & 'incoming mail queue'에 삽입하고 이를 queue 매니저에게 알림? 
								ㄴ 처리 내역 
									ㄴ ??? 비어있는 메세지 헤더 삽입? 
									ㄴ ??? envelope와 헤더 주소를 '표준 형식'으로 변환? 
									ㄴ ~~~??? 
									ㄴ ???메세지 내용에 문제가 없는지 체크 & 있을시, cleanup client에게 알리고 알아서 처리하도록 맡기거나 반송시킴? 
							ㄴ pickup 
								ㄴ ??? pickup daemon process. 
								ㄴ ??? 'maildrop' directory에 새 메세지가 drop되는지 대기하고 있다가, 이를 'cleanup' daemon에게 넘김? 
								ㄴ ??? 형식이 잘못된 파일은 삭제됨? originator에게 알리는 것 없이? 
								ㄴ ??? 대용량의 메세지를 pickup 서비스를 통해 전송하지 않아야 한다? 
									ㄴ ??? High volume sites should avoid using "simple" content filters that re-inject scanned mail via Postfix sendmail(1) and postdrop(1).
							ㄴ sendmail 
								ㄴ??? postfix의 sendmail 호환 인터페이스? 즉, postfix에서 sendmail 사용을 위한 인터페이스인듯? 
									ㄴ 호환성을 위해, 일부 sendmail의 옵션은 무시될 수 있다?  
								ㄴ ??? standard input으로부터 EOF나 '.'문자로만 이루어진 줄을 만날때까지 메세지를 읽어들여 배열함? 
								ㄴ ??? postdrop을 이용하여 'maildrop' directory에 queue파일을 생성? 
							ㄴ qmqr (postfix queue manager)
								ㄴ??? 메일 전달 agent 스케줄러? 
								ㄴ 제한된 리소스 하에서, 메일이 잘 전달되도록함? 
								ㄴ 새 메일이 들어오기를 대기. 새 메일이 postfix delivery process를 통해 전달될 수 있도록 준비. 
								ㄴ ??? 메일 라우팅 전략은 'trivial-rewrite' 데몬에게 위임? 
								ㄴ smtp, lmtp, local, virtual, pipe, discard, error delivery agent에 연결하여 delivery 요청을 전달. 
									ㄴ discard, error delivery agent는 모든 메일을 버리거나 반송시킴. 
								ㄴ ~~~??? 
							ㄴ postfix queue 
								ㄴ maildrop queue 
									ㄴ sendmail을 통해 보내졌으나, 아직 pickup에 의해 메인큐로 이동되지 않은 메세지들이 대기하는 큐. 
									ㄴ postfix가 실행중이 아니어도 이곳에 메세지들이 추가될 수 있음. postfix가 시작되면 알아서 처리되기 시작함. 
									ㄴ single threaded인 pickup 서비스가 이 큐에서 데이터를 가져가며, 
										pickup 서비스가 주기적으로 이 큐를 스캔하거나, postdrop이 새 메세지가 있음을 알릴때 가져감. 
									ㄴ ??? The rate at which the pickup(8) service can inject messages into the queue is largely determined by disk access times, since the cleanup(8) service must commit the message to stable storage before returning success. The same is true of the postdrop(1) program writing the message to the "maildrop" directory.
										ㄴ ??? cleanup 서비스가 결과를 반환하기 전에 메세지를 다른 안정적인 저장소에 저장해야 하기 때문에, 
											pickup 서비스가 메세지를 이동시키는 속도는 대부분 디스크 접근 시간에 의해 결정된다.??? 
									ㄴ ??? pickup 서비스가 싱글스레드이기 때문에, 한번에 하나의 메세지만 이동시킬 수 있으며, 
										그 속도는 cleanup 서비스의 ???  reciprocal disk I/O latency를 넘지 못함? 왜? 
									ㄴ 이 큐에서 막힘이 생기는 경우, 
										ㄴ 과하게 많이 쌓인 로컬 메세지 전송
										ㄴ 또는 cleanup 서비스의 body 체크 단계에서의 과한 cpu사용량이 원인일 수 있다. 
										ㄴ 또는 'active queue'가 꽉차서 cleanup 서비스가 메세지 삽입을 메세지마다 일정시간 지연시키는 경우. 
									ㄴ 로컬에서 전송된 메일의 비율이 많은 경우, 
										캐치못한 전송 루프가 돌고 있을 수 있다함. 
									ㄴ ??? 'postsuper -r'명령어 사용시, 선택된 특정 메세지들을 'maildrop queue'로 넣어 다시 처리되도록 할 수 있다. 
										ㄴ ??? This is most useful for resetting any stale content_filter settings.
										ㄴ 많은 메세지를 다시 넣는 경우, 당연히 큐의 사이즈가 급격히 커짐. 
								ㄴ hold queue 
									ㄴ ~~~???
								ㄴ incoming queue
									ㄴ ??? postfix 큐에 들어오는 모든 메일들은 cleanup 서비스에 의해 'incoming queue'에 저장된다. 
									ㄴ cleanup 서버는 처리완료한 메일을 파일 형태로 이 큐에 저장하며, 
										모든 큐 파일은 'postfix' 유저 소유의 600 권한으로 생성됨. 
									ㄴ??? 큐 파일이 추가적인 처리를 위한 준비가 되면, cleanup 서비스가 이 큐파일의 mode를 700으로 수정하고 
										queue manager에게 새 메일이 있음을 알림? 
									ㄴ queue manager는 mode가 600인 파일은 불완전파일로 인지하고 무시. 
									ㄴ ???'active queue' 리소스 제한이 초과된 상태가 아니라면, queue manager는 incoming queue를 스캔하고 
										메일을 'active queue'로 이동시킴. 
										ㄴ 디폴트로, active queue는 최대 20000개의 메세지 수용 가능. 
										ㄴ active 큐의 제한에 도달시, queue manager는 incoming queue를 스캔하지 않음. 
									ㄴ ??? 보통의 상태에서 incoming 큐는 거의 비어있음. ?mode 600인 파일만 가지고 있음? 
										큐 매니저가 파일들이 이용가능해지자마자 active큐로 보낼 수 있는 상태. 
									ㄴ ??? incoming 큐는 큐 매니저가 메세지를 active큐로 보낼 수 있는 속도 이상으로 메세지가 들어올 때 쌓이기 시작. 
										ㄴ 큐 매니저의 이 속도 저하의 원인은 
											disk I/O 속도 또는 ?'trivial-rewrite service에 대한 lookup 쿼리'?
										ㄴ ??? 큐 매니저의 성능이 원인이면 다음을 고려해라?
											consider not using "slow" lookup services (MySQL, LDAP, ...) for transport lookups or speeding up the hosts that provide the lookup service. 
										ㄴ 디스크 I/O가 원인이면 다음을 고려ㅕ하라? 
											???  consider striping the queue over more disks, faster controllers with a battery write cache, or other hardware improvements.
										ㄴ ??? At the very least, make sure that the queue directory is mounted with the "noatime" option if applicable to the underlying filesystem.
										ㄴ in_flow_delay 설정값 
											ㄴ 큐 매니저의 속도가 뒤져지기 시작할 때 메세지 유입 속도 제어를 위해 사용. 
											ㄴ??? cleanup 서비스가 새 큐파일 생성 전에 설정값만큼의 second를 일시정지. 
										ㄴ ??? Since the number of cleanup(8) processes is limited in most cases by the SMTP server concurrency, the input rate can exceed the output rate by at most "SMTP connection count" / $in_flow_delay messages per second.
											With a default process limit of 100, and an in_flow_delay of 1s, the coupling is strong enough to limit a single run-away injector to 1 message per second, but is not strong enough to deflect an excessive input rate from many sources at the same time.
											If a server is being hammered from multiple directions, consider raising the in_flow_delay to 10 seconds, but only if the "incoming" queue is growing even while the "active" queue is not full and the trivial-rewrite service is using a fast transport lookup mechanism.
								ㄴ active queue 
									ㄴ ??? os의 process run queue와 유사? 
									ㄴ 전송되기를 기다리고 있는 메세지들이 들어있음. 
										꼭, 전송중인 상태일 필요는 없음. 
									ㄴ ??? 디스크상의 디렉토리가 아닌, 큐ㅠ 매니저 프로세스의 메모리 내의 데이터 구조체 집합이다? 
										ㄴ maildrop, hold, incoming, deferred queue는 디스크상에 저장되고 메모리 차지 안함. 
										ㄴ??? active queue내의 메세지의 'envelope'정보는 메모리상에서 관리된다?  
											이를 통해 큐매니저가 global 스케줄링을 할 수 있고, 
											delivery agent process를 active 큐 내의 적절한 메세지에 할당할 수 있다? 
									ㄴ??? active 큐 내에서, '다중 수신'메세지는 여러 recipient 그룹으로 나뉨? 
										같은 transport/nexthop combination을 공유하는 것들끼리? 
										ㄴ ???  the group size is capped by the transport's recipient concurrency limit.
										ㄴ ??? Multiple recipient groups (from one or more messages) are queued for delivery grouped by transport/nexthop combination. The destination concurrency limit for the transports caps the number of simultaneous delivery attempts for each nexthop. Transports with a recipient concurrency limit of 1 are special: these are grouped by the actual recipient address rather than the nexthop, yielding per-recipient concurrency limits rather than per-domain concurrency limits. Per-recipient limits are appropriate when performing final delivery to mailboxes rather than when relaying to a remote server.

										Congestion occurs in the "active" queue when one or more destinations drain slower than the corresponding message input rate.
									ㄴ active queue의 인풋은 incoming queue에서 온 새 메일과 deferred queue에서 온 retry 메일. 
									ㄴ 목적지가 다운된 경우, 큐 매니저는 목적지에 마크를 하고, 해당 목적지로 가는 모든 메일들을 연기시키고 
										delivery agent에 할당하지 않음. 
										메세지들은 active queue에서 deferred queue로 이동됨. 
									ㄴ 목적지가 단순히 느리거나 ??? excessive arrival rate를 유발하는 문제가 있는 경우? 
										active 큐는 해당 목적지로 가는 메일들로 쌓이게됨. 
										ㄴ 이런 경우, input을 줄이거나 throughput을 늘려야함. 
											ㄴ??? throughput은 concurrency를 늘리거나 delivery의 지연율을 줄여서 가능. 
										ㄴ 규모가 큰 사이트의 경우, 이를 위한 핵심 설정값은 ??? smtp, relay transports에 할당된 
											'smtp delivery agent'의 개수이다. 
											규모가 큰 경우, 많은 목적지로 전송을 할것이고, 많은 목적지들 중엔 분명 느린 목적지도 많이 존재할 것. 
											따라서 delivery agent의 많은 비율이 이 느린 목적지 때문에 블락상태일 것. 
											??? 또한 ?global 목적지인 메일들은 응답 지연율이 높을 것. 
											하여 메세지 throughput을 높이는 유일한 방법은 동시에 실행되는 delivery agent의 개수를 늘리는 것이다. 
									ㄴ ~~~???

								ㄴ deferred queue 
									ㄴ ??? When all the deliverable recipients for a message are delivered, 
										일부 recipient delivery에 대해서 과사용 관련 이유로 전송이 실패한 메세지가 들어가는 큐. 
									ㄴ 큐 매니저는 주기적으로 이 큐를 스캔. 
										ㄴ 스캔 주기는 'queue_run_delay' 설정값으로 설정. 
										ㄴ deferred 큐 스캔 중인데, incoming 큐에 대한 스캔도 진행중인 경우, 
											큐 매니저는 이 두 큐를 번갈하가며 스캔한다함. (??? round-robin 전략?)
											???이를 통해 두 큐가 고갈되는것을 방지한다함? 
									ㄴ ??? cool-off time. 
										ㄴ 이 큐로 들어오는 큐 파일들에는 'cool-off' time이 할당됨. 
										ㄴ ??? 큐 파일의 수정시간을 미래시점으로 설정하는 것에 의해 이루어짐. 
										ㄴ 큐 스캔시, 이 변경된 미래시점 수정시간에 도달하지 않은 큐파일들은 재시도의 대상이 아직 아님. 
										ㄴ 결과적으로, deferred 큐 스캔시마다, 큐에 있는 메세지들 중 일부만이 active큐로 돌아가 재시도됨. 
										ㄴ cool-off time은 'minimal_backoff_time', 'maximal_backoff_time' 설정값에 의해 결정. 
										ㄴ ???  The next retry time is set by doubling the message's age in the queue, and adjusting up or down to lie within the limits.
											ㄴ 즉, 새로운 메세지가 오래된 메세지보다 초기에 더 많이 재시도됨. 
									ㄴ ??? 크기가 매우 커야함? 매우 많을 수 있어서? 
										ㄴ 보통 10만~100만 메세지 수용 가능한 정도? 
										ㄴ ??? 근데 이 정도로 큰 대기열이 있는 경우, 새 메일을 더이상 받으면 안된다함. 
										ㄴ??? deferred 큐가 많이 차있는 경우가 많다면, 
											'queue_run_delay', 'minimal_backoff_time', 'maximal_backoff_time'를 설정하여 
											첫번째 실패시엔 더 짧은 텀의 재전송, 반복적인 실패시엔 더 긴 텀의 재전송이 되도ㅗㄺ하여 
											active 큐에 deferred큐의 메세지들이 많이 머무는 것을 방지할 수 있음. 
										ㄴ ???If you want a really low minimal_backoff_time, you may also want to lower queue_run_delay, but understand that more frequent scans will increase the demand for disk I/O.
										ㄴ deferred큐가 커지는 주된 이유는 
											??? SMTP input 단계에서 recipient의 유효성 검증 실패 때ㅜㅁㄴ? 
									ㄴ ~~~??? 
						ㄴ 동작 흐름 
							ㄴ 메일 받기 
								ㄴ 네트워크를 통해 들어온 메일은 'smtpd', 'qmqpd' 서버를 통하여 Postfix로 들어옴. 
								ㄴ 이 서버들은 SMTP | QMQP 프로토콜의 캡슐화를 제거 후, 몇가지 검증 후, 데이터를 cleanup 서버로 전달. 
								ㄴ ??? smtpd 서버의 경우, 원치않는 메일 블락 가능. 
								ㄴ 로컬 전송의 경우, 위 postfix queue, command 설명부분 참고. 
								ㄴ ??? 'internal source'로부터 온 메일들은 바로 'cleanup'으로 전달? 
									ㄴ internal source들이란. 
										ㄴ mail that is forwarded by the local(8) delivery agent (see next section), messages that are returned to the sender by the bounce(8) server (see second-next section), and postmaster notifications about problems with Postfix.
						ㄴ 설정 
							ㄴ 디폴트 설정 파일 위치 ) /etc/postfix 
							ㄴ 주요 파일 ) 
								ㄴ main.cf, master.cf 
									ㄴ??? 이 파일들은 root가 소유해야하며, 이 파일들에 대해 또는 부모디렉토리에 대해 다른이에게 write권한을 주면 안된다함. 
										write권한을 주는 경우, root권한을 주는것과 동일하다함. 
								ㄴ main.cf 
									ㄴ ~~~ 
									ㄴ 설정값 목록 
										ㄴ??? myorigin 
											ㄴ 로컬상에서 발송된 메일에 표시될될 '보낸이'의 도메인명? 
												즉, 로컬상에서 메일주고받을 때, 메일 보낸이의 도메인명을 설정하는 것? 
												ㄴ ex ) 
													이 설정값이 'mail.stockcosmos.kr' 이면, 
													보낸 메일의 발신인이 '(*username*)@mail.stockcosmos.kr'로 표시됨. 
											ㄴ 디폴트 ) $myhostname 
											ㄴ ??? If you run a domain with multiple machines, you should (1) change this to $mydomain and (2) set up a domain-wide alias database that aliases each user to user@that.users.mailhost.
										ㄴ myhostname 
											ㄴ 메일시스템의 hostname 설정. 
											ㄴ ??? hostname이란 한 네트워크 내에서 구분되는 컴퓨터 이름 같은 것? 
											ㄴ ex ) 
												대략 (*hostname*).(*domain*) 형식? 
												localhost.stockcosmos.kr 
											ㄴ 디폴트 ) 
												??? gethostname()로부터 얻은 'fully-qualified domain name(FQDN)' 또는 
												gethostname()으로부터 얻은 non-FQDN 에다가 '.(*mydomain설정값*)'을 추가한 값. 
										ㄴ mydomain 
											ㄴ 메일시스템의 도메인 이름. 
											ㄴ ex ) stockcosmos.kr 
											ㄴ 디폴트 ) 
												'myhostname'설정값에서 첫번째 요소 제거한 값. 
												또는 'localdomain' (postfix 2.3 이상에서)
										ㄴ ???mydestination 
											ㄴ ??? 어떤 도메인을 다른머신으로 전달하는게 아닌 로컬로 전달할지 명시? 
												도착지가 이 도메인, hostname인 메일이 들어오면 로컬로 보낸다, 즉, 받아들인다? 
										ㄴ ???mynetworks 
											ㄴ postfix는 디폴트로, 인증된 네트워크 내의 클라이언트로부터 온 메일을 
												임의이ㅡ 목적지로 포워딩함. 
												이 '인증된' 네트워크가 어딘지 리스팅하여 결정하는 설정값. 
												ㄴ 'trusted'로 취급되는 remote SMTP client 목록. 
											ㄴ CIDR형태로 값 나열. 
											ㄴ 파일의 path로도 설정 가능. 
											ㄴ ex ) 
												mynetworks = 127.0.0.1/32 [::1]/128 
											ㄴ 디폴트 
												ㄴ 'mynetworks_style'설정값에 따라 설정됨. 
												ㄴ mynetworks_sylte = host 
													ㄴ 로컬머신으로부터 온 메일만 전달. 
												ㄴ mynetworks_style = subnet 
													ㄴ 로컬머신과 같은 IP subnetwork 내의 SMTP 클라이언트로부터 온 메일만 전달. 
												ㄴ mynetworks_style = class
													ㄴ??? 로컬 머신과 같은 IP class A/B/C 네트워크내의 SMTP 클라이언트로부터 온 메일만 전달. 
												ㄴ 로컬 머신 
												ㄴ??? 3.0부터, 로컬 머신이 속한 IP subnetwork 내의 모든 클라이언트
											ㄴ??? 인증된 네트워크에 속하지 않지만 'mobile' 클라이언트가 보낸 메일을 전달도 가능하다함
												ㄴ 참고 
													ㄴ https://www.postfix.org/TLS_README.html
													ㄴ https://www.postfix.org/SASL_README.html
											ㄴ ??? 머신이 wide area netword에 연결되어 있다면, 
												'mynetworks_style'설정값을 'subnet'으로 설정하는게 좋다함.  
											ㄴ 이 목록의 클라이언트에서 온 메일은 postfix를 통해 ?relay?될 수 있다? 
											ㄴ network address 또는 netmask pattern 목록을 값으로 설정.  
											ㄴ ~~~???
										ㄴ relay_domains 
											ㄴ ??? 메일을 relay할 인증된 도메인 목록? 
										ㄴ smtpd_milters 
											ㄴ 
										ㄴ ???default_destination_recipient_limit 
											ㄴ ??? 한 메세지에 포함된 recipient의 최대 수? 
												이를 초과하면 메세지가 나뉘어 전송? 
												'To' 헤더에 컴마구분으로 여러 이메일 넣는거 말하는건가? 
										ㄴ ???default_destination_rate_delay 
											ㄴ ??? 동일한 메세지 전송방식으로 동일한 목적지에 메세지 전달할 때, 전송 사이사이에 들어가는 
												일종의 대기 텀. ? 
											ㄴ ex ) 값을 10s로 주면, noname@gmail.com 에 대한 메일발송이 연속으로 10개 있을 시, 
												이를 10초 간격으로 보냄. 하나 전송하고 10초 후 다시 하나 전송 이런식. 
											ㄴ ??? 한 메일에 수신인 여러명으로 하여 보낸건 텀 적용 안되나? 
										ㄴ ???default_destination_concurrency_limit 
										ㄴ ???initial_destination_concurrency 
										ㄴ ???smtp_destination_concurrency_limit 
										ㄴ ???smtp_extra_recipient_limit 
										ㄴ ~~~

							ㄴ 모든 파라미터 디폴트 값 가짐. 꽤 적절한 값들이라함. 
							ㄴ 일부 파라미터들은 주요한 몇가지 파라미터들의 값으로부터 유래되어 설정됨. 
							ㄴ 설정파일 업데이트 후, root권한으로 postfix reload 명령어 필요. 변경사항 반영. 
							ㄴ ??? 두가지를 제외하고 postfix의 설정 파라미터는 'shell 변수'와 비슷하다? 
								ㄴ 차이점 두가지 
									ㄴ ???unix shell처럼 quotes를 지원하지 않음? 
									ㄴ ???설정파일 상에서, '$'뒤에 변수명을 사용하여 변수 사용가능한데, 이 변수에 값할당 전에도 변수 사용이 가능하다함. 
										설정값이 lazy evaluation이라 런타임시에 변수가 필요해지는 순간까지 평가가 이루어지지 않는다함? 
										ㄴ ex ) 
											parameter = value 
											parameter2 = $parameter 
							ㄴ ???'database file'? 
								ㄴ postfix는 database file을 사용? 
							ㄴ??? postfix에선 인증된 network의 클라이언트가 보낸 메일만 임의의 destination에 보낼 수 있음. 
							ㄴ??? postfix에선, 인증된 network 이외의 클라이언트에서 보낸 메일은 인증된 destination으로만 보낼 수 있음? 
							ㄴ ~~~ 
							ㄴ 추가 설정 
								ㄴ https://www.postfix.org/STANDARD_CONFIGURATION_README.html
						ㄴ 디버깅 
							ㄴ 방법 목록 
								ㄴ 기본 시스템 로그. 
									ㄴ /var/log/maillog, /var/log/mail 등에 디폴트로 생기는 로그 확인. 
									ㄴ??? 별도의 고유 로그 시스템 사용하려면 'maillog_file' 설정값 이요 가능. 
										ㄴ ??? https://www.postfix.org/MAILLOG_README.html 참조. 
									ㄴ 로그 단계 분류. 
										ㄴ 이 로그들은 4가지 단계로 분류. 
										ㄴ panic 
										ㄴ fatal 
										ㄴ error
										ㄴ warning 
								ㄴ ??? mail delivery report 이용 
									ㄴ postfix 2.1 이상부터 디버깅용으로 mail delivery report 기능 제공. 
									ㄴ 여러가지 정보 제공. 
									ㄴ 두가지 모드 존재 
										ㄴ what-if 
											ㄴ 실제 메일을 보내진 않고, '어떤일이 일어났을지'에 대한 정보 제공. 
											ㄴ ??? 다음을 통해 가능? 
												sendmail -bv (*address*) ... 
										ㄴ what happened 
											ㄴ 메일을 실제로 보내며, 성공여부, remote SMTP서버로부터의 응답 등의 정보 제공. 
											ㄴ ??? 다음을 통해 가능? 
												sendmail -v (*address*) ...
									ㄴ??? report 내용은 sender에게 'mail'로서 전달된다? 
										ㄴ /var/spool/mail/(*user*) 에서 확인 가능? 
								ㄴ ??? Try turning off chroot operation in master.cf
								ㄴ ??? Verbose logging for specific SMTP connections
								ㄴ ~~~???

						ㄴ 성능 
							ㄴ 디스크 I/O에 달려있음. 
							ㄴ ??? 단, cleanup단계의 헤더, 본문에 대한 정규식 표현 검사에 CPU가 많이 사용되지 않는다면. 
						ㄴ 관련 명령어 
							ㄴ postconf 
								ㄴ postfix의 설정값을 보여주는 명령어. 
								ㄴ 기본적으로 main.cf 파일의 설정값 보여줌. 
								ㄴ 옵션 
									ㄴ -d 
										ㄴ 실제 설정값이 아닌, 디폴트 설정값 보여줌. 
						ㄴ 참고 
							ㄴ https://www.postfix.org/documentation.html
							ㄴ https://www.postfix.org/BASIC_CONFIGURATION_README.html
					</pre>

			ㄴ 기본적인 동작 방식 )
				ㄴ aaa@domain1.com 이 bbb@domain2.com에게 메일을 전송. 
				ㄴ SMTP 서버(outgoing mail server)는 이 이메일을 받음. 
				ㄴ SMTP 서버는 이메일을 어디로 보내야할지를 체크. 
					ㄴ SMTP서버는 도메인을 읽지 못하므로, IP주소 형태로 변환 필요. 
					ㄴ SMTP서버는 DNS서버에 연결하여 매핑되는 IP주소 확인. 
					ㄴ ??? 해당 도메인이 MX(mail exchange server)가 있는지 확인? 
						MX로 해당 도메인에 해당하는 메일 서버를 확인? 
				ㄴ SMTP 서버가 domain2의 메일서버와 연결되어 메일을 전송. 
				ㄴ domain2의 메일서버는 메일을 POP서버(또는 IMAP서버)로 전달.  


				ㄴ 1. MUA(mail user agent)가 메세지를 email format으로 구성,
						전송 프로토콜(SMTP)를 사용하여 로컬 MSA(mail submission agent)에게 메세지 전달. (smtp.a.org???)
				ㄴ 2. MSA가 SMTP 프로토콜에서 제공하는 목적지 address를 결정.(FQDA로)
				ㄴ 3. DNS 서버가 해당 도메인에 대한 MX records를 반환.
				ㄴ 4. ??? MSA가 메세지를 SMTP로 MDA로 전달. 중간에 MTA를 거칠 수도 있다?
				ㄴ 5. ??? MDA가 메세지를 받아 mailbox에 전달.
				ㄴ 6. ??? MUA가 POP3나 IMAP 프로토콜을 이용하여 메세지를 가져옴.
			ㄴ 기본적인 동작 방식은 위와 같으나, 이 외에도 이메일을 전달하는 다양한 변형 방식들이 존재.
				ㄴ ~~~
			
			ㄴ SMTP (Simple Mail Transfer Protocol)
				ㄴ 메일을 인터넷상으로 보내는데 사용되는 프로토콜. 

			ㄴ SMTP 서버 
				ㄴ ~~~ 
				ㄴ 보통 sendmail 프로그램 등을 이용하여 동작한다함. 
			ㄴ 관련 프로토콜 
				ㄴ POP, IMAP protocol 
					ㄴ 메일 서버로부터 이메일을 받아오는데 사용되는 프로토콜. 
					ㄴ POP 
						ㄴ 메일서버에 있는 모든 이메일을 로컬로 다운 & 메일서버상에서 삭제. 
						ㄴ 메일서버에서 로컬로의 단방향 흐름인셈. 
						ㄴ 한계 
							ㄴ??? 로컬과 관련하여 동작하기 때문에, 같은 메일서버에 대해 여러 디바이스에서 사용시, 
								디바이스 A에서 읽은 메일들이 디바이스B에서는 안읽힌 상태로 남아있다? 
								? 로컬로 다운 후 메일서버상에서 삭제하는데 왜 디바이스B에선 다운가능? 
					ㄴ IMAP, Internet Message Access Protocol 
						ㄴ 메일서버와 메일 클라이언트 사이의 양방향 통신이 가능하며, 
							양쪽의 메일들이 완전히 동기화됨. 
							메일을 메일서버로부터 다운받으며, 다운 후에도, 메일이 서버에 남아있음? 
			ㄴ 관련 표준 규약 
				ㄴ RFC 5322 (Internet Message Format, IMF)
					ㄴ 이메일의 메세지 형식에 대한 표준을 정의한 것. 
					ㄴ https://datatracker.ietf.org/doc/html/rfc5322
					ㄴ 필드가 'from', 'to', 'sender' 등이 있고, 각 필드들의 형식은 어떄야 하고 등. 
				ㄴ MIME (Multipurpose Internet Mail Extensions) 
					ㄴ 이메일의 메세지 형식에서 멀티미디어 콘텐츠와 ASCII 이외의 character set 문자를 포함시킬 수 있게 해주는 표준.  
						ㄴ 멀티미디어엔 오디오, 비디오, 이미지, application 등이 포함. 
					ㄴ RFC(requests for comments)에 명시되어 있다함. 
					ㄴ SMTP를 위해 만들어졌긴 하나 HTTP 등 다른 프로토콜에서도 많이 사용된다함. 
					ㄴ MIME의 header field 목록 
						ㄴ MIME-Version 
							ㄴ MIME의 버전을 명시. 
							ㄴ ex ) MIME-Version: 1.0 
							ㄴ 일반적으로 값은 1.0 으로 고정. 
							ㄴ 이 필드 존재시, 메세지가 MIME형태로 포메팅되었음을 나타낸다함. 
						ㄴ Content-Type <button>more</button>
						<pre>
							ㄴ 메세지 컨텐츠의 'media type'을 나타냄.
							ㄴ ex ) Content-Type: text/plain
							ㄴ 값 
								ㄴ 'type', 'subtype'으로 구성. 
								ㄴ 디폴트 ) 'text/plain' 
								ㄴ descrete 형 
									ㄴ text 
									ㄴ image 
									ㄴ audio 
									ㄴ application 
										ㄴ application/octet-stream 
											ㄴ 이진 파일을 나타냄.
								ㄴ composite 형 
									ㄴ multipart  
										ㄴ content가 여러 MIME 타입 또는 여러 컴포넌트로 분리되어 구성됨을 나타냄. 
											ㄴ ex ) text/plain과 applicatin/pdf 로 구성된 메세지 등. 
										ㄴ 이를 통해, 
											ㄴ text인 메세지 내용에 첨부파일을 추가하거나 
											ㄴ 내용에 원문을 첨부하여 답장하거나 등이 가능. 
											ㄴ 
										ㄴ boundary 
											ㄴ Content-Type이 multipart MIME 타입인 경우, Content-Type값 뒤에 붙는 값으로, 
												메세지 body의 시작과 끝, 그리고 multipart 컨텐츠의 각 part들 사이사이에 이 boundary값이 
												들어가서 part들을 구분짓는 역할. 
											ㄴ ex ) 
												MIME-Version: 1.0
												Content-Type: multipart/mixed; boundary=frontier

												This is a message with multiple parts in MIME format.
												--frontier  // body시작. 
												Content-Type: text/plain

												This is the body of the message.
												--frontier  // part 경계
												Content-Type: application/octet-stream
												Content-Transfer-Encoding: base64

												PGh0bWw+CiAgPGhlYWQ+CiAgPC9oZWFkPgogIDxib2R5PgogICAgPHA+VGhpcyBpcyB0aGUg
												Ym9keSBvZiB0aGUgbWVzc2FnZS48L3A+CiAgPC9ib2R5Pgo8L2h0bWw+Cg==
												--frontier--  // body 끝. 
										ㄴ 목록 
											ㄴ multipart/mixed 
											ㄴ multipart/digest 
											ㄴ multipart/form-data 
												ㄴ html의 form을 통해 보내진 데이터를 나타내기 위해 사용. 
											ㄴ multipart/byteranges 
											ㄴ multipart/alternative 
												ㄴ 각 part들이 같은 컨텐츠에 대한 다른 버전임을 나타내는 값. 
													같은 컨탠츠에 대한 text/plain, text/html 등. 
											ㄴ ~~~ 
									ㄴ Message 
								
								ㄴ 
						</pre>
						ㄴ Content-Disposition 
						ㄴ Content-Transfer-Encoding 
					ㄴ 팁 
						ㄴ 네이버, gmail등에서 메일보기 페이지에 '원문보기' 기능들 존재. 이걸로 보면 메일의 MIME 헤더 등에 대해 실 예를 볼 수 있다. 
					ㄴ 참고 
						ㄴ https://en.wikipedia.org/wiki/MIME
						ㄴ https://learn.microsoft.com/en-us/previous-versions/office/developer/exchange-server-2010/aa494204(v=exchg.140)

			ㄴ 이메일 보안 관련 <button>more</button>
			<pre>
				ㄴ SPF 
					ㄴ ??? DNS 관리자가, 해당 도메인으로 이메일을 보낼 수 있는 서버들의 목록을 사전에 명시해둠.
						이를 'SPF record'라고함? 
						어떤 메일서버가 이메일을 받았을 때, 이메일의 ??? 답신 주소를 확인하고, 이 주소가 
						SPF record에 명시된 서버들 중 하나인지 확인. 
					ㄴ 도메인 주인이 아닌 다른 사람이 이 도메인에서 보낸것처럼 메일을 전송하는 것을 방지? 
					ㄴ 설정 방법 
						ㄴ dns에 record 설정. 
							ㄴ DNS 관리자에 들어가서 record 추가.
								'TXT' 타입, host는 '@', value는 'v=spf1 mx ip4:xxx.xxx.xxx.xxx -all' 
				ㄴ DKIM, Domain Key Identified Mail 
					ㄴ 동작 
						ㄴ sender가 메일의 내용에 대해 해시값을 만듦 (DKIM Signature)
						ㄴ DKIM signature를 private key로 암호화. 
						ㄴ 암호화한 값을 메일의 header에 추가 후 전송. 
						ㄴ receiver는 메일을 받고, public key로 암호화된 값을 복호화하여 signature를 얻음.
							ㄴ ??? public key는 DNS에 등록되어 있음.? 
						ㄴ 메일의 내용에 대해 sender와 같은 방식으로 signature 생성. 
						ㄴ receiver쪽에서 만든 서명값과 메일의 서명값이 같은지 확인. 
						ㄴ 같다면, 이 메일은 '전송과정에서 변조되지 않았'으며, ???'메일의 서명을 만든게 실제 메일의 주인'임을 보장할 수 잇다? 
					ㄴ 발송 메일에 적용하는 방법 
						ㄴ openDKIM 이용 
							ㄴ DKIM 인증을 구현해주는 오픈소스. 
								ㄴ http://www.opendkim.org/docs.html
							ㄴ 설치 
								ㄴ dnf install opendkim opendkim-tools 
									ㄴ 안되면 dnf install epel-release 
									ㄴ 안되면 dnf install opendkim opendkim-tools --enablerepo=crb 
							ㄴ 디폴트 설정파일 /etc/opendkim.conf 수정
								
								Mode sv 
								
								KeyFile /etc/opendkim/keys/default.private 
								
								KeyTable /etc/opendkim/KeyTable 
								
								SigningTable refile:/etc/opendkim/SigningTable 
								
								ExternalIgnoreList refile:/etc/opendkim/TrustedHosts 
								
								InternalHosts refile:/etc/opendkim/TrustedHosts 

								## openDKIM이 이곳을 listen. 
								Socket inet:8891@localhost 

								## ex ) deepq.kr 
								Domain (*도메인명*)   

								RequireSafeKeys False 
							ㄴ SigningTable 수정 
								ㄴ /etc/opendkim/SigningTable에 다음줄 추가 
									*@(*도메인명*) (*DKIM selector명*)._domainkey.(*도메인명*) 
									ㄴ ex ) *@deepq.kr default._domainkey.deepq.kr 
									ㄴ 메일의 보낸이가 '*@(*도메인명*)'에 매칭되는 경우 '(*DKIM selector명*)._domainkey.(*도메인명*)' 키를 
										이용하여 서명을 진행하라는 의미. 
							ㄴ KeyTable 수정
								ㄴ /etc/opendkim/KeyTable에 다음줄 추가 
									(*DKIM selector명*)._domainkey.(*도메인명*) (*도메인명*):(*DKIM selector명*):/etc/opendkim/keys/default.private
									ㄴ ex ) default._domainkey.deepq.kr deepq.kr:default:/etc/opendkim/keys/default.private 
									ㄴ '(*DKIM selector명*)._domainkey.(*도메인명*)'에 대한 private key가 
										'/etc/opendkim/keys/default.private'에 있다는 의미.
							ㄴ TrustedHosts 수정 
								ㄴ /etc/opendkim/TrustedHosts에 다음줄 추가
									*.(*도메인명*) 
									ㄴ ex ) *.deepq.kr 
							ㄴ 키 생성 
								ㄴ ex ) opendkim-genkey -b 1024 -d (*도메인명*) -D /etc/opendkim/keys -s (*DKIM selector명*) -v 
								ㄴ opendkim 의 키 생성명령어로 키 생성. 
								ㄴ keys폴더와 키 파일들의 소유자를 opendkim으로 변경 
									ㄴ chown opendkim:opendkim /etc/opendkim/keys -R 
							ㄴ public 키를 DNS에 등록 
								ㄴ 생성된 키파일 중, .txt 파일이 public key. 
								ㄴ 이 내용을 쌍따옴표와 공백을 제거하여 DNS record에 등록. 
								ㄴ 형식 
									TXT (*DKIM selector명*)._domainkey (*public key 내용*)
									ㄴ ex ) TXT default._domainkey "v=DKIM1; k=rsa; p=(*public key 내용*)"
							ㄴ postfix에 연결 
								ㄴ postfix의 main.cf 설정파일에서 다음 설정 
									# postfix가 openDKIM에 연결하기 위해 이 위치에 연결 시도. 
									smtpd_milters = inet:127.0.0.1:891 
									non_smtpd_milters = $smtpd_milters 
									milter_default_action = accept 
								ㄴ postfix, opendkim 재시작 
									ㄴ systemctl restart postfix 
									ㄴ systemctl restart opendkim
							ㄴ 정상 동작 확인 
								ㄴ DKIM을 위한 DNS record 정상 등록 확인 
									ㄴ https://easydmarc.com/tools/dkim-lookup 
								ㄴ 메일을 통한 확인 
									ㄴ gmail 등에 실제 메일이 들어오는지, 
									ㄴ 메일 '원문보기'에서 DKIM 관련 헤더가 존재하는지. 
										ㄴ Authentication-Results 값에 'dkim=pass' 등. 
								ㄴ 전문 사이트 
									ㄴ https://www.mail-tester.com/
										ㄴ 진입시 뜨는 주소로 이메일 발송하고 체크시, 여러가지 상태 알려줌. 
										ㄴ 블랙리스트 여부, SPF, DKIM, DMARC 설정 여부 등. 
										ㄴ 하루 3회 무료. 
  
							ㄴ 참고 
								ㄴ https://easydmarc.com/blog/how-to-configure-dkim-opendkim-with-postfix/
								ㄴ https://jhansol.tistory.com/190
								ㄴ https://www.linuxbabe.com/mail-server/setting-up-dkim-and-spf
				ㄴ DMARC 
					ㄴ ??? 위의 검증을 실패한 메일들을 어떻게 처리할지 설정하는 전략? 
						3가지 옵션. 
						ㄴ none 
							ㄴ 그냥 일반 메일처럼 처리가 진행되도록함. 
							ㄴ 메일을 조사하길 원하는 관리자 서버 등에 필요? 
						ㄴ quarantine 
							ㄴ 메일이 특정 safe존에 들어가도록함. 유저는 접근 못하고 관리자만 접근 가능한 위치같이. 
							ㄴ 역시 관리자용? 
						ㄴ drop 
							ㄴ 메일을 그냥 버림. 
							ㄴ 많은 상용 메일서버용? gmail 등. 
			</pre>
			ㄴ 메일 서버 구현 
				ㄴ 유의 
					ㄴ 일단 세팅이 간단치 않음. 
					ㄴ 해킹 등으로 인해 메일서버 ip가 블랙리스트에 올라가면 당연히 전송이 안되며, 해제하기 매우 까다롭다함. 
					ㄴ 수신 기능 구현시, 스팸 등에 대한 필터링 기능도 구현 필요. 
					ㄴ 주요 메일 서버들로부터 블락 이슈 
						ㄴ 당연히, 자체 메일서버에서 메일을 전송하더라도 gmail등에서 블락이나 스팸처리해버리면 제대로 전송되지 않음. 
						ㄴ 주요 메일 서버들이 블락하는 기준은 당연히 고정적으로 정해진게 아니고 서버마다 조금씩 다름. 
						ㄴ 최대한 유의하는 수 밖에? 경험적 데이터에 의존하고. 
						ㄴ 팁 
							ㄴ 같은 메일서버로의 전송은 전송간 약간의 딜레이를 둔다? 
							ㄴ 수신자가 해당 메일을 스팸으로 처리하지 않도록, 
								이메일 수신을 허용한 사람에게만 메일을 전송한다. 또한 언제든 이메일 수신 구독을 취소 가능하게. 
								ㄴ 스팸처리된 경우 많을 수록 블락 확률 높아짐? 
							ㄴ 전송 메일서버에서 전송 결과에 대해 모니터링. 

			ㄴ 참고 
				ㄴ https://steemit.com/steemstem/@rebelheart/how-does-email-work-an-in-depth-look-at-the-workings-of-email
				ㄴ https://computer.howstuffworks.com/e-mail-messaging/email.htm


		</pre>

	</pre>

	<br>front-end<button>더보기</button>
	<pre>
		html<button>더보기</button> 
		<pre>
			ㅇ HTML이란?<button>더보기</button>
			<pre>
				ㅡ 그냥 일반 텍스트 문서인데, '요소(태그)'라는걸로 구조화된 텍스트 문서이다.
			</pre>
			ㅇ 한글 인코딩
				ㅡ 브라우저는 html문서를 화면에 나타낼때 기존에 설정된 글자셋을 가지고 문서를 읽는다.
				ㅡ 해서 기존에 설전된 글자셋이 문서의 내용과 맞지않으면 글자가 깨지게되며,
				ㅡ 이를 해결하기위해 html문서의 < head>아래에 < meat>태그를 이용해 charset을 설정해준다.
				ㅡ ex)	< head>
							< meta charset="UTF-8">
						< /head>

			ㅡ요소 중첩시 닫히는 순서를 지켜야한다.
			ㅡ블럭요소와 인라인요소로 나뉘어질수있음. 블럭은 새로운줄을 만들며생기는것 인라인은 그 줄에 해당되는 요소.
			ㅡ속성값을 ""로 감싸야함
			ㅡ boolean 속성값이란것이 존재. 속성이름과 같은 값만을 속성값으로 가질수있다. ex) disabled="disabled"
			ㅡ< strong >태그 : 내용을 강조해줌.
			ㅡ< em >태그 : 글자를 기울림.
			ㅡ< div > : 아무런 기능도하지않고 구역을 나누는 역할. 주로 css적용목적.
			ㅡ< article > : 독립된 내용을 담는데 쓰임
			ㅡ< nav > : html 문서 구조의 한 구획으로, 보통 페이지안이나 다른페이지로넘어가는 링크를 걸어둔다.
			ㅡ

			ㅇ html에서 파일업로드하기
				ㅡ ...
				ㅡ 파일 이름 가져오기
					ㄴ getFileSystemName ( String name ) : 실제로 저장된 파일 이름을 가져온다
					ㄴ getOriginalFileName ( String name ) : 파일의 원래 이름을 가져온다.
					ㄴ getFileNames() : 여러개의 파일을 올릴경우 Enumeration의 형태로 그 이름들을 가져온다는데 어떻게 쓰는건지 잘 모르겠다.
							그냥 input을 여러개 동적으로 만들어서 넘겨주는 형태가 더 쉬웠다.

			ㅇ 태그 종류 )
				ㅡ < img>
					ㄴ src 속성에 있는 url에 해당하는 이미지를 뿌려주는 태그.
						ㄴ url이기때문에 다른 웹페이지 주소형태로 입력하여도 그 페이지의 이미지가 출력된다.
			ㅇ 태그<button>더보기</button>
			<pre>
				ㅡ < img>
					ㄴ ~~~~~
					ㄴ 실무 )
						ㄴ src 속성에 base64로된 url를 넣으면 이미지 출력이 가능하다. 
			</pre>

			ㅇ Escape (이스케이프)
				ㅡ < , ' 등과같은 사전에 문법적으로 약속된 문자를 표현하기 위해선 그냥 해당 문자를 작성하는 것이 아닌, 'html 엔터티'를 사용하여야 한다.
				ㅡ html 엔터티란 '& l t ;', '& n b s p ;' 등을 말한다.
				ㅡ 이렇게 특정문자를 html로 변환하는 것을 '이스케이프'한다고 한다. 
		</pre>
		css<button>더보기</button>
		<pre>
			ㅡ https://developer.mozilla.org/en-US/docs/Learn/CSS 참조.
			ㅇ css 동작 과정 )
				ㄴ 다음은 매우 간소화한 내용이고 브라우저마다 조금씩 다르다는점 기억.
				ㄴ 단계 )
					1. 브라우저가 html을 로드받는다.
					2. html이 dom으로 변환된다.
					3. 브라우저가 html문서에 링크된 이미지, 비디오, linked css등을 가져온다.(fetch한다)
					4. 브라우저거 fetch된 css를 파싱하여 선택자에 따라 어떤 rule이 어떤 dom에 적용되어야하는지 분류하고 이를 적용한다.
					5. ???The render tree is laid out in the structure it should appear in after the rules have been applied to it.
					6. 스크린에 css가 적용된 페이지가 보여진다.
				ㄴ 오류가있을시)
					ㄴ 프로퍼티나 value에 오류가 있을시, (스펠링이 틀리거나 아직 지원하지않는 내용이거나) 해당부분은 그냥 무시된다.

			ㅇ 선택자
				ㅡ 콤마(,)를 이용하여 여러개항목을 동시에선택할수도있다. ex) $(" (*요소1*) , (*요소2*), ... ").~~~
				ㅡ E F	E 요소의 자손인 F 요소를 선택합니다.
				ㅡ E>F	E 요소의 자식인 F 요소를 선택합니다.
				ㅡ E+F	E 요소를 뒤따르는 F 요소를 선택합니다.(E와 F 사이에 다른 요소가 존재하면 선택하지 않습니다.)
				ㅡ E~F	E 요소가 앞에 존재하면 F를 선택합니다. (E가 F보다 먼저 등장하지 않으면 선택하지 않습니다.)
				ㅡ 선택자 : 가상 요소, 가상 클래스
					ㄴ 가상 클래스 : ':'로 표시되며 ex) a:visited, button : hover 같은 것. 선택된 요소의 특정 상태를 선택하기 위한 선택자.
					ㄴ 가상 요소 : ' :: ' 로 표시되며 선택된 요소의 특정 부분을 선택하기위한 키워드. ex) p :: first-line ( p태그의 첫번째 줄을 선택 )

			ㅡ css 적용 우선순위)
				1. !important
				2. 태그에 style속성 사용
				3. id 선택자
				4. class 선택자
				5. 속성 선택자
				6. 가상클래스
				7. 태그 선택자
				8. 상속된 속성
				ㄴ 같은 순위 안에서는 선택자에서 지정항 항목?이 많을수록 우선시되는 듯 하다. (정확하게는 모르겠다)
					ㄴ .aaa 보다 .aaa td 이렇게 하나라도 더 세세한 정보가 제시된게 우선적용된다.

			ㅡ 상속이 되는 속성과 안되는게 있다.
				ㄴ color같은건 상속. display같은건 상속안됨.
				ㄴ ex)
					< div>
						< form> ~~ < /form>
					< /div>
					div에 display : inline을 하더라도 form은 변화없이 디폴트인 block이다.

			ㅡ 퍼센트 css value 타입 )
				ㄴ 대부분의 경우 특정 값의 상대값으로 작용한다.
					ㄴ font-size이면 부모 font-size의 상대값, width면 부모 width의 상대값.
			ㅡ 크기 조절하기 )
				ㄴ 요소들은 본래의 intrinsic size를 가지고 있다고 한다. ex) img
				ㄴ div같은 요소들은 내용물이없으면 size가 없다. 이런 요소들은 안의 content에 따라 intrinsic size가 결정된다고 할 수 있다.
				ㄴ margin, padding을 퍼센트로 적용할 경우, top,bottom은 height를기준으로, left,right는 width를 기준으로 적용되는게 아니라
					모든 방향의 margin, padding값이 수평값인 width을 기준으로 적용된다.
				ㄴ span과 같은 inline요소에는 width, height를 지정할 수 없다.
					ㄴ 하려면 display:block 또는 display:inline-block으로 바꿔주어야 한다.
				ㄴ width, height를 %값으로 설정할경우, 부모요소의 크기를 기준으로 %가 적용된다.
			ㅡ image, media, form elements )
				ㄴ 특정 요소들은 css에서 좀 특별하게 적용된다고 한다. image, 다른 media형태의 요소, form 요소가 대표적이다.
				ㄴ replaced elements : image, video와 같이 css가 내부내용에 관여하지 못하는 요소들을 말한다. (그 요소부분이 css가 관여못하는
					다른것으로 대체되었다해서 이렇게부르나?)
				ㄴ 별내용없는듯하다
			ㅡ css 설계나 유지보수에 도움이 될 팁 )
				ㄴ 내 경우에 도움이 될만한 것들은..
				ㄴ 너무 옵션이 많은 선택자 사용은 지양해라
				ㄴ 하나의 css에 모든 내용을 담지말고 적절하게 분산해라.
			ㅡ 'containing block'
				ㄴ 요소의 위치나 크기에 영향을 미치는 개념.
				ㄴ 요소가 들어있는 박스 같은걸로 생각하면 된다.
				ㄴ 보통 그냥 요소의 영역을 생각하면 쉬운데 엄밀히 content area, padding area, border area, margin area 로 나뉜다고한다.
					( margin, padding 구분할때 그 영역 맞음)
				ㄴ width, height, padding, margin과 position프로퍼티가 absolute인 요소들의 위치프로퍼티(top,bottom등)을 설정할때
					이 containg block이 기준이 된다고한다.
				ㄴ 결정 요소 )
					ㄴ containing block은 'position'속성값에 의해 결정된다고 한다.
					ㄴ position값이 static, relative, sticky일 경우 )
						ㄴ 'block container', 'formatting context'를 가지는 가장 가까운 부모요소의 'context box'가
							containing block이 된다고 한다.
					ㄴ position값이 absolute인 경우 )
						ㄴ position값이 static이상으로(즉, fixed, absolute,relative,sticky) 설정되어있는 가장 가까운 부모요소의
							'padding box'가 containg block이 된다한다.
					ㄴ fixed인 경우 )
						ㄴ viewport나 page area가 containg block이 된다.
					ㄴ absolute나 fixed인 경우 )
						If the position property is absolute or fixed, the containing block may also be formed by the edge of the padding box of the nearest ancestor element that has the following:
						A transform or perspective value other than none
						A will-change value of transform or perspective
						A filter value other than none or a will-change value of filter (only works on Firefox).
						A contain value of paint (e.g. contain: paint;)
			ㅡ position
				ㄴ 요소의 위치를 결정하는 개념.
				ㄴ 디폴트로 static. 설정값으로 relative, absolute, fixed, sticky가 있다.
				ㄴ
				ㄴ ex)
					position : relative ;
					top : 40px;
					left : 10%;
				ㄴ static )
					ㄴ 디폴트값으로, 이걸로 설정되어있으면 top, bottom, left, right, z-index 프로퍼티가 효과가 나오지 않는다.
					ㄴ normal flow에 따라 위치가 설정된다.
				ㄴ relative )
					ㄴ 요소의 normal position을 기준으로 top, bottom, left, right가 결정된다.
				ㄴ absolute )
					ㄴ position의 값이 absolute인 요소에 해당
					ㄴ 요소의 containg block을 기준으로 위치가 설정된다.
						ㄴ absolute의 containg block이란 : position값이 static 이상으로 설정되어있는 가장 가까운 조상의 padding box.
					ㄴ 요소가 normal flow에서 제거되고 페이지레이아웃에서 해당 요소의 공간이 없어진다.
					ㄴ 따라서 다른 요소들은 이 absolute 요소가 존재하지 않는 것처럼 위치한다.
				ㄴ fixed )
					ㄴ 요소가 normal flow에서 제거되고 페이지레이아웃에서 해당 요소의 공간이 없어진다.
					ㄴ viewport의 containg block을 기준으로 위치가 설정된다.
					ㄴ 조상요소중 transfer, perspective, filter 프로퍼티의 값이 none 이상인 경우, 해당 조상이 containg block과 같이된다. ???
					ㄴ containg block의 설정부분만 제외하고는 absolute와 같다.
				ㄴ sticky )
					ㄴ position의 값이 sticky인 경우.
					ㄴ ???정확한 동작방식은 모르겠음. 주어진 offset값에서 fixed처럼 위치해있다가 다른 relative positioned 요소를 만나면 그곳에 위치가 고정된다.
					ㄴ top, bottom, left, right중 하나가 반드시 있어야한다.


			ㅡ layout )
				ㄴ https://developer.mozilla.org/en-US/docs/Learn/CSS/CSS_layout 참조.
				ㄴ 요소들을 위치시키는 것에 대해 배움.
					ㄴ normal flow, display property, flexbox, grid, floats, positioning, table layout, multiple-column layout에 대해 배울것.
				ㄴ normal flow )
					ㄴ 아무런 설정도 하지 않았을때 브라우저가 요소들을 배치시키는 방식.
					ㄴ block 요소들은 부모요소의 넓이를 100% 차지한다.
					ㄴ inline 요소들은 내부 컨텐츠의 높이와넓이만큼의 높이와넓이를 차지한다.
				ㄴ display 속성 )
					ㄴ 각 요소들은 디폴트 display값을 가지고있음. (< a>는 inline, < li>는 block 등등)
					ㄴ flex 값 )
						ㄴ 참고 사이트 )
							ㄴ https://heropy.blog/2018/11/24/css-flexible-box/
							ㄴ  https://developer.mozilla.org/en-US/docs/Learn/CSS/CSS_layout/Flexbox
						ㄴ 개요 )
							ㄴdisplay속성값중 하나.
							ㄴ 요소들을 1차원으로(한줄로) 배치하는데쓰이는 값.
						ㄴ 사용법 ) 부모요소에 'display : flex' 를 주면 바로 아래 자식요소들이 1줄로 배치된다.
						ㄴflex box 구성 )
							ㄴ flex_box.png참조.
							ㄴ axis가 축을 말함. 이 축을 기준으로 flex box내의 요소들이 정렬된다.
						ㄴ 관련 속성 )
							ㄴ 부모에 설정하는 속성)
								ㄴ flex-direction )
									ㄴ 어떤 축을 기준으로 1줄로 배치할지 결정할수있다.
										ㄴ flex-direction : row ) 수평으로 한줄로 배치
										ㄴ flex-direction : colum ) 수직으로 한줄로 배치
										ㄴ flex-direction : row-reverse ) 수평으로 한줄로 순서를반대로하여 배치
										ㄴ flex-direction : colum-reverse ) 수직으로 한줄로 순서를 반대로 하여 배치.
								ㄴ flex-wrap )
									ㄴ 한줄로 배치할때 overflow되는경우 어떻게 처리할지 결정하는 속성.
								ㄴ flex-flow )
									ㄴ flex-direction과 flex-wrap의 shorthand.
									ㄴ 형식 ) flex-flow : (*flex-direction값*) (*flex-wrap값*) ;
								ㄴ align-items )
									ㄴ flex요소들의 정렬을 설정하는 속성.
									ㄴ 값 )
										ㄴ stretch : 디폴트값. 'cross axis'의 방향으로 요소들이 부모요소를 꽉채우도록 하는 설정.
										ㄴ center : 'cross axis'를 기준으로 요소들이 가운데 정렬이 되게하는 값.
										ㄴ flex-start, flex-end : 요소들이 'cross axis'의 시작부분이나 끝부분에 정렬될수있도록 하는 값.
								ㄴ justify-content )
									ㄴ main axis를 기준으로 flex의 요소들이 어떻게 정렬될지를 설정하는 속성.
									ㄴ 값 )
										ㄴ flex-start : 디폴트값. main axis를 기준으로 처음부분에 정렬.
										ㄴ flex-end : 위의 반대.
										ㄴ center : 중간
										ㄴ space-around : main axis를 기준으로 요소들을 균등한 간격으로 정렬시킴. (맨왼쪽과 오른쪽에 여백을 남긴다)
										ㄴ space-between : space-around와 같으나 맨왼쪽과오른쪽에 여백을 남기지 않는다.
							ㄴ 자식에 설정하는 속성 )
								ㄴ flex )
									ㄴ 1차원 배치상에서 해당 요소가 차지하는 사이즈를 설정.
								ㄴ order )
									ㄴ 디폴트로 0이 설정되어있다.
									ㄴ 값이 낮을수록 main axis를 기준으로 먼저나온다.
									ㄴ 같다면 소스상에서 먼저 나온 요소가 우선된다.

					ㄴ gird 값 )
						ㄴ display 속성의 값중 하나.
						ㄴ 요소를 2차원으로 배치하려할때 사용.
						ㄴ 구성 )
							ㄴ grid_layout.png 참조.
							ㄴ column과 row로 구성되고 그 사이사이를 gutter라고 한다.
						ㄴ 사용법 )
							ㄴ 부모요소에 display : gird 를 부여하면 grid layout이 되며 디폴트는 column하나라 normal flow와 차이가 없다. grid-template-rows, grid template-column을 통해
								gird layout을 구성하면 이에 맞게 요소들이 2차원구조안에 배치된다. ( table처럼 표형식으로 배치된다. )
						ㄴ 관련 속성 )
							ㄴ 부모에 사용하는 속성 )
								ㄴ grid-template-rows, grid-template-column ) gird layout을 구성하는 속성.
									ㄴ ex)
										grid-template-rows : 10px 10px 10px;		=>row가 높이 10px로 세줄로 구성.
										grid-template-column : 1fr 2fr 1fr 1fr; 	=>column이 해당 fr비율에 맞게 4칸으로 구성.
									* fr : 비율로서 값을 나타내는 단위. 가용한 공간을 해당 비율에 맞게 자동으로 부여한다. 위와같은 경우, 1: 2: 1: 1의 비율로 가용한공간을 분할하여 할당한다.
									ㄴ 값으로 repeat( (*원하는 column,또는 row수*), (*사이즈*) ) 를 사용할 수 있다.
										ㄴ ex) grid-template-rows : repeat ( 3, 1fr ) ;
								ㄴ grid-column-gap, grid-row-gap, gird-gap ) gird layout에서 각 column과 column사이, row와 row사이의 gap을 만들고싶을때 사용. 원하는 크기를 값으로 부여하면되며,
									gird-gap은 column, row동시적용할때.
								ㄴ grid-auto-columns, grid-auto-rows )
									ㄴ grid-template-rows,columns로 명시적으로 설정을 하지 않았거나 명시적으로 설정한 범위 이상으로 요소가 위치하게될때(요소가 명시한것보다 많거나하는경우) 이 auto속성값들이 적용된다
									ㄴ 값으로 minmax( (*최소값*), (*최대값*) ) 을 사용 할 수 있다. (안에 어떤 크기의 내용이 들어갈지 모르기때문에 사용하는것)
							ㄴ 자식에 사용하는 속성 )
								ㄴ grid-column-start, grid-column-end, grid-row-start, grid-row-end, gird-column, grid-row )
									ㄴ grid layout상에서 해당 요소의 시작위치와 끝위치를 설정하는 속성.
									ㄴ grid layout에서 각 column과 row를 구분하는 선이 있다고 보고 이 선을 값으로 주면된다. (column에선 맨왼쪽선이 1번, row에선 맨위에 선이 1번)
									ㄴ ex ) grid-column : 1/3; =>column상에서 첫번째선에서 시작해 3번째선에서 끝남.
									ㄴ grid-column, grid-row는 shorthand.
							ㄴ ...
				ㄴ Float 속성 )
					ㄴ 값으로 left, right, none, inherit이 있으며 해당요소는 normal flow에서 나와 부모요소의 한쪽에 위치하게 되며, 다른 요소들이 해당 요소를 감싸게 된다.
						ㄴ inherit은 부모요소의 float값을 상속받는단 의미.
					ㄴ https://developer.mozilla.org/en-US/docs/Learn/CSS/CSS_layout/Floats 에 잘나와있으니 더 알아야되면 그때 참고하자.
				ㄴ positioning )
					ㄴ 위에 정리한 내용있음.
				ㄴ multi-column layout )
					ㄴ 신문에서 글들이 표시된것처럼. 컬럼묶음으로? 글들을 나열하는 방식으로 구성하고싶을때 사용.
					ㄴ column-count, 또는 column-width를 이용해 글묶음의 개수를 지정하거나 넓이를 지정하면, 자식 내용들이 해당 값에 맞게 컬럼처럼 글이 묶음으로 배치된다.

			ㅡ border-collapse : table의 경계선이 하나로 합쳐져야하는지 분리되어야 하는지 설정
				ㄴ 값 : collapse, separate


			ㅡ 벤더 프리픽스 (Vender Prefix)
				ㄴ 웹표준이 아닌 특정 기능들을 사용하기 위해서 브라우저마다 해당 기능을 사용하기 위해서 붙이는 '접두어'.
				ㄴ ex)
					.button {
							background: red;          <!-- gradient 속성을 지원하지 않는 모든 브라우저를 위한 코드 -->
						background: -webkit-linear-gradient(red, yellow); <!-- 크롬과 사파리 4.0 이상을 위한 코드 -->
						background: -moz-linear-gradient(red, yellow);    <!-- 파이어폭스 3.6 이상을 위한 코드 -->
						background: -ms-linear-gradient(red, yellow);     <!-- 익스플로러 10.0 이상을 위한 코드 -->
						background: -o-linear-gradient(red, yellow);      <!-- 오페라 10.0 이상을 위한 코드 -->
						background: linear-gradient(red, yellow);         <!-- CSS 표준 문법 코드 -->
						}

		</pre>
		자바 스크립트<button>더보기</button>
		<pre>
			기본<button>더보기</button>
			<pre>
				ㅇ 기본 )
					ㅡ 클라이언트쪽 브라우저 안에서 동작하는 코드.
					ㅡ ECMAScript 스펙을 따르는 프로그래밍 언어.
					* ECMAScript란?
						ㅡ ECMA 국제기구에서 설정한 프로그래밍 언어의 표준.
					ㅡ 개인적인 개요 )
						ㄴ js가 하는일은 보통, 이벤트 처리, 그리고 그에 따른 동적인 화면조작(화면 요소조작)인것 같다.

				ㅇ 문법
						ㅡ js는 대소문자를 구분.
					ㅡ 리터럴 : 직접표현되는 값 자체를 말함
						ㄴex ) 12 =>숫자 리터럴, "hello" => 문자열 리터럴
					ㅡ 식별자 : 변수나 함수의 이름.
						ㄴ 영문대소문자, 숫자, 언더스코어(_), 달려($)만 사용할수있다.
						ㄴ 숫자로는시작할수없다.
					ㅡ 키워드: js의 예약어.
						ㄴ function, var 등등.
					ㅡ 주석 : java와 같다.

				ㅇ js에서 출력하는방법
					1. window.alert() 메소드
						ㅡ 대화상자 창을띄워 내용을 출력해준다.
						ㅡ ex ) alert(" (*내용*) ");
					2. HTML DOM요소를 이용한 innerHTML 프로퍼티
						ㅡ document객체의 getElementByID() 또는 getElementsByTagName()에 HTML요소를 인자로넘겨줌으로써 선택하고 반환받은 것을 변수에 저장하고 이에 대해
							innerHTML프로퍼티의 값을 바꾸면 선택한 요소의 내용이나 속성을 변경할수있다
						ㄴ ex ) 	var str=document.getElementById(" (*id이름*) ");
								str.innerHTML = "(*바꿀내용*)";
								=>이렇게하면 id이름에 해당하는 요소의 내용이 (*바꿀내용*)으로 바뀜
					3. document.write()메소드
						ㅡ 페이지에 내용을 출력하는 메소드.
						ㅡ 웹페이지의 로딩시에 가장먼저 출력된다고함.
						ㅡ 다른내용들이 로딩된 이후에 이 메소드가 실행되면, 기존의 내용들을 다지우고 해당내용을 출력한다고한다.
						ㅡ 따라서 테스트나 디버깅용도로만 주로사용된다고함.
					4. console.log()메소드
						ㅡ 콘솔창에 출력.


				ㅇ js코드 삽입방법
					1. 내부 js코드
						ㄴex ) &lt script>~~ &lt /script>로 코드를 삽입하는방법.

					2. 외부 js파일
						ㅡ 외부파일로 js를 만들에 삽입하는방법.
						ㅡ 외부의 js파일은 .js확장자를 가지며,
						ㅡ 삽입하려는 페이지에 삽입하면된다
							ㄴ ex ) &lt script src="(*url*)"> &lt /script>
						ㅡ 깔끔하ㅏ고 유지보수가 편해진다함.

				ㅇ js 타입<button>더보기</button>
				<pre>
					ㅡ number. 숫자
						ㄴ 정수 실수 구분없이 모든수를 실수로표현.(64비트 부동소수점으로표현)
						ㄴ toString() 을 이용해 수를 여러진법의 형태로 바꿀수 있다.
							ex)	var num=100;
								num.toString(16);	=>16진법으로 변경.
								num.toString(8);	=>8진법으로 변경.
						ㄴ Infinity와 -Infinity라는 양의 무한대와 음의무한대를뜻하는 값이 있다.
						ㄴ NaN : 숫자가 아니라는 의미로, 정의되지 않은 값이나 표현할 수 없는 값을 가리킵니다.
					ㅡ 문자열. string
						ㄴ 큰따옴표나 작은따옴표로 둘러싸인 문자집합.
						ㄴ 큰따옴표 안에 작은따옴표. 또는 그반대 가능.
							ㄴ ex) "이것도 '문자열'입니다", '이것도 "문자열"입니다'
					ㅡ boolean
						ㄴ 참거짓값.
					ㅡ 심볼(symbol)
						ㄴ ECMAScript 6부터 새로나옴.
						ㄴ 유일하고 변경할수없는타입으로, 객체의 프로퍼티를 위한 식별자로 사용할수있다고함.
					* typeof연산자
						ㅡ 피연산자의 타입을 반환하는 연산자
						ㅡ ex)  typeof 10; =>number타입
					ㅡ null : object타입으로 아직 값이 정해지지않은것 의미.
					ㅡ undefined : null과 달리 타입이 정해지지 않은것.
					ㅡ falsy value )
						ㄴ 거짓 값.
						ㄴ Boolean형과 만났을때 거짓으로 처리되는 값들을 말한다.
						ㄴ 종류 )
							ㄴ false, 0, -0, 0n, -0n, "", '', ``, null, undefined, NaN, document.all
				</pre>

				ㅇ js의 형변환
					ㅡ js는 상황에 맞게 자동으로 형을 변환해줌.
						ex) 10+"3" =>문자열3이 숫자3으로변환.
							1- "문자열" =>문자열이 NaN으로 변환( NaN은 표현할수 없는값이라는뜻)

					ㅡ명시적으로 타입을 변환할수도있다.
						ㄴ Number(), String(), Boolean(), Object() 등을 이용한다.
						ㄴex) Number("10"); =>문자열 10을 숫자10으로 바꿈
							String(true)=> boolean true를 문자열 true로 바꿈.
							Boolean(0)	=>숫자 0을 boolean false로 바꿈.

				ㅇ js연산자 )<button>더보기</button>
				<pre>
					ㅡ 산술, 비교, 대입, 증감, 논리, 비트 모두동일
					ㅡdelete연산자
						ㄴ 피연산자인 객체, 객체의 프로퍼티, 배열의 요소를 삭제.
						ㄴ 삭제되면 true반환. 아니면 false반환.
					ㅡ instanceof연산자
						ㄴ (*확인대상*) instanceof( (*비교대상*) )
							: 확인대상이 비교대상과 일치하는지를 알려준다. 단순히 객체인것뿐아니라 어떤 객체인지도 확인할 수 있다.
						ㄴ ex)	var str=new String("aaa");
								str instanceof Object; => true
								str instanceof String; => true
								str instanceof Array;  => false
					ㅡ typeof 연산자
						ㄴ typeof( (*확인대상*) ) : 대상의 데이터 유형을 확인하는 함수.
							ㄴ 'undefined', 'boolean', 'number', 'string', 'object', 'function' 중 어디에 속하는지 알려준다.
					ㅡ 전개연산자, '...' )
						ㄴ 함수의 인자나 배열의 인자에 값을 넣을때, 배열, 문자열 등의 반복가능한 값을 요소 하나하나로 전개하여 대입할수있게해주는 연산자.
						ㄴ ex)	function sum(x, y, z) {
								return x + y + z;
								}

								const numbers = 'hello';
								const aa = [...numbers];
								console.log(...numbers);	// > "h" "e" "l" "l" "o"
								console.log(aa);			// > Array ["h", "e", "l", "l", "o"]
								console.log(sum(...numbers));	// > "hel"
							ㄴ 문자열 'hello'가 전개되어 요소 하나하나로 나뉘어 값이 들어간다.
							ㄴ 'hello'같은 문자열이 아니고 배열이어도 똑같다.
					ㅡ 논리연산자 )
						ㄴ && ) expr1 && expr2  : expr1이 true이면 expr2를 반환, 아니면 expr1을 반환.
						ㄴ || ) expr1 || expr2  : expr1이 true이면 expr1을 반환, 아니면 expr2를 반환.
						ㄴ ! ) !expr1  : expr1이 true이면 false반환, 아니면 true반환.
				</pre>
				ㅇ 제어문
					ㅡ 조건문 : 자바와 동일
					ㅡ 반복문
						ㅡ for, while 자바와 동일.
						ㅡ for/in문 : 해당 객체의 모든 열거할수 있는 프로퍼티에 대해 반복을해주는 반복문.
							ex) for( (*변수*) in (*객체*) ){ (*반복하는부분*) }
								=> 객체의 모든 프로퍼티에대해 각각을 변수에 넣어 반복하는부분 실행해줌.
						* 열거할수 있는 프로퍼티 :내부적으로 enumberable 플래그가 true로 설정된 프로퍼티를 의미.

						ㅡ for/of문 : 반복할수있는객체를 반복해주는 반복문.
							ex) for( (*변수*) of (*객체*) ){ (*반복하는부분*) }
						*반복할수있는객체란 : js에서는 Array, Map, Set, arguments 객체 등이있다.

						ㅡ continue, break 자바와 동일.

				ㅇ 배열<button>더보기</button>
				<pre>
					ㅡ 배열은 js에서 Array객체에 해당한ㄴ다.
					ㅡ 요소로 아무 타입이나올수있으며 모두 동일하지 않아도된다.
					ㅡ 생성
						ㄴ ex)	var arr=[ ~~, ~~, ...];
								var arr=Array(~~, ~~, ...);
								var arr= new Array(~~, ~~, ...);
					ㅡ 배열의 참조
						ㄴ 자바와 동일.
						ㄴ ex) (*배열이름*)[ (*인덱스*) ]
						ㄴ 배열 객체에 length라는 프로퍼티로 배열의 길이가 저장되어있다.
					ㅡ 배열의 추가
						ㄴ ex) 	(*배열이름*).push( (*추가할요소*) );
								(*배열이름*)[(*배열이름*).length] = (*추가할요소*);
								(*배열이름*)[(*특정 인덱스*)] = (*추가할요소*);
					ㅡ 배열 객체의 함수 )
						ㄴ pop() : 맨 뒤 index에서부터 하나씩 삭제하고 반환.
						ㄴ unshift() : 맨 뒤 index부터 하나씩 삭제하고 반환.
						ㄴ shift()
						ㄴ push()
						ㄴ splice( (*index*), (*개수*) ) : (*index*)위치에서 (*개수*)만큼 뽑아서 삭제후 배열형태로 반환.
						ㄴ join( (*구분자*) ) : 배열안의 요소들을 (*구분자*)를 기준으로 하나의 문자열로 합침.
							ㄴ ex)	var i = [ 2,3, 4,5 ]
								i.join(',')	=> "2,3,4,5"
					ㅡ 희소배열
						ㄴ js의 배열은 꼭 순차적인 인덱스대로 값을 넣지 않아도 된다.
						ㄴ 이런특성으로 인해, 배열의 요소의 위치가 연속적이지 않은 배열을 희소배열이라한다.
						ㄴ ex) var arr= new Array();
							arr[99]="aaa"; => 0부터 98인덱스에 암것도 안넣고 99에 값넣음.
					ㅡ 다차원배열
						ㄴ Array를 하나 만들고 각 인덱스에대해 Array를 또만드는식으로 생성가능.
					ㅡ 연관배열
						ㄴ 인덱스값으로 숫자가 아닌 문자열로된 '키'값을 지정하는 배열을 말하는데. js에서는 따로 지원을 하지않아 만들수는 있지만 내부적으로 Array객체의 length프로퍼티가 사라짐.
							ex) 	var arr=[]; =>이렇게 배열하나 만들고
									arr["하나"] = 1; =>이렇게 키값형태로 인덱스저장을하면
									document.write(arr.length); =>안나옴.
					ㅡ js의 문자열은 []연산자를 사용하여 각 인덱스에 해당하는 문자를 읽어올수있다. (읽어올수만 있다)
				</pre>
				ㅇ 함수
					ㅡ js에서 함수는 데이터 타입의 일종.
					ㅡ function키워드로 정의한다.
						ex)	function (*함수이름*)( (*매개변수1*), ...){
								(*함수내용*)
								}
					ㅡ 함수를 변수에 저장할수도있다.
						ex)	function sqr(x){~~}
							var aaa=sqr;
							aaa(4);	=>저장한 변수를 통해 함수호출.
					ㅡ 매개변수)
						ㄴ arguments : 함수가 기본적으로 가지고있는값으로 배열은 아니지만 배열과 유사.

				ㅇ 함수의 매개변수
					ㅡ js에서는 함수정의시 매개변수 타입을 따로 정의하지않음. 따라서 호출시 전달하는 인자의 타입검사또한 없음. 그만큼 형식에서 자유롭다.
					ㅡ 인자의 개수또한 자유롭다. 매개변수보다 적으면 인자를받지못한 매개변수는 undefined로, 더 많으면 매개변수에 저장이 안되어도 arguments객체에 저장이된다.
					ㅡ arguments객체 : 함수가 기본적으로 가지고있는객체로, Array는 아니지만 Array와 유사하다.
						ㄴ 함수호출시 전달된 인자를 순서대로 저장하고있으며
						ㄴ arguments[ (*인자의 인덱스*) ] 형태로 접근할수 있다.
						ㄴ length프로퍼티도 가지고있어 인자의 개수를 알수있다.ex) arguments.length

				ㅇ 변수의 유효범위<button>펼치기</button>
				<pre>
					ㅡ js는 다른언어와 다르게 영역을 {}단위로 나누지 않고 함수단위로 나눈다.
						따라서 {}안에있으면 지역변수, 밖에있음 전역.이게아니라 함수안에있으면 지역변수, 밖에있으면 전역변수가된다.
						ex) for(var i=0;i<3;i++){~~} => 변수i는 전역변수이다. for문이끝나도 접근가능.
					ㅡ 함수 내에서 선언되었으면 지역변수. 자바의 지역변수와 동일.
					ㅡ 함쉬 외에서 선언되었으면 전역변수. 자바의 전역변수와 동일.
					ㅡ 따라서 js에서는 되도록 전역변수말고 지역변수를 쓰는게 좋다.

					ㅡ변수 호이스팅
						ㄴ 호이스트란 변수의 정의가 그 범위에 따라 선언과 할당으로 분리되는것을 의미한다.
						ㄴ 즉, var a=10;과 같이 정의가 되어있어도 이 정의가 코드 어느위치에 있건 해당 변수의 '선언'이 코드 최상위 부분으로 변경되는것. (지역변수일경우 함수의 최상위,
							전역일경우 전역코드의 최상위) '선언'위치는 이렇게 바뀌고 초기화나 할당은 원래의 위치에서 발생.
							ex) var a = 10; 이면 최상위 부분에 var a가 오고 원래의 위치에 a=10;이 온다고 이해하면 된다.

					ㅡ js의 스코프 )
						ㄴ 식별자의 유효범위. 자신이 어디서, 어떻게 선언되었는지에 따라 스코프가 결정된다.
					ㅡ js의 식별자 선언 세가지 : var, let, const )
						ㄴ var : 함수 스코프를 따른다. 자신이 선언된 곳과 가장 ㅏㄱ까운 함수를 스코프로 가진다.
							ㄴ ex)
								var x =0;
								{
									var x =1;
									console.log(x); //1
								}
								console.log(x); //1	=>var은 함수 스코프를 따르기때문에 첫번째 var x, 두번째 var x모두 같은 메인함수안에있고 둘다 메인함수의 스코프를 가진다. 따라서 첫번째에서 0을 넣었지만 두번째에서 덮어씌워진것.
										ㄴ let, const : 블록 스코프를 따른다. 자신이 선언된 곳과 가장 가까운 블록을 스코프로 가진다.
											ㄴex)
								let x = 0;
								{
									let x=1;
									console.log(x);//1	=>let은 블록 스코프를 가직때문에 여기서의 x는 같은 블록안에있는 바로 위의 1이 들어간 x이다.
								}
								console.log(x);//0	=>여기서의 x는 맨처음 0이 들어간 x이다.
									ㅡ 스코프 체인 )
										ㄴ js는 식별자를 찾을때 자신이 속한 스코프에서 찾지 못하면 그 상위스코프에서 식별자를 찾는다. 이러한 방식을 '스코프 체인'아라한다ㅏ.
										ㄴ 상위 스코프 결정 )
											ㄴ 어떤 스코프가 상위 스코프인지 결정하는 방법에는 두가지가있다.
											ㄴ 동적 스코프 ) 함수의 호출 지점을 기준으로 상위스코프를 결정
											ㄴ 렉시컬 스코프 ) 함수의 선언 지점을 기준으로 상위스코프를 결정.
											ㄴ ex)
								var x = 1;

								function foo() {
								var x = 10;
								bar();
								}

								function bar() {
								console.log(x);
								}

								foo(); // 10? 1?	=> 동적 스코프일경우, foo()호출->bar()호출->console.log(x)호출->bar()안에 x가없음->상위스코프에서탐색(bar()를 호출한곳인 foo()가 상위스코프로 결정)->var x=10찾음->10출력
											렉시컬 스코프인경우, foo()호출->bar()호출->console.log(x)호출->bar()안에 x가없음->상위스코프에서탐색(bar()가 선언된곳인 main()가 상위스코프로 결정)->var x=1찾음->1출력.
								bar(); // 1

					ㅡ js 함수의 bind() 메소드 )
						ㄴ https://developer.mozilla.org/ko/docs/Web/JavaScript/Reference/Global_Objects/Function/bind참조
						ㄴ Function.prototype.bind()
						ㄴ 어떤 함수에게 그 함수 안에서 사용될 this값을 넘겨줄수있는 메소드. (다른기능들도있는듯하다)
						ㄴ 위에서 나오는 js의 this의 특징으로 인해, 함수안에서 this사용시, 그게 어떤것인지 정확하게 장담할수없다. 따라서 이 메소드를 통해 함수안에서 사용될this가 무엇인지를 결정할 수 있다.
						ㄴ ex)
							this.x = 9;
							var module = {
							x: 81,
							getX: function() { return this.x; }
							};

							module.getX(); // 81

							var retrieveX = module.getX;
							retrieveX();
							// 9 반환 - 함수가 전역 스코프에서 호출됐음

							// module과 바인딩된 'this'가 있는 새로운 함수 생성
							// 신입 프로그래머는 전역 변수 x와
							// module의 속성 x를 혼동할 수 있음
							var boundGetX = retrieveX.bind(module);	=>retrieveX함수 안에서의 this는 module객체임을 지정.
							boundGetX(); // 81
					ㅡ javascript의 this
						ㄴ 함수에서 사용되는 this는 어떻게 호출되는지에 따라 내용물이 달라진다.
							ㄴ ?????
						ㄴ '화살표 함수'를 사용하고 그안에서 this를 호출하는 경우 )
							ㄴ 이 경우에는 화살표함수를 둘러싸는 '렉시컬 범위'의 this가 사용된다.

				</pre>
				ㅇ 구조 분해 할당 <button>더보기</button>
				<pre>
					ㅡ 배열과 객체를 하나의변수에 한번에 저장하는것이 아니라, 여러 변수에 분해해서 저장할 수 있는 기능.
					ㅡ ex )
						const arr = ["name1", "name2"];
						const [aaa, bbb ] = arr ; //변수 aaa, bbb가 생기고, aaa에는 'name1'이, bbb에는 'name2'가 들어간다.

						객체 )
						let obj = {
							title : 'sampleTitle',
							name : 'sampleName'
						}
						let {title, name} = obj;  // 변수 title, name이 생기고, title에는 obj.title인 'sampleTitle'이, name에는 obj.name인 'sampleName'이 들어간다.
					ㅡ 배열의 구조 분해 할당 )
						ㄴ 좌측 변수에 컴마를 기준으로 인덱스순서대로 배열의 값이 분해되어 할당된다.
						ㄴ 컴마를 비울수도있고 (ex) const [a, , b] = "hello";
						ㄴ 변수의 수와 할당하려는 배열의 수가 맞지 않으면 알아서 조정된다. 배열의 수가 부족하면 변수가 undefined로 비게되고,
							배열의 수가 더 많으면 있는 배열의 수만큼만 들어간다.
						ㄴ 좌측에 ...rest를 사용할 수있다. 남은 배열값들이 배열로 할당되게 된다.
							ㄴ ex)
								const arr  = ['a','b', 'c', 'd'];
								const [ x, y, ...z ] = arr; //x='a', y='b', z=['c', 'd']
						ㄴ 문자열도 할당할수잇으며, 문자 하나가 배열의 한 요소가 된다. ex) const [a,b,c] = "hello";
						ㄴ 문자열뿐만 아니라 set 등 '반복가능한 객체'는 뭐든 올 수 있다.
					ㅡ 객체의 구조 분해 할당 )
						ㄴ 순서와 상관없이 객체의 키값과 일치하는 변수명에 값이 할당된다.
						ㄴ 마찬가지로 ...rest를 사용할 수있다. 남은 값들이 객체로 들어간다.
						ㄴ 키값이 아닌 원하는 변수명을 설정할 수도 있다.
							ㄴ ex) let { title : t, name : n } = obj;    //obj.title인 'sampleTitle'은 변수 t에, obj.name인 'sampleName'은 변수n에 저장.
						ㄴ 키값이 없을시 디폴트값 설정도 가능하다.
							ㄴ ex) let { title : t = 'noTitle', name = getDefaultName() } = arr ;
							ㄴ ' = '을 붙여 디폴트값을 설정한다. 값이 아닌 함수를 줄 수도 있다.
						ㄴ 중첩 객체의 구조 분해 할당 )
							ㄴ 객체 구조를 똑같이 맞춘다면 중첩객체도 구조분해 할당이 가능하다.
							ㄴ ex)
								let options = {
								size: {
									width: 100,
									height: 200
								},
								items: ["Cake", "Donut"],
								extra: true
								};

								// 코드를 여러 줄에 걸쳐 작성해 의도하는 바를 명확히 드러냄
								let {
								size: { // size는 여기,
									width,
									height
								},
								items: [item1, item2], // items는 여기에 할당함
								title = "Menu" // 분해하려는 객체에 title 프로퍼티가 없으므로 기본값을 사용함
								} = options;
							ㄴ 단, size, items라는 변수를 생성되지 않는다. 그 하위 요소인 width, height, item1, item2만 변수로 생성되고 값이 할당된다.
				</pre>
			</pre>
			함수와 객체, 프로토타입<button>더보기</button>
			<pre>
				ㅇ 생성자 함수
					ㅡ js에서 함수는 그냥 함수일뿐만 아니라 객체를 만드는데도 쓰인다. 정의된 함수앞에 new라는 키워드를 붙이면되는데,
						ex) function Person(name){
							this.name= name;					=>객체로만들어졌을시 name이란 변수를갖게됨.
							this.introduce =  function(){		=>객체로만들어졌을시 introduce란 메소드를가짐.
								return 'My name is '+this.naem;
							}
						}
						var p = new Person('tjrgh');			=>'tjrgh'를 name매개변수로 넘겨주어 함수Person을
																	객체로서 만들어줌.
					ㅡ 이렇게 객체를 만드는데 쓰이는 함수를 '생성자 함수'라고 하고,
						구분을 위해 첫알파벳을 대문자로써준다.

				ㅇ 객체
					ㅡ 개요)
						ㄴ js에서 객체는 이름(name)과 값(value)로 구성된 프로퍼티의 정렬되지 않은 집합을 말한다.
						ㄴ 자바의 'map'자료형과 유사.
					ㅡ 형식)
						var (*이름*) = { (*키1) : (*값1*), (*키2*) : (*값2*), ...};
						또는
						var (*이름*) = {};
						(*이름*)[ (*키1*) ] = (*값1*);
						(*이름*)[ (*키2*) ] = (*값2*);
						...
						또는
						var (*이름*) = new Object();
						(*이름*)[ (*키1*) ] = (*값1*);
						...
						ㄴ 이렇게 만들어진 객체를 인스턴스라고한다.
					ㅡ 값을 읽을때)
						ㄴ	(*이름*)[" (*키*) "]
							또는
							(*이름*).(*키*);
						ㄴ 모든값을읽고싶을때는 반복문사용시 인덱스값이 없으므로 for/in문을사용.
					ㅡ 메도스호출할때)
						ㄴ 프로퍼티로 함수가 올수있으며 이때이함수를 '메소드'라고한다.
						ㄴ (*이름*).(*메소드이름*)();
						ㄴ (*이름*).(*메소드이름*) 이렇게만쓰고 뒤에 ()를붙이지않아 호출을하지않으면 프로퍼티값자체가 반환이되어 메소드정의자체가 반환된다.
					ㅡ js에서는 숫자, 문자열, boolean, undefined타입을 제외하고는 모두 객체이다.
					ㅡ 수사, 문자열, boolean도 값이정해진 객체로 취급되어 객체의특징도 갖는다.
					ㅡ 객체 초기화시, '계산된 속성명(computed property name)'을 사용할수있다.
						ㄴex) var a = {
								[name + 1] : value1,
								[name + '22'] : value2
							}
						ㄴ 프로퍼티부분에 []를 주고 그안에 js의 식을 사용할 수 있다.

				ㅇ 프로토타입이란?<button>더보기</button>
				<pre>
					ㅡ js의 모든 객체는 함수이다.
						ㄴ Object도 fucntion으로 정의된 함수의 일종.

					ㅡ 개요)
						간단하게말하면, 객체에 대해 인스턴스생성시마다 인스턴스를 새로 생성하는게 아니고 원형이되는 프로토타입을 하나 만들어놓고
						인스턴스들이 그 프로토타입객체를 참조해서 사용하는 방식.???

					ㅡ함수가 정의될때 일어나는일)
						ㄴ 해당함수에 생성자 자격을 부여한다고한다. 이를통해 해당 함수에 대해 new키워드로 객체를 생성할수있다.(생성자 함수)
						ㄴ Prototype Object도 같이 생성된다.
						<img src="image/프로토타입구조1.png" style="height:300px; width:auto;">

					ㅡ 생성된함수는 prototype이라는 속성을 통해 Prototype Object에 접근가능.
						ㄴ 이 함수를 생성자로서 객체생성시(new연산사용해서), 생성자에 해당하는 함수의 prototype속성이 가리키는 Prototype Object가 만들어지는 객체의 프로토타입이 된다.
							ex) var date = new Date();	=> date객체는 Date()함수의 prototype속성이 가리키는 Prototype Object를 프로토타입으로 갖는다.

					ㅡ Prototype Object는 constructor, __proto__라는 속성을 가짐.
						ㄴ contructor는 Prototype Object와 함께 생성되었던 함수를 가리키고있다.
						ㄴ __proto__ 속성은 모든 객체가 가지고있는 속성으로서, 객체가 생성될 당시 원형이 되는 함수의 Prototype Object를 가리키는 값이다.
							<img src="image/프로토타입구조2.png" style="height:300px; width:auto;">
							ex)	function Person(){};	=>이렇게 함수가 생성되었을때 함수에 생성자 자격이 부여되고 이 함수에 대한 Prototype Object가 생성된다.
								var kim= new Person();	=> 함수를 객체로 생성하여 kim에 넣었다.
								=> 이렇게 되면 kim은객체이므로 __proto__속성을 가지고 잇으며 그 값은 kim객체의 원형이 되는 함수인 Person()함수의 Prototype Object.
									Person()함수가 생성되었을때 같이 생성된 Person()함수의 Prototype Object가 __proto__값으로 들어있다.
					ㅡ 이 __proto__속성값을 통해 kim이 원형인 Prototype Object를 참조하는식으로 객체가 동작????
					ㅡ __proto__를 참조하여 속성을찾고 없으면 __proto__의 __proto__로 올라가서 찾고 이런식으로 작동. 이런식으로 상속을 구현하며, 이렇게 엮여있는것을
						'프로토타입체인'이라고함.
						<img src="image/프로토타입구조3.png" style="height:300px; width:auto;">
						ㅡ 객체에 프로퍼티 및 메소드 추가하기)
							ㄴ ex)	function Dog(color, name, age){
										this.color=color;
										this.name=name;
										this.age=age;
									}
									var myDog = new Dog("~~~);
									myDog.family="~~";	=>이렇게 새로운 프로퍼티를 추가.
									=>이렇게 인스턴스에 추가를하면 그냥 해당인스턴스에만 추가가 되며, 프로토타입이나 같은프로토타입을가지는 다른인스턴스에 영향x.

					ㅡ 프로토타입에 프로퍼티 및 메소드추가하기)
						ㄴ 생성자함수의 prototype속성에 추가함으로서 프로토타입에 프로퍼티 및 메소드 추가가능.
						ex)	위 예에 이어서..
							Dog.prototype.breed="~~";	=>이러면 프로토타입에 breed프로퍼티가 추가되어 현존하는 인스턴스뿐아니라 새로생길 인스턴스에 모두 적용.

					ㅡ this 키워드
						ㄴ this는 this가 있는 위치의 영역을 포함하고있는 객체를 가리킨다.
							ex)	메소드 내부에선 메소드를 포함하고있는 객체,
								객체 내부에선 객체 그자체.
						ㄴ 생성자함수 내부에서 사용되는 this는 어떤값도 가리키지않으며 앞으로 생성될 객체로 값이 채워진다.

					ㅡ 객체 프로퍼티 삭제하기
						ㄴ delete (*객체이름*).(*프로퍼티이름*); 을하면 객체의 프로퍼티가 삭제됨.
						ㄴ '프로퍼티'삭제이므로 함수나 변수에는 작동 x.

					ㅡ 객체의 비교
						ㄴ완전히 동일한 인스턴스가 아닌이상 비교연산자(==, ===)는 false가 나옴.

					ㅡ Object의 메소드
						ㄴ 모든 객체는  Object.prototype이 가리키는 객체를 상속받으므로 여기에 있는 프로퍼티와 메소드를 사용할수있다.
						ㄴ hasOwnProperty() : 해당객체에 특정 프로퍼티가 존재하는지를 판별하여 boolean값 반환. 직접선언된 프로퍼티만을 검사하므로 상속받은건 없는셈친다.
						ㄴ propertyIsEnumerable() : hasOwnProperty()를 만족하면서 열거할수있는 프로퍼티인지 검사하여 boolean값 반환.
						ㄴ isPrototypeOf() : 특정객체의 프로토타입체인에 현재 객ㅊ체가 존재하는지.
						ㄴ toString() : 호출한 객체의 값을 문자열로 반환.
						ㄴ valueOf() : 모르겟다.
						ㄴ getter, setter : 모르겟다.

					ㅡ 무제
						ㄴ 프로토타입 체인
							ㄴ 객체에서 어떤 속성에 대해 접근할때, 객체는 해당 속성을 자기 자신의 속성, 자신의 프로토타입의 속성, 프로토타입의 프로토타입의 속성을
								올라가며 탐색한다.
								이 체인의 종단점은 prototype 값이 null인 Object 객체가 된다.
							ㄴ 자기자신부터 순서대로 올라가므로, 당연히 자기자신의 속성에서 찾으면 프로토타입을 탐색하지 않는다.
								이를 상속의 오버라이드 개념으로 사용할 수 있다.
							ㄴ 성능 이슈
								ㄴ 속성에 대해 체인 종단까지 탐색하는 과정이 성능에 이슈가 될 수 있음.
						ㄴ class, function을 정의 후, 이에 대한 인스턴스, 변수를 만들어도
							각각의 그 인스턴스, 변수의 prototype과 정의한 class, function의 prototype은 동일.
							ㄴ ex )
								class NoName{
									a = 1;
								}
								var noname = new NoName();
								noname.__proto__ === NoName.prototype  // true

								function aaa(){}
								var a1 = new aaa()
								a1.__proto__ === aaa.prototype  // true
						ㄴ 최상위 prototype은 Object의 prototype인 Object.prototype
						ㄴ prototype 관련 객체 생성 방법?
							ㄴ js 기본 문법 사용
								ㄴ ex )
									var o = {name : "john"}  // 이 형식으로 객체 생성시, o는 Object.prototype을 프로토타입으로 가진다.

									var arr = [1, 2, 3]  // 이 형식으로 객체 생성시, arr는 Array.prototype을 프로토타입으로 가진다.

									function func(){}  // 이 형식으로 객체 생성시, func는 Function.prototype을 프로토타입으로 가진다.
							ㄴ new 연산자 이용
								ㄴ ex )
									function NoName(){
										this.a = "hello";
									}

									var noname = new NoName();  // noname은 NoName.prototype을 프로토타입으로 가진다.
							ㄴ Object.create() 이용
								ㄴ ex )
									var a = {name: "hello"}
									var b = Object.create(a)  // b는 a를 프로토타입으로 가진다.
								ㄴ 특정 객체를 프로토타입으로 하는 객체를 생성해주는 메소드.
							ㄴ class 키워드
								ㄴ ~~~



				</pre>
				ㅇ 기타 <button>더보기</button>
				<pre>
					ㅡ Rest 파라미터 <button>더보기</button>
					<pre>
						ㄴ 함수에 몇개의 인자가 들어올지 알 수 없을때, 이 정해지지 않은 개수의 인자를 받게해주는 문법이다.
						ㄴ 간단 사용법 )
							ex)	function myFunc(a, b, ...theArgs) {	//함수의 인자 중 마지막인자의 앞에 '...'을 붙여준다.
								// ...
								}
								~~~~~
								myFunc("one", "two", "three", "four", "five", "six");
													//함수 호출시, 인자a,b와 매핑되는 처음 두개 이외에, 그 뒤로 몇개의 인자가 오든,
													이 추가적인 인자들은 Rest파라미터인 theArgs안에 js배열의 형태로 저장된다.
													즉, theArgs안에 ['three','four','five','six']가 저장되어있다.

					</pre>

				</pre>
				ㅇ 표준 내장 객체<button>더보기</button>
				<pre>
					ㅡ Object 객체<button>더보기</button>
					<pre>
						ㄴ ~~~~~
						ㄴ 메소드<button>더보기</button>
						<pre>
							ㄴ ~~~~~
							ㄴ is()<button>더보기</button>
							<pre>
								ㄴ 두 값이 같은지 비교
								ㄴ ~~~~~
								ㄴ ==연산자나, ===연산자와 같지 않다.
							</pre>
						</pre>
					</pre>
					ㅡ Date <button>more</button>
					<pre>
						ㄴ ~~~~~
						ㄴ 메소드 <button>more</button>
						<pre>
							ㄴ toISOString()
								ㄴ iso형식으로 문자열 반환. ex) 2011-10-05T14:48:00.000Z
								ㄴ utc기준 시간으로 자동 변환한다.
									가령, 한국이라 GMT+9000인 경우, toISOString()은 -9시간을 하여 반환.
									ex )
										new Date()  // Thu Oct 20 2022 12:24:12 GMT+9000 (한국 표준시)
										new Date().toISOString()  // "2022-10-20T03:25:33.691Z"
							ㄴ getHours()
								ㄴ 시간 integer값 반환. local timezone에 맞게 반환.
							ㄴ getUTCHours() : getHours()의 utc버전.
							ㄴ getTimezoneOffset()
								ㄴ utc시간에서 현재 local timezone 시간을 뺀 값을 분단위 integer로 반환.
									ㄴ ex ) 한국의 경우, +0900이므로, -9시간 즉, -540.

						</pre>

					</pre>
					ㅡ Array <button>more</button>
					<pre>
						ㄴ ~~~~~
						ㄴ 메소드 <button>more</button>
						<pre>
							ㄴ slice( [beginIdx [, endIdx]] )
								: beginIdx의 인덱스부터 끝까지, endIdx가 있을시, endIdx의 인덱스 전까지에 해당하는 부분을 자른 배열을 복사한 새 배열 반환.
									숫자, 문자열 등의 일반 데이터는 새로
						</pre>
					</pre>

				</pre>

			</pre>
			이벤트<button>더보기</button>
			<pre>
				ㅇ 이벤트<button>더보기</button>
				<pre>
					ㅡ 웹브라우저가 알려주는 html요소에 대한 사건발생의미.
					ㅡ js는 이 사건에 대해 특정 동작을 수행할수있다. (이벤트중심 프로그래밍)
					ㅡ 이벤트 타입 : 발생한 사건, 즉 이벤트의 종류를 나타내는 문자열.
					ㅡ 이벤트 명세?????
					ㅡ 개인적인정리)
						ㄴ 이벤트에서 고려해야할것 : 어떤요소에서 발생했는지, 어떤 이벤트인지(이벤트 타입), 어떤동작을 할것인지(리스너), 어떻게 등록할것인지.

					ㅡ 이벤트 리스너
						ㄴ 이벤트 발생시 그 이벤트 처리를 담당하는 함수를 말함. 이벤트 헨들러라고도함.

					ㅡ 이벤트 등록
						ㄴ 세가지 방법이있다.
						1. 자바스크립트 코드에 프로퍼티로 등록
							ㄴ ex) window.onload = function(){~~~}
							ㄴ function이 리스너부분. onload가 어떤 이벤트인지지정하는것.
							ㄴ 어떤 요소에서 발생하는지 특정하기가 어렵다.
							ㄴ 이벤트 종류당 한가지 리스너밖에 등록할수없다.

						2. html 태그 속성에 등록
							ㄴ ex) < p onclick = "alert(~~~)">
							ㄴ 요소특정이 가능하고, 1번과 달리 한종류의 이벤트장 한 리스너만있지않아도된다.
							ㄴ 대신 가독성이떨어진다함.

						3. addEventListener()이용
							ㄴ 형식) (*객체*).addEventListener( "(*이벤트명*)", (*리스너*), (*이벤트 전파방식*) );
							ㄴ ex)	var aaa= document.getElementById("(*id명*)");	=>id명에 해당하는 태그를 반환하여 aaa에 저장.
								aaa.addEventListener("click", ~~~);	=>해당 태그들에 click이벤트 리스너 등록. 클릭이벤트발생시 해당리스너가 실행되게됨.
							ㄴ 버전에따라 위함수가 지원되지않을경우 attackEvent()를 사용해야함.

					*document.getElementById()
						ㅡ 인자로준 id에 해당하는 요소하나를 반환한다.
						ㅡ document.getElementsByTagName()은 인자로넘긴 태그명에 해당하는 컬렉션을 반환한다고함.

					ㅡ이벤트 삭제
						ㄴ (*객체*).removeEventListener( "(*이벤트명*)", (*리스너*) );

					ㅡ 이벤트 호출
						ㄴ 리스너가 등록되면, 해당 요소에서 지정된이벤트발생시 브라우저가 해당 리스너를 호출한다.
						ㄴ호출하면서 '이벤트 객체'를 인자로 전달한다.
						ㄴ 이벤트객체에는 해당 이벤트에 대한 정보를 가지고 있으며, 어떤이벤트인지를 나타내는 type프로퍼티와 이벤트대상을 나타내는 target프로퍼티가있다.

					ㅡ 이벤트 호출순서
						ㄴ 하나의 이벤트종류에 여러개의 리스너가 있으면, 브라우저는 위 이벤트 등록방법에서 1,2로 등록한 이벤트리스너를 먼저 실행하며 그다음 3으로 등록한 이벤트리스너를 호출한다.

					ㅡ 이벤트 전파 (event propagation)
						ㄴ js에선 요소에서 이벤트가 발생하면 그 요소에서만 발생하지 않고 이벤트가 DOM구조를 타고 전파한다.
						ㄴ 버블링방식과 캡쳐링 방식이 있다.
						ㄴ ex)
							< body>
								< div class="one">
									< div class="two">
										< div class="three">
										< /div>
									< /div>
								< /div>
							< /body>
						ㄴ 버블링방식)
							ㄴ 이벤트가 발생한 요소로부터 부모요소쪽으로 root요소까지 이벤트가 전파되는 방식.
							ㄴ 위의 예에서, class 'three'에서 클릭 이벤트가 발생하면, three으로 이벤트전달된뒤, two, one, body...순서로
								이벤트를 받게된다(전파된다).
							ㄴ 물론 이 이벤트에 해당하는 핸들러가 있을시 이벤트를 받아서 처리하게되며, 없으면 아무것도일어나지않고 위로 전파하게된다.
						ㄴ 캡쳐링방식)
							ㄴ root요소로부터 이벤트가 발생한 요소까지 이벤트가 전파되는 방식.
							ㄴ 위의 예에서, class 'three'에서 클릭 이벤트가 발생하면, ... body, one, two, 그리고 three순서로
								이벤트를 받게된다.


					ㅡ 이벤트 기본동작의 취소
						ㄴ < a>요소는 클릭이벤트 발생시 해당 url로 이동하는 동작이 지정되어있다. 이런것들을 기본동작이라고한다.
						ㄴ preventDefalult()메소드나 returnValue프로퍼티를 이용하여 이런 기본동작을 취소할수있다.

					ㅡ 이벤트 전파의 취소
						???
				</pre>
				ㅇ 이벤트 객체<button>더보기</button>
				<pre>
					ㅡ js의 Event interface를 말한다.
					ㅡ 유저의 동작(마우스, 키보드 클릭 등), api호출, 임의의 이벤트 발생함수호출 등을 통해 생성되며, 특정 DOM타겟에게 전달된다.
					ㅡ 이 Event interface를 상속하는 많은 이벤트 인터페이스들이 존재한다.
						ㄴ ex) FetchEvent, FocusEvent, InputEvent, KeyboardEvent, MouseEvent
					ㅡ properties )
						ㄴ ~~~~~
						ㄴ target )
							ㄴ read only
							ㄴ 이벤트를 발생된 dom을 가리킨다.
						ㄴ currentTarget )
							ㄴ read only
							ㄴ 현재 이벤트객체를 받아서 가지고있는 dom을 가리킨다.
								ㄴ target과의 차이점 )
									ㄴ 클릭 이벤트가 버블링되어 전달되는경우를 생각해볼때, target은 클릭된 dom자체를 가리키지만,
										currentTarget은 클릭된 dom으로부터 이벤트객체가 전파되어 어느 이벤트핸들러가받게되면,
										해당 이벤트핸들러가 부착되어있는 dom을 가리키게된다.
									ㄴ ex)
										< li onclick="sampleFunc()"> < span> sample button < /span> < /li>
										ㄴ sample button을 클릭하게되면 span dom이 클릭되고, 이벤트를 발생시킨 dom은 span이므로,
											target은 항상 span dom을 가리키게된다.
										ㄴ span에서 발생한 이벤트가 전파되어 li에게 전달되면, li의 이벤트핸들러 sampleFunc()가 이벤트를 받아
											처리하게되고 이때 currentTarget은 li dom을 가리키게된다.
						ㄴ ~~~~~
					ㅡ method )
						ㄴ ~~~~~
						ㄴ preventDefault() )
							ㄴ 이벤트의 기본동작을 중지한다.
						ㄴ ~~~~~

				</pre>
			</pre>
			문서조작<button>더보기</button>
			<pre>
				ㅡ js의 일반적으로하는일중 하나는 문서구조를 어떤방식으로 조작하는것이다.
				ㅡ 그리고이것은 DOM과 Document객체를 사용하여 많이 수행된다.

				ㅇ DOM (Document Object Model)
					ㅡ DOM은 일종의 문서에대한 표현방식이다. 더 자세히말하면, DOM방식은 문서를 구조화된 nodes, 프로퍼티, 메소드를 가지고있는 객체로 표현한다.
						(일종의 객체지향표현방식이라 할수있다)
						ㄴ html을 예로들면, 여러태그들, < html>, < a>, < body>등을 객체로서 보고 문서를 인식하는 방식을 말함.
						ㄴ 그리고 이런방식은 프로그래밍언어가 문서의 내용을 다룰수있게 해준다.
						ㄴ DOM API를 통해 이 객체들을 다룰수 있다.
							ex) document.getElementById("~~");
						<img src="image/html dom 구조 예.png" style="height:300px; width:auto;">
					ㅡ 웹페이지가 로딩될때 브라우저는 위 그림과같은 HTML DOM을 내부적으로 생하며, 브라우저마다 각기의 방식으로 문서를 DOM으로 구현한다.

						<img src="image/html dom 구조 예2.png" style="height:300px; width:auto;">
					ㅡ 구조가 바로 위 그림과같이되어있다.
						ㄴ 어떤요소노드의 자식노드로 (만약 그 요소가 내용을 갖는다면) 가장먼저 그요소의 내용노드(즉, 텍스트노드)가 오고, 그다음에 나머지 자식요소들이온다.
						ex)	< ul id="list"> aaa
								< li> bbb < /li> ccc
								< li> ddd < /li> eee
								< li> fff < /li> ggg
							< /ul>
							=>이럴때 ul태그의 첫번째 자식노드는 바로아래있는 li태그가 아닌 ul의 내용인 "aaa"가 된다. li는 그다음자식노드.
							그림으로설명하면,
								ul
									ㄴ ul의 텍스트("aaa")		=>첫번째자식노드
									ㄴ 첫번째 li				=>두번째자식노드
										ㄴ li의 텍스트("bbb")	=>...
									ㄴ li뒤의 텍스트 노드("ccc")
									ㄴ 두번째 li
										ㄴ li의 텍스트("ddd")
									ㄴ 두번째li뒤의 텍스트("eee")
									...
							이런식이다.
						ㄴ NodeList건 HTMLCollection이건 이게 DOM구조이기때문에 이걸따름.

					ㅡ HTML문서에서 dom구조는 node tree형태이며, 각 요소들, 즉 객체는 node에 대응된다. 속성,또한 노드이다.

					ㅡ 객체 지향 구조이기때문에 Document인터페이스, HTMLDocument인터페이스, HTMLElement인터페이스, Element 클래스, Node 인터페이스,
						등 여러 클래스와 인터페이스가 상속,구현관계에 있으며 이들이가지고있는 프로퍼티와 메소드로 문서를 조작한다.
						ex) < talbe> 태그에 해당하는 노드는 Node인터페이스 및 HTMLElement인터페이스 Element클래스 등 여러가지를 가지고있다.

				ㅇ 요소 선택하기
					ㅡ DOM 요소를 조작하기위해선 우선 해당요소를 선택하고 변수에 참조를 저장해야한다.
					ㅡ 가장 최신 메소드로 document.querySelector( (*선택자*) ) 가 있다. 선택자에 해당하는 요소중 첫번째요소에해당하는 Element객체를 반환해준다. 없으면 null반환.
						ㄴ 선택자부분은 css의 선택자와 같은 방식으로 써야한다. 아닐경우 SYNTAX_ERR발생
						ㄴ Document.querySelectorAll( (*선택자*) )을 이용하여 선택자에해당하는 모든요소를 가져올수도있다. NodeList형으로 반환한다.
						ㄴ 좀 오래된메소드로는
							document.getElementsByTagName(태그이름) : 해당 태그 이름의 요소를 모두 선택함.
							document.getElementById(아이디) : 해당 아이디의 요소를 선택함.
							document.getElementsByClassName(클래스이름) : 해당 클래스에 속한 요소를 모두 선택함.
							document.getElementByName(name속성값) : 해당 name 속성값을 가지는 요소를 모두 선택함.
							또는 프로퍼티로 있는 객체집합을 통해 요소를 선택할수도 있다( document.images, document.links 등 각각 < img>요소와 href속성을
							가지는 < a>와 < area>요소를 모두반환함.)
					ㅡ 요소의 참조를 저장한 변수를 이용해 해당요소의 속성과 내용등을 조작할수있다
						ex)	var aaa=document.querySelector("a");
							aaa.textContent="~~~";	=>요소의 내용 변경.
							aaa.href="~~~"		=>속성 href값 변경.
					ㅡ 'Node 인터페이스'의 프로퍼티들로 요소에 접근하거나 요소의 정보를 알수있다.
						ㄴ parentNode : 부모노드를 반환.
						ㄴ childNoodes : 자식노드 리스트 반환.
						ㄴ firstChild : 첫번째자식노드
						ㄴ lastChild : 마지막자식노드
						ㄴ nextSibling : 다음 형제노드
						ㄴ previousSibling : 이전 형제노드
						ㄴ nodeName : 노드 고유이름 대문자로. 요소노드에선 태그이름, 속성노드에선 속성이름, 텍스트노드에선 #text
						ㄴ nodeValue : 노드의 값. 요소노드에선 undefined, 속성노드에선 속성값, 텍스트노드에선 해당텍스트문자열.
						ㄴ nodeType : 노드 고유의 타입을 숫자로 저장. ex) 요소노드는 1, 속성노드는 2 등등..

				ㅇ 노드만들기, 배치하기
					ㅡ 요소노드만들기
						document.createElement( (*요소이름*) ) : 이름에 해당하는 요소를 생성해 반환. Element객체 반환.
					ㅡ 속성노드만들기
						document.createAttribute( (*속성이름*) ) : 이름에 해당하는 속성을생성해반환. attribute 노드인 Attr객체반환.
							ex)	var atr= document.createAttribute(~~);	=>해당속성의 참조정보를 저장.
								atr.value="~~";							=>속성에대해 value프로퍼티에 값을저장함으로서 속성값부여. value는 Attr객체의 프로퍼티
								(*속성넣으려는요소*).setAttributeNode(atr);	=>만든속성을 원하는 요소에 setAttributeNode()메소드로 삽입.
					ㅡ 텍스트노드만들기
						document.createTextNode("~~") : 해당내용을가지는 텍스트노드생성반환.

					ㅡ 노드의 배치 및 추가하기
						ㄴ (*목표노드*).appendChild( (*추가할노드*) )
							: 추가할노드를 목표노드의 자식노드리스트의 맨 마지막에 추가함. Node인터페이스의 메소드.
						ㄴ (*목표노드*).insertBefore( (*추가할노드*), (*기준노드*) )
							: 추가할노드를 목표노드의 자식노드리스트에서 기준노드 바로앞에추가함. Node인터페이스의 메소드.
						ㄴ (*텍스트노드*).insertData( (*오프셋*), (*새로운내용*) )
							: 텍스트노드에 내용을  추가하는메소드. 오프셋은 기존텍스트에서 몇번째위치에추가할지를나타내며 0부터시작한다.

				ㅇ 노드 이동, 삭제
					ㅡ appendChild를 이용하면 새로추가하는것뿐만아니라 이동도가능하다. 기존에 있는 요소를 이 메소드의 인자로넘겨주면 그요소의 위치를 이동시킬수있다.
						ex)	var aaa=document.querySelector("body");
							var bbb=document.querySelector("div");
							aaa.appendChild(bbb);					=>div요소의 위치가 body요소의 자식리스트중 가장 마지막부분으로 이동된다.
					ㅡ 노드삭제
						ㄴ (*목표노드*).removeChild( (*삭제할노드*) ) : 목표노드의 자식노드중에서 삭제할노드를 삭제.
						ㄴ (*목표노드*).removeAttribute( (*삭제할속성명*) ) : 목표노드의 속성중 속성명에해당하는 속성제거.

				ㅇ 노드 복제
					ㅡ (*복제할노드*).cloneNode( (*자식노드복제여부*) ) : 자식노드복제여부에따라 복제할노드를 복제하여 반환.

				ㅇ 스타일 조작
					ㅡ 'document.stylesheets프로퍼티'에는 'CSSStyleSheet 객체'의 배열이 담겨있어 이를이용하면 스타일시트를 조작할수있다. 하지만 어렵고 옛날방식이라함.
					ㅡ 더 편한방법으로 각 요소들이 가지고있는 'HTMLElement.style프로퍼티'를 이용하면 스타일속성을 인라인형태로 설정할수가있다고한다.
						ex)	(*요소*).style.color="red";	=>스타일속성의 color를 red로설정.
							(*요소*).style.padding="10px"; 등등.
					ㅡ 또는 요소에 속성을 설정하는  메소드를 통해 스타일시트를 설정해줄수있다(class나 id같은)
						ex)	(*요소*).setAttribute( '(*추가할속성이름*)', '(*속성값*)' )
							aaa.setAttribute('class', 'character');

				*NodeList 객체와 HTMLCollection 인터페이스
					ㅡ NodeList는 node의 콜렉션, HTMLCollection은 Element의 콜렉션이다.
					ㅡ 둘다 기능은 비슷.
					ㅡ node는 dom에서 최소구성요소단위. element는 node의 종류중 하나인 element에 해당하는 node. element node외에도 text node,
						attribute node등이있다. 그중 하나일뿐.
					ㅡ 요소 선택자들(DOM구조에서 document.getElementsByName나 .childNodes같은)을 통해 반환받을때 반환할 노드가 한개가 아닌경우 보통
						이 두 타입중 하나를 반환하게된다.
						ㄴ브라우저마다 조금씩 차이가있는경우가있는것같다.
					ㅡ사용법은 두개가 비슷하여 큰의미는없을듯하다. 그래도하자면,
						ㄴ document.getEelementsByClassName() : HTMLCollection을 반환.
						ㄴ document.getEelementsByTagName() : HTMLCollection을 반환.
						ㄴ document.getEelementsByTagNameNS() : NodeList반환. (인터넷익스플로어에선 HTMLCollection반환)
						ㄴ Node 인터페이스의 프로퍼티 childNodes : NodeList반환.
						ㄴ document.querySelectorAll() : NodeList반환.


			</pre>
			js의 API<button>더보기</button>
			<pre>
				ㅡ 흔히 알고있는 그 API를 말한다.
				ㅇ js API 분류)
					자바스크립트에는 많은 api들이 있고, 이들은 보통 두종류로 나뉜다고한다.
					ㄴ Browser apis)
						ㄴ 브라우저에 있는 api들
						ㄴ 예로, Web Audio API가 있고, 볼륨조절, 오디오효과적용 등 브라우저에서 오디오를 컨트롤하는 js construct를 제공한다.
					ㄴ Third party APIs)
						ㄴ 기본적으로 브라우저에 깔려있는게 아닌 따로 설치를해야하는 api들
						ㄴ Twitter API같은 것들이 있다.

				ㅇ API 이외의 것들)
					그외에 api는 아니지만 관련된것들
					ㄴ js libraries) 사용자가 추가할수있는 커스텀 함수를 포함하는 js파일들. 제이쿼리나 React등이 있다.
					ㄴ js frameworks) 앵귤러나 Ember등이 있으며, html,css,js와 기타 다른 기술들이 패키지화되는 경향이 있다. 설치하여 전체 웹 어플리케이션을
						작성할수있게한다. 라이브러리와의 차이점은 '제어의 역전'이라한다. 라이브러리를 사용할때는 개발자가 제어권을가지고 메소드를 호출하지만,
						프레임워크에선 프레임워크가 제어권을 가지고 개발자의 코드를 호출한다고한다(아직무슨말인지모르겟다)

				ㅇ 주요 API들
					ㅡ browser APIs)
						무수히 많은 browser api들이 있지만 주로 많이 쓰이는 api들은 다음과같다.
						ㄴ document 조작 api) 알고있는 DOM 조작 api들이 이에 해당한다. document.~~하는거
						ㄴ 서버로부터 데이터 fetch api) 페이지 일부를 업데이트하거나 할때 사용되는 api. XMLHttpRequest와 FetchAPI등을 포함하며, 흔히 Ajax을 말함.
						ㄴ 그래픽을 그리고 조작하는 api) Canvas, WebGL등이 있고, 도형그리거나 이미지 삽입하거나 필터적용하거나 할때 쓰이는것들.
						ㄴ 오디오, 비디오 api)
						ㄴ Device api) 하드웨어 장치로부터 데이터를 받는데 쓰이는 api
						ㄴ Client-side storage api) 클라이언트쪽에 데이터를 저장하는 기술.

					ㅡ third-party APIs)
						역시 무수히 많은 third-party api들이 있지만 유명한것들은 다음과같다.
						ㄴ Twitter api
						ㄴ Map api) Mapquest나 Google Maps API처럼 지도와관련된것들을 할수있게해주는 api
						ㄴ FaceBook suite of APIs)
						ㄴ Telegram APIs, YouTube API, Pinterest API 등등..


				ㅇ api들은 어떻게 작동하는가?
					ㅡ api들은 객체로 되어있다.
						ㄴ api들은 하나 또는 그이상의 js object들을 사용하며, 이 객체들은 api가 사용하는 데이터를 담는역할(객체의 프로퍼티로서)과 api가 수행할
							기능을 담는역할(객체의 메소드로서)을 한다.
					ㅡ Web Audio API를 이용한 사례)
						ㄴ api의 대표적인 객체)
							AudioContext : 브라우저에서 오디오를 조작할때사용하는 audio graph를 나타내는 객체. 오디오조작을 위해쓰이는 많은 메소드와 프로퍼티를가지고있다.
							MediaElementAudioSourceNode : 사용자가 재생하고 조작하기를원하는 오디오를 가지고있는 < audio>태그를 나타내는 객체
							AudioDestinationNode : 오디오의 목적지를 나타내는 객체. 목적지란 오디오가 실제로 출력될 device같은걸 말함.스피커 헤드셋같은.
					ㅡ API들을 사용할때 entry point를 지정해야한다. Web Audio API같은 경우, AudioContext객체를 생성할때가 entry point가 된다.
						DOM API의 경우 Document객체를 생성할때이고.
					ㅡ API들은 대부분 이벤트를 활용한다.
					ㅡ API들은 각자의 추가적인 보안메커니즘을 가진다.

				ㅇ Web API들 상세 <button>더보기</button>
				<pre>
					ㅡ FormData <button>더보기</button>
					<pre>
						ㅡ form태그의 데이터들을 쉽게 전송할 수 잇게 해주는 api
						ㅡ 간단 사용법 )
							ㄴ ex)
								const formData = new FormData();//FormData 객체 생성후,

								formData.append("id",this.state.companyId);	//append( (*파라미터명*), (*값*) )을 통해
										인자를 넣어주면된다.
								formData.append('memberId', this.state.memberId);

								fetch(this.context+"/v2/api/manage/company",{
									method:'PUT',
									body: formData 		//request body에 formData를 통째로 넣어주면 request의 header가 자동으로
															설정된다.
								})
									.then(res => res.json())
									.then(
										(result) => {
											/*this.setState({
												result:result
											})*/
										}
									)
						ㅡ append( (*파라미터명*), (*값*) )
							ㄴ request에 파라미터 추가하는 메소드
							ㄴ (*값*)부분에 파일을 넣을 수 있다.
							ㄴ (*값*)부분에 파일이 아닌경우 String형태로 저장된다.
								ㄴ js의 null이나 undefined를 저장해도 "null"과 같은식으로 문자열형태로 저장된다.
						ㅡ ~~~~~
						ㅡ 실무 )
							ㄴ multipart/form-data을 js에서 ajax으로 전송시 사용하는듯하다.

					</pre>
					ㅡ DOM <button>더보기</button>
					<pre>
						ㄴ
					</pre>
					ㅡ Window<button>more</button>
					<pre>
						ㄴ ~~~
						ㄴ instance method
							ㄴ ~~~
							ㄴ close()
								ㄴ 해당 window를 닫는 메소드.
								ㄴ 보안상의 이유로 자기 자신을 닫을 수 없다.
									var w = window.open()을 통하여 새로 열은 window만 닫기 가능.
								ㄴ tip )
									ㄴ 팝업으로 띄운 창을 js 상에서 닫고 싶으면 window.postMessage()로 부모 window에
										메세지를 보내 닫도록 처리 가능. postMessage() 부분 참고.
							ㄴ open()
								ㄴ

					</pre>

				</pre>
			</pre>
			AJAX<button>더보기</button>
			<pre>
				ㅇ ajax 기술의 배경과 장점
					ㅡ 고전적방식인 요청을 보내고 그에대한 응답을 받아서 컴퓨터에 출력하는 방식은 사용자가 페이지으 일부를 업데이트하고자할때 전체페이지를 다시
						받아야하기때문에 낭비가심하고 낮은 사용자 경험을 제공한다고한다.
					ㅡ 이런 문제를 해결해주는 api가 XMLHttpRequest와 Fetch API이다. 이것들은 웹페이지가 작은조각의 데이터(html,xml,json등같은)를
						요청하여 원하는 일부에서만 업데이트할수있게해준다.
					ㅡ 장점)
						ㄴ 웹페이지가 서버에서 이용가능한 특정자원을 위해서 직접 HTTP request를 만들수있게해주고 그 데이터를 출력전에 가공할수있게해준다.
						ㄴ 일부만 업데이트를 하기때문에 훨씬빠르다.
						ㄴ 더 적은 데이터를 주고받으므로 bandwidth의 낭비가 적다.(데스크탑에선 별로 해당되지않는문제이지만 모바일이나 개도국에선 중요한 이슈라고한다)
					ㅡ 더 빠른 속도를 위해, 몇몇사이트들은 처음 요청이 들어왔을때, 데이터를 사용자에 컴퓨터에 저장해놓느낟고한다. 이후 방문 하게되면 데이터를 서버로부터
						다운받는게 아니라 저장된 로컬버젼을 사용하고, 업데이트가 필요할때만 리로드하는 방식.

				ㅇ Promise 객체
					ㅡ 개요) 비동기적 작업의 결과(성공인지 실패인지)를 나타내주는 객체.
					ㅡ 배경) 이전의 비동기 작업 코딩방식이 '콜백 헬'이라부르는 문제가 심각하여 해결책으로서 나온 방법이라함.
					ㅡ 메소드와 프로퍼티들을 사용하여 이 비동기적 작업들을 훨씬더 깔끔하고 편하게 프로그래밍할수있다.
					ㅡ Promise chainning : 여러 비동기 작업이 순차적으로 이전의 작업결과를 이용해 수행되어야할때 Promise chain을 이용해 이를 구현할수있다.
						ㄴ ex)	const promise = doSomething().then(successCallback, failureCallback);
							=> doSomething()을 실행하고 반환된 Promise에 대해 then()을 호출하는식으로 이전의 작업결과를 이용한 순차적 비동기작업을 수행하도록 할수있다.
						ㄴ 체인안에서 각각의 Promise는 어떤 비동기 작업의 완료를 의미한다. (비동기작업이 완료되면 인자로넘어간 콜백함수가 실행되고 또다른 Promise가 반환되는거니까)
						ㄴ 예전에 Promise가없었을때는 이런 비동기작업을 처리하는부분에서 '콜백 헬'이 생겨 어려움이있었는데, 이제는 promise chain을 이용해
							이렇게 then()을 추가하기만 하면된다.

					ㅡ 생성자) new Promise(executor)
						ㄴ 함수를 인자로 하나 받는다(executor라고 부르겟다)
						ㄴ 이 executor함수는 인자로 resolve와 reject(함수명은 자유)함수를 가진다.
						ㄴ executor는 생성자가 종료되기도 전에 바로 실행된다.
						ㄴ executor가 완료되면서 resolve가 호출되어 promise가 resolved되거나, 에러가 발생하면 reject가 호출되며 promise가 rejected된다.
						ㄴ executor의 리턴값은 무시된다.

					ㅡ 프로퍼티)

					ㅡ 메소드)
						ㄴ then( (*응답성공했을시 실행되는함수*), (*응답실패했을시 실행되는함수*) )
							ㄴ 비동기작업의 결과를 나타낸다는 Promise에 성공과 실패에 따른 핸들러를 붙이는기능.
							ㄴ 두번째 인자는 생략가능하다.
							ㄴ 성공적으로 수행되었을때 첫번째 인자의 함수가 실행되며, 실패했을때는 두번째인자의 함수 실행.
							ㄴ 첫번째인자는 자동적으로 응답받은 response(Response인터페이스)를 인자로 받는다고한다. 매개변수이름은 자유.
							ㄴ 반환값)
								기본적으로 Promise객체를 반환하지만, 인자로 넘어간 함수의 반환값에따른 규칙이있다한다.
								ㄴ value를 반환하면, 반환되는 Promise는 그 value로 resolved된다한다.
								ㄴ 아무것도 반환하지않으면, Promise는 undefined로 resolved된다한다.
								ㄴ 에러를 반환하면, Promise는 그 에러를 던지며 rejected된다
								ㄴ 이미 fulfilled된 promise를 반환하면, 반환되는 Promise는 이 promise의 값으로 fulfill된다.
								ㄴ 이미 rejected된 promise를 반환하면, 반환되는 Promise는 이 promise의 값으로 rejected된다.
								ㄴ 다른 pending중인 promise를 반환하면, 반환되는 Promise의 resolution과 rejection은 pending중인 promise의
									resolution과 rejection뒤에 대기한다.
						ㄴ catch( (*함수*) )
							ㄴ promise에 reject 핸들러 콜백함수를 붙이는 기능. then(null, (*응답실패했을시 실행되는함수*) )와 같다고 보면된다.

				ㅇ XMLHttpRequest 객체
					ㅡ 서버와 상호작용하는 객체이다.
					ㅡ 프로퍼티)
						ㄴ readyState : XMLHttpRequest객체의 상태(생성되었거나, open()되었거나 등)을 나타내는 값을 가지는 프로퍼티. 다음의 5가지값을가짐.
							ㄴ 0 (UNSENT) : 생성됨. 아직 open()되지는 않음.
							ㄴ 1 (OPENED) : open()이 호출됨.
							ㄴ 2 (HEADERS_RECIEVED) : send()가 호출되고, header가 이용가능.
							ㄴ 3 (LOADING) : 다운로딩
							ㄴ 4 (DONE) : 작업이 완료됨.
						ㄴ onreadystatechange : 콜벡함수를 저장하는 프로퍼티. 이벤트 핸들러역할이다. 'readyState'프로퍼티의 값이 바뀔때마다 호출된다.
												(여기서 등록한 콜백함수에서 readyState의 값을 if문으로 체크하면서 각각의 경우 실행할 내용을 정의하는식으로사용)
						ㄴ responseType : enumberated된 값으로, response의 type을 결정한다.
						ㄴ response : 위 responseType 프로퍼티에 따라  ArrayBuffer, Blob, Document, JavaScript object, DOMString
										중 하나를 반환한다. response의 body내용을 담고있다.
					ㅡ 메소드)
						ㄴ open( (*어떤 HTTP request 메소드인지*), (*요청할 url*) ) : 보낼 요청을 초기화하는 역할을한다.
						ㄴ send() : 초기화한 url로 요청을 보낸다.

				ㅇ Fetch API
					ㅡ 기본적으로 XMLHttpRequest와 같은기능을 하지만 더 사용하기좋게 최근에 나온 API.
					ㅡ 제공하는 인터페이스들)
						1. WindowOrWorkerGlobalScope.fetch( (*url*) )
							ㅡ Fetch API에서 제공하는 메소드로, 이 메소드가 entry point이다.
							ㅡ XMLHttpRequest의 open()과 send() 기능을 한다.
							ㅡ Promise객체를 반환한다.

						2. Header
						3. Request
						4. Response 인터페이스
							ㅡ request에 대한 response를 나타내는 인터페이스로.
							ㅡ 응답의 내용과 이를 처리할수있는 프로퍼티와 메소드들을 가지고있다.
							ㅡ 직접 Response()생성자를 이용해 만들ㅇㅓ도되지만 보통 fetch()같은 메소드의 반환값으로 받아서 많이쓰게된다.
							ㅡ Body mixin을 구현하므로 이안에있는 프로퍼티와 메소드를사용할수있다.
							ㅡ 프로퍼티)
							ㅡ 메소드)
								ㄴ (Body mixin의) text() : 응답 스트림을 가져다 끝까지 읽고, 그것을 USVString으로 resolve된 Promise를 반환한다.
												XMLHttpRequest의 프로토타입 responseType을 'text'로 설정하는 기능과 같다한다.
								ㄴ (Body mixin의) json() : 응답 스트림을 가져다 끝까지 읽고, 응답의 body를 json형태로 파싱한 결과로 resolve된
												Promise를 반환한다.

					* mixin
						ㅡ 클래스 또는 인터페이스. 둘중 어느것이라고 하기어려운것.
						ㅡ 가지고있는 프로퍼티나 메소드의 일부,또는 전부가 구현되지않은상태이다.
						ㅡ 때문에, 이 구현을 다른 클래스나 인터페이스가 해야함.
						ㅡ 여러 인터페이스가 쓰이는 APIs만들때 설계상의 이점이 있다고한다.

					ㅡ 들어있는 mixin)
						Body mixin
						ㅡ request, response의 body를 나타내는 mixin.
						ㅡ request, response의 contentType을 설정하거나 이것이 어떻게 다루어져야하는지를 설정하게해주는 mixin.

				ㅇ AJAX 사용하기
					1. XMLHttpRequest를 이용)
						ㅡ XMLHttpRequest를 이용한 기술은 꽤 오래된 기술이다.
						ㅡ 예제를 만들어보며 설명.
						<a href="code/ajax_XMLHttpRequest이용.txt" target="_blank">XMLHttpRequest 예제</a>
						ㅡ 네트워크로부터 데이터를 받는것은 '동기적'작업이다.
						ㅡ XMLHttpRequest를 사용할때, onload 이벤트핸들러를 사용할수있다. onload 이벤트핸들러는 load 이벤트가 발생하였을때 실행되며,
							즉 응답을 반환받았을때를 말한다.
						ㅡ XMLHttpRequest객체의 response프로퍼티를 이용해 응답받아온 데이터를 이용할수있다.

					2. Fetch를 이용)
						ㅡ fetch()를 호출하여 url로 요청을 보낸다.
						ㅡ ex) 위 XMLHttpRequest 예제에서 updateDisplay(verse)함수 부분만 다르다.
							function updateDisplay(verse) {
								//< select>에 의해 선택된 내용을 불러오려는 텍스트파일이름과 같이 변경해주는부분.('Verse 1'을 'verse1.txt'이런식으로)
								verse = verse.replace(" ", "");
								verse = verse.toLowerCase();
								var url = verse + '.txt';

								//Fetch API를 이용해 처리.
								fetch(url).then(function(response) {	=>fetch()로부터 반환받은 Promise에대해 then()을호출.
								response.text().then(function(text) {	=>응답에 대해 text()를 호출하고 반환받은 Promise에대해 다시 then()호출.
									poemDisplay.textContent = text;		=>반환받은 내용을 페이지의 내용에 삽입해줌.
								});
								});
							};

						ㅡ 반환받은 promise객체에 대해 then()을 호출하며 응답성공시 실행할 함수를 정의하여 인자로 넘긴다.
							ㄴ XMLHttpRequest예제에서 onload를 통해 응답에대해 이벤트핸들링을 설정하는것과 같은기능.
						ㅡ 방금 정의한 함수가 자동으로 받은 Response인터페이스에 대해 tex()를 호출하여 contentType을 설정한다.
						ㅡ text()에서 반환받은 Promise객체에 대해 다시 then()을 호출하여 인자로 넘기는 함수에서 응답내용을
							출력함.
						ㅡ tip)
							ㄴ ex)	fetch(url).then(function(response) {
									return response.text()
									}).then(function(text) {
									poemDisplay.textContent = text;
									});
							ㄴ 위와 같은 형태로 많이 작성한다고한다.(이 예제 이전에 나온예제보다) 더 보기좋기때문.
							ㄴ text()에서 promise를 반환하므로 이전예제에서는 text()바로뒤에 promise에 대해 then()을 붙여서 구문을 중첩시켯지만,
								이 예제는 then()이 인자로 전달한 함수의 반환값과 같은 promise를 반환한다는것을 이용해, then()뒤에 반환한 promise에
								대해 또 then()을 호출하는식으로 코딩을함.

					ㅡ 둘중 어떤방식을 이용해야하나)
						ㄴ XMLHttpRequest방식은 오래된방식이기때문에 많은곳에서 지원이 되는기술이긴하다.
						ㄴ Fetch방식은 최신의 방식으로 앞으로 계속 쓰임이 늘어날것이다.

				ㅇ 기타
					ㅡ 한계?) AJAX기술은 요청을 하고 응답을 받아올수는 있지만, 서버단에서 하는것처럼 복잡한작업은 이걸이용해서 할수없는듯하다.
						결국 돌아가는건 브라우저상에서 자바스크립트 안에서 돌아가는것이기때문에. 단순한 데이터 받아서 그거 사용하는정도.

			</pre>
			클라이언트 저장소 <button>more</button>
			<pre>
				ㄴ 브라우저단에서 웹사이트가 사용자의 컴퓨터에 데이터를 저장할 수 있게 해주는 기능들에 대해 알아봄.
				ㄴ 흔한 사용 케이스 )
					ㄴ 개인 맞춤 데이터 저장.
					ㄴ 웹사이트에서의 이전 활동 기억.
					ㄴ 사이트에서 사용하는 데이터 및 파일 사전 저장. 이를 통해 다운 네트워크량, 속도 개선.
					ㄴ 오프라인에서 사용 가능.
				ㄴ 방법 )
					ㄴ Cookie )
						ㄴ 가장 초기에 사용하던 방식. 현대엔 이보다 더 쉽고 유용한 방법들 존재.
						ㄴ http 항목이나 서버 쿠키 항목에서 자세히 설명.
					ㄴ Web Storage API <button>more</button>
					<pre>
						ㄴ 브라우저단에 key value 형태의 저용량 데이터 저장하는 기능 제공.
						ㄴ 문자열 형태만 저장 가능.
							ㄴ 숫자, 객체 등 저장시, 문자열로 변환되어 저장. 객체는 '[object object]' 같이 나옴.
						ㄴ Storage라는 인터페이스를 통하여 동작. Storage에는 sessionStorage 또는 localStorage가 있고 이들을 이용.
						ㄴ localStorage
							ㄴ 데이터 만료기한 없음. 데이터는 js로 임의로 삭제하거나 브라우저 캐시를 지우거나 로컬 저장 데이터를 지우지 않는 한 영구 저장.
							ㄴ 용량 크기는 대략 5MB
							ㄴ window 객체의 localStorage 프로퍼티를 통하여 해당 origin의 local storage객체에 접근 가능. (window.localStorage)
							ㄴ ??? UTF-16 string format을 사용한다? 문자당 2바이트 사용.
							ㄴ 프로토콜에 따라서도 별개의 storage를 가진다. (즉, 같은 주소라도 http와 https가 각각의 storage를 가짐)
							ㄴ 'file:' 형태의 url에 대해서는 localStorage 동작에 대해 정해진게 없어 브라우저에 따라 다를 수 있다.
							ㄴ SecurityError
								ㄴ 해당 origin의 scheme, host, port 쌍이 유효하지 않으면 해당 오류 발생.
									ㄴ ex ) same-origin 정책을 위반했거나 등 또는 scheme가 file:, data: 등이거나.
								ㄴ ??? 정책을 위반하는 경우? 유저가 브라우저에 페이지에서 데이터를 영구저장하는걸 막아놨거나 등.
						ㄴ sessionStorage
							ㄴ 페이지 세션 종료시 데이터 유지기간 만료. 즉, 브라우저(또는 탭)가 닫히기 전까지만 데이터 유지.
							ㄴ window 객체의 sessionStorage 프로퍼티를 통하여 해당 origin의 session storage객체에 접근 가능. (window.sessionStorage)
							ㄴ 세션 및 유지기간
								ㄴ 브라우저 탭에서 document 로드시, 고유의 page session 생성. 해당 탭에 유일하게 매핑.
								ㄴ 여러 탭이 origin이 같아도 각각의 sessionStorage 소유.
								ㄴ 탭 복사시, sessionStorage 복사하여 생성.
								ㄴ 해당 탭, 브라우저 창이 열려있는 동안 session 유지. 탭, 브라우저 종료시 sessionStorage는 clear됨.
							ㄴ 그 외 localStorage와 동일.
						ㄴ storage 이용가능 여부 확인
							ㄴ 대부분의 브라우저에서 지원하겠지만, 아닌 경우도 있으므로 확인 필요.
						ㄴ 사용법 )
							ㄴ (*Storage*).setItem( (*키값*), (*값*) )
								ㄴ web storage에 key-value쌍 데이터 저장.
							ㄴ (*Storage*).getItem( (*키값*) )
								ㄴ 저장소에 있는 데이터 중 (*키값*)과 동일한 키값을 가진 데이터 반환. 없음 null.
							ㄴ (*Storage*).removeItem( (*키값*) )
								ㄴ (*키값*)에 해당하는 key-value쌍 데이터 삭제.
							ㄴ (*Storage*).clear()
								ㄴ 저장소의 모든 데이터 삭제.
							ㄴ (*Storage*).key( (*idx*) )
								ㄴ storage의 (*idx*)번째 키값 반환.
								ㄴ ??? (*idx*)에 매핑되는 키의 순서는 user-agent에 따라 다르다?
						ㄴ storage event
							ㄴ 'StorageEvent' 이벤트.
							ㄴ 저장소 데이터에 변경사항 발생시 발생하는 이벤트.
							ㄴ 같은 origin의 다른 페이지에서 저장소에 변경사항 발생시에만 발생한다. (origin 같으면 같은 저장소 사용함)
								즉, 저장소의 데이터를 변경하는 페이지에서는 발생하지 않는다.
							ㄴ sessionStorage에선 발생하지 않는다.
							ㄴ ex )
								window.addEventListener("storage", (e)=>{  // 'storage'란 키워드로 이벤트등록.
									e.key;  // 변경된 키-값 데이터의 키.
									e.oldValue;  // 변경된 키-값 데이터의 변경 전 값.
									e.newValue;  // 변경된 키-값 데이터의 변경 후 값.
									e.url;  // 데이터를 변경한 document의 url.
									e.storageArea;  // Storage 객체.
								} )
					</pre>
					ㄴ IndexedDB API )
						ㄴ ??? database 시스템같이 복잡한 데이터 저장?
						ㄴ 저장 가능한 데이터 타입 : 문자열, 숫자 등의 기본적 데이터 타입, 비디오, 이미지 등
						ㄴ ??? db를 생성, 그 db안에 여러개의 'object store'를 생성?,
							'object store'은 db의 table과 유사하며, 안에 object들을 포함하고 있는 형식?
						ㄴ ~~~

					ㄴ Cache API )
						ㄴ 특정 HTTP 요청에 대한 응답을 저장해 놓기 위해 만들어짐.
						ㄴ 웹사이트의 asset 파일들을 저장해 놓는데 유용.
						ㄴ ??? 필수는 아니지만 보통 'Service Worker API'와 함꼐쓰인다함.

			</pre>
			기타<button>더보기</button>
			<pre>
				ㅇ 전역객체
					ㅡ js에서 미리정의된 객체로, 전역 프로퍼티나 전역함수를 담는공간의 역할을 한다.
					ㅡ 전역범위에서 this연산자를통해 접근가능하다.
					ㅡ 전역객체는 코드상에서 생략이 가능하다.
						ex)	document.~~~	=	window.docucment.~~~

				ㅇ 래퍼객체
					ㄴ js에서 원시타입은 객체가 아니므로 프로퍼티를 가질수없다. 그런데도 원시타입의 값에 대해 프로퍼티에 접근하려하면 자동적으로 그 원시타입에 해당하는
						객체가(Number, String, Boolean, Symbol) 원시타입의값을 감싸 객체가 되어 프로퍼티를 사용할수있게해준다.
					ㄴ 사용이 끝나면 이 생성된 객체는 사라지고 값은 다시 원시타입이 되며, 이때 이렇게 잠깐 생겼다사라지는 임시객체를 '래퍼객체'라고한다.
						ex)	var str="문자열;	=>string형 원시타입값이다.
							var len = str.length;	=>원시타입인str은 length란 프로퍼티를 가질수도없고 사용할수도없지만, 이때 자동으로
														new String(str)을 호출한것같은 동작이 일어나 str이 String객체가 된다. 이때 이 객체가 래퍼객체.
				ㅇ 표준객체
					ㅡ 기본적으로 있는 js에서 자주쓰이는 객체를 말한다.
					ㅡ 각 객체에 있는 프로퍼티와 메소드들은 <a href="https://developer.mozilla.org/ko/docs/Web/JavaScript/Reference">참조</a>에
						자세하게 나와있다. 이것들은자세하게안썼으니 이걸보면서 참고하자.
					1. Number 객체
						ㅡ 숫자를 이 객체로 표현할수도있다.
						ㅡ 리터럴 숫자와 Number객체는 당연히 다른것. 이걸로 표현할수도 있는것뿐.
						ㅡ 메소드)
							ㄴ Number.parseFloat() : 인자로넘ㅇ어오는 문자열을 파싱하여, 문자열에 포함된 숫자부분을 실수형태로 반환. 숫자가 여러개면 첫번째숫자만반환.
							ㄴ Number.parseInt() : 위와동일. 정수로 반환하는것만다름.
							ㄴ Number.isNaN() : 인자로받은 '숫자'가 NaN인지 확인. 맞으면 true반환.
							ㄴ Number.isFinite() : 인자로받은 '셀수있는값'이 유한한수인지확인. 유한하면 true반환.
							ㄴ Number.isInteger() : 인자로받은값이 정수이면true.
							ㄴ Number.isSafeInteger()
					2. Math객체
						ㅡ 수학상수 및 함수에대한 프로퍼티,메소드를 가지고있다.
					3. Date객체
						ㅡ 날짜와 시간과 관련된 프로퍼티와 메소드제공.
					4. String객체
						ㅡ 문자열과 관련된 프로퍼티,메소드를 가지고있다
						ㅡ 문자열위치찾기, 해당인덱스에있는문자반환, 문자열추출, 분리,결합, 대소문자변경, 공백제거, 등의기능이있다.
					5. Array 객체
						ㅡ  배열과 관련된 프로퍼티, 메소드를 제공.

				ㅇ BOM(Browser Object Model)
					ㅡ 모르겟다. 그냥 브라우저창 관련 기능을 제공해주는 객체정도로만 알고있자.
					ㅡ window객체가 있다.
						ㄴ js에서는 모든객체, 전역함수, 전역변수가 window객체의 프로퍼티가된다한다
						ㄴ js에서는 전역범위에 해당하는 window를 생략할수있다.
						ㄴ 함수 )
							ㄴ prompt() : 윈도우 창에서 데이터를 입력받고 이값을 반환해주는 함수. 인자로 값을 넘기면 입력창에 그 인자 값이 출력된다.
								ㄴ ex) var answer = prompt(word); 	=>word의 값을 출력하며 값을 입력받는 창을 띄워준다.
																		값을 입력하면 그값을 반환해 answer에 넣는다.
					ㅡ 프로퍼티)
						ㄴ document : 위에있는 Document객체.
						ㄴ innerWidth, innerHeight : 창 크기를나타내는 프로퍼티.
					ㅡ  메소드)
						ㄴ open(), close() : 브라우저창 열고닫는 메소드.
					ㅡ location객체
						ㄴ 현재 브라우저에 표시된 html문서의 주소를 얻거나 브라우저에 새문서를 불러올때사용
						ㄴ window으 ㅣ프로퍼티로 존재.
						ㄴ loaction.href : 현재문서의 전체url 문자열로반환.
						ㄴ location.hostnaem : 현재문서의 인터넷호스트이름반환.
						ㄴ location.pathname : 현재문서의 파일경로명 반환.
						ㄴ location.assign( (*url*) ) : url에 해당하는문서를 불러옴.
					ㅡ history객체 : 브라우저의 히스토리정보를 저장.
					ㅡ screen객체 : 사용자의 디스플레이 화면에대한 객체.
					ㅡ navigator객체 : 브라우저 공급자 및 버전정보 등을 포함한 브라우저에대한 다양한정보를 저장하는 객체.

				ㅇ JSON
					ㅡ 객체를 텍스트 형식으로 주고받아 데이터 교환을 경량화 해주는 기술.
						ㄴ js객체를 텍스트형식으로 변환하고 텍스트를 js객체형식으로 변환하여 서버와 주고받을때 많이 쓰임.
					ㅡ 문법)
						ㄴ js의 객체와 거의비슷하지만 조금다른부분이있다.
						ㄴ json 데이터는 이름,값의 쌍으로 구성되어야하며
							ex) " (*이름*) ":" (*값*) "
							와 같은 형태이다. 이름은 따옴표("")로 묶여있는 문자열이어야한다.
							'값'부분에는 String, number, (json형)객체, 배열, boolean, null만 올수있다.
					ㅡ JSON.parse( (*문자열*) )
						ㄴ json형식으로 되어있는 문자열을 받아 js객체로 변환해준다.
					ㅡ JSON.stringify( (*객체*) )
						ㄴ 객체를 받아서 이를 json형태의 문자열로 변환한다.
				ㅇ Date 객체<button>더보기</button>
				<pre>
					ㅡ js에서 날짜와 시간 등을 나타내는 객체.
					ㅡ 기본적으로 형태가 'Thu May 09 2019 10:23:18 GMT+0900 (한국 표준시)' 이런식인듯하다.
					ㅡ 메소드 )
						ㄴ Date.now() : 그 기준시간대로부터 밀리세컨드를 숫자로 바환
						ㄴ Date.parse() : 날짜의 string표현을 가지고 그 날짜에 맞는
						ㄴ new Date() : 여러 인자를 통해 Date객체 생성.
						ㄴ getTime() : '그 기준'시간대로부터 지난시간을 밀리세컨드단위로 반환.
						ㄴ Date.prototype의 메소드들 )
							ㄴ https://developer.mozilla.org/ko/docs/Web/JavaScript/Reference/Global_Objects/Date/prototype 참조
							ㄴ getDate(), getFullYear()등 현재 Date객체의 시간, 날짜, 요일 등을 여러 형태로 가져올수있는 getter메소드와
								설정할수있는 setter메소드들, 기타 여러 메소드들이 있다.
					ㅡ Date.UTC )
						ㄴ ?????
					ㅡ 실무 )
						ㄴ Date객체 변환하기 )
							ㄴ Date객체를 원하는 형태로 변경해주는 방법.
							ㄴ 가장 간단하게 Date.prototype의 getMonth()등의 메소드를 이용하여 각 일, 월 등을 가져와 수작업으로 바꿔주는 방법.

				</pre>
			</pre>
			실무<button>더보기</button>
			<pre>
				ㅇ < input type="file">에서 파일 업로드 클릭하고 바로 이미지 보기<button>더보기</button>
				<pre>
					ㅡ 코드 )
						function readURL(input) {	//1. input태그의 이벤트 핸들러. input은 이벤트객체의 target을 받도록.
							if (input.files && input.files[0]) {
								var reader = new FileReader();
								reader.onload = function (e) {//3. 2번에서 reader에 파일을 저렇게 넣으면 base64형태로 데이터가 가져와지고
									$('#blah').attr('src', e.target.result);//4. #blah는 < img>를 말하고, img태그의 src에 이 base64를
																				넣으면 바로 이미지를 볼 수 있다.
								}
								reader.readAsDataURL(input.files[0]);//2. targer으로부터 업로드한 파일을 가져와 reader에 처리.
							}
						}

				</pre>
 
			</pre>
			라이브러리<button>more</button>
			<pre>
				jQuery<button>더보기</button>
				<pre>
					ㅇ jquery란
						ㅡ 자바스크립트의 라이브러리. 퓨어 자바스크립트는 코드가길고 쓰기어렵기때문에 한줄로 기능을 구현하게해주는 제이쿼리를 만듦.
						ㅡ 참고 : https://api.jquery.com/Types/
							ㄴ 제이쿼리 공식사이트
						ㅡ 쓰기쉽게 함수로 만들어 놓은 것이기때문에 더 디테일한 기능이나 커스터마이징이 필요한 경우 퓨어 자바스크립트가 더 편할 수도 있다.
							ㄴ 그러나 왠만한 기능이 다 있고 쓰기 편함.
						ㅡ 공식사이트에서 왼쪽카테고리에 분류가 되어있고 이곳에서 원하는 기능을 뒤져서 사용하면 된다.

					ㅇ 문법
						ㅡ 사용하기 위해서 먼저 선언해야한다.
							ㄴ html등의 파일에서 jquery를 사용하기 이전에 다음의 내용을 추가해준다.
								ㄴ < script src="http://code.jquery.com/jquery-latest.js">< /script>
							ㄴ 위 방법이 아니더라도 다른 방법이 몇가지 더 있다.
						ㅡ $( (*선택자*) ). (*액션*)() 의 형태이며,
							ㄴ 선택자는 html요소를 쿼리(또는 찾기)하는 부분.
							ㄴ 액션은 해당 요소에 대해 실행될 기능을 쓰는 부분.
						ㅡ 선택자)
							ㄴ 기본적으로 css의 선택자 형식과 같다.
							ㄴ 위 선택자부분에 " (*요소이름*) " 이렇게오면, 해당요소에대해 작업실행.
							ㄴ " # (*id이름*) " 이렇게오면 해당 id에 대하여 작업실행. (이 id는 css의 id를 말함)
							ㄴ " . (*클래스이름*)" 이렇게오면 해당 css클래스에대해 작업실행.
							ㄴ this나 다른 jQuery 객체를 집어넣어도 동작한다.
								ㄴ ex)
									var temp = $(this).after('< textarea> empty < /textarea>');
												$(temp).on('keypress', keyEvent);
							ㄴ 그외 여러가지 선택자들이 있음.
							ㄴ 기타 추측 )
								ㄴ 선택자로 선택하면 해당하는 하나의 요소가 아닌 모든 요소가 선택되는 듯하다. 그리고 이에대해 이벤트bind를 하거나하면 그 모든
									요소에 바인드가 된다.
						ㅡ 액션)
							ㄴ 일반적으로 $() 다음에 와서 여러가지 기능을 제공하는 함수를 말함.
								ㄴ 여러가지 처리가 가능하며 대표적으로 예를 들어보면
									ex) $("p").click(function(){....});	=>모든 요소p에 대해 클릭이되었을때 function부분을
																			수행함.
									$(document).ready();	=> 문서가 완전히 로드되기 이전에 제이쿼리가 실행되어 오류가 발생하는것을
																방지하고자 문서가완전히 로드될때까지 기다리는 작업.
									등등...
							ㄴ 액션 목록 ) <button>펼치기</button>
							<pre>
								ㄴ on( (*이벤트타입*), (*이벤트핸들러*) )
									ㄴ 이벤트 바인드함수. 선택자에 대해 해당 이벤트타입발생시 이벤트핸들러를 실행시킨다.
										ㄴ ex)
											$('textarea').on('keypress', function(e){
												~~~
											});
									ㄴ 이벤트핸들러에서 '이벤트 객체'를 넘길 수 있다. (자바스크립트와 동일)
									ㄴ 이벤트객체의 사용법, 이벤트 타입의 종류, 기타 다른 이벤트함수들은 공식사이트에서 확인.
									ㄴ bind()라는 액션이 있지만 on()과 약간 차이가 있고 bind()는 더이상 사용하지 않는 액션이라 한다.
								ㄴ text(), html()
									ㄴ html문서상의 요소의 내용을 가져오는 액션
								ㄴ val()
									ㄴ 위 text(), html()과 비슷한데 이 액션은 input에 입력된 값을 가져올 수 있따.
								ㄴ $().css()함수
									ㄴ 선택대상의 css 조작 및 값가져오는 함수.
									ㄴ css( (*스타일속성명*) ) : 해당 스타일값을 string으로 가져옴
									ㄴ css( (*스타일속성명*), (*속성값*) ) : 해당 스타일속성값 설정.
										ㄴ ex)
											if($(this).css('display') == 'block'){
												$(this).css('display', 'none');
											}
								ㄴ next() : 바로 다음 형제요소를 반환
								ㄴ after() : 바로 다음 위치에 (자식위치가아니고) 인자로 넘긴 요소 추가.
									ㄴ ex)
										$(this).after('< textarea> empty < /textarea>');
								ㄴ ajax()
									ㄴ ~~~~~ 
									ㄴ 인자 
										ㄴ dataType 
											ㄴ 서버로부터 데이터를 받을 때, 그 데이터가 어떤 타입이길 기대할지를 명시. 
											ㄴ ~~~
										ㄴ data 
											ㄴ 
											ㄴ 값 변환 
												ㄴ method가 GET인 경우, request body를 가질 수 없기 때문에, data인자의 값이 URL 쿼리 파라미터로 추가됨. 
												ㄴ method가 GET이 아닌 경우, 
													ㄴ data 값이 object인 경우, 
														ㄴ ajax()의 또다른 인자 'processData'가 false가 아니라면, 
															객체가 문자열로 변환. 
														ㄴ ex ) 
															{"name": "홍길동", "age": 20}  
															// "name=홍길동&age=20" 
													ㄴ data값이 array인 경우, 
														object인 경우처럼 문자열로 변환하되, 배열원소들이 같은 키값을 가짐. 
														ㄴ ex ) 
															{"list_arg": [1,2,3]}
															// "list_arg=1&list_arg=2&list_arg=3" 
													ㄴ??? data의 값이 문자열인 경우, 
														그 문자열값은 'contentType'에 맞게 적절히 인코딩된 상태여야함. 
										ㄴ contentType 
											ㄴ ??? 요청의 'content-type'을 설정? 
											ㄴ default ) 'application/x-www-form-urlencoded; charset=UTF-8' 
											ㄴ 명시적 설정시, 값이 그대로 'content-type'에 들어가서 req가 전송된다? 
											ㄴ false 설정시, 
												jquery가 아무런 content-type을 설정하지 않음. default값으로도. 
										ㄴ processData 
											ㄴ 'data'인자 값이 object인 경우, jquery가 자동으로 이를 문자열로 적절히 변환. 
												이 인자값을 false로 설정시, 이런 자동변환 하지 않음. 
											ㄴ ???무조건 디폴트 content type인 'application/x-www-form-urlencoded'에 맞는 형태로 변환하는듯? 
											ㄴ default ) true. 
									ㄴ ex )
										$.ajax({
											url: "/more/addUserWithdrawal",  // url.
											type: "POST",  // 메소드 유형.
											headers: {  // 헤더 커스텀 입력 가능. .
												"X-CSRFTOKEN": csrfToken2,
											},
											// 요청에 같이 보낼 데이터. 'type'이 'get'같이 body를 가질 수 없는 경우, 쿼리 파라미터로 들어간다.
											data: {"feedbackChoice": feedbackChoice, "feedbackText": feedbackText },
											// 성공 응답시 호출되는 함수.
											success: function ( (*응답데이터*), String status, jqXHR jqXHR){
												~~~~~
											},
											// 에러 응답시 호출되는 함수.
											error: function ( jqXHR jqXHR, String status, String thrownError ) {~~~~~}
											// 요청에 대한 응답 완료 후 호출. success, error로 설정된 콜백함수가 호출된 뒤 호출.
											complete: function ( jqXHR jqXHR, String status ) {~~~~~}
										})
									ㄴ 실무 
										ㄴ ajax()으로 파일 전송
											ㄴ ex ) 
												var formData = new FormData(); 
												formData.append("prompt", this.currentPrompt)
												formData.append("file1", this.file1)
									
												return $.ajax({
													url: "{% url 'cosmos_chat'  %}",
													type: "POST",    
													data: formData,
													headers: { "X-CSRFTOKEN": csrfToken, }, 
													dataType: "json", 
													processData: false, 
													contentType: false, 
													async: true,  // true: 비동기 요청, false : 동기 요청.
												}) 
											ㄴ js의 formData API와 같이 써야하는듯. ajax()만으로 전송하는법은 안나옴. 
											ㄴ processData false 필요. multipart데이터인데 true이면 데이터를 잘못 변환하기떄문. 
											ㄴ contentType false 필요. formData사용시 content-type헤더가 알아서적절하게 설정됨. 
												디폴트값 들가면 파일데이터라 당연 오류나고, 
												명시적으로 'multipart/form-data' 넣어도 boundary 등 없어 오류. 
								ㄴ css 관련 
									ㄴ offset() 
										ㄴ document 기준으로 해당 요소의 좌표 반환. 
										ㄴ 좌표는 {"top": ~~~, "left": ~~~} 형태. 
									ㄴ outerHeight() 
										ㄴ outgerHeight( (*margin포함여부*))
											ㄴ 해당 요소의 높이 반환.
											ㄴ 요소의 padding영역, border까지 포함한 높이를 반환. 
											ㄴ (*margin포함여부*) 인자에 true 넘길시 margin영역까지 포함한 높이 반환. 
											ㄴ <img src="/image/jquery_outerHeight.png"/> 
									ㄴ innerHeight() 
										ㄴ innerHeight() 
											ㄴ 해당 요소의 높이 반환.
											ㄴ padding영역까지 포함한 높이 반환. border는 포함하지 않음. 
									ㄴ scrollTop() 
										ㄴ 해당 요소의 스크롤의 top 좌표 반환. 
										ㄴ 스크롤되는 영역 내부를 기준으로한 좌표. 
											즉, 스크롤되는 div요소가 화면상 어느 좌표에 있던지 스크롤이 맨꼭대기에 있으면 0 반환, 
											내려가면 내린 좌표만큼의 값 반환. 
								
							</pre>

					ㅇ 타입<button>더보기</button>
					<pre>
						ㅇ JQuery 에서 사용되는 type
							ㅡ https://api.jquery.com/Types/#Element 참조.
							ㅡ Anything : 제이쿼리의 가상타입으로, 어떤한 타입이 와도 괜찮다는 의미.
							ㅡ String
								ㄴ js의 타입.
								ㄴ 비었거나, 하나 또는 여러 문자를 담을수있는 immutable한 원시타입이다.
								ㄴ 작은따옴표 안에 큰따옴표사용이 가능하고 그 반대도 가능. 같은걸쓰려면 역슬래쉬로 처리.
								ㄴ 내장 함수를 가짐. charAt(), toUpperCase(), replace(), split() 등등.
								ㄴ length 프로퍼티를 가짐. 마지막 null을 제외한 문자의 개수를 반환.
								ㄴ 빈 string은 디폴트로 false값을 가짐
							ㅡ htmlString
								ㄴ 제이쿼리의 타입.
								ㄴ string형이 jquery의 함수로 전달될때, < 태그>형태로 시작하는걸로 확인되면 html로 취급되며 내부적으로 htmlString으로 변환된다.
								ㄴ .append() 같은 함수의 인자로 전달되는 경우도 변환된다.
							ㅡ Number
								ㄴ js의 타입. 이며 string과같이 immutable한 원시타입이다.
								ㄴ c언어 기반의 모든 공통연산자를 사용할수있다한다.
								ㄴ 0이면 false를가진다.
								ㄴ js에서 Math객체를 통하여 여러기능을 제공한다. ex) Math.cos( ~~);
								ㄴ string을 파싱할수있다. ex) parseInt("123") => 123, parseInt("010") => 8, parseInt("010",10) =>10...
								ㄴ number에서 string 변환
									ㄴ string과 number을 +연산할 수 있다. string이 + 된 이후로는 string으로 변환되면 +연산역시 string의 +연산이된다.
									ㄴ ex )
										""+1+2; =>12. 처음부터 string이되고 1,2,를 string에 append.
										1+2+""; =>3. 1+2를 number로 연산후, ""를더해 string형으로 변환.
									ㄴ 확실하게하기위해 ( ) 을 사용권장.
								ㄴ js의 String 클래스를 사용하여 값을 string으로 변환가능. ex) String(1) + String(2) =>"12"
							ㅡ Boolean
							ㅡ Object
								ㄴ js의 Object형을 말함.
								ㄴ js의 모든것을 object라고는 하나
								ㄴ { } 형태로 선언하는 property : value형태의 값을 PlainObject라고 한다.
								ㄴ dot notation (.) 또는 array notation으로 프로퍼티에 접근할수있다. ex) x.name = "abc"; ,  x["name"] = "ccc";
							ㅡ Array
								ㄴ js의 array타입을 말함.
								ㄴ jQuery에서 Array< String>과 같은 형식이 가끔보이는데, 이는 보이는대로 String값이들어간 Array값을 기대한다는 의미.
							ㅡ Null
							ㅡ Date
								ㄴ js의 object.
								ㄴ 생성자를 통해 생성되며, 현재의 날짜와 시간을 나타낸다.
							ㅡ Function
							ㅡ Callback
							ㅡ Error
							ㅡ Selector
							ㅡ Event
								ㄴ 이벤트 핸들러에 자동으로 넘어가는 객체.
								ㄴ 다양한 프로퍼티들을 제공 )
									ㄴ target : 이벤트가 발생한 바로 그 요소를 가리킨다. 핸들러가 바인딩된 요소가 아니라.
							ㅡ Element
								ㄴ DOM의 element를 말함.
							ㅡ Text
								ㄴ DOM에서 요소나 속성의 글자를 나타내기위한 node.
							ㅡ JQuery
								ㄴ jquery에서 사용되는 object.
								ㄴ html string에 의해 생성된 요소나, 선택된 요소들의 collection.
								ㄴ jQuery()를 통하여 사용되나, $()로도 사용할 수 있다.
								ㄴ Array와 비슷하게 length가 있거나 []로도 접근이 가능하나 js의 Array는 아니다.
								ㄴ 대부분의 jQuery 메소드들은 같은 jQuery형태를 반환한다. 선택된 collection들을 한번더 필터링하는 식으로 자주사용되는듯하다.
									ex) $( "p" ).css( "color", "red" ).find( ".special" ).css( "color", "green" );
								ㄴ collection안에 아무 DOM도 없을 수 있으며, 이는 에러가 아니다. $()에서 아무인자도넘기지않는것을통하여 빈 jQuery object를 만들수있다.
							ㅡ XMLHttpRequest
								ㄴ jQuery의 Ajax 관련 함수들에서 사용된다.
								ㄴ ???자세한건 ajax에서..
							ㅡ 그외에도.. )
								ㄴ jqXHR, Thenable, Deferred Object, Promise Object, Callback Object, XML Document, Assert 가 있다.
					</pre>
					ㅇ AJAX
						ㄴ 전체 페이지를 다시로드하지않고 서버와데이터를교환해 페이지의 일부를 업데이트하는기술이다.
				</pre>
				ㄴ 차트 라이브러리<button>more</button>
				<pre>
					ㄴ 비교<button>more</button>
					<pre>
						ㄴ 목록 )
							ㄴ ~~~~~
							ㄴ AmCharts )
								ㄴ https://www.amcharts.com/
								ㄴ 조건부 무료. (차트에 개발사 링크가 출력되는 조건)
							ㄴ HighCharts )
								ㄴ  https://www.highcharts.com/
								ㄴ 상업용이 아닐 경우 무료.
							ㄴ D3 )
								ㄴ https://d3js.org
								ㄴ 그냥가져다 쓰는 라이브러리가 아니고 시각화 프레임워크 같은 것. 만들어서 써야 한다.
								ㄴ 무료.
							ㄴ Chart.js )
								ㄴ http://www.chartjs.org
								ㄴ 무료.
							ㄴ google chart )
								ㄴ https://developers.google.com/chart
							ㄴ Morris.js )
								ㄴ http://morrisjs.github.io/morris.js
								ㄴ 무료
							ㄴ Chartist.js
								ㄴ http://gionkunz.github.io/chartis-js
								ㄴ 무료.
							ㄴ C3 )
								ㄴ https://c3js.org
								ㄴ 오픈소스 / 무료
								ㄴ D3 위에 만든 라이브러리.
								ㄴ 속도 빠르고, 브라우저 호환이 좋다함.
							ㄴ Plotly.js )
								ㄴ 무료.
								ㄴ 종류가 많음.

							ㄴ 대략, 많이 사용되는 것들로
								chart.js, highcharts, c3, nvd3, chartist, victory, plotly.js 등이 있다.

					</pre>
					ㄴ flotchart<button>more</button>
					<pre>
						ㄴ http://www.flotcharts.org/
							ㄴ 기본 사용법 ) https://github.com/flot/flot/blob/master/API.md#multiple-axes

					</pre>
					ㄴ plotly.js<button>more</button>
					<pre>

					</pre>
					ㄴ amChart<button>more</button>
					<pre>
						ㄴ 개요 )
							ㄴ 조건부 무료 차트 라이브러리. (렌더링되는 그래프에 amchart의 로고와 링크가 표시)
							ㄴ 판매하는 라이브러리인 만큼 질이 좋고 다양하다.
							ㄴ 2021년9월에 5버전 출시.
						ㄴ 설치 및 세팅 )
							ㄴ ~~~~~
						ㄴ 기본 사용법 )
							ㄴ ~~~~~
						ㄴ Root Element<button>more</button>
						<pre>
							ㄴ var root = am5.Root.new("chartdiv"); 로 생성.
								ㄴ new()의 인자는 그래프를 삽입할 div의 id.
							ㄴ Root Element를 제외한 다른 인스턴스 생성시, new()의 첫번째 인자로 항상 이 Root Element가 들어간다.
							ㄴ	var chart = root.container.children.push(
									am5pie.PieChart.new(root, {})
								);
								ㄴ 해당 div에 Pie chart가 삽입된다.
							ㄴ 설정 )
								ㄴ Formatter )
									ㄴ 내부적으로 다음 3개의 포메터가 있다함.
										ㄴ NumberFormatter
										ㄴ DateFormatter
										ㄴ DurationFormatter
									ㄴ 이들은 '글로벌 포메터'라고함.
								ㄴ fps )
									ㄴ root.fps 속성을 통해 애니메이션의 fps를 설정할 수 있다함.
								ㄴ time zone )
									ㄴ root.timezone = am5.Timezone.new("America/Vancouver");
									ㄴ timezone 속성으로 timezone설정 가능. "UTC", "Asia/Tokyo", "America/New_York", "Europe/Lisbon" 등
								ㄴ new()의 setting인자 )
									ㄴ new()의 두번째 인자로 객체를 넘길 수 있고, 이는 root element에 대한 설정으로 사용된다.
									ㄴ ex)
										var root = am5.Root.new("chartdiv", {
										useSafeResolution: false
										});
									ㄴ 현재 이걸로 넘기는 옵션이 'useSafeResolution'밖에 없다하.ㅁ
									ㄴ 옵션 )
										ㄴ useSafeResolution : boolean )
											ㄴ 자동으로 해당 장치에 맞는 그래프 해상도를 설정할지 말지를 설정.
								ㄴ Locale )
								ㄴ Top-level tab index
							ㄴ root.container.children.clear()
								ㄴ root의 컨테이너 안의 요소들을 모두 지운다.
								ㄴ root가 제거되지는 않음. (root에 다시 요소들을 push할 수 있음)
							ㄴ root.dispose()
								ㄴ root를 제거. (다시 요소 push 등 안됨)
							ㄴ root 컨테이너 크기 자동 조절 )
								ㄴ root element의 컨테이너 div의 크기가 변경되면 root element가 자동으로 조절된다.
								ㄴ root.autoResize = false 로 off가능.
								ㄴ root.resize() 로 수동 리사이즈 가능.
							ㄴ 차트 준비 이벤트 ????? )
								ㄴ ?????

						</pre>
						ㄴ XY chart <button>more</button>
						<pre>
							ㄴ index, xy 모듈 필요
							ㄴ ex )
								var chart = root.container.children.push(
									am5xy.XYChart.new(root, {})
								);
							ㄴ axes )
								ㄴ ex )
									var yAxis = chart.yAxes.push(
									am5xy.ValueAxis.new(root, {  // 필요한 타입에 맞는 Axis를 생성.
										renderer: am5xy.AxisRendererY.new(root, {})
									})
									);
								ㄴ XYChart 인스턴스의 yAxes, xAxes 속성에 Axis 인스턴스를 push함으로써 axis를 추가할 수 있다.
								ㄴ 위의 경우, ValueAxis가 y축 axis에 추가된다.
								ㄴ axis renderer )
									ㄴ axis는 renderer를 통해 실제로 화면에 그려지게 된다.
									ㄴ AxisRendererX, AxisRendererY가 있다.
								ㄴ axis type )
									ㄴ 종류 )
										ㄴ CategoryAxis : 축의 값이 문자열일 경우.
										ㄴ CategoryDateAxis : ?????
										ㄴ DateAxis : ?????
										ㄴ ValueAxis : 축의 값이 숫자인 경우.
									ㄴ 타입에 따라 생성시 필요한 설정값들이 존재.
								ㄴ 설정들 )
									ㄴ Grid )
									ㄴ Ticks )
									ㄴ Labels )
										ㄴ renderer의 labels속성의 template 속성을 설정하여 설정.
											ㄴ ex )
												let yRenderer = yAxis.get("renderer");
												yRenderer.labels.template.setAll({
												fill: am5.color(0xFF0000),
												fontSize: "1.5em"
												});
							ㄴ series )
								ㄴ 이 객체에 데이터가 저장된다.
								ㄴ xy chart에서는 최소한 한개의 series를 추가해 줘야함.
								ㄴ ex )
									var series = chart.series.push(
									am5xy.ColumnSeries.new(root, {
										name: "Series",
										xAxis: xAxis,  // 사용할 xaxis객체를 설정.
										yAxis: yAxis,  // 마찬가지.
										valueYField: "value",  // 아래 valueXFiedl와 함께 데이터와 관련된 부분.
										valueXField: "date"  // 이 두 설정값은 사용할 각 축 axis의 type과 맞아야 한다.
									})
									);
									ㄴ data field )
										ㄴ valueYField, valueXField 부분이 series의 데이터 관련 설정이다.
										ㄴ 이 두 설정값은 사용할 각 축 axis의 type과 맞아야 한다.
											ㄴ 가령, xaxis가 valueAxis를 사용중이면 데이터 필드로 'valueXField'가 와야한다.
										ㄴ 속성의 이름으로 필드의 유형을 구분.
											ㄴ valueXField => value 타입, x축에 대한 데이터 필드.
											ㄴ categoryYField => category 타입, y축에 대한 데이터 필드.
										ㄴ DateAxis인 경우, 축에 들어갈 데이터가 timestamp(정수값)이므로 value타입 데이터 필드를 사용한다.
								ㄴ series 객체 종류 )
									ㄴ CandlestickSeries : 캔들스틱 데이터를 표현하려 할때 사용.
									ㄴ ColumnSeries : 컬럼이나 막대를 표현
									ㄴ LineSeries : 선 표현.
									ㄴ SmoothedXLineSeries : ?????
									ㄴ SmoothedXYLineSeries : ?????
									ㄴ SmoothedYLineSeries : ?????
									ㄴ StepLineSeries : ?????
								ㄴ 데이터 저장 )
									ㄴ series의 data속성의 setAll()를 사용
									ㄴ ex )
										series.data.setAll([{
										category: "Research",
										value: 1000
										}, {
										category: "Marketing",
										value: 1200
										}, {
										category: "Sales",
										value: 850
										}]);
								ㄴ 날짜 기반 데이터 )
									ㄴ DateAxis에 js의 timestamp를 나타내는 정수값을 넘겨주어야함.
							ㄴ Legend
							ㄴ Cursor

						</pre>

						ㄴ Element states<button>more</button>
						<pre>
							ㄴ 'State'라는 객체. amChart의 다른 요소들과 마찬가지로.
							ㄴ 다른 요소들과 마찬가지로 키/값 쌍의 setting값들을 가진다.
							ㄴ 세팅값을 가지기만 할 뿐, 아무런 기능도 하지 않다가 특정 조건하에서 특정 요소에 적용되어 본인이 가지고 있던
								세팅값들을 해당 요소에 적용시킨다?
							ㄴ 특정 조건은
								built-in state들일 수도, 사용자 정의가 될 수도 있다.
								ㄴ built-in state
									ㄴ hover
						</pre>

						ㄴ Template<button>more</button>
						<pre>
							ㄴ
						</pre>

						ㄴ 라이센스 구매
							ㄴ 차트별로 라이센스 별도 존재.
								ㄴ 기본 차트, Map차트, stock 차트
								ㄴ 가격 상이.
							ㄴ 적용 서비스별 라이센스 등급 존재.
								ㄴ 싱글 웹사이트, SaaS( or app?), OEM, extended OEM
							ㄴ 구매하면 이메일로 일련번호 전달되고 
								이를 html페이지의 차트 코드 이전 부분에 js코드로 추가하면 적용된다함. 
								ㄴ ex ) am5.addLicense("asda213123123");


					</pre>
				</pre>
				ㄴ 테이블 라이브러리<button>more</button>
				<pre>
					ㄴ CloudTables<button>more</button>
					<pre>
						ㄴ https://datatables.net/manual/index
					</pre>
				</pre>

				ㄴ pdf 파일 관련 
					ㄴ pdfmake 
						ㄴ 라이브러리 내의 함수, 코드들을 사용하여 pdf파일을 직접 생성해주는 라이브러리. 
							ㄴ js코드상으로 문단 작성하면 pdf파일에 문단 입력되고, js로 표 작성하면 파일에 표 입력되고.. 이런식. 
								직접 pdf파일 내용을 js코드로 하나하나 구현하는식인드. 
					ㄴ html2pdf 
						ㄴ html 페이지를 모습 그대로 pdf파일로 만들어주는 라이브러리. 
						ㄴ html의 요소들을 읽어들여 pdf파일을 만든다고함. 
						ㄴ 실험적 라이브러리. prod에 적합하지 않다고 공식적으로 나옴. 
						ㄴ 실제로 생성된 css, 뷰 관련 이슈가 많음. 똑같이 안나오는 경우가 많음. 
			</pre>
		</pre> 

		ㄴ 타입 스크립트 (TypeScript)
			ㄴ js위에 문법을 추가하여 만든 언어?
			ㄴ js에 정적 타입 등 여러 문법 기능을 사용할 수 있음.
			ㄴ js컴파일하여 동작하는 컴파일언어.
 
		<!-- </pre> -->
		Vue.js<button>더보기</button>
		<pre>
			Vue 기본<button>더보기</button>
			<pre>
				ㅇ 기초
					ex)	< div id="app">
							{{ message }}
						< /div>
					위는 html부분, 아래는 script부분.
						var app = new Vue({
							el: '#app',
							data: {
								message: '안녕하세요 Vue!'
							}
						})
					=> 대충이런식으로 Vue객체를선언하고 이를 통해 선언적으로 DOM에 데이터를 렌더링하는것이 핵심이라고한다.

				ㅇ 뷰 템플릿
					ㅡ 뷰 템플릿은 html,css 등의 마크업속성과 뷰 인스턴스에서 정의한 데이터 및 로직들을 연결하여, 사용자가 브라우저에서 볼수있는형태의 html로 변환해주는 속성.
					ㅡ 라이브러리 내부적으로 template속성에서 정의한 마크업+뷰 데이터를 가상 돔 기반의 render()함수로 변환한다. 변환된 render()는 최종적으로 사용자가 볼수있게
						화면을 그리는 역할을 한다고한다. 변환과정에서   뷰의 '반응성'이 화면에 더해진다고한다.
					ㅡ 템플릿 속성을 사용하는 방법은 두가지로, 뷰 인스턴스에 template속성을 정의하는방법과 싱글파일 컴포넌트 체계의 < template>코드를 활용하는방법.
					ex)	전자의 예,
						new Vue({
							template: "< p>hello< /p>"
						});
						후자의예,
						< template>
							< p>hello< /p>
						< /template>

					ㅡ싱글파일 컴포넌트 체계)
						ㄴ template 옵션속성을 통해 치환될 html코드를 만들다보면 이게 문자열로 쭉 쓰는거라 보기힘들다. 그래서 싱글파일 컴포넌트 체계라는것을 이용한다.
						ㄴ ' .vue '라는 확장자를 가진 파일을 하나 만들어 이안에 컴포넌트를 정의하는것이다. 파일 하나당 컴포넌트 하나이다.
						ㄴ 문법)
							< template>
								(*치환도리내용*)	=>template 속성에 들어갈 내용이 들어간다.
							< /template>
							< script>
								export default{	=>ES6의 js모듈화와 관련된문법이라함.
									(*컴포넌트 내용*)
								}
							< /script>
							< style>
								(*template부분의 html내용의css스타일을 정의하는영역*)
							< /style>
						ㄴ 이 체계를 사용하기위해서는 브라우저가 .vue파일을 인식할수있는형태로 변환시켜주는 '웹팩(Webpack)'이나 '브라우저리파이(Browerify)'같은 도구가 필요하다.
						ㄴ 하지만 뷰에서 지원하는 CLI ( Command Line Interface) 도구를 통해 쉽게 프로젝트를 구성할수있다.

				ㅇ 데이터 바인딩 : html화면요소를 뷰 인스턴스의 데이터와 연결하는것을 의미한다. {{}}와 v-bind속성을 이용한다.
					ㅡ ex)	{{message}}	=>data속성의 message의 값이 치환된다.
					ㅡ v-bind : id,css,class같은 html요소의 속성값에 뷰 data값을 연결하려고할때사용하는 방식. 'v-bind'부분을 생략하고 ':'만 입력해도 작동한다.
						ex)	< p v-bind : (*속성이름*) = " (*뷰인스턴스의 data옵션속성의 프로퍼티 이름*) ">
					ㅡ 템플릿 안에 자바스크립트 표현식을 사용할수있다.
						ex)	{{message + "!!"}}, 또는 {{message.split('').reverse().join('')}}등등
						ㄴ 선언문이나 분기구문, 복잡한연산은 안된다.

				ㅇ 디렉티브
					ㅡ thml태그안에서 'v-'접두사를 가지는 모든 속성을 의미. v-bind같은거.	ex) < a v-if="flag">~~
					ㅡ 화면요소를 더 쉽게 조작하기위해 사용하는 기능. 데이터값이변경됨에따라 '반응형'으로 동작한다.
					ㅡ 종류)
						ㄴ {{ }} : 위에서말한 data항목안에 있는값들을 불러올수있는문법.
						ㄴ v-text = " (*뷰 인스턴스의 data옵션속성의 프로퍼티이름*) " : 태그속성으로 이값을 넣으면 해당태그내용으로 데이터값이 할당되는듯.
							ex)	< h1 v-text="name">< /h1>	=>뷰 인스턴스안에 data항목안에 name이란 데이터이름을가진 값이 < h1>의 내용으로들어감.
						ㄴ v-html = " (*뷰 인스턴스의 data옵션속성의 프로퍼티이름*) " : v-text는 그냥 값을 문자열로서 가져오는반면, 이속성값을 사용하면 데이터값을 html내용으로서 가져옴.
							즉, 내용을 html문법취급한다는말.
							ex)	< h1 v-html="name">< /h1>이고, name값이
								< p>aaa< /p>이면 < p>를 html문법취급하여 p태그를 적용시켜 값을가져온다는말. v-text속성을사용하면 그냥 < p>aaa< /p>가 그대로출력.
									(이런걸 html형식으로 렌더링?한다?고하는듯)
						ㄴ v-show = (*참거짓판별가능한값*) : 값이 참이면 해당속성이있는 태그를 보여줌.
						ㄴ v-if = (*참거짓판별가능한값*) : 위와같음 참이면 보여줌. 비슷한걸로 v-else-if, v-else도 있다.
						ㄴ v-pre : 이 속성이 있는 위치 다음에오는 속성들을 없는것으로취급한다.
						ㄴ v-cloak : 페이지가 로드될때 html부분이로드되고 js부분이 로드되는데(js가 로드되면서 Vue인스턴스가 준비됨) 이 두개가 로드되는 사이에 시간적텀이있어
							페이지가 제대로 보여지지않는경우가있음. 이때 Vue인스턴스가 준비되기전까지 html코드를숨기고싶을때? 이 속성을사용하면된다.
						ㄴ v-once : 이 속성이 있는 해당 태그를 초기에 딱한번만 렌더링하고싶을때 사용.
						ㄴ v-on:(*이벤트종류*)=" (*메소드, 객체, 명령문*) " : 이벤트 핸들링 디렉티브. 해당 이벤트종류 발생시 실행할것들을 정할수있다.
							ㄴ 메소드를 사용할시, 해당 메소드에서 'event'라는 이름의 매개변수를 선언하면 '이벤트객체'를 사용할수있다.
						ㄴ v-model : html태그 < input>, < select>, < textarea>와 컴포넌트에 대해 양방향 바인딩 기능을 부여하는 디렉티브.

						*양방향 바인딩
							ㅡ 뷰인스턴스 data속성에서 data의 값을 바꾸면 html화면단에서 해당 값이 동적으로 바뀌는걸 볼수있는데 이때 인스턴스쪽에서 화면단으로 한쪽으로만
								데이터를 바인딩한거면 이를 단방향 바인딩이라한다.
							ㅡ 양방향 바인딩은 html요소에서 input, select등의 입력폼?에서 입력하는그대로 인스턴스data의 값이 바뀌고, 또 인스턴스 data의 값이 바뀌면 그대로
								화면단의 입력폼의 내용이 바뀌는식으로 양방향으로 데이터가 바인딩 된것을 말한다.

			</pre>
			Vue 인스턴스<button>더보기</button>
			<pre>
				ㅡ 뷰로 화면을 개발하기위해 필수적인 기본단위.
					ex)	new Vue({
							el : "#app",
							data : {
								message: "hello"
							}
						});
					ㄴ 대충 이런식으로 생겼다.
					ㄴ el, data 등은 뷰인스턴스의 속성들.

				??? 뷰 인스턴스에 대한 내용이지만 아직 잘모르겟는것들.
					ㄴ 뷰인스턴스를 생성할때 options object를 전달한다.
					ㄴ 모든 뷰 인스턴스는 뷰 컴포넌트이다.
					ㄴ 뷰 어플리케이션은 root vue 인스턴스로 이루어져있다고한다. root vue인스턴스는 new Vue를 통해 만들어지는 인스턴스.
					ㄴ 뷰가생성될때, data항목에 있는 객체들을 reactivity 시스템에 넣는다고한다. 그래서 이값들이 바뀌면 바로 반응하여 해당값들을 변경해준다고함.
						'반응형'말하는거같음.


				ㅡ 뷰 인스턴스의 옵션속성 : 인스턴스를 생성할때 재정의할 data, el, template 등을 말함.
					ㄴ el : 뷰로 만든 화면이 그려질 시작점. 화면이그려질 DOM요소를 선택하는 속성.
					ㄴ template : 화면에 표시할 html, css등의 마크업요소를 정의하는속성. 뷰의 데이터및 기타속성들도 함께화면에 그릴수 있다.
					ㄴ methods : 화면 로직제어와 관련된 메서드를 정의하는 속성.
					ㄴ created : 뷰 인스턴스가 생성되자마자 실행할 로직을 저의하는 속성.
					ㄴ computed
						ㄴ 깔끔하고 유지보수가 쉬운 코드를 위해서 데이터 가공 등의 복잡한 연산은 인스턴스 안에서 하고 html에는 데이터를 표현하는것만 하는게 좋다.
						ㄴ 여기서 이 '복잡한' 연산부분을 computed속성에서 진행한다.
						ㄴ ex)	< div id="app">
									{{reversedMessage}}	=>이런식으로 html부분에는 간단하게 표현만진행. 아래의 복잡한 연산식부분을 넣지않는다.
								< /div>
								~~
								new Vue({
									~~
									computed:{
										reversedMessage : function(){
											return this.message.split('').reverse().join('');	=>computed속성에서 이렇게 복잡한 연산을 미리
																									정의하여 이름만으로 출력될수있도록.
										}
									}
								})
						ㄴ computed속성은 data속성의 값변화에 따라 자동으로 연산을 다시해준다.
						ㄴ 캐싱기능도 지원한다. 캐싱이란 동일한 연산을 반복하지 않기위해 결과값을 저장해두었다가 필요할때 가져다쓰는 것을 말함.
					ㄴ watch 옵션 속성
						ㄴ computed와 비슷하게 데이터 변경이 일어날때마다 자동으로 특정 로직을 수행하는 속성.
						ㄴ data와 같은 이름의 값들을 설정해두고 해당 값에 변경이 일어나면 설정해둔 함수를 실행시킨다.
						ㄴ ex)	data:{
								number:0;
							},
							watch:{
								number: function(~~){~~}	=>data의 number의 값변경시 이 함수 실행.
							}


					*methods속성과 computed속성의 차이점
						ㅡ 전자는 호출될때만 로직수행, 후자는 데이터 변경이 일어나면 자동으로 수행.

				*뷰 인스턴스가 화면에 적용되는과정
					1. 뷰 라이브러리 파일 로딩
					2. 인스턴스 객체생성(옵션속성포함)
					3. 특정화면 요소에 인스턴스를 붙임
					4. 인스턴스내용이 화면요소로 변환
					5. 변환도니 홤녀요소를 사용자가 최종확인

				ㅡ 뷰 인스턴스의 유효범위
					ㄴ 뷰 인스턴스의 옵션속성들은 html의 특정범위 안에서만 적용이되어 나타난다. 이를 유효범위라고한다.
					ㄴ el 옵션속성에 지정한 값에 해당하는 DOM에 뷰 인스턴스가 붙게되며, 이 DOM요소가 해당 인스턴스의 유효범위가 된다.
					ㄴ 인스턴스가 해당DOM요소에 부착되고 인스턴스의 data옵션속성의 값이 해당DOM요소와 그 안의 요소에 적용되어 값이 치환된다. 당연히 이 data의 값들도 유효범위
						안에서만 사용할수있다. ex) {{ message }}같이 .

				*뷰의 반응성
					ㅡ el 속성에 지정한 요소에 인스턴스를 부착하고나면 인스턴스에 정의된 속성들이 화면 요소에 치환된다.
					ㅡ 치환된 값들은 뷰의 '반응성'을 제공하기위해 '$watch' 라는 속성으로 감시가되며
					ㅡ 감시하고있다가 데이터가 변경되면 해당값에 맞게 화면을 다시 그려준다.
					ㅡ 뷰 인스턴스가 처음 생성될때 존재했던 data 값들에 대해서만 반응성이 유지가 된다. 나중에 추가한건 해당없음.

				ㅡ 뷰 인스턴스와 라이프사이클)
					ㄴ 뷰 인스턴스도 라이프사이클을 가진다. 인스턴스가 생성되고, 화면에 부착되고, 소멸되기까지의 과정.
					ㄴ 라이플사이클속성 : 뷰인스턴스의 속성의 일종. 라이플사이클의 특정 시점들에서 호출되는 속성들. created, beforeCreate, beforeMount등등이 있다.
					ㄴ 라이플사이클 훅(hook) : 각 라이플사이클 속성에서 실행되는 커스텀 로직. (커스텀로직이란 개발자가 임의로 작성한 추가로직)
					ㄴ 크게 인스턴스의 '생성', 화면에 '부착', 인스턴스 내용의 '갱신', 인스턴스 '제거'의 4단계로 나뉘어져있다.
					ㄴ beforeCreate : 인스턴스 생성후 가장 처음으로 실행되는 단계. data속성과 methods속성이 아직 인스턴스에 정의되어잇지않고 DOM에도 접근할수없다.
					ㄴ created : beforeCreate단계다음에 실행. data속성과 methods속성의 정의되기때문에 이들을 이용할수있다. 아직부착되기는 전이라서 template에 있는DOM에는 접근 x.
					ㄴ beforeMount : created 다음단계. template속성이 제정한마크업속성을 render()로 변환후 el속성으로 지정된 요소에 인스턴스를 부착하기전에 호출되는단계.
						(render()함수는 js로 화면에 DOM을 그리는 함수)
					ㄴ mounted : 인스턴스 부착후 호출되는단계. 이제 DOM에 접근할수가있다.
					ㄴ beforeUpdate : 관찰하고있는 데이터가 변경되고나면 가상 DOM으로 화면을 다시그리기전에 호출되는단계. 변경예정인 새 데이터에 접근할수있고 관련로직을 미리넣을수있다.
					ㄴ updated : 데이터변경에따라 가상DOM으로 화면이 다시그려지고나서 호출되는 단계. 데이터변경후 화면요소제어와 관련된 로직을 추가하기에좋다.
					ㄴ beforeDestroy : 인스턴스 파괴전에 호출되는단계. 아직 인스턴스에 접근할수잇다.
					ㄴ destroyed : 인스턴스가 파괴되고나서호출되는단계.

					<img src="image/뷰 인스턴스 라이프사이클.png" style="height:600px; width:auto;">
			</pre>
			Vue 컴포넌트 <button>더보기</button>
			<pre>
				ㅇ 컴포넌트
					ㅡ 컴포넌트란 말그대로 화면의 구성요소, 즉 조합하여 화면을 구성ㅇ할수있는 블록(화면의 특정영역)을 의미한다
						ㄴ 이를 이용하면 화면을빠르게 구조화할수가잇으며
						ㄴ 재활용성, 유지보수가 편해진다.
						ㄴ 웹화면을 예를들면, <img src="image/컴포넌트 예.png" style="height:300px; width:auto;">
						Header, content, Footer이란 컴포넌트로 구성되어있고 Content안에는 또 Aside, List라는 컴포넌트로 구성이 되어있다.

					ㅡ 컴포넌트는 지역컴포넌트와 전역컴포넌트가있으며, 전자는 특정 인스턴스에서만 휴효한 범위를 갖고, 후자는 여러 인스턴스에서 공통으로 사용할수있다.
					ㅡ 컴포넌트는 재사용가능하고 이름이잇는 뷰 인스턴스라고한다.
					ㅡ컴포넌트의 data항목은 직접 객체로 존재하는게아니라 함수의 리턴값으로서 존재한다고한다.
						ex)	data:{
								count:0
							}
							이게 아니라,
							data: function(){
								return {
									count:0
								}
							}
							이런식으로.

				ㅇ 동적 컴포넌트
					ㅡ 컴포넌트를 만드는데 어떤컴포넌트인지 정해져있는게 아니라 특정 값에따라서 동적으로 결정되도록 하는 컴포넌트
					ㅡ < component> 태그를 사용하며 v-bind로 is속성을 설정시켜준다. 이 is속성의 값에 따라서 동적으로 어떤컴포넌트인지 정해진다.
					ㅡ ex)	< component v-bind:is=" (*값*) "> ~~< /~~>	=>(*값*)은 등록된 컴포넌트의 이름이 들어있는 data옵션속성의 속성이름.

					*is 속성
						ㅡ 위 동적컴포넌트 이외에도 is속성이 쓰이는 경우가 있다.
						ㅡ < ul>, < ol>, < table>, < select>요소는 문법상 그 내부에 사용자가만든 컴포넌트 이름을 사용할수없다.
						ㅡ 해서 원래 들어가야하는 요소를 일단 쓰고 속성으로 'is'를 주고 그 속성값으로 사용자가만든 컴포넌트 이름을 주는 방식으로 컴포넌트를 사용한다.

				ㅇ 컴포넌트 등록방법
					ㅡ 지역등록과 전역등록 두가지가있다고함.
					ㅡ 전역 컴포넌트등록)
						ㄴ 뷰 라이브러리를 로딩하고 나면 접근가능한 Vue변수의 component()함수를 이용해 등록한다.
							ex)	Vue.component( " (*컴포넌트이름*) ", { (*컴포넌트 내용*) } )
						ㄴ 컴포넌트이름은 html사용자 정의태그 이름을 의미. 컴포넌트 내용은 컴포넌트 태그가 실제 화면의 html요소로 변환될때 표시될 속성들을 작성하는부분이다.
							template, data, methods 등의 인스턴스 옵션속성을 정의할수잇다.
						ㄴ 컴포넌트 명명법으로 파스칼이나 카멜 표기법을쓰면 오류뜨는듯함.
						ㄴ 이유는모르겟지만 이렇게 등록한다음 뷰인스턴스를 생성해야 사용이 가능하다. 등록전에 생성한 인스턴스에 대해선 사용불가.
						ㄴ '컴포넌트이름'부분이 '커스텀 엘리먼트'라고 하며 페이지에서 해당부분이 컴포넌트의 template의 내용을 교체된다.
					ㅡ 지역컴포넌트 등록)
						ㄴ 인스턴스에 components속성을 이용해 등록한다.
						ㄴ형식)
							var v= new Vue({
								~~~,		=>그냥 뷰인스턴스정의하듯이 data나 el속성등이 온다.
								components : {	=>data, el같은 속성중 하나로서 components란 속성을 사용하여 지역컴포넌트 등록. 이 뷰인스턴스에 대해서만 컴포넌트 사용가능.
									"(*컴포넌트이름*)" : (*컴포넌트 내용*)	=>전역컴포넌트등록처럼 이름과 컴포넌트 내용을 입력한다. 근데 보통 내용부분은 따로 변수로
																		저장해주었다가 이곳에 입력하는방식으로 하는것같다.
								}
							})

						ex)	var cmp={		=>컴포넌트내용으로쓸 정보를 변수에 미리저장.
								data:function(){~~~}
								template:~~~
							}
							new Vue({
								components : {
									'my' : cmp	=>컴포넌트 내용이 저장되어있는변수를 전달.
								}
							})

			</pre>
			컴포넌트간 통신<button>더보기</button>
			<pre>
				ㅡ 뷰는 컴포넌트로 화면을 구성하고, 컴포넌트마다 자체적으로 고유한 유효범위를 가지기때문에 컴포넌트간의 직접적인 값을 참조할수가 없기때문에 같은 웹페이지상에서 데이터를 공유할수가 없는 특징이있다.
				ㅡ 해서 뷰에서는 뷰 프레임워크에서 정의한 컴포넌트 데이터 전달방식을 따라야만 데이터 공유가 가능하다.
				ㅡ 상위,하위 컴포넌트간 데이터 전달방법.
					ㄴ 앞서배운방법으로 전역,지역컴포넌트를 등록하면 해당컴포넌트는 하위컴포넌트, 이 컴포넌트들을등록한 인스턴스는 상위컴포넌트가 된다.
					<img src="image/컴포넌트 통신.png" style="height:300px; width:auto;">
					ㄴ 뷰에서 제공하는 상위,하위컴포넌트간 데이ㅣ터 전달방법은 그림과같다. 상위컴포넌트는 props라는 속성을 하위컴포넌트에게 전달할수있고 하위컴포넌트는 상위컴포넌트에게 이벤트만 전달할수있다.
					ㄴ 상위에서 하위컴포넌트로 통신 : props 속성)
						ㄴ 먼저 하위컴포넌트에 props라는 이름의 속성을 정의해야한다.
							ex)	Vue.component("~~", {
									props : [ " (*props 속성이름*) " ],
									~~
								});
						ㄴ 그다음 컴포넌트 태그에서 v-bind속성을 통해 props속성값을 넘겨주어 데어터를 전달한다.
							ex)	<~~ v-bind:props (*속성이름*)=" (*상위컴포넌트의data속성*) ">< /~~>
								=> 속성이름 부분에는 props속성이름이 와야한다.
					ㄴ 하위에서 상위컴포넌트로 통신 : 이벤트전달)
						ㄴ 기본적으로 하위에서 상위컴포넌트로의 데이터전달은 되지않는다. 뷰의 단방향 데이터 흐름에 어긋나는 방법이기때문에. 하지만 이후나오는 '이벤트 버스'를 사용하여 구현이 가능하기는 하다.
						ㄴ 하위컴포넌트에서 상위컴포넌트로의 통신은 이벤트를 상위컴포넌트로 전달하는 방식을 이용한다.
						ㄴ 이벤트 발생과 수신)
							ㄴ발생)
								$emit( " (*이벤트명*) " )을 이용하여 (*이벤트명*)이란 이름의 이벤트를 발생시킨다.
								보통 하위컴포넌트의 특정 메소드 내부에서 발생시킨다.
								ex)	this.$emit("show-log");	=>show-log라는 이름의 이벤트 발생.

							ㄴ수신)
								v-on : (*이벤트명*) = " (*상위컴포넌트의 메소드명*) " 을 통해 이벤트를 수신한다.
								이유는 잘모르겟지만 하위컴포넌트 요소에 대해 이벤트 수신설정을 해야지만 제대로 작동한다. 위의 $emit로 발생시킨 이벤트명이 (*이벤트명*)부분에 오게되며 $emit로 이벤트를 발생시키면 v-on으로 수신설정해둔곳으로 이벤트가전달된다. 그럼 (*상위컴포넌트의메소드명*)부분이 실행되는방식.
								ex)	<(*컴포넌트이름*) v-on: show-log="printText">< /~~>	=>show-log라는 이름의 이벤트발생시, printText라는 메소드실행.
									~~
									Vue.component('simple-counter', {
									template: '< button v-on:click="showLog">haha< / button>',
									methods:{
										showLog:function(){
											this.$emit("show-log");	=>show-log라는 이름의 이벤트를 발생시킴.
										}
									}
									})

									new Vue({
									el: '#example-2',
									methods:{
										printText:function(){
											console.log("mmm"+(this.num2++));
										}
									}
									})

					ㄴ 같은레벨 컴포넌트간 통신
						ㄴ 공통의 상위컴포넌트로 전달후(없으면 만들어서) 그 상위컴포넌트에서 props속성으로 데이터를 내려주는방식으로 진행된다. 근데 복잡해서 잘안쓰임.

				ㅡ 이벤트 버스형식 컴포넌트간 통신
					ㄴ 컴포넌트가 많아지면 통신을 위해 상,하위 컴포넌트들이 많아져 데이터전달이 매우 복잡해진다.
					ㄴ 그래서 이벤트버스형식을이용해 바로 직접적으로 데이터를 주고받음.
					ㄴ 임의의 새로운 뷰 인스턴스를 만들고 그 인스턴스에 대해 이벤트를 발생시키고 수신하는 방식을 사용한다.
					ex)	var eventBus = new Vue();
						~~
						(값을 전달하려는 컴포넌트 안에서)
						eventBus.$emit( "(*이벤트명*)", (*전달할값*) );	=>임의로만든 인스턴스에 대해 (*이벤트명*)이름을 가진 이벤트를 발생시키며 값을전달한다.
						~~
						(값을 받으려는 컴포넌트 안에서)
						eventBus.$on( "(*이벤트명*)", function( (*매개변수*) ) {	=>매개변수부분에 위 $emit()를통해 전달된값이 저장된다.
							(*실행할 내용*)
						});
			</pre>
			트랜지션 및 애니메이션<button>더보기</button>
			<pre>
				ㅇ 트랜지션 기본
					ㅡ 뷰에서는 transition이라는 컴포넌트를 이용해 요소가 생성되고 제거될때마다 발생하는 효과를 쉽게 설정할수있다. 트랜지션효과란 장면전환효과 같은것.
					ㅡ < transition > : 트랜지션 래퍼 컴포넌트. 이태그로 감싸진 요소가 생성되고 제거될때마다 발생하는 트랜지션을 설정할수있다.
						ㄴ 하나의 컴포넌트나 html요소에 대해서만 트랜지션 설정이 가능하다.
						ㄴ v-if, v-else 등을 이용해 여러컴포넌트,요소간 트랜지션 설정이 가능하다.
							ex)	< transition>
									< table v-if="~~">
									~~
									< /table>
									< p v-else>~~< /p>
								< /trasition>

								(html에서)
								< transition name=" (*이름*) ">	=>발생시킬트랜지션효과 이름지정. css에서 해당이름의 트랜지션클래스와 연결이된다.
									(*트랜지션 발생시킬부분*)
								< /transition>
								~~
								(css에서)
								.(*이름*)-enter-active { (*원하는 css효과*) }	=>트랜지션 name에 해당하는 트랜지션클래스
								.(*이름*)-leave { (*원하는 css효과*) }

				ㅇ 트랜지션 설정하기
					ㅡ 트랜지션 클래스)
						ㄴ 트랜지션 클래스는 트랜지션 효과를 설정해주는 css클래스이며, 6종류가 있고  각각 적용되는 타이밍이있다. 클래스이름은 < transition>에서 부여한 name속성값을
							앞에 붙여주는 형태이다.
						ㄴ 트랜지션 클래스 종류
							ㄴ (*이름*)-enter : 요소가 삽입되기전에 적용되고 한프레임 후에 제거.
							ㄴ (*이름*)-enter-active : 요소가 나타나는 트랜지션이 진행되는동안 적용
							ㄴ (*이름*)-enter-to : 요소가 나타나는 트랜지션이완료될때 적용
							ㄴ (*이름*)-leave : 요소가 사라지기시작할대 적용
							ㄴ (*이름*)-leave-active : 요소가 사라지느 트랜지션이 진행되는 동안 적용
							ㄴ (*이름*)-leave-to : 요소가 사라지는 트랜지션이 완료될때적용
						ㄴ css클래스이기때문에 트랜지션클래스의 내용으로는 css에서쓰는 트랜지션이나 애니메이션효과를 사용할수있다.

					ㅡ 트랜지션 설정하기 방법2)
						< transition>에 다음 속성들을 추가하는 방식으로 커스텀 트랜지션 클래스를 설정할수도있다. 외부 css라이브러리와 연결할때 유용하다고한다.
							ㄴ enter-class, enter-active-class, enter-to-class, leave-class, leave-active-class, leave-to-class

					ㅡ 트랜지션 설정하기 방법3)
						ㄴ < transition>에 js훅을 이벤트 등록하여 트랜지션효과를 설정할수도있다.
						ㄴ 제공되고있는 js훅은 다음과같다.
							before-enter, enter, after-enter, enter-cancelled, before-leave, leave, after-leave, leave-cancelled
						ㄴ ex)	< transition
									v-on:before-enter="beforeEnter"
									v-on:enter="enter"
									v-on:after-enter="afterEnter"
									v-on:enter-cancelled="enterCancelled"

									v-on:before-leave="beforeLeave"
									v-on:leave="leave"
									v-on:after-leave="afterLeave"
									v-on:leave-cancelled="leaveCancelled"
								>
								<!-- ... -->
								< /transition>
						ㄴ 속성값들을 인스턴스의 methods로 정의하면 된다.
						ㄴ enter, leave훅에 대해서는 해당 속성값인 함수안에 done()를 추가해야한다고한다.
						ㄴ v-bind:css="false"를 추가하여 css부분이 아예무시되도록 확실하게 설정하는것도 좋은방법이다.

					ㅡ 트랜지션효과와 애니메이션효과를 동시에쓸경우 주의사항)
						뷰가 내부 시스템상에서 트랜지션 효과가 끝났음을 알아야하는데, 이를 transitionend나 animationend로 파악을한다. 해서 트랜지션효과로 둘중 하나만사용하면
						문제가없지만, 둘다 사용하는경우 어떤동작이 끝났을때가 트랜지션효과가끝난건지를 결정해주어야한다고한다. 이를 < transition>의 type속성값으로 animation또는
						transition을 주어 결정해준다.

					ㅡ 트랜지션 래퍼 컴포넌트에 duration속성을 사용하여 트랜지션 지속시간을 설정할수있다.
						ex)	< transition :duration="1000">~~

				ㅇ 최초 렌더링시 효과부여
					ㅡ 요소 또는 컴포넌트가 최초 렌더링될때 트랜지션 효과가 나타나도록 설정할수있다.
						ㄴ 트랜지션 래퍼 컴포넌트에 'appear' 속성을 입력하면된다(속성값없이 그냥 appear만)
						ㄴ 또는 '트랜지션설정하기 방법2'처럼 커스텀 트랜지션 클래스를 지정할수도잇다.
							< transition
							appear
							appear-class="custom-appear-class"
							appear-to-class="custom-appear-to-class" (2.1.8+)
							appear-active-class="custom-appear-active-class"
							>
						ㄴ '트랜지션설정하기 방법3'처럼 js훅을 이용할수도있다.
							< transition
							appear
							v-on:before-appear="customBeforeAppearHook"
							v-on:appear="customAppearHook"
							v-on:after-appear="customAfterAppearHook"
							v-on:appear-cancelled="customAppearCancelledHook"
							>

				ㅇ html요소 간 트랜지션
					ㅡ < transition>안에는 요소나 컴포넌트 하나만 와야하지만, 예에서 보는것처럼 v-if등을 이용해서 여러 요소를 넣어놓고 동작시킬수있다.
						ㄴ단, 트랜지션 래퍼 컴포넌트 안에 같은이름의 태그가 겹치면 태그에 key라느 속성값을 주어 구분ㅇ이가능하도록해야한다.
					ㅡ ex)	< transition>
								< table v-if="items.length > 0">
									<!-- ... -->
								< /table>
								< p v-else>Sorry, no items found.< /p>
							< /transition>

				ㅇ 컴포넌트 간 트랜지션
					ㅡ 컴포넌트를 트랜지션할때)
						ㄴ 요소들간 트랜지션과 마찬가지로 < transition>내에는 하나의 컴포넌트만 올수있는데 '동적컴포넌트'를 이용하면 이런 제약을 좀 해결할수있다.

				ㅇ 트랜지션 모드
					ㅡ 트랜지션 래퍼 컴포넌트의 특징중 하나는 요소가 삽입되는과정과 제거되는과정이 동시에 이루어진다는것이다.
					ㅡ 이게 보기에 원하는 효과일수도있지만 아닐수도있다. 이때 트랜지션 모드를 이용하면 이를 조절할수있다.
					ㅡ < transition>태그에 'mode'라는 속성을 추가하고 속성값으로 'in-out' 또는 'out-in'을 준다.
					ㅡ in-out : 새로운 요소가 삽입된뒤, 제거될요소가 제거된다.
					ㅡ out-in : 위의 반대.

				ㅇ 리스트 트랜지션
					ㅡ 한꺼번에 여러개의 요소나 컴포넌트들을 동시에 트랜지션 설정하고자 할때 < transition-group>컴포넌트를 사용하면된다.
					ㅡ < transition>이 DOM요소를 직접랜더링하지않고 단순히 트랜지션 동작만 건드렸다면, < transition-group>은 DOM요소 자체를 랜더링한다. tag속성의
						속성값에 해당하는 요소하나를 랜더링한다. 기본값은 span.
					ㅡ 트랜지션 모드는 이것에선 의미가 없다.
					ㅡ 내부의 모든요소들은 key속성을 가져야한다. (key값은 리터럴 안됨)
					ㅡ ex)	< transition-group name="list" tag="p">      	=>< p>를 랜더링하며 그 내부에 아래의 내용들이 들어간다.
							< span v-for="item in items" v-bind:key="item" class="list-item">
								{{ item }}
							< /span>
						< /transition-group>
					ㅡ 리스트 트랜지션은 요소의 움직임에 대한 트랜지션 효과부여도 가능하다. css에 ' (*트랜지션name*)-move ' 형태로 클래스를 정의하면 트랜지션 래퍼 컴포넌트
						안의 요소가 움직일때 적용할 틀내지션 효과를 설정할수있다.
						ex)	< transition-group name="flip-list"~~>		=>name은 flip-list.
							~~
							(css에서)
							.flip-list-move{		=>이런식으로 이름을 사용.
								transition:transform 1s;
							}

				ㅇ 트랜지션 재사용
					ㅡ 컴포넌트로 트랜지션 내용을 미리 등록해놓고 재사용할수있다.
					ㅡ ex)
						Vue.component('my-special-transition', {
						template: '\
							< transition\
							name="very-special-transition"\
							mode="out-in"\
							v-on:before-enter="beforeEnter"\
							v-on:after-enter="afterEnter"\
							>\
							< slot>< /slot>\	=>이 slot태그부분이 지금만든 컴포넌트 안에 입력할 태그로 대체될부분.
							< /transition>\
						',
						~~
						(html에서)
						< my-special-transition>
							< p>haha< /p>	=>slot부분이 이 p부분으로 대체된다.
						< /my~~>

					ㅡ 이런식의 트랜지션 재사용은 컴포넌트부분에설명되어있는 'functional component' 와 잘 맞는다.

				ㅇ 상태 트랜지션
					ㅡ 요소나 컴포넌트뿐만 아니라 데이터값이나 css, svg노드의 위치?, 사이즈와 요소ㅇ의 다른속성들에 대해서도 트랜지션효과를 적용할수있다. 이 문서에서는 서드파이 라이브러리를 사용하였다.
					ㅡ watch 옵션속성을 사용하여 데이터 변화에 대한 애니메이션을 설정할수있다.
					ㅡ 예제1에서는 데이터 값의 변경에 대한 애니메ㅣㅇ션 효과를 넣고있고, 예제2에서는 css같은 색변화에 대해 애니메이션 효과를 넣굉ㅆ다.
					ㅡ예제 3은 뭘말하고싶은지모르겟음
					ㅡ 이런 상태 트랜지션이 많아질수록 코드의 복잡도가 빠르게증가하는데, 상태트랜지션을 하위컴포넌트로 분리해 정의하는것으로 이를 해결할수있다.

			</pre>
			재사용성과 컴포지션?<button>더보기</button>
			<pre>
				ㅇ Mixin
					ㅡ mixin 객체를 말한다. 이 객체는 컴포넌트가 가지는 옵션속성들을 모두 가질수있으며, 이후에 컴포넌트의 옵션속성으로 삽입되면 가지고있던
						모든 옵션속성들이 그 컴포넌트에 포함된다.
					ㅡ ex)	// define a mixin object
							var myMixin = {
							created: function () {
								this.hello()
							},
							methods: {
								hello: function () {
								console.log('hello from mixin!')
								}
							}
							}

							// define a component that uses this mixin
							var Component = Vue.extend({
							mixins: [myMixin]
							})

					ㅡ 컴포넌트의 재사용성을 높이는 유연한 기능이다.
					ㅡ 옵션속성의 중복시)
						ㄴ mixin의 옵션속성과 믹스인이 포함되는 컴포넌트의 옵션속성의 내용이 겹치면 특정 규칙에 의해 통합된다.
						ㄴ data옵션속성의 내용이 겹치면 컴포넌트가 가지고있느느 내용이 우선권을가지고 덮어씌여진다.
						ㄴ 훅(hook)이 겹치면 두개의 훅이 배열로써 통합되고 둘다 호출된다. 믹스인의 훅이 먼저 호출된다.
						ㄴ methods, components, directives와 같은 객체형태의 옵션속성들은 하나의 객체로 통합되며, 충돌시 컴포넌트의 내용이
							우선권을 가지고 덮어씌여진다.

					ㅡ 뷰의 Global Config인 'Vue.config.optionMergeStrategies'을 이용하면 통합규칙을 설정할수있다고한다.
						(어떻게쓰는지는 이해가 안감.)

				* 커스텀 옵션속성, custom option
					ㅡ 뷰 컴포넌트에 직접 만든 옵션속성을 추가할수있다.
					ㅡ 방법)
						1. 그냥 다른 옵션속성 정의하듯이 원하는 이름과 'Object'형태의 값을가지는 옵션속성을 정의한다.
							ex)	new Vue({
									el:"#app",
									mycustomoption1 : 'hello',
									mycustomoption2 : {
										x1:"haha",
										x2:"hehe"
									}
								}
								=> 'mycustomoption1'과 'mycustomoption2'를 커스텀옵션속성이름으로 정하고 값으로 문자열 'hello'
									와 객체 {x1:"haha",x2:"hehe"}를 주엇다.
						2. 정의한 커스텀 옵션속성을 인스턴스 내에서 '$options'키워드를 이용해 사용할수있다.
							ex)	~~~
								methods:{
									xxx:function(){
										console.log(this.$options.mycustomoption1);
										console.log(this.$options.mycustomoption2.x2);
									}
								}
								=>콘솔로 'mycustomoption1'의 문자열과 'mycustomoption2'의 x2값을 출력하였다.
					ㅡ 주의)
						ㄴ 문서를 읽고안게 아니라 대충예시보고 해보면서 안거라 정확하지 않을수있다.

				ㅇ 글로벌 Mixin
					ㅡ 글로벌 컴포넌트처럼 믹스인도 글로벌로 등록할수있다.
					ㅡ 주의)
						ㄴ 등록하면 이후에 생기는 모든 뷰 인스턴스에 이 믹스인이 포함되므로(third party까지) 매우 주의해서 사용해야한다
						ㄴ 보통 커스텀 옵션속성에 대한 로직처리로만 사용한다고한다. 아래 예와 같은
							ex)
								// inject a handler for `myOption` custom option
								Vue.mixin({
								created: function () {
									var myOption = this.$options.myOption
									if (myOption) {
									console.log(myOption)
									}
								}
								})

								new Vue({
								myOption: 'hello!'
								})
								// => "hello!"

				ㅇ custom directive (커스텀 지시자)
					ㅡ v-model, v-show 등과 같은 뷰 지시자들을 직접 만들수있다.
					ㅡ 방법)
						ㄴ 역시 글로벌 커스텀 지시자와 로컬 커스텀 지시자의 등록방법이있다.
							ㄴ 글로벌 커스텀 지시자 등록)
								ex)	Vue.directive( " (*커스텀지시자이름*) ", { (*커스텀 지시자 내용*) });
							ㄴ 로컬 커스텀 지시자 등록)
								ㄴ 옵션속성으로 'directives'옵션속성을 사용하면된다.
								ex)	~~
									directives:{
										(*커스텀지시자1이름*):{ (*커스텀지시자 내용*) },
										(*커스텀지시자2이름*):{ (*커스텀지시자 내용*) }
									}
						ㄴ (*커스텀지시자 내용*)으로 오는것들은 지시자를 정의할때 제공하는 hook function들이있다.
							ㄴ bind : 커스텀 지시자가 요소에 바운드될때 한번만 호출되는 함수.
							ㄴ inserted :
							ㄴ update :
							ㄴ componentUpdated :
							ㄴ unbind :
						ㄴ 그리고 이 hook function들은 자동적으로 다음과 같은 인자를 받는다.
							ㄴ el
							ㄴ binding : 다음의 프로퍼티들을 포함하고있는 객체.
								ㄴ name
								ㄴ value
									ㄴ 어떠한 자바스크립트 표현식도 값으로 받을수있다.
								ㄴ oldValue
								ㄴ expression
								ㄴ arg
									ㄴ 받는 값이 동적으로 바뀐다.
								ㄴ expression
								ㄴ modifiers
							ㄴ vnode
							ㄴ oldVnode

			</pre>

		</pre>
		React<button>더보기</button>
		<pre>
			ㅡ 리액트 공식홈페이지 문서 참고
			ㅇ 기본 개념<button>더보기</button>
			<pre>
				ㅡ 기타 기본) <button>더보기</button>
				<pre>
					ㄴ DOM vs virtual DOM )
						* DOM이란?
							ㅡ document object model
							ㅡ 브라우저 상에서, html이나 xml문서를 '노드'형태로 구조화하여, 각 노드에 접근하고 상호작용할 수 있게 해주는 api.
								ㄴ 노드란, html의 div같은 요소나 문자열 등이라 볼 수 있다.
								ㄴ js와 같이 자주 사용되지만 js와 dom은 독립적이다. 가령, 파이선에서도 dom이 존재한다.
						ㄴ 일반 DOM 조작 )
							ㄴ dom이란, 문서 객체 모델이라 하여, html의 요소들을 js가 이용할 수 있는 객체형태로 나타낸 것
							ㄴ 브라우저는 DOM을 그려서 웹 페이지를 보여준다.
							ㄴ js등으로 dom을 조작하게 되면 브라우저는 dom을 다시그리고, dom에 css을 다시 입혀서 화면을 보여준다.
								ㄴ 작은 변화가 생길때마다 브라우저가 dom을 다ㅣㅅ그리고 css를 입히는 식으로 불필요한 작업량이 많아진다.
								ㄴ 이 과정에서 성능이슈가 생길 수 있다.
						ㄴ 리액트의 virtual DOM 조작 )
							ㄴ 리액트에서는 실제DOM의 사본을 만들어(virtual dom) 이를 조작하는 방식으로 화면을 조작한다.
							ㄴ 가상 dom은 js코드이므로, 실제 dom보다 업데이트하는 속도가 매우 빠르다.
							ㄴ 가상 dom을 수정한후, 리액트가 실제 dom과 가상 dom의 차이를 확인하고 다른 부분만 업데이트 시켜주는 방식으로 동작.
							ㄴ 불필요하게 화면 전체의 dom을 다시그리지 않아 성능이슈가 해결된다.
							ㄴ 리액트에서는 이 가상 dom이 '리액트 엘리먼트'로 이루어져 있다. 이 리액트 엘리먼트와 dom과의 차이를 비교해서 다시그려주는 작업을 해주는게 '리액트 dom'이라 한다.
								ㄴ ex) const element = < h2>hello< /h2>
				</pre>
				ㅡ JSX )<button>펼치기</button>
				<pre>
					* JSX<button>더보기</button>
					<pre>
						ㅡ js로 컴파일되는 statically-typed, object-oriented 프로그래밍 언어이다.
						ㅡ js보다 더 강력한 언어를 만들기 위해, 그리고 js의 성능향상을 위해 만들어졌다.
							ㄴ 그래서 statically-typed이고
							ㄴ 'inline expansion'이라는 기능으로 js의 성능을 향상시켜준다.
								ㄴ 'inline expansion'은 함수의 바디가 그 함수가 호출되는 곳으로 확장되는 것? { ()=>{ ~~~~ } } 이런걸 말하나?
						ㅡ 문법과 표현이 js와 많이 닮았다.
						ㅡ ????? 이건 DeNA Co의 JSX? 리액트에서 사용하는 JSX랑 다른건가? 똑같을거같은데..
					</pre>
					ㄴ js의 일종. js를 확장한 문법이라함.
					ㄴ 리액트에서 js코드로 '리액트 엘리먼트'를 쉽게 생성하게 하기위해 추가된 문법이다. 아래 예제와 같이 문법에 맞게 작성하면
						'Babel'컴파일러가 이를 React.createElement()로 적절하게 변환해주어 '리액트 엘리먼트'를 생성할 수 있게 된다.
					* Babel <button>더보기</button>
					<pre>
						ㅡ https://babeljs.io/docs/en/index.html
						ㅡ js 컴파일러
						ㅡ 주로, 현재와 이전 브라우저, 환경에서 ECMAScript 2015+코드를 이전버전js로 변환하는데 사용되는 도구모음.
						ㅡ 기능
							ㄴ 변환 구문
							ㄴ 대상 환경에서 누락된 기능들
							ㄴ 소스코드 변환
							ㄴ 기타 등등
						ㅡ 이 안에 React의 JSX를 변환해 주는 기능이 포함되어 있다.
					</pre>
					ㄴ 구체적으로 어떻게 변환되는지는 안알아봄.
					ㄴ 'XML-Like js'라 하여 'JSX'라 불린다한다.
						ㄴ html요소들이 나열된 코드가 xml같이 생겼는데, 이런 html요소들을 js에서 작성하여 사용하는 형식이 xml하고 비슷하다해서..
					ㄴ ????? 위에서 아주 간략하게 설명한 JSX와 동일한건지는 잘 모르겠다.
					ㄴ ex)	const name = 'aaa';
						const element = < h1>hello, {name}< /h1>
						ㄴ name이라는 변수를 JSX의 중괄호 안에 넣었다.
						ㄴ JSX의 중괄호 안에는 모든 'js의 표현식'을 넣을 수 있다.
							ㄴ 수식, 함수 등등
					ㄴ jsx자체도 js의 표현식.
					ㄴ 중괄호 뿐만 아니라 큰 따옴표로도 값을 부여할 수 있다. ex)	const element = < div tabIndex="0">< /div>
					ㄴ ????? jsx의 주입공격 방지 )
						ㄴ ????? React DOM은 jsx에 삽입된 값을 렌더링하기 전에 '이스케이프'한다.
					ㄴ 자식 태그를 포함할수있다.
						ㄴ ex)	const element = (
								< div>
									< h1>hello< /h1>
									< h2>good to see you< /h2>
								< /div>
							);
					ㄴ 리액트에서는 JSX를 React.createElement()를 호출해 컴파일한다.
						ㄴ 대략 다음과 같이 생긴 객체를 생성한다.
							const element = {
							type: 'h1',
							props: {
								className: 'greeting',
								children: 'Hello, world!'
							}
							};
							ㄴ 이러한 객체를 'React 엘리먼트'라고 한다.
							ㄴ 리액트는 이러한 객체를 읽어 DOM을 구성 및 최신상태로 유지한다.
				</pre>
				ㅡ 엘리먼트 렌더링 )<button>펼치기</button>
				<pre>
					ㄴ 엘리먼트란?
						ㄴ React의 가장 작은 단위.
						ㄴ ex)	const element = < h2>hello< /h2>; =>element를 리액트의 '엘리먼트'라고 한다.
						ㄴ html의 < h2>hello< /h2>와 같은 브라우저DOM엘리먼트가 아닌 일반 객체(plain object)이다.
						ㄴ 화면에 표시할 내용에 대해 기술하는 단위?
						ㄴ 'React DOM'은 'React 엘리먼트'와 일치하도록 DOM을 업데이트한다.
						ㄴ '컴포넌트'와는 다르다.
					ㄴ 루트 dom 노드?????
					ㄴ 리액트 엘리먼트를 루트dom노드에 렌더링하려면 ReactDOM.render()를 호출하면서 인자로 넘기면 된다.
					ㄴ 리액트 엘리먼트는 '불변객체'이다. 한번 생성한 후에는 자식이나 속성을 변경할수없다.
					ㄴ 리액트 DOM은 해당 엘리먼트와 그 자식엘리먼트를 이전 엘리먼트와 비교하여 DOM을 원하는 상태로 만드는데 있어서 변경이 필요한 부분만 dom을 업데이트한다.
					ㄴ ReactDOM.render(element, container[, callback])
						ㄴ 인자로 전달받은 '리액트 엘리먼트(element인자)'를 실제 DOM(container인자)에 붙여서 렌더링한다.
						ㄴ ex)
							↓ html코드
							< body>
								< div id="root">< /div>
								< div id="root2"> < /div>
							< /body>
							----------------------------------------
							ReactDOM.render(	//root div에 App 리액트 컴포넌트를 붙이고 있다.
								< React.StrictMode>
									< App />
								< /React.StrictMode>,
							document.getElementById('root')
							);
							ReactDOM.render(//root2 div에 App2 리액트 컴포넌트를 붙이고 있다.
								< React.StrictMode>
									< App2 />
								< /React.StrictMode>,
								document.getElementById('root2')
							);
						ㄴ ?????
						ㄴ 컨테이너 노드 자체를 수정하지 않고, 그 하위 노드들만 수정한다.
					ㄴ ReactDOM.render ( (*리액트 엘리먼트*), (*DOM엘리먼트??*) )를 수행하면 (*DOM엘리먼트*)에 (*리엑트 엘리먼트*)에서 나타내는 내용을 리액트에서 알아서 잘 랜더링을 해주는식인듯함.
					ㄴ 엘리먼트는 변수 안에 저장 가능하다.
					ㄴ < div>hello< /div>와같은 일반 DOM 리액트 엘리먼트도 있지만,
						사용자 정의 컴포넌트와 같이 ( < MyComponent props={props}/> ) Component 리액트 엘리먼트도 있다.
				</pre>
				ㅡ 컴포넌트 )<button>펼치기</button>
				<pre>
					ㄴ js의 함수와 유사하다.
					ㄴ 'props'라는 입력값을 받아 React엘리먼트를 반환한다.
					ㄴ 함수 컴포넌트 )
						ㄴ ex)	function Welcom(props){
								return < h1>hello, {props.name}< /h1>;
							}
						ㄴ 'porps'라는 객체인자를 받아서 리액트 엘리먼트를 반환하므로 유효한 리액트 컴포넌트???
						ㄴ 이 컴포넌트는 js함수이기때문에 '함수 컴포넌트'라고 부른다.
					ㄴ ES6 class를 사용한 컴포넌트 )
						ㄴ ex)	class Welcome extends React.Component {
								render() {
									return < h1>hello, {this.props.name}< /h1>;
								}
							)
						ㄴ ES6 class를 사용하지 않고도 리액트 컴포넌트를 사용할 수 있다.
					ㄴ React는 사용자 정의 컴포넌트가 나오면, JSX의 속성과 자식을 컴포넌트에게 단일 객체로 전달한다. 이 객체를 'props'라고 한다.
					ㄴ React는 props를 전달하면서 해당 컴포넌트를 호출한다.
					ㄴ 컴포넌트에서 리액트 엘리먼트가 반환되고 React는 이를 DOM에 적절히 업데이트한다.
					ㄴ 컴포넌트는 내부에서 다른 컴포넌트를 참조할 수 있다.
						ㄴ ex)
							function App() {
							return (
								< div>
								< Welcome name="Sara" />
								< Welcome name="Cahal" />
								< Welcome name="Edite" />
								< /div>
							);
							}
					ㄴ '훅'이 나오기 이전에는 '컨테이너 컴포넌트'(전체 state, 라이프사이클, 로직 담당)로서 클래스형 컴포넌트를 사용하고
						'뷰 컴포넌트?'(화면에 보여지는 부분만 담당)으로 함수형 컴포넌트를 주로 사용했다고 한다.
					ㄴ 컴포넌트는 대문자로시작해야하는듯??
					ㄴ 컴포넌트 추출 )
						ㄴ 컴포넌트를 재사용가능한 요소로서 만들어 적절하게 모듈화?같이 사용해라.
						ㄴ ex)
							function Comment(props) {
							return (
								< div className="Comment">
								< div className="UserInfo">
									< img className="Avatar"
										src={props.author.avatarUrl}
										alt={props.author.name}
									/>
									< div className="UserInfo-name">
									{props.author.name}
									< /div>
								< /div>
								< div className="Comment-text">
									{props.text}
								< /div>
								< div className="Comment-date">
									{formatDate(props.date)}
								< /div>
								< /div>
							);
							}
							ㄴ 위와 같이 복잡하게 커다란 컴포넌트를 만들지 말고, 적절하게 여러 컴포넌트들로 나누어서 재사용될수있고 단순하게 만들어라.
					ㄴ props는 변경되어서는 안된다. 읽기만 해야한다.
					ㄴ null반환시 아무것도 랜더링되지 않는다.
				</pre>
				ㅡ State와 lifecycle )<button>펼치기</button>
				<pre>
					ㄴ 틱톡 컴포넌트 예제 )
						ㄴ
						ㄴ 클래스형 리액트 컴포넌트 )
							ㄴ
						class (*이름*)
					ㄴ State 업데이트는 constructor를 제외하고는 this.state를 통해 직접 넣을경우, 리액트는 컴포넌트를 다시 랜더링하지 않는다.
						ㄴ setState()를 사용해야한다.
					ㄴ State 업데이트는 한번에 여러개가 될수있지만 비동기적일 수 있기때문에 각 업데이트가 props, state에 의존해서는 안된다.
					ㄴ State 병합 )
						ㄴ State에 부여한 객체들은 독립적으로 존재한다?
						ㄴ 내부적으로 이 객체들은 State안으로 병합된다.
						ㄴ ex)
						constructor(props) {
							super(props);
							this.state = {
							posts: [],
							comments: []
							};
						}	=>이렇게 posts, comments라는 객체를 State가 가지고있다하면,
						componentDidMount() {
							fetchPosts().then(response => {
							this.setState({
								posts: response.posts		=>State안의 comments에는 전혀 영향이없다.
							});
							});

							fetchComments().then(response => {
							this.setState({
								comments: response.comments
							});
							});
						}	=>이런식으로 따로따로 setState()를 하여도 State안에있는 다른객체에 영향을 주지않는다. 그리고 병합된다.
					ㄴ 컴포넌트 내부의 자식 컴포넌트에게 State를 인자로 넘겨줄수있다. 위로는 안된다 (하향식 데이터 흐름)
						ㄴ 자식은 이게 state인지 다른것인지 전혀모른다.
					ㄴ setState()
						ㄴ state에 대해 수정요청을하고 리액트에게 바뀐값에 맞게 다시 랜더링 되어야한다고 알린다.
						ㄴ 즉각ㅈ적으로 수행되지 않는다. setState()는 요청을 넣기만하고 리액트에서 이후에 다시 랜더링하는 방식.
						ㄴ 얕은 update만 수행한다.
							ㄴ 무슨말이냐하면,
								this.state = {
									id : 1,
									list : { num : 2, sum : 10 }
								}
								위와같이 state내부에 또다른 객체가있으면 setState()시, list의 내부값까지 수정할수 없다. setState()로 list를 수정할 경우, 그 수정하는 값으로 완전히 대체된다.
						ㄴ 프로퍼티부분에 '계산된 속성명(computed property name)'을 사용할수있다.
					ㄴ 실무적인 팁 )
						ㄴ 컴포넌트 내의 어떤 값이 props나 state로부터 계산될수있는값이면 굳이 그 값을 props나 state로 만들어두지 말라고한다. 최소한의 props, state만 남겨두고 이것들로부터 계산할수있는것들은 render()안에서 props,state로부터 계산하여 사용하라고 한다.
				</pre>
				ㅡ 이벤트 처리 )<button>펼치기</button>
				<pre>
					ㄴ ex)
						< button onClick={activateLasers}>
						Activate Lasers
						< /button>
						ㄴ 리액트에서는 이베트처리시, 문자열이 아닌 JSX를 이용해 함수를 값으로 전달한다.
					ㄴ 리스너함수에서 false를 반환하더라도 이벤트 기본동작을 막을수없다. 명시적으로 priventDefault()를 호출해야한다.
					ㄴ 리스너 함수 정의시 인자로 'SyntheticEvent'를 받을 수있다.
					ㄴ 클래스형 컴포넌트 사용시 일반적인 리액트의 이벤트 처리 방식은, 이벤트 핸들러를 컴포넌트의 메소드로 만드는것이다.
					ㄴ ?????onClick={(*함수*)}에서 (*함수*)부분에 함수명과같은 식별자를 전달하지 않고 '함수명()'과 같은형식으로 함수를 실행하면 무한루프에 빠진다고한다.
					ㄴ 이벤트 인자 전달하기 )
						ㄴ < button onClick={(e) => this.deleteRow(id, e)}>Delete Row< /button>
							ㄴ 화살표함수를 사용하여 인자전달. 이벤트인자(e)를 명시적으로 전달해주어야한다.
						ㄴ < button onClick={this.deleteRow.bind(this, id)}>Delete Row< /button>
							ㄴ Funtion.prototype.bind()를 이용하여 인자전달. 이벤트인자(e)가 자동으로 전달된다고 한다.
				</pre>
				ㅡ 조건부 랜더링 )<button>펼치기</button>
				<pre>
					ㄴ js의 if문과 같은 조건부연산자를 이용하여 조건부 랜더링이 가능하다.
					ㄴ ex)
						function Greeting(props) {
						const isLoggedIn = props.isLoggedIn;
						if (isLoggedIn) {
							return < UserGreeting />;
						}
						return < GuestGreeting />;
						}

						ReactDOM.render(
						// Try changing to isLoggedIn={true}:
						< Greeting isLoggedIn={false} />,
						document.getElementById('root')
						);
					* js 논리연산자 &&, ||
						ㄴ expr1 && expr2 : expr1이 true인경우 expr2반환. 아니면 expr1반환.
						ㄴ expr1 || expr2 : expr1이 true인경우 expr1반환. 아니면 expr2반환.
						ㄴ !expr : expr이 true이면 false반환. 아니면 true.
					ㄴ 논리연산자 &&, || 또는 삼항 논리연산자 () ? () :() 도 사용가능하다.
				</pre>
				ㅡ 리스트와 key )<button>펼치기</button>
				<pre>
					* js 의 Array의 map()
						ㅡ ex)	array1.map( x => x*2 );
						ㅡ 배열 안의 각 요소에 대해 map()안에정의된 콜백함수를 수행하여 새로운 배열을 반환한다.
					ㄴ 리액트에서 여러개의 컴포넌트를 렌더링하는 방법은 js의 map()이용하는것과 비슷하다.
						ㄴ ex)
							const numbers = [1, 2, 3, 4, 5];
							const listItems = numbers.map((number) =>
							< li>{number}< /li>
							);
							ReactDOM.render(
							< ul>{listItems}< /ul>,
							document.getElementById('root')
							);
							ㄴ listItems에는 엘리먼트배열이 저장된다.
							ㄴ 그리고 이걸 < ul>안에 랜더링하면된다.
					ㄴ  일반적으로는 컴포넌트 안에서 엘리먼트 리스트를 만드는식으로 개발한다고함.
						ㄴ ex)
							function NumberList(props) {
							const numbers = props.numbers;
							const listItems = numbers.map((number) =>
								< li key={number.toString()}>
								{number}
								< /li>
							);
							return (
								< ul>{listItems}< /ul>
							);
							}
					ㄴ 리액트에선 리스트 엘리먼트 등에 대해 '키'값을 부여해주어야 한다.
						ㄴ 항목들에 대해 변경,추가,삭제하는걸 돕는다.
						ㄴ 해당 항목을 고유하게 실별할수있는 문자열을 사용해야한다.
							ㄴ 보통 데이터의 id를 사용한다.
							ㄴ 아니면 최후의 수단으로 항목의 인덱스를 key로 사용한다.
								ㄴ 항목의 순서가 바뀔수있으므로 권장하지않는다함.
						ㄴ ?????키값은 반복되는 각 항목에 지정하는게 아닌, 배열부분에 지정해주어야한다??
							ㄴ map()함수 안에있는 엘리먼트에 지정해주는게 일반적으로 좋다함
							ㄴ ex)
								const listItems = numbers.map((number) =>
									// 맞습니다! 배열 안에 key를 지정해야 합니다.
									< ListItem key={number.toString()} value={number} />
								);
											ㄴ 키값은 형제 사이에서만 고유하면된다.
											ㄴ 키값은 컴포넌트 내부로 전달되지 않는다. key의 값이 필요하면 동일한 값의 다른 속성을 선언하여 넘겨주어야한다.
												ㄴ ex)
								const content = posts.map((post) =>
								< Post
										key={post.id}
										id={post.id}
										title={post.title} />
								);
								ㄴ key는 컴포넌트 내부에서 사용할수없다. 전달되지 않는다.
								ㄴ kdy와 같은값이 필요하면 id라는 이름의 다른 props를 선언하여 넘겨주어야한다.
				</pre>
				ㅡ <a name="React_기본개념_form">form</a> )<button>펼치기</button>
				<pre>
					ㄴ html의 < input>, < textarea>, < select>등은 고유의 상태값을 가지고, 이는 사용자의 입력값에따라 변경된다.
					ㄴ 리액트에서는 state가 존재하고 이는 setState()에 의해서 변경된다.
					ㄴ 리액트의 state를 'single source of truth'로 만들어 위의 두 요소를 결합할 수 있다고 한다.
						ㄴ 이를 통해 리액트 컴포넌트에서 form에서 발생하는 사용자 입력값을 제어할 수 있다고 한다.
						ㄴ 이러한 폼 엘리먼트르 ㄹ'제어 컴포넌트'라고 한다.
					ㄴ ex)
						class NameForm extends React.Component {
						constructor(props) {
							super(props);
							this.state = {value: ''};

							this.handleChange = this.handleChange.bind(this);
							this.handleSubmit = this.handleSubmit.bind(this);
						}

						handleChange(event) {
							this.setState({value: event.target.value});
						}

						handleSubmit(event) {
							alert('A name was submitted: ' + this.state.value);
							event.preventDefault();
						}

						render() {
							return (
							< form onSubmit={this.handleSubmit}>
								< label>
								Name:
								< input type="text" value={this.state.value} onChange={this.handleChange} />	=>value값이 항상 컴포넌트의 state.value가 된다. 그리고 input에 값을 입력할때마다 handleChange가 호출되어 입력된 값을 컴포넌트의 state.value에 업데이트하므로, input의 value값은 항상 현재 바로 그순간에 입력되어있는값이 되며, 이를 통해 컴포넌트에서 이값을 처리하거나 다른컴포넌트로 넘길수도있다.
								< /label>
								< input type="submit" value="Submit" />
							< /form>
							);
						}
						}
					ㄴ < textarea >의 폼제어의 경우)
						ㄴ html의 < textarea > 는 바로 아래있는 자식text dom을 내용으로 가진다.
						ㄴ 리액트에서는 자식text dom이 아닌 < textarea >의 value속성값을 주어 form과 똑같이 컨트롤한다.
							ㄴ ex)
								render() {
									return (
									< form onSubmit={this.handleSubmit}>
										< label>
										Essay:
										< textarea value={this.state.value} onChange={this.handleChange} />
										< /label>
										< input type="submit" value="Submit" />
									< /form>
									);
								}
					ㄴ < select>의 폼제어의 경우 )
						ㄴ 아는 select와 동일...
						ㄴ 리액트에서는 < select value={this.state.id}>와 같이 < select>안에 value속성을 가질수있다.
					ㄴ file input )
						ㄴ < input type="file">은 사용자만 값을 입력할수있는 읽기전용이기때문에 '비제어 컴포넌트'이다.
						ㄴ '고급 안내서'의 '비제어 컴포넌트'에서 더 자세하게 나온다.
					ㄴ 모든 폼의 값에 대하여 이벤트처리로 리액트의 state에 값을 반영하는식으로 입력값을 제어하는게(즉, 제어컴포넌트 사용) 너무반복작업일경우 '비제어 컴포넌트'가 대체기술이 될수있다고한다.
					ㄴ Formik : 가장 대중적인 리액트 form 라이브러리. 유효성검사, 방문한 필드추적, 제출처리 등 다양한 기능 제공.
						ㄴ '제어 컴포넌트'와 state관리를 원리로 만들어졌다고 한다.
				</pre>
				ㅡ 컴포넌트간 state전달. state끌어올리기 )<button>펼치기</button>
				<pre>
					ㄴ 컴포넌트간 데이터를 전달하는게 필요할때 사용할수있는 방법을 소개한다.
					ㄴ 부모,자식 관계의 컴포넌트간 데이터 전달 방법 )
						ㄴ 부모 컴포넌트에서 자식컴포넌트로 props를 전달할때, 부모 컴포넌트의 state와 그 state를 변경할수있는 메소드를 같이 넘겨준다.
						ㄴ 자식 컴포넌트에서는 원래props을 수정할수없지만, 같이넘겨받은 메소드를 호출하여 부모컴포넌트의 state를 변경할수있다.
					ㄴ 이런식의 하향식 데이터 흐름으로 컴포넌트간 데이터를 주고받음으로서 버그를 더 찾기쉽다고한다.
				</pre>
				ㅡ 합성, 상속 )<button>펼치기</button>
				<pre>
					ㄴ 합성 )
						ㄴ 리액트에서 합성이란, 한 컴포넌트에서 여러컴포넌트들을 사용하여 컴포넌트를 구성하는것.
							ㄴ 그냥 render안에서 다른 컴포넌트 가져와 사용하는걸말함.
							ㄴ ex)
								function App() {
								return (
									< SplitPane
											left={
										< Contacts />
									}
									right={
										< Chat />
									} />
								);
								}
						ㄴ 다른 컴포넌트를 props로 받을수도있다고 한다.
					ㄴ 상속 )
						ㄴ extends를 사용하여 컴포넌트를 만드는 방식.
						ㄴ 공식문서에서는 추천하지 않는다고한다.
							ㄴ 합성을 사용하는것만으로도 충분히 대부분의 기능구현이 가능하고
							ㄴ 합성이 더 유연하고 안전하다.
							ㄴ ui부분이 아닌 js함수와 같은 로직을 재사용하기를 바란다면, 이건 상속할필요없이 js파일을 따로만들고 import하는 방식으로도 가능하다.
				</pre>
				ㅡ 리액트 간단 실습 )<button>펼치기</button>
				<pre>
					ㄴ 먼저 컴포넌트 구성을 설계한다 )
						ㄴ 전체컴포넌트를 어떻게 구성할건지, 아마 계층형으로 구성하게될거고, 컴포넌트마다 이름을 붙이고, 그런단계
						ㄴ 컴포넌트 결정에 있어서 하나의 원칙은 '단일책임원칙'이다. 하나의 컴포넌트는 하나의 책임만 맡아야한다.
							ㄴ 마치 html페이지에서 div로 페이지 부분부분을 세분화하듯이 컴포넌트를 나누는 느낌이다.
					ㄴ '정적인' 버전을 만든다 )
						ㄴ 데이터를 가져와 뿌려주고, 전체 페이지가 렌더링되어 완전하게 나오기는 하되, 동적인 동작이 없는 것부터 만드는것.
							ㄴ 동적인 부분이 없기때문에 state는 사용하지 않는다함. state는 동적인 상호작용에 쓰이는거라함.
							ㄴ props를 통해 데이터를 전달하며 정적버전을 만들게됨.
						ㄴ '상향식'과 '하향식' 방식 )
							ㄴ 하위 계층의 컴포넌트부터 만들어가는게 상향식. 상위의 전체 컴포넌트부터 만드는게 하향식.
							ㄴ 간단한거면 하향식이 좋지만 크고 복잡한 프로젝트는 상향식으로 테스트를 해가며 개발하는게 좋다함.
					ㄴ 최소한의 state 찾기 )
						ㄴ 동적인 부분을 만들기 위해 state를 사용할건데, 이때 필요로하는 state의 최소집합을 찾아야 한다.
						ㄴ '중복배제'의 원칙을 생각하며 찾는다.
						ㄴ 최소한의 state를 찾고 나머지는 이 state들로 계산이나 로직을 통해 사용하도록 하라.
						ㄴ 또한 props에 있는 값이면 제외시켜라.
					ㄴ state를 가지는 컴포넌트 결정 )
						ㄴ 동적인 부분을 위해 필요한 최소한의 state값들을 어떤 컴포넌트가 가져야 하는가를 결정.
						ㄴ 참고사항 )
							ㄴ 그 state를 가지고 렌더링을 하는 모던 컴포넌트를 찾는다.
							ㄴ 이 컴포넌트들의 공통 조상컴포넌트인 '공통 소유 컴포넌트'를 찾는다.
							ㄴ 공통 조상일수록 그 state를 가지는게 좋다.
					ㄴ 역방향 데이터흐름 추가 )
						ㄴ 위에서 배운 'state 끌어올리기'를 통해 역방향 데이터 흐름을 필요시에 만든다.
				</pre>
				ㅡ 리액트 어플리케이션 구조 )<button>펼치기</button>
				<pre>
					ㄴ 크게 node_modules, public, src로 이루어짐.
						ㄴ 개발은 주로 src/App.js와 src아래에 하위폴더를 만들어 이 안에 Component별 js파일을 생성하며 진행된다.
					ㄴ src/index.js : App의 엔트리 포인트. 루트 컴포넌트를 DOM에 마운팅하는 역할.
				</pre>

			</pre>
			ㅇ 고급 안내서<button>더보기</button>
			<pre>
				ㅇ 접근성<button>더보기</button>
				<pre>
					ㅡ ????? 무슨 신체적 장애를 가진 사람들도 웹페이지에 쉽게 접근할수있도록 해야한다???

				</pre>
				ㅇ 코드분할<button>더보기</button>
				<pre>
					ㅡ ~~~~~
					ㅡ 웹팩, 번들 사용과 관련하여 번들이 너무 커지지 않도록 동적? 지연로딩? 같이 사용하는 방법 등을 통해
						'코드 분할'을 하는 방법을 설명하는듯하다.

				</pre>
				ㅇ Context <button>더보기</button>
				<pre>
					ㅡ 간단하게 리액트 컴포넌트 사이의 전역변수같은 느낌의 데이터를 사용하게 해주는것.
					ㅡ 간단 사용법 )
						ㄴ ex)
							const ThemeContext = React.createContext('light');	//context생성
							~~~
							< ThemeContext.Provider value="dark">
								< Toolbar />
							< /ThemeContext.Provider>	//이런식으로 context로 컴포넌트를 감싸주면, 해당 컴포넌트와
														그 하위에 있는 컴포넌트에서 context에 접근할수있다.
							< Toolbar>하위의 컴포넌트에서 context를 사용하려면,
							static contextType = ThemeContext; //contextType으로 context를 지정.
							render() {
								return < Button theme={this.context} />; //context값 사용. 위에서 지정한 'dark'값이 적용.
							}
					ㅡ api )
						ㄴ React.createContext( (*디폴트context값*) )
							ㄴ ex) const MyContext = React.createContext(defaultValue);
							ㄴ context객체 생성.
							ㄴ context의 범위 안에있는 컴포넌트를 랜더링할때 리액트는 부모쪽으로 가장 가까운 'Provider'를 찾아
								그 값을 읽어들인다.
							ㄴ (*디폴트context값*) : 적절한 Provider를 찾지 못했을때 사용되는값.
						ㄴ < (*context객체*).Provider value = { (*값*) } />
							ㄴ context객체 안의 Provider 컴포넌트를 이용해, 하위의 context범위 안의 컴포넌트들에게 context값의
								변화를 알린다.
								ㄴ context값을 찾을때 부모쪽으로 가장 가까운 Provider를 찾아 그 값을 사용한다했으므로,
									이 아래의 컴포넌트들에는 Provider가 제공한 (*값*)이 context에 사용되는것.
							ㄴ context의 범위 아래의 컴포넌트들은 (*값*)이 바뀔때마다 랜더링된다.
							ㄴ ????? Provider로부터 하위 consumer(.contextType와 useContext을 포함한)로의 전파는
								shouldComponentUpdate 메서드가 적용되지 않으므로, 상위 컴포넌트가 업데이트를 건너 뛰더라도
								consumer가 업데이트됩니다.
							ㄴ ?????내부적으로 context값이 변경되었는지 아닌지의 기준은 js의 Object.is()의 메커니즘과 동일하다고 한다.
						ㄴ (*컴포넌트 클래스*).contextType
							ㄴ 컴포너트 클래스의 contextType 프로퍼티에 context객체를 주어서 해당 클래스 안에서 context를 사용하도록
								할 수있다.
							ㄴ ex)	class MyClass extends React.Component {
									componentDidMount() {
										let value = this.context;
										/* MyContext의 값을 이용한 코드 */
									}
									componentDidUpdate() {
										let value = this.context;
										/* ... */
									}
									componentWillUnmount() {
										let value = this.context;
										/* ... */
									}
									render() {
										let value = this.context;
										/* ... */
									}
									}
									MyClass.contextType = MyContext;
							ㄴ context 값을 찾는 방식은 동일하다.
						ㄴ  Context.Consumer
							ㄴ ex)	< MyContext.Consumer>
									{value => /* render something based on the context value */}
									< /MyContext.Consumer>
							ㄴ context객체의 컴포넌트 Consumer. 위와같이 Consumer컴포넌트 내부에 함수를 정의하면 이 함수의
								인자로 context값이 넘어간다.
							ㄴ 함수형 컴포넌트 안에서 context를 사용하는데에 쓰인다.
							ㄴ context의 값을 찾는 방법은 동일하다.
						ㄴ ????? Context.displayName
					ㅡ 단점 )
						ㄴ 컴포넌트 재사용성이 어려워지므로 주의해서 사용.
							ㄴ context보다 컴포넌트 '합성'이 더 좋을수도있다.
					ㅡ 여러 context값을 사용하는 경우 )
						ㄴ ?????'render props 컴포넌트'를 사용하라고 한다.
					ㅡ 주의사항 ?????
					ㅡ 실무 )
						ㄴ Provider의 value를 컴포넌트의 state값을 주어서 state가 변화할때마다 context를 사용하는 하위의
							컴포넌트들이 다시 랜더링되는식으로 사용.
						ㄴ 아주 깊숙히 있는 컴포넌트에서 context의 값을 변경하려면, props로 함수를 넘겨 자식컴포넌트가 상위 컴포넌트의
							state값을 변경시켜주듯이, context의 값에 함수를 넘겨주고, 그 함수에서 context값을 변경시켜주면된다.
				</pre>
				ㅇ 에러 경계 <button>더보기</button>
				<pre>
					ㅡ 개요 )
						ㄴ 에러 경계란? 렌더링 과정에서 발생하는 하위 컴포넌트에서 발생하는 에러를 주시하고있다가 발생시, 에러로 인해
							깨진 컴포넌트 대신 폴백ui를 보여주는 React 컴포넌트이다.
					ㅡ 기본 사용법 )
						ㄴ ex) 	class ErrorBoundary extends React.Component {
								constructor(props) {
									super(props);
									this.state = { hasError: false };
								}

								static getDerivedStateFromError(error) {
									// 다음 렌더링에서 폴백 UI가 보이도록 상태를 업데이트 합니다.
									return { hasError: true };
								}

								componentDidCatch(error, errorInfo) {
									// 에러 리포팅 서비스에 에러를 기록할 수도 있습니다.
									logErrorToMyService(error, errorInfo);
								}

								render() {
									if (this.state.hasError) { //에러가 발생하여 hasErorr값이 true일경우 대체ui를 렌더링할수있도록.
									// 폴백 UI를 커스텀하여 렌더링할 수 있습니다.
									return < h1>Something went wrong.< /h1>;
									}

									return this.props.children;
								}
								}
								~~~~~
								에러 경계 사용시,
								< ErrorBoundary>
								< MyWidget />
								< /ErrorBoundary>	//이런식으로 에러를 확인하려는 대상 컴포넌트를 에러경계로 감싸주면 된다.
						ㄴ getDerivedStateFromError()나 componentDidCatch()를 사용하여 하위의 컴포넌트에서 발생한 에러를 받아
							처리를 할 수 있다.
							ㄴ getDerivedStateFromError( error )
								ㄴ 생명주기 메소드.
								ㄴ 하위의 컴포넌트에서 에러 발생시 호출된다.
								ㄴ 매개변수로 에러를 받는다.
								ㄴ 갱신된 state값을 반드시 반환해야 한다.
								ㄴ ?????랜더링 단계에서 호출되므로 부수효과를 발생시켜서는 안된다.
							ㄴ componentDidCatch( error, info )
								ㄴ 생명주기 메소드.
								ㄴ 하위 컴포넌트에서 에러 발생시 호출된다.
								ㄴ 매개변수로 에러와 어떤 컴포넌트가 에러를 발생시켰는지에 대한 정보 등이 담긴 객체를 받는다.
								ㄴ ????? 커밋단계에서 호출되므로 getDerivedStateFromError()와 다르게 부수효과를 발생시켜도 된다.
					ㅡ 다음과 같은 에러는 포착하지 않는다.
						ㄴ 이벤트 핸들러의 에러
							ㄴ 이벤트 핸들러 내에서 에러를 잡아야 할경우 js의 try-catch문을 사용하라.
						ㄴ 비동기적 코드의 에러
						ㄴ 서버 사이드 렌더링
						ㄴ 에러 경계 자체에서 발생한 에러.
					ㅡ 클래스형 컴포넌트만이 에러경계가 될 수 있다.
					ㅡ React 16부터는 에러 경계에 포착되지 않은 에러 발생시, 전체 React컴포넌트의 마운트가 해제된다.
						ㄴ 문제가있는 컴포넌트를 그래도 렌더링하는것보다는 아예 안나오게하는게 더 낫다고 판단했기때문이라함.
				</pre>
				ㅇ Ref와 DOM <button>더보기</button>
				<pre>
					ㅡ 개요 )
						ㄴ Ref라는것을 하위 컴포넌트에게 전달하는 기술을 말함.
						ㄴ 대부분의 컴포넌트에서는 사용할일이 없지만, 재사용 라이브러리와 같은 일부 컴포넌트에서 유용하게 사용된다.
						ㄴ ~~~~~
					ㅡ 기본 사용법 )<button>펼치기</button>
					<pre>
						ㄴ ex)	class CustomTextInput extends React.Component {
								constructor(props) {
									super(props);
									// textInput DOM 엘리먼트를 저장하기 위한 ref를 생성합니다.
									this.textInput = React.createRef();	//React.createRef()를 통해 Ref생성.
									this.focusTextInput = this.focusTextInput.bind(this);
								}

								focusTextInput() {
									// DOM API를 사용하여 명시적으로 text 타입의 input 엘리먼트를 포커스합니다.
									// 주의: 우리는 지금 DOM 노드를 얻기 위해 "current" 프로퍼티에 접근하고 있습니다.
									this.textInput.current.focus();	//current속성에 < input>이 담겨있고, 이 input에 focus설정을해주고있다.
								}

								render() {
									// React에게 우리가 text 타입의 input 엘리먼트를
									// 우리가 생성자에서 생성한 `textInput` ref와 연결하고 싶다고 이야기합니다.
									return (
									< div>
										< input
												type="text"
												//생성한 Ref가 들어있는 textInput을 DOM에 ref속성값으로 넘김.
												//그러면 textInput에 들어있는 Ref의 current속성에 이 input DOM이 담긴다.
												//그러면 이 ref값을 현재 컴포넌트CustomTextInput에서 사용가능하다.
												ref={this.textInput} />
										< input
												type="button"
												value="Focus the text input"
												onClick={this.focusTextInput}
										/>
									< /div>
									);
								}
								}
						ㄴ html DOM에 ref속성을 주었다면 Ref의 current에는 그 DOM엘리먼트가 들어가고, 컴포넌트에 ref속성을 주었다면
							컴포넌트의 인스턴스가 Ref의 current에 들어간다.
						ㄴ 함수 컴포넌트는 인스턴스가 없기때문에 컴포넌트에 ref속성을 부여하여 current로 받아올 수 없다.
							ㄴ ex)  < MyFunctionComponent ref={this.textInput} />와 같이 MyFUnctionComponent 컴포넌트가 함수형
									컴포넌트라면 ref사용 못함.
							ㄴ 함수형 컴포넌트 안에서 Ref를 정의하고 그 하위 컴포넌트 등으로 ref속성을 넘기는 등, Ref를 사용하는건 된다.
								함수형 컴포넌트를 Ref로 참조하는게 안되는것.
							ㄴ 사용하려면 forwardRef(), useImperativeHandle()을 사용하라함.
						ㄴ 이 Ref의 current를 이용해 이안에 들은 엘리먼트나 인스턴스를 직접 조작할 수 있다.
					</pre>
					ㅡ 컴포넌트 마운트시, current에 요소가 들어오며, 마운트 해제시, current가 null로 세팅된다.
					ㅡ 부모 컴포넌트에게 DOM ref 공개하기 )
						ㄴ ?????
						ㄴ 다음챕처에 나오는 'Ref 전달하기' 방법이 권장된다함.
					ㅡ 콜백 ref )
						ㄴ Ref를 설정하는 방법 중 하나. (위에서는 React.createRef()를 사용)
						ㄴ 참조하려는 컴포넌트 또는 DOM요소에 ref속성값으로 Ref가 아닌 콜백 함수를 넘겨준다. 이 콜백함수는 리액트에 의해
							인자로 해당 컴포넌트 인스턴스나 DOM요소를 전달받는다.
							ㄴ 더 정확하게는 마운트시, 해당 컴포넌트나 DOM요소와 함께 콜백함수가 호출되고, 마운트해제시 null과함께
								콜백함수가 호출된다.
						ㄴ ref 콜백은 componentDidMount(), componentDidUpdate()이전에 호출된다.
						ㄴ ref 사용시 주의사항 )
							ㄴ 마운트 해제시 null과함께 호출되고 마운트시 해당 컴포넌트나 DOM요소화 함께 호출된다고 하였으므로,
								컴포넌트 업데이트시, null로 함번 호출되고 해당 컴포넌트나 DOM요소화 함께 호출되어 두번 호출됨을 기억.
						ㄴ ex)	class CustomTextInput extends React.Component {
								constructor(props) {
									super(props);

									this.textInput = null;

									this.setTextInputRef = element => {
									this.textInput = element;
									};

									this.focusTextInput = () => {
									// DOM API를 사용하여 text 타입의 input 엘리먼트를 포커스합니다.
									if (this.textInput) this.textInput.focus();
									};
								}

								componentDidMount() {
									// 마운트 되었을 때 자동으로 text 타입의 input 엘리먼트를 포커스합니다.
									this.focusTextInput();
								}

								render() {
									// text 타입의 input 엘리먼트의 참조를 인스턴스의 프로퍼티
									// (예를 들어`this.textInput`)에 저장하기 위해 `ref` 콜백을 사용합니다.
									return (
									< div>
										< input
												type="text"
												ref={this.setTextInputRef}
										/>
										< input
												type="button"
												value="Focus the text input"
												onClick={this.focusTextInput}
										/>
									< /div>
									);
								}
								}
					ㅡ 문자열 ref : 문자열을 이용해 ref를 사용하는 방법인데 없어질예정이라함.


				</pre>
				ㅇ Ref 전달 <button>더보기</button>
				<pre>
					ㅡ 말 그대로 ref를 다른곳으로 전달하는 방법에 대해 배운다.
					ㅡ 말단 컴포넌트인 버튼이나, input컴포넌트 등에서 이것들을 계속 재사용하게될때 이 컴포넌트(또는 요소)들에 대한 ref값이 상위에서 필요할 때가 있다.
						이때 ref전달하기가 유용하게 쓰인다고한다.
					ㅡ ????? 이해못함.
					ㅡ 기본 사용법 )
						ㄴ ex)	//2. FancyButton컴포넌트에서 React.forwardRef()메소드를 통해 ref를 전달하고있다. ref인자에 상위로부터 받은 ref가 넘겨진다.
								const FancyButton = React.forwardRef((props, ref) => (
								//3. 함수 내부에서 컴포넌트나 DOM요소에 상위컴포넌트에서와 같이 ref속성을 주고 값으로 인자로받은 ref를 넘겨주면 'ref전달하기'가 된다.
								//이제 상위 컴포넌트에서 ref.current사용시, FancyButton컴포넌트가 아닌 < button>요소가 나온다.
								< button ref={ref} className="FancyButton">
									{props.children}
								< /button>
								));

								// You can now get a ref directly to the DOM button:
								const ref = React.createRef();
								//1. ref사용을 위해 < FancyButton>컴포넌트에 ref속성에 Ref객체를 넘겨준다. 이것만있다고보면 여기까지는 이전 챕터에서
								//배운것처럼 일반적인 ref사용법이다. ref.current에는 FancyBUtton 컴포넌트가 들어있다.
								< FancyButton ref={ref}>Click me!< /FancyButton>;
							ㄴ 즉, 일반적인 Ref사용하는것과 비슷한데, React.forwardRef()를 통해 Ref객체를 한단계 더 아래로 전달함으로서
								더 아래단계에 있는 DOM요소(또는 컴포넌트)를 Ref의 참조값으로 넣을수있는것.
					ㅡ ????? Note for component library maintainers
						ㄴ ?????


				</pre>
				ㅇ Fragment<button>더보기</button>
				<pre>
					ㅡ 컴포넌트가 여러 엘리먼트를 반환하게 해주는 기능.
						ㄴ 일반적으로 컴포넌트는 하나의 엘리먼트(여러개일경우 하나의 엘리먼트로 묶어서)반환해야한다.
						ㄴ 그러나 여러 엘리먼트를 반환해야하는 경우는 많으며 이때 사용되는 기능이다.
							ㄴ ex)
								render() {
								return (
								< table>
									< tr>
									< Columns />
									< /tr>
								< /table>
								);
							}
								ㄴ 이 경우 Column컴포넌트는 여러개의 < td>를 반환해야 한다.
					ㅡ 사용법 )
						ㄴ < React.Fragment>로 감싸거나, (빈 태그와 유사한) < >, < />로 감싸주어 반환하면 된다.
						ㄴ ex)
							render() {
								return (
								< React.Fragment>
									< td>Hello< /td>
									< td>World< /td>
								< /React.Fragment>
								);
							}
						ㄴ ex)
							render() {
								return (
								<>
									< td>Hello< /td>
									< td>World< /td>
								< />
								);
							}
					ㅡ Fragment의 key
						ㄴ 반환하는 여러 요소들이 key를 가져야 한다면, < React.Fragment>를 이용해야한다.
						ㄴ ex)
							return (
								< dl>
								{props.items.map(item => (
									// React는 `key`가 없으면 key warning을 발생합니다.
									< React.Fragment key={item.id}>
									< dt>{item.term}< /dt>
									< dd>{item.description}< /dd>
									< /React.Fragment>
								))}
								< /dl>
							);
					ㅡ 배열로 반환 )
						ㄴ 배열형태로 엘리먼트를 반환할 수도 있다.
						ㄴ ex)
							render() {
							// No need to wrap list items in an extra element!
							return [
								// Don't forget the keys :)
									< li key="A">First item< /li>,
									< li key="B">Second item< /li>,
									< li key="C">Third item< /li>,
							];
							}
				</pre>
				ㅇ Higher-Order Components, HOC<button>더보기</button>
				<pre>
					ㅡ 개요 )
						ㄴ 컴포넌트를 받아서 새로운 컴포넌트를 반환하는 함수를 말한다.
							ㄴ ex) const EnhancedComponent = higherOrderComponent(WrappedComponent);
							ㄴ React의 API가 아닌, 패턴이다.
								ㄴ 그냥 일반적인 함수이다. 함수가 어떤 컴포넌트를 받아서 다른 컴포넌트를 반환하도록 함수를 정의한 것뿐이다.
						ㄴ third-party 리액트 라이브러리에서 자주 사용된다. ex) Redux의 connect, Relay의 createFragmentContainer 등
					ㅡ 기본 사용법 )
						ㄴ ex)
							HOC의 사용.
							const CommentListWithSubscription = withSubscription(	//withSubscription()이 HOC 함수.
																					인자로 컴포넌트와 화살표함수를 넘기고있다.
							CommentList,
							(DataSource) => DataSource.getComments()
							);

							const BlogPostWithSubscription = withSubscription(
							BlogPost,
							(DataSource, props) => DataSource.getBlogPost(props.id)
							);

							HOC 정의
							// This function takes a component...
							function withSubscription(WrappedComponent, selectData) {	//함수의 인자로 컴포넌트를 받고 원하는 형식의 데이터를 받는다.
							// ...and returns another component...
							return class extends React.Component {	//container 컴포넌트를 반환.
								constructor(props) {
								super(props);
								this.handleChange = this.handleChange.bind(this);
								this.state = {
									data: selectData(DataSource, props)	//넘어온 인자로 함수를 호출하여 state에 데이터 저장.
								};
								}

								componentDidMount() {
								// ... that takes care of the subscription...
								DataSource.addChangeListener(this.handleChange);
								}

								componentWillUnmount() {
								DataSource.removeChangeListener(this.handleChange);
								}

								handleChange() {
								this.setState({
									data: selectData(DataSource, this.props)
								});
								}

								render() {
								// ... and renders the wrapped component with the fresh data!
								// Notice that we pass through any additional props
								return < WrappedComponent data={this.state.data} {...this.props} />;
																				//인자로 넘어온 WrappedComponent를 랜더링.
																				props로 필요한 데이터들을 넘겨줌.
								}
							};
							}
					ㅡ 입력받은 컴포넌트를 수정해서는 안된다.
						ㄴ ex)
							//다음은 InputComponent을 수정하고 반환하는HOC이다.
							function logProps(InputComponent) {
							InputComponent.prototype.componentDidUpdate = function(prevProps) {
								console.log('Current props: ', this.props);
								console.log('Previous props: ', prevProps);
							};
							// 원본의 입력을 반환한다는 것은 이미 변형되었다는 점을 시사합니다.
							return InputComponent;
							}

							// EnhancedComponent 는 props를 받을 때 마다 log를 남깁니다.
							const EnhancedComponent = logProps(InputComponent);
						ㄴ ex)
							//위 예제와 같이 입력컴포넌트를 수정하는게 아니라, 새컴포넌트로 감싸서 반환함으로서 똑같은 기능을 구현할 수 있다.
							function logProps(WrappedComponent) {
							return class extends React.Component {
								componentDidUpdate(prevProps) {
								console.log('Current props: ', this.props);
								console.log('Previous props: ', prevProps);
								}
								render() {
								// 들어온 component를 변경하지 않는 container입니다. 좋아요!
								return < WrappedComponent {...this.props} />;
								}
							}
							}
					ㅡ ????? 래핑된 컴포넌트를 통해 관련없는 prop전달하기.
					ㅡ ????? 잘모르겠다. 번역본이 이해가 안간다.
				</pre>
				ㅇ 다른 라이브러리와 통합하기<button>더보기</button>
				<pre>
					ㅡ 리액트를 다른 어플리케이션에 포함시키거나 리액트 안에 다른 어플리케이션을 포함시킬 수 있다.
					ㅡ DOM 조작 플러그인과 통합하기 )
						ㄴ 리액트는 그 내부적인 데이터에 기반하여 업데이트를 하므로, 리액트 외부에서 DOM에 적용된 변화들은 알지 못하고, 충돌의 가능성이 있다.
						ㄴ 해서 이렇게 다른 곳에서 접근하는 DOM에 대한 충돌을 막기위해, 리액트에서 비어있는 < div/>를 반환하는 방법이 있다.
							ㄴ 비어있는 < div/>반환시 리액트엘리먼트가 아무것도 변화될게 없으므로 리액트는 이를 업데이트하지 않고, 따라서
								충돌걱정없이 외부 라이브러리가 DOM에 접근하여 사용할 수 있다.
						ㄴ 유의사항 )
							ㄴ jQuery와 같이 사용하는 경우, 위와같은 방식으로 빈 < div/>를 반환하여 jQuery가 DOM을 조작할수있게하는건 좋은데 다 사용하고나서
								해당 DOM에 부착된 이벤트 리스너 등을 모두 떼어내어 이후에 충돌이 발생할 소지를 없애야한다.
					ㅡ ????? 먼소린지

				</pre>
				ㅇ JSX 이해하기 <button>더보기</button>
				<pre>
					ㅡ JSX는 React.createElement(component, props, ...children) 함수를 약간 편하게 사용하는 정도의 기능을 하는것뿐이라한다.
						ㄴ JSX의 다음 코드는
							< MyButton color="blue" shadowSize={2}>
							Click Me
							< /MyButton>
						ㄴ 컴파일되어 다음과 같이 바뀐다
							React.createElement(
							MyButton,
							{color: 'blue', shadowSize: 2},
							'Click Me'
							)
					ㅡ JSX의 첫번째 부분이 리액트 엘리먼트의 타입을 결정한다.
						ㄴ 대문자로 시작하면 JSX는 리액트 컴포넌트를 의미하게된다. 이 JSX태그는 named 변수에 대한 참조로 컴파일되기때문에,
							해당이름이 '스코프' 안에 존재해야한다.
					ㅡ JSX는 React.createElement()를 호출하여 컴파일을 진행하기때문에, React library또한 JSX가 사용된 코드의 스코프 안에 존재해야한다.
						ㄴ ex)
							//아래에서 < CustomButton>을 사용하려면 JSX가 이를 컴파일하기 위해 React.createElement()를 사용하므로 import React from 'react'가
							// 필요하고, CustomButton에 대한 참조변수가 생성되어야하기때문에 import CustomButton from './CustomButton'이 필요하다.
							import React from 'react';
							import CustomButton from './CustomButton';

							function WarningButton() {
							// return React.createElement(CustomButton, {color: 'red'}, null);
							return < CustomButton color="red" />;
							}
					ㅡ ????? JSX에서 Dot Notation 사용하기 )
						ㄴ JSX안에서 dot notation( . )으로 리액트 컴포넌트를 가리킬 수 있다고 하는데 잘 이해가 안간다.
					ㅡ 소문자로 시작하는 엘리먼트 타입은 < div>, < span>등과 같은 내장된 컴포넌트를 의미하게 된다. 그리고 React.createElement()의
						인자로 'div', 'span'과 같은 형식으로 넘어가게 된다.
						ㄴ 대문자로 시작하는 리액트컴포넌트는 컴포넌트명이 'Foo'라고 하면, React.createElement(Foo)같이 그대로 넘어간다.
					ㅡ JSX의 엘리먼트 타입부분에 js의 일반표현식을 사용할 수 없다.
						ㄴ ex)
							const components = {
							photo: PhotoStory,
							video: VideoStory
							};

							function Story(props) {
							//이런식으로 jsx의 엘리먼트타입부분에 component[props.storyType]와 같이 일반표현식을 사용할 수 없다.
							return < components[props.storyType] story={props.story} />;
							}
						ㄴ 저런식으로 사용하고자한다면 components[porps.storyType]을 대문자로 시작하는 변수에 넣어서 엘리먼트타입으로 주는식으로
							사용해야 한다.
							ㄴ ex)
								function Story(props) {
									// Correct! JSX type can be a capitalized variable.
									const SpecificStory = components[props.storyType];
									return < SpecificStory story={props.story} />;
								}
					ㅡ JSX에서의 props )
						ㄴ 어떠한 js expression이라도 넣어서 props로 넘겨줄 수 있다. ex) < MyComponent foo={1 + 2 + 3 + 4} />
						ㄴ string literal )
							ㄴ jsx안에 써서보내든 일반 문자열을 보내든 동일하다. ex) < MyComponent foo={'hello'} />, < MyComponent foo="hello" />
							ㄴ string literal은 html코드로 넘겨지기때문에 html 특수문자 코드를 넘겨도 상관없다.
						ㄴ props에 아무 값도 주지 않으면 true값이 넘어간다. 혼동의 여지가 있기때문에 추천하지 않는다함.
						ㄴ spread 연산자 (...)
							ㄴ 넘기려는 prosp가 객체형태이면, '...'연산자를 통해 한번에 넘길 수 있다.
							ㄴ ex) 아래 두코드는 동일한 props가 넘어가게 된다.
								function App1() {
								return < Greeting firstName="Ben" lastName="Hector" />;
								}

								function App2() {
								const props = {firstName: 'Ben', lastName: 'Hector'};
								return < Greeting {...props} />;  //
								}
							ㄴ js의 '구조 분해 할당'을 사용하여 props를 주고받을 수도 있다.
					ㅡ JSX의 Children )
						ㄴ jsx로 표현한 태그 사이의 내용은 props의 일종으로 취급된다. props.children
							ㄴ ex) < MyComponent> hello < /MyComponent> //hello는 MyComponent에게 props.children으로 넘어가게된다.
						ㄴ props.children으로 넘어가는 데이터 유형 )<button>더보기</button>
					<pre>
							ㄴ string literal )
								ㄴ jsx 태그 사이에 문자열을 넣을 경우, string literal이 넘어간다.
								ㄴ 공백이나, white space에 대해 jsx가 임의로 처리를 한다. 다음과 같다.
									ㄴ 문자열 맨 처음과 마지막에 있는 white space를 제거한다.
									ㄴ 아무내용이 없는비어있는 줄을 제거한다.
									ㄴ 태그에 인접해있는 새 라인쓰기는 제거된다.
									ㄴ 문자열 중간에 존재하는 새 라인쓰기는 하나의 white space로 대체된다.
							ㄴ 또다른 jsx )
								ㄴ 또다른 jsx 엘리먼트를 children으로 넘길 수 있다.
									ㄴ ex)
										< MyComponent>
											< MyFirstComponent/>
											< MySecondComponent/>
										< /MyComponent>
							ㄴ js expression )
								ㄴ { }로 감싸서 js 표현식을 children으로 넘길 수 있다. ex) < MyComponent>{'foo'}< /MyComponent>
							ㄴ 함수 )
								ㄴ props.children은 일반 props처럼 사용될 수 있기때문에 함수를 children으로 넘겨서 이를 받은 컴포넌트에서 콜벡용도로 사용할 수 있다.
								ㄴ ex)
									function Repeat(props) {
									let items = [];
									for (let i = 0; i < props.numTimes; i++) {
										items.push(props.children(i));
									}
									return < div>{items}< /div>;
									}

									function ListOfTenThings() {
									return (
															< Repeat numTimes={10}>
										{(index) => < div key={index}>This is item {index} in the list< /div>}
										< /Repeat>
									);
									}
							ㄴ booleans, null, undefined 값들 )
								ㄴ 전달될 수 있으나, 아무것도 렌더링되지 않고 무시된다.
								ㄴ 단, 일부 js의 falsy value는 무시되지 않고 렌더링된다. 가령 0 같은것들.
									ㄴ ex)
									< div>
											//props.messages가 비어있는 경우에 0이 렌더링된다. 0은 falsy value이지만 리액트에선 이를 렌더링하기때문.
										{props.messages.length &&
										< MessageList messages={props.messages} />
										}
									< /div>
							ㄴ 위의 children에 올수있는 유형들은 섞여서 사용될 수 있다.
					</pre>
				</pre>
				ㅇ 성능 최적화 <button>더보기</button>
				<pre>
					ㅡ ~~~~~

				</pre>
				ㅇ Portals<button>더보기</button>
				<pre>
					ㅡ 컴포넌트의 children을 현재 컴포넌트 계층 안에 없는 다른 DOM으로 넣어줄수있게 해주는 기능.
					ㅡ ~~~~~
				</pre>
				ㅇ Profiler API<button>더보기</button>
				<pre>
					ㅡ 리액트 어플이 얼마나 자주 렌더링되는지 측정하여 프로그램에서 느린부분을 식별하고 최적화에 도움을 주는 기능이다.
					ㅡ ~~~~~
				</pre>
				ㅇ ES6가 없는 리액트 <button>더보기</button>
				<pre>
					ㅡ ES6가 없는 경우 리액트를 사용하는 방법에 대해 나옴.
					ㅡ ~~~~~
				</pre>
				ㅇ JSX가 없는 리액트<button>더보기</button>
				<pre>
					ㅡ ~~~~~
				</pre>
				ㅇ Reconciliation <button>더보기</button>
				<pre>
					ㅡ ?????
				</pre>
				ㅇ render props <button>더보기</button>
				<pre>
					ㅡ ~~~~~
				</pre>
				ㅇ static type checking<button>더보기</button>
				<pre>
					ㅡ 코드를 실행하기전에 js코드를 검사해주는 기능을 제공해주는 툴들이 있다.
						ㄴ ex) Flow, TypeScript
					ㅡ ~~~~~

				</pre>
				ㅇ Strict Mode<button>더보기</button>
				<pre>
					ㅡ 코드상에서 좀더 엄격하게 경고를 표시하는 기능.
						ㄴ 어플에 영향을 미치거나 추가적인 렌더링 없이 그냥 경고만 추가한다.
					ㅡ ~~~~~

				</pre>
				ㅇ TypeChecking with PropTypes<button>더보기</button>
				<pre>
					ㅡ Flow, TypeScript와 같은 도구를 사용하지 않더라도 리액트 안에서 props에 대한 typecheck를 할 수 있다.
					ㅡ 컴포넌트의 propTypes 속성을 이용하면 된다.
					ㅡ ~~~~~
				</pre>
				ㅇ Uncontrolled Components<button>더보기</button>
				<pre>
					ㅡ 대부분의 경우에는 리액트에서 form사용시, <a href="#React_기본개념_form">일반적인 리액트에서 form사용</a>처럼
						form의 값이 컴포넌트에 의해 controlled되는 controlled component 방식을 추천한다고함.
					ㅡ 근데, 드문 몇몇 경우에, form의 값이 컴포넌트에 의해서가 아닌, dom자체에 대해서 컨트롤되는 'uncontrolled component'가 필요.
					ㅡ 이를 위해, form에 'ref'를 사용하면 된다고함.
					ㅡ ~~~~~
				</pre>
				ㅇ Web Components<button>더보기</button>
				<pre>
					ㅡ web component와 리액트를 같이 사용하는 것에 대한 내용.
					ㅡ ~~~~~
				</pre>

			</pre>
			ㅇ API 참고서 <button>더보기</button>
			<pre>
				ㅡ React<button>더보기</button>
				<pre>
					ㄴ 컴포넌트<button>더보기</button>
					<pre>
						ㄴ React.Component<button>더보기</button>
						<pre>
							ㄴ React.Component Api<button>더보기</button>
							<pre>
								ㄴ class형태로 React component를 생성하려면 React.Component를 상속해야한다.
								ㄴ 컴포넌트 생명주기 <button>더보기</button>
								<pre>
									<img src="image/리액트컴포넌트_생명주기.png"/>
									ㄴ 렌더링 단계 )
										ㄴ dom과 관계없이 리액트 내부적으로만 처리하는 단계.
									ㄴ 커밋단계 )
										ㄴ 리액트가 리액트 엘리먼트를 가지고 실제 dom을 업데이트하는 단계. dom에 접근이 가능하여 dom관련 작업이 가능하다.
									ㄴ 마운트 )<button>더보기</button>
									<pre>
										ㄴ 마운트란? ReactDOM이 리액트 엘리먼트를 실제 DOM으로 적절하게 만들어서 DOM에 추가하는 작업.
											ㄴ ex)
												html코드
												< body>
													< noscript>You need to enable JavaScript to run this app.</noscript>
													< div id="root">< /div>
												< /body>
												---------------------------------
												index.js 코드
												ReactDOM.render(
												< React.StrictMode>
														< App />
												< /React.StrictMode>,
												document.getElementById('root')
												);
												----------------------------------
												ㄴ App 컴포넌트에서 < div>hello < /div>를 반환하고 있다고치면,
													App에 의해 반환된 < div>hello< /div>라는 리액트 엘리먼트가 js 객체로 존재하다가
													ReactDOM.render()에 의해 root div아래에 < div>hello< /div>가 실제 DOM으로 생성되어
													추가되는 과정이 '마운팅'.
										ㄴ 1. constructor()
											ㄴ 컴포넌트 마운트 이전에 호출.
											ㄴ 몸체에 가장 최우선으로 super(props)를 호출해야함. 컴포넌트의 this.props을 정의하기위함.
											ㄴ 일반적인 사용목적 )
												ㄴ state초기화, 이벤트 처리 메소드 바인딩.
											ㄴ 몸체에서 setState()를 호출해서는 안된다.
											ㄴ 이 안에서만 this.state를 직접 할당할 수 있다.
										ㄴ 2. getDerivedStateFromProps()
											ㄴ 최초 마운트할때와 컴포넌트 업데이트할때, render()호출 직전에 호출된다.
											ㄴ ?????
										ㄴ 3. render()
											ㄴ 클래스형 컴포넌트에서 반드시 구현되어야하는 메소드.
											ㄴ this.props와 this.state의 값들을 활용하여 다음중 하나를 반환한다.
												ㄴ React 엘리먼트 : 일반적으로 JSX를 사용하여 생성된다.
													ㄴ ex) < div/>, < MyComponent/> 등. < div> DOM노드나 사용자가만든 < MyComponent>라는
														리액트 컴포넌트를 반환하는 리액트 엘리먼트이다.
												ㄴ 배열, Fragment : 여러개의 리액트 엘리먼트를 반환한다.
												ㄴ Portal : ?????
												ㄴ 문자열과 숫자 : 텍스트 노드로서 렌더링된다.
												ㄴ Boolen, null : 아무것도 렌더링하지 않는다.
											ㄴ ????? 이함수는 순수해야 한다고함. state를 변경하지도, 브라우저와 상호작용하지도 않고
												호출시마다 동일한 결과를 반환해야 한다고 한다.
										ㄴ componentDidMount()
											ㄴ 컴포넌트가 마운트된 직후 호출된다.
												* 마운트란? 리액트 컴포넌트가 DOM트리상에 삽입되는것을 말한다. dom트리상에 삽입되었으므로 화면에 그려지게된다.
											ㄴ ????? ajax등의 네트워크 데이터를 불러오기 좋은 위치라고하는데 잘 이해가 안간다. 왜 좋은위치라는건지.
											ㄴ 이 안에서 setState()를 호출하는 경우가 있다.
												ㄴ 렌더링이 한번더 호출되어 성능상의이슈가 있을수도 있다고 한다.
									</pre>
									ㄴ 업데이트 )<button>더보기</button>
									<pre>
										ㄴ 1. static getDerivedStateFromProps()
											ㄴ ?????
										ㄴ 2. shouldComponentUpdate(nextProps, nextState)
											ㄴ props, state가 갱신되어 다시 렌더링되기 직전에 호출된다.
											ㄴ 디폴트 반환값은 true.
											ㄴ 새로 갱신되는 props, state값을 인자로 받아 다시렌더링을 할지 확인한후 false를 반환하여 업데이트를 생략할 수있다.
											ㄴ '성능 최적화'를 위해서만 사용해야한다. 버그로 이어지기 쉽다.
											ㄴ 이 메소드 대신 PureComponent를 사용하는걸 추천한다함.
										ㄴ 3. render()
										ㄴ 4. getSnapshotBeforeUpdate( prevProps, prevState)
											ㄴ render()이후에, 리액트가 dom을 업데이트하기 직전에 호출된다.
											ㄴ 이 메소드 호출 후, dom이 업데이트 되고, 그 다음 componentDidUpdate()가 호출되는것.
											ㄴ ????? 어디에써야할지는 아직 잘모르겠음.
											ㄴ 값을 리턴해야한다. 반환값을 componentDidUpdate()에서 snapshot이라는 인자로 받게된다.
												ㄴ ????? 그냥 반환만하면되는지 잘모르겠다.
										ㄴ 5. componentDidUpdate( prevProps, prevState, snapShot )
											ㄴ dom 업데이트가 일어난 직후에 호출된다.
											ㄴ 내부에서 setState()호출시, 무한루프가 돌게되므로 prevProps, prevState인자로 조건체크를 해주어야한다.
									</pre>
									ㄴ 언마운트<button>더보기</button>
									<pre>
										ㄴ 컴포넌트의 마운트가 해제되어 제거되기 직전에 호출된다.
										ㄴ ????? render()안에 return에서 안보이면 언마운트 되는듯하다.
									</pre>
									ㄴ 오류 처리<button>더보기</button>
									<pre>
										ㄴ 다음 메소드들은 자손컴포넌트가 렌더링, 생명주기메소드호출, 생성자 호출시에 오류발생시 호출되는 메소드들이다.
										ㄴ static getDerivedStateFromError( error )
											ㄴ 매개변수로 해당 오류를 전달받는다.
											ㄴ 업데이트된 state를 반드시 반환해야한다.
											ㄴ '렌더링 단계'에서 호출된다.
										ㄴ componentDidCatch( error, info )
											ㄴ 매개변수 )
												ㄴ error : 오류
												ㄴ info : 어떤 컴포넌트가 오류를 발생시켰는지에 대한 정보를 포함한 componentStack 키를 가지고있는 객체.
											ㄴ '커밋 단계'에서호출된다.
									</pre>
								</pre>
								ㄴ 기타 api )<button>더보기</button>
								<pre>
									ㄴ setState( updater, [callback])<button>더보기</button>
									<pre>
										ㄴ 컴포넌트 state변경사항을 대기열에 넣고 리액트에게 해당컴포넌트와 그 자식컴포넌트들이 다시 렌더링 되어야 한다고알린다.
											ㄴ 즉각적인 갱신이 아닌, '요청'으로 생각하라함. 바로 바뀌는게 아니다.
											ㄴ 따라서 setState()직후 바로 state에 접근하는게 오류가생길수도있다.
											ㄴ [callback]이나 ?????componentDidUpdate를 사용하라고한다.
										ㄴ 화면상의 성능을 위해, 매 setState()마다 화면을 리렌더링하지는 않는다. 적절하게 한꺼번에 처리할 수도 있다.
										ㄴ shouldComponentUpdate()가 false를 반환하지 않으면 setState()는 항상 다시 렌더링을 발생시킨다.
										ㄴ updater
											ㄴ 다음과 같은 형태의 함수이다.
											ㄴ (state, props) => (*새로운 state를 '표현'하는 객체*)
											ㄴ 인자로 받는 state, props는 최신값이 보장된다.
											ㄴ 반환값으로 state를 '표현'하는 객체를 반환하면 이에 맞게 state가 갱신된다.
												ㄴ ex ) setState( (state,props) => {
															return{ count: 1 };
														}); //state의 count프로퍼티가 1로 업데이트된다.
											ㄴ 함수형태가 아닌 (*새로운 state를 '표현'하는 객체*)를 그대로 updater부분에 전달해도 똑같이 적용된다.
												ㄴ ex) setState( {count: 1} );
										ㄴ callback
											ㄴ setState가 실행완료되고 컴포넌트가 다시 렌더링된후 실행될 함수이다.
											ㄴ 생략가능하다.
										ㄴ 기타 )
											ㄴ setState는 왜, 언제 일괄처리되는가?
												ㄴ https://stackoverflow.com/questions/48563650/does-react-keep-the-order-for-state-updates/48610973#48610973
											ㄴ this.state는 왜 즉시 실행되지 않는가
												ㄴ https://github.com/facebook/react/issues/11527
									</pre>
									ㄴ forceUpdate( callback )
										ㄴ 다시 렌더링을 수행하게 한다.
										ㄴ shouldComponentUpdate()가 생략되고 render()가 호출된다.
										ㄴ 자식컴포넌트들에서는 일반적인 생명주기가 실행된다.
								</pre>
								ㄴ 클래스 프로퍼티 )<button>더보기</button>
								<pre>
									ㄴ defaultProps )
										ㄴ props에 값이 제공되지 않을경우 사용할 디폴트 props를 설정할 수 있다.
										ㄴ ex) class NoName extends React.Component{
												~~~~~
												NoName.defaultProps = {
													color: 'blue'
												}
											}
											ㄴ NoName에 color props가 전달되지 않았다면 'blue'가 설정된다.
									ㄴ displayName )
										ㄴ ~~~~~
								</pre>
								ㄴ 인스턴스 프로퍼티<button>더보기</button>
								<pre>
									ㄴ props )
									ㄴ state )
								</pre>
							</pre>
						</pre>
						ㄴ React.PureComponent<button>더보기</button>
						<pre>
							ㄴ ?????
						</pre>
						ㄴ React.memo<button>더보기</button>
						<pre>
							ㄴ 고차컴포넌트이다.
							ㄴ 컴포넌트를 인자로 받아서, 이컴포넌트를 '메모이징'해둔다. (그대로 저장해둔다는 의미인듯하다)
								이후 해당 컴포넌트의 props이 변경되지 않았다면 메모이징해두었던 내용을 그대로 보여준다.
							ㄴ state, context 등에 대해서는 일반적인경우과 같이 리렌더링을 한다.
							ㄴ 성능최적화를 위해서만 사용해야한다.
						</pre>
					</pre>
					ㄴ 리액트 엘리먼트 생성<button>더보기</button>
					<pre>
						ㄴ JSX를 사용하여 생성하는게 일반적인 경우이다.
						ㄴ JSX없이 직접 생성하려는 경우, 사용되는 메소드들은 다음과 같다.
							ㄴ React.createElement( type, [props], [...children] )
								ㄴ JSX를 사용하여 엘리먼트생성시 호출되는 메소드이다.
								ㄴ type에는 html 태그이름, 리액트 컴포넌트, 리액트 Fragment 중 하나가 올수있다.
							ㄴ React.createFactory( type )
								ㄴ createElement()와 동일한 type을 인자로 받는다.
								ㄴ type에 해당하는 리액트 엘리먼트를 반환하는 함수를 반환한다.
								ㄴ 레거시 기능이다.
					</pre>
					ㄴ 리액트 엘리먼트 조작 api들<button>더보기</button>
					<pre>
						ㄴ cloneElement( element, [props], [...children] )<button>더보기</button>
						<pre>
							ㄴ element가 리액트 엘리먼트를 의미하며, props, children인자들을 이용해 element를 복사한다.
							ㄴ 복사되어 생성된 리액트 엘리먼트의...
								ㄴ props은 원래의 props와 cloneElement()의 인자로넘긴 props가 얕게 병합된 props를 가진다.
								ㄴ children은 cloneElement()의 인자로넘긴 children으로 대체된다.
								ㄴ key와 ref는 원래의 element와 동일하다.
							ㄴ 사실상 cloneElement()는 다음구문과 동일하다 (ref와 key에 대한것만제외하고)
								ㄴ < (*엘리먼트 type*) (*기존props들...*) (*새 props*)> (*새children*) < /~~~>
						</pre>
						ㄴ isValidElement( object ) : object가 리액트 엘리먼트인지 판별
						ㄴ React.Children <button>더보기</button>
						<pre>
							ㄴ 리액트 엘리먼트의 children을 다루는 함수들을 제공한다.
							ㄴ React.Children.map
							ㄴ React.Children.forEach
							ㄴ React.Children.count
							ㄴ React.Children.only
							ㄴ React.Children.toArray

						</pre>
					</pre>
					ㄴ Fragment )
					ㄴ Refs )<button>더보기</button>
					<pre>
						ㄴ React.createRef
						ㄴ React.forwardRef )
							ㄴ ~~~~~
					</pre>
					ㄴ Suspense<button>더보기</button>
					<pre>
						ㄴ ~~~~~
					</pre>
				</pre>
				ㅡ ReactDOM<button>더보기</button>
				<pre>
					ㄴ
				</pre>
				ㅡ ~~~~~
				ㅡ

			</pre>
			ㅇ 훅 Hook<button>더보기</button>
			<pre>
				ㅡ React 16.8부터 새로 추가된 기능.  class를 사용하지 않아도 리액트를 사용할 수 있게해준다.
				ㅡ 소개 <button>더보기</button>
				<pre>
					ㄴ 등장 배경 )
						ㄴ 기존에 함수형 컴포넌트에서는 리액트 컴포넌트의 라이프 사이클과 state를 사용할 수 없었다.
						ㄴ 훅이 등장하면서 이것들이 가능해진 것인데
						ㄴ 기존의 클래스형 컴포넌트로는 상태와 관련된 로직을 재사용하기 까다롭다는 문제가 있었다.
							ㄴ HOC와 render props를 사용하여 재사용했었음.
						ㄴ 해서 함수형컴포넌트에 state와 라이프사이클을 사용할 수 있게 함으로써 상태관련 로직을 재사용하기 쉽게 만들었다고한다.
					ㄴ 특징 )
						ㄴ 선택적 사용. 기존코드 수정없이 훅을 사용하거나 사용안할 수 있다.
					ㄴ ?????
				</pre>
				ㅡ 개요<button>더보기</button>
				<pre>
					ㄴ 훅이란?
						ㄴ 함수 컴포넌트에서 state와 생명주기를 연동(hook)할 수 있게해주는 함수.
						ㄴ class안에서는 동작하지 않음.
						ㄴ 내장된 hook들이 존재하며, 직접 만드는것도 가능하다.
					ㄴ 훅 규칙<button>더보기</button>
					<pre>
						ㄴ 반복문, 조건문 등의 안에서가 아닌 최상위레벨에서만 훅을 호출해야한다.
						ㄴ React 함수컴포넌트 내에서만 훅을 호출해야한다.
					</pre>
					ㄴ 커스텀 훅 만들기<button>더보기</button>
					<pre>
						ㄴ 공통로직을 빼는데 사용한다고한다.
						ㄴ 일반적인 함수와 다를바가 없지만, 커스텀 훅은 내부에서 다른 훅을 호출할 수 있다는 특징이 있다.
						ㄴ 이름이 'use'로 시작하는 js함수를 만들면 이는 커스텀 훅이 된다.
					</pre>
					ㄴ Hook Api 참고서<button>더보기</button>
					<pre>
						ㄴ 참고 ) 리액트 훅 flow
							<img src="image/리액트 훅 flow.png" height="600"/>
						ㄴ useState<button>더보기</button>
						<pre>
							ㄴ 함수형 컴포넌트에서 useState훅을 사용하여 state를 사용할 수 있다.
								ㄴ 원래는 함수형 컴포넌트 내에서는 state를 못썼음.
							ㄴ 사용법 ) <button>더보기</button>
							<pre>
								ㄴ const [count, setCount ] = useState(0)
									ㄴ useState()는 class형 컴포넌트에서의 state와 똑같은 state 변수와 이 변수를 업데이트할 수있는 함수를 반환해준다.
									ㄴ useState()의 인자는 해당 state변수값의 초기값이다.
										ㄴ 함수를 주어서 이 함수의 리턴값으로 초기화 할 수 있다.
											ㄴ ex)
												const [count, setCount] = useState( ()=>{
													//초기값 계산 로직
													return (*계산한 초기값*);
												})
									ㄴ 일반적으로 위와같이 js의 '구조분해할당'을 이용하여 생성,할당받는다.
								ㄴ 사용을 위해선 그냥 변수명을 사용하면된다. class형 컴포넌트와 같이 'this.state.count' 이렇게 안해도된다.
									ㄴ ex)    < p>You clicked {count} times< /p>
								ㄴ 업데이트를 위해선 useState()에서 반환받은 함수를 사용하면된다.
									ㄴ ex)
										< button onClick={() => setCount(count + 1)}>
											Click me
										< /button>
									ㄴ set함수의 인자로 함수를 주어도 된다.
										ㄴ 인자로 함수를 줄 경우, 이 함수는 첫 번째 인자로 기존의 state값을 받게 된다.
										ㄴ 함수의 반환값이 state에 저장되게 된다.
										ㄴ setCount( ( aaa, bbb )=>{
												console.log(aaa); //기존의 count state의 값.
												console.log(bbb); //인자로는 기존의 state값만 받으므로 bbb는 undefined.
												return aaa + 1; //setCount( aaa+1 ) 과 동일하다.
											}
									ㄴ state값에 변화가 없을 경우, 리렌더링을 건너뛴다.
									ㄴ state가 객체인 경우, 클래스형 컴포넌트의 setState()처럼 자동으로 병합해주지 않는다.
										ㄴ ex)
											const [obj, setObj] = useState( { num1: 111, num2: 222 });
											setOjb( { num3: 333 }); // state obj는 { num1:111, num2:222, num3:333 }가 아닌 { num3: 333 }이 된다.
										ㄴ '객체 전개 연산자'를 이용하여 병합 효과를 낼 수 있다.
											ㄴ ex)
												setObj( preState => {
													return { ...preState, (*객체에 추가할 프로퍼티*) }
												}
										ㄴ useReducer 훅을 사용할 수도 있다.
							</pre>
						</pre>
						ㄴ useEffect <button>더보기</button>
						<pre>
							ㄴ 기본 <button>더보기</button>
							<pre>
								* side effect
									ㅡ 데이터를 가져오거나, dom을 업데이트하거나, 구독(네트워크를 연결하여 지속적으로 데이터를 받아오거나 보내는작업?) 등의
										작업을 side effect라고 한다.
									ㅡ componentDidMount(), componentDidUpdate()등에서 ajax으로 데이터를 가져와 다시렌더링해주는 등의 작업이 포함된다.
								ㄴ clean up이 필요없는 side effect의 경우 )
								ㄴ useEffect 훅은 이러한 side effect를 수행할수있도록 만들어진 훅이다.
								ㄴ useEffect( (*함수*), [ (*데이터 배열*) ] )
								ㄴ 함수형 컴포넌트에서 DOM이 그려진 이후(렌더링 이후)에 호출되어 인자로 넘어간 함수를 호출한다.
									ㄴ 넘어간 함수를 effect라고 부른다.
									ㄴ 호출시마다 새로운 effect가 대체되어 전달되고 실행된다.
										ㄴ 최신값들이 적용되어 로직이 돌아갈수있도록 하기 위해서.
								ㄴ effect 동작 시점 )
									ㄴ ????? 화면이 모두 그려지고 난 뒤?
								ㄴ 조건부 effect 실행
									ㄴ 두번째 인자로 배열을 넘길 경우, 해당 배열의 데이터들이 변경된 경우에만 useEffect()가 호출된다.
									ㄴ 불필요한 리렌더링을 막는 용도이다.
									ㄴ 이 두번째 인자를 사용하는 경우, effect안에서 사용되는 모든 데이터들이 배열안에 포함되는지 확인해야 한다.
										ㄴ 기본적인 값들과 그 값들로부터 파생되는 모든 값들도 포함시켜야한다.
									ㄴ 빈 배열([])을 전달하면, 한번만 실행되게 된다.
									ㄴ 주의 사항 )
										ㄴ 의존하는 데이터를 빼먹는 것 )
											ㄴ ex)
												function doSomething() {
													console.log(someProp);
												}

												useEffect(() => {
													doSomething();
												}, []);
												ㄴ doSomething()안에서 someprop를 사용하지만 함수가 분리되어있어 추적하기어려워 실수의 여지가 있다.
											ㄴ 해서, effect내부에서 필요한 함수는 effect안에서 선언하여 사용하는걸 권장한다고 한다.
											ㄴ 또는 eslint-plugin-react-hooks 패키지의 일부로 exhaustive-deps 규칙을 사용하면 의존하는 데이터들을 추적하여 표시해준다.
											ㄴ 또는 effect내부에서 사용하는 함수들을 useCallback()훅을 이용하여 만들어 놓고, useEffect()의 의존성 인자로 해당 함수를 줄 수 있다.
												그러면, useCallback()의 함수가 관련 데이터에 따라 다시 정의될것이고 그러면 해당 함수가 변했으므로 useEffect()도 호출이 된다.
								ㄴ useEffect()는 함수를 반환할 수 있다.
									ㄴ 함수 반환시, 해당 함수는 componentWillUnmount()의 시점과 동일한 시점에서 호출된다.
									ㄴ 컴포넌트에서 '구독'을 하고있는경우, 이를 이용하여 구독을 해제할 수 있다.
								ㄴ 함수형 컴포넌트 내부에 있기때문에 당연히 함수컴포넌트의 props와 state에 접근가능하다.
								ㄴ componentDidMount(), componentDidUpdate(), componentWillUnmount()와 유사한 기능을 한다고 보면된다.
									ㄴ 처음 렌더링시, 이후 업데이트시마다 호출된다.
								ㄴ 이런 기능을 통해, class형태에서 componentDiDMount(), componentDidUpdate(), componentWillUnmount()에서
									나누어져 수행되던 기능을 한 함수 안에서 사용할 수 있다.
								ㄴ ex)
									import React, { useState, useEffect } from 'react';

									function Example() {
									const [count, setCount] = useState(0);

									useEffect(() => {
										document.title = `You clicked ${count} times`;
									});

									return (
										< div>
										< p>You clicked {count} times< /p>
										< button onClick={() => setCount(count + 1)}>
											Click me
											< /button>
										< /div>
									);
									}
							</pre>
							ㄴ 더 알아보기<button>더보기</button>
							<pre>
								ㄴ class형 컴포넌트의 라이프사이클 메소드 안에서 여러 로직들이 모두 들어가있는 경우가 많다.
									useEffect를 여러개 사용하면 관련있는 로직끼리 한 useEffect함수안에 넣어두어 코드를 깔끔하게 할 수 있다.
									ㄴ ex)<button>더보기</button>
									<pre>
										클래스 라이프사이클 메소드를 사용하는 경우,
										class FriendStatusWithCounter extends React.Component {
										constructor(props) {
											super(props);
											this.state = { count: 0, isOnline: null };
											this.handleStatusChange = this.handleStatusChange.bind(this);
										}

										componentDidMount() {
											document.title = `You clicked ${this.state.count} times`;
											ChatAPI.subscribeToFriendStatus(
											this.props.friend.id,
											this.handleStatusChange
											);
										}

										componentDidUpdate() {
											document.title = `You clicked ${this.state.count} times`;
										}

										componentWillUnmount() {
											ChatAPI.unsubscribeFromFriendStatus(
											this.props.friend.id,
											this.handleStatusChange
											);
										}

										handleStatusChange(status) {
											this.setState({
											isOnline: status.isOnline
											});
										}
										// ...

										useEffect를 사용하는 경우,
										function FriendStatusWithCounter(props) {
										const [count, setCount] = useState(0);
										useEffect(() => {	//페이지의 title변경 로직이 들어있음.
											document.title = `You clicked ${count} times`;
										});

										const [isOnline, setIsOnline] = useState(null);
										useEffect(() => {	//구독 연결, 해제관련 로직이 들어있음.
											function handleStatusChange(status) {
											setIsOnline(status.isOnline);
											}

											ChatAPI.subscribeToFriendStatus(props.friend.id, handleStatusChange);
											return () => {
											ChatAPI.unsubscribeFromFriendStatus(props.friend.id, handleStatusChange);
											};
										});
										// ...
										}
										ㄴ 이렇게 관련있는 로직끼라 하나의 useEffect()안에 넣어둘수있다.
									</pre>
								ㄴ effect가 업데이트시마다 실행되는 이유<button>더보기</button>
								<pre>
									ㄴ
								</pre>
							</pre>
						</pre>
						ㄴ useContext<button>더보기</button>
						<pre>
							ㄴ ex)
								const value = useContext( MyContext );
							ㄴ 클래스형 컴포넌트에서 context 사용시 static contextType = (*context변수명*) 을 했었는데, 이 부분이
								함수형 컴포넌트에서 위와 같음. 나머지는 동일( Provider사용하고 등등.. )
						</pre>
						ㄴ useReducer<button>더보기</button>
						<pre>
							ㄴ useState() 훅의 대체 함수. 유사하게 state를 업데이트 해주는 기능을 하나, 좀 더 복잡한 업데이트가 가능하게 한다.
							ㄴ 사용법 )
								ㄴ const [ (*state값*), (*dispatch함수명*) ] = useReducer( (*reducer함수*), (*state초기값*), (*state초기값반환함수*) )
								ㄴ ex)
									const initialState = {count: 0};

									function reducer(state, action) {
									switch (action.type) {	//dispatch()에서 인자로 들어간 데이터가 그대로 action에 들어온다.
										case 'increment':
										return {count: state.count + 1};
										case 'decrement':
										return {count: state.count - 1};
										default:
										throw new Error();
									}
									}

									function Counter() {
									const [state, dispatch] = useReducer(reducer, initialState);
									return (
										<>
										Count: {state.count}
										< button onClick={() => dispatch({type: 'decrement'})}>-< /button>	//dispatch()호출시, reducer가 호출되어 state가 갱신된다.
										< button onClick={() => dispatch({type: 'increment'})}>+< /button>
										< />
									);
									}

								ㄴ (*dispatch함수명*)이 useState()훅 사용할때 const [count, setCount]=useState()에서 setCount()같은 부분이다.
								ㄴ (*state초기값*) 부분에 초기값을 바로 입력할 수 있고, 또는 (*state초기값반환함수*)를 통해 초기값을 계산하여 설정 할 수 있다.
								ㄴ (*reducer함수*)
									ㄴ ( (*이전state값이 들어갈 인자*), (*dispatch함수에서 설정한 action이 들어갈 인자*) ) => (*새로운 state값*) 형태의 함수.
									ㄴ 두 인자를 받아서 원하는 로직대로 새로운 state값을 계산하여 반환하면 state가 반환값으로 설정된다.
								ㄴ dispatch함수는 dispatch( (*reducer함수의 action에 들어갈 데이터*) ) 형태로 사용한다.
									ㄴ 데이터에는 정해진 형식이나 제한이 없다.
									ㄴ dispatch()호출시, state와 action을 가지고 reducer가 호출되어 state가 업데이트된다.
						</pre>
						ㄴ useCallback<button>더보기</button>
						<pre>
							ㄴ const func = useCallback( (*함수*), (*의존하는 데이터의 배열*) )
							ㄴ 일반적인 함수정의처럼 (*함수*)를 정의하여 func에 저장한다.
								그리고 이를 '메모이제이션'하여 저장해둔다.
								useEffect에서와 비슷하게 의존하는 데이터의 배열을 두번째 인자로 넘긴다. 그리고 이 데이터들이 변화하지 않는 한,
								func호출시 '메모이제이션'된 함수를 계속 사용한다. 의존하는 데이터들이 변할시, (*함수*)를 다시 정의하여 저장해둔다.
							ㄴ useEffect에서의 주의점처럼, (*의존하는 데이터의 배열*)에 의존되는 모든 데이터가 포함되어야 한다.
						</pre>
						ㄴ useMemo<button>더보기</button>
						<pre>
							ㄴ const value = useMemo( (*함수*), (*의존하는 데이터의 배열*) )
							ㄴ useCallback과 유사하다. (*함수*)에서 계산하여 반환한 값을 value에 저장한 뒤, (*의존하는 데이터의 배열*)의 값들이
								변하지 않는 한, 똑같은 값을 사용한다. 값들이 변하면 (*함수*)를 다시 호출하여 값을 계산해준다.
							ㄴ useMemo()에서 사용되는 (*함수*)는 렌더링시에 호출되어 값이 계산된다.
							ㄴ useEffect에서의 주의점처럼, (*의존하는 데이터의 배열*)에 의존되는 모든 데이터가 포함되어야 한다.
						</pre>
						ㄴ useRef<button>
						<pre>
							ㄴ 클래스형 컴포넌트에서 React.createRef()와 동일한 기능을 한다.
							ㄴ ?????
						</pre>
						ㄴ useImperativeHandle<button>더보기</button>
						<pre>
							ㄴ useImperativeHandle( ref, createHandle, [deps] )
							ㄴ 일반적으로 forwardRef()와 같이 사용된다.
							ㄴ 부모 컴포넌트로 전달될 ref참조값을 'createHandle'에 넘길 함수에서 반환하는 값으로 설정 할 수 있다.
								ㄴ 공식문서에서는 부모 컴포넌트에게 전달될 ref참조값을 '커스텀' 할 수 있다 고 표현하고있다.
							ㄴ ex)
								const NoName2 = React.forwardRef( (props, ref)=>{//ref참조를 부모로부터 받음.
									let localRef = useRef();
									useImperativeHandle(ref, ()=> {
										if(localRef.current.value === '1'){return localRef;}//value가 1일 경우, input에 대한 참조를 하고있는 localRef참조를 ref에 전달.
										else return function (){localRef.current.value = 'hehe';}//value가 1이 아닐경우, value를 수정하는 함수를 ref에 전달.
									});
									return(
										<>
											< label>name< /label>< input type='text' ref={localRef} value='1'/>
										< />
									)
								})

								부모 컴포넌트..
								< button onClick={()=>{
									// parentRef.current();//함수를 전달받은 경우 이런식으로 사용한것.
									console.log(parentRef.current.current.value);//parentRef.current안에는 NoName2에서 받은 localRef참조가 들어있고 이 localRef.current안에 input에 대한 참조가 들어있는것.
								}}>button4< /button>
								< NoName2 ref={parentRef}/>//ref를 자식인 NoName2에게 전달.
						</pre>
						ㄴ useLayoutEffect<button>더보기</button>
						<pre>
							ㄴ 형식은 useEffect()와 동일하다. 기능도 대부분 동일한데, 호출 시기만 다르다.
							ㄴ 위의 리액트 훅 flow에서 볼 수 있듯이, useEffect의 effect는 브라우저가 화면을 그린 이후에 호출되는데 반면,
								useLayoutEffect는 브라우저가 화면을 그리기 이전에 '동기적'으로 호출된다.
								ㄴ 따라서 useEffect()를 이용해 화면에 보여줄 데이터를 설정하는 경우, 유저가 보기에 약간의 딜레이가 생기지만,
									useLayoutEffect를 사용하면 이런 것 없이 유저에게 화면을 보여 줄 수 있다.
						</pre>
						ㄴ useDebugValue<button>더보기</button>
						<pre>
							ㄴ ????? 디버깅용. 개발자 툴에서 뭐 표시하는 기능..?
						</pre>
					</button>
					</pre>
				</pre>
			</pre>
			ㅇ Redux<button>더보기</button>
			<pre>
				ㅡ 리액트 훅의 useReducer와 유사한 형식인듯하다.
					ㄴ reducer가 최조 한번 무조건 실행된다함. 이때의 state값은 undefined.
					ㄴ reducer에서 반환할때는 기존의 state를 그대로 반환하지 말고, 이를복제하여 새로운 state값을 리턴하라함. 권장임.
					ㄴ '구독' 개념 )
						ㄴ 특정 함수를 '구독'하게 해두면, state가 변경될 때마다, 해당 함수를 호출해준다.
						ㄴ store.subscribe( (*함수*) )
				ㅡ redux dev tool )
					ㄴ 공식문서에 설정 방법
					ㄴ redux store에 저장된 state의 변화를 깃 버전관리하듯이 히스토리를 볼 수 있다.
				ㅡ 공식 홈페이지 참고
				ㅡ 설치 및 설정<button>더보기</button>
				<pre>
					ㄴ redux toolkit )<button>더보기</button>
					<pre>
						ㄴ redux사용에 도움을 주는 도구.
						ㄴ 이를 사용하면 redux를 좀더 손쉽게 사용 할 수 있으며, 사용하기를 추천한다함.
						ㄴ 설치 )
							ㄴ npm install @reduxjs/toolkit, yarn add @reduxjs/toolkit
							ㄴ
					</pre>
					ㄴ redux 코어
						ㄴ npm install redux, yarn add redux
				</pre>
				ㅡ 추가적인 공부 자료들 )
					ㄴ https://ko.redux.js.org/introduction/learning-resources 참고
				ㅡ redux 생태계 )
					ㄴ 리덕스를 중심으로 하여 추가되고 확장되는 다양한 라이브러리, 에드온, 도구들을 말하는 듯 하다.
					ㄴ 이것들의 목록은 https://ko.redux.js.org/introduction/ecosystem#table-of-contents 참고.
				ㅡ redux 예제들 )
					ㄴ https://ko.redux.js.org/introduction/examples 참고
				ㅡ redux란? )<button>더보기</button>
				<pre>
					ㄴ 어플리케이션 전반적으로 사용되는 state를 'action'을 통해 한 곳에서 중앙집중적으로 관리하는 패턴, 라이브러리.
					ㄴ 이런 state들이 예상되는 대로 변경되도록 해주고, 언제, 어디서, 왜, 어떻게 변경되는지를 알아보기 쉽게 해준다.
					ㄴ 사용해야할 때 )
						ㄴ 어플에서 state가 많은 부분에서 사용되고 state가 많을때
						ㄴ 시간이 지남에 따라 state가 빈번하고 업데이트될때
						ㄴ state업데이트 로직이 복잡할 때
					ㄴ redux는 standalone js 라이브러리이다.
					ㄴ 다른 패키지들과 자주 같이 사용된다.
						ㄴ React-Redux :
						ㄴ Redux Toolkit
						ㄴ Redux DevTools Extenstion
				</pre>
				ㅡ 주요 용어 및 개념<button>더보기</button>
				<pre>
					ㄴ 주요 개념<button>더보기</button>
					<pre>
						ㄴ state 관리
							ㄴ ~~~~~ 그냥 위에서도 나왔던 리덕스의 핵심 개념 이야기.
						ㄴ 불변성 )
							ㄴ 리덕스에서는 모든 state의 업데이트가 불변성을 보장해야한다.
					</pre>
					ㄴ 주요 용어<button>더보기</button>
					<pre>
						ㄴ state )
							ㄴ store에 저장된 데이터를 말함.
							ㄴ plain js value만 할당 할 수 있음. (js객체, arrays, 원시자료형 등만 가능. 함수, class인스턴스 등은 안됨)
						ㄴ actions )
							ㄴ 'type'이라는 필드를 가지고있는 plain js 객체이다.
							ㄴ 리덕스에서 의미상으로 어플에 어떤 일을 발생시키는 '이벤트'라고 봐도 무방하다.
							ㄴ 'type'필드는 해당 action을 표현하는 string값이어야 한다.
								ㄴ 보편적인 형태는 다음과 같다. ex) "todos/todoAdded"
								ㄴ 슬래쉬 앞부분은 기능이나 카테고리를 의미하고, 두번째는 발생한 일을 의미한다.
							ㄴ 'type'필드 이외에 다른 필드들을 추가하여도 된다. 보편적으로 'payload'라는 필드안에 넣는다.
								ㄴ ex )
									const addTodoAction = {
									type: 'todos/todoAdded',
									payload: 'Buy milk'
									}
						ㄴ action creators )
							ㄴ action을 반환하는 함수. 이를 따로 만듦으로써 매번 action객체를 만들지 않아도 된다.
							ㄴ ex)
								const addTodo = text => {
								return {
									type: 'todos/todoAdded',
									payload: text
								}
								}
						ㄴ reducers )
							ㄴ 리액트 훅의 useReducer( reducer, initialState )에서 reducer와 매우 유사하다.
							ㄴ (state, action) => newState 형태의 함수이다.
							ㄴ 리덕스에서는, 'action'이라는 '이벤트'에 대한 '이벤트 리스너'라고 봐도 무방하다.
							ㄴ reducers가 따라야 하는 규칙 )
								ㄴ state, action에 기반해서만 새로운 state를 계산해야한다.
								ㄴ 기존의 state를 변경해서는 안된다. state의 불변성을 보장해야하므로 새로운 state를 복사하여 업데이트, 반환하는식이어야 한다.
								ㄴ 비동기 로직을 포함해서는 안되고, 랜덤값을 계산해서는 안된다. 'side effect'를 수행해서도 안된다.
								ㄴ 이유 )
									ㄴ 리덕스의 목표중 하나는 코드가 예측가능하도록 하는 것이다. 함수의 결과값이 인풋값에만 영향을 받으면 코드를 예측하기 쉽우며,
										반면, 결과값이 외부의 변수에 의존하거나 랜덤하게 동작하면 예측하기 어렵다.
									ㄴ 함수가 인자를 포함한 다른 값을 수정하면 어플리케이션이 의도치 않게 동작할 위험이 있다.
									ㄴ state의 불변성을 보장하지 않으면,
										ㄴ 업데이트되지 않은 값으로 ui가 보여지거나, state추적이 어려워지거나, 테스트 작성이 어려워지거나, devtool의 'time-travel debuggin'을
											사용 할 수 없게되거나, 리덕스의 핵심 패턴과 정반대로 가게된다.
							ㄴ 전형적으로 reducer는 다음의 로직을 따른다.
								ㄴ reducer가 해당 action에 관련이 있는것인지 체크. 있다면, state를 복사하여 새로운 state를 계산하여 반환.
								ㄴ 관련이 없다면, 기존에 존재하던 state를 그대로 반환.
						ㄴ Store )
							ㄴ 현재 state가 저장되어있는 객체.
							ㄴ reducer를 인자로 받으며 생성 가능하다.
							ㄴ getState() 메소드를 가지고 있으며, 이는 현재의 state값을 반환해준다.
						ㄴ Dispatch )
							ㄴ store는 dispatch() 메소드도 가지고 있으며, 이는 state를 업데이트 할 수 있는 유일한 방법이다.
							ㄴ dispatch()메소드는 인자로 'action'객체를 받는다.
							ㄴ ex ) store.dispatch( { type: 'counter/increment' })
							ㄴ 리덕스에서는, dispatch()를 'action'이라는 '이벤트'를 발생시키는 '트리거'라고 봐도 무방하다.
							ㄴ 전형적으로, dispatch()의 인자로 'action'을 주기 위해 'action creator'를 사용한다고 한다.
								ㄴ ex)
									const increment = () => {
									return {
										type: 'counter/increment'
									}
									}

									store.dispatch(increment())
						ㄴ Selectors )
							ㄴ state에서 필요한 값을 가져와주는 일반 함수를 의미함.

					</pre>
					ㄴ 리덕스 어플리케이션의 데이터 흐름<button>더보기</button>
					<pre>
						ㄴ 초기 세팅 )
							ㄴ store가 root reducer를 인자로 받아 생성된다.
							ㄴ store가 맨 처음 한번 root reducer를 호출하고 초기 state를 저장한다.
							ㄴ UI가 이 state를 가지고 처음으로 렌더링된다.
						ㄴ 업데이트 )
							ㄴ dispatch() 호출
							ㄴ store가 reducer호출. state가 새롭게 설정됨.
							ㄴ store가 자신을 '구독'하고 있는 모든 UI 부분들에게 이를 알림.
							ㄴ 해당 store의 데이터가 필요한 UI컴포넌트들은 자신이 필요한 데이터가 변경되었는지 확인.
							ㄴ 필요한 데이터가 변경되었다면, 새 데이터를 사용해 리렌더링.
					</pre>
				</pre>
				ㅡ 기초 사용법 <button>더보기</button>
				<pre>
					ㄴ 리덕스 dev tool )
						ㄴ
					ㄴ 기초 사용법 )
						ㄴ redux toolkit의 configureStore )
							ㄴ store를 생성하는데 사용된다.
							ㄴ 인자로 reducer필드를 포함하는 객체를 넘겨야 한다.
							ㄴ reducer 필드 안에는 reducer들이 들어있는 객체를 넘긴다. 여기에서의 키값은 state의 키값이 된다.
								ㄴ ex)
									import { configureStore } from '@reduxjs/toolkit'
									import counterReducer from '../features/counter/counterSlice'

									export default configureStore({
									reducer: {
										counter: counterReducer
									}
									})
								ㄴ 이 경우, state에서 state.counter부분이 생긴다.
								ㄴ 값으로 넘어간 counterReducer는 state.counter부분을 담당하게 된다.
							ㄴ 리덕스에서는 store 설정을 'middleware', 'enhancers'등의 다른 플러그인으로 커스텀 할 수 있게 해준다.
						ㄴ redux Slices )
							ㄴ 'slice'란, state에서 한 feature, category를 위한 로직, action의 모음을 의미한다.
							ㄴ 일반적으로 하나의 파일에 한 slice를 작성한다.
							ㄴ 생성 )
								ㄴ redux toolkit의 createSlice()를 사용하여 생성한다.
								ㄴ ex)
									import { createSlice } from '@reduxjs/toolkit'

									export const counterSlice = createSlice({
									name: 'counter',
									initialState: {//state값 초기화에 사용될 필드.
										value: 0//초기화 값을 0으로 설정.
									},
									reducers: {
										increment: state => {//'increment'에 해당하는 reducer함수.
										state.value += 1
										},
										decrement: state => {//'decrement'에 해당하는 reducer함수.
										state.value -= 1
										},
										incrementByAmount: (state, action) => {
										state.value += action.payload
										}
									}
									})

									export const { increment, decrement, incrementByAmount } = counterSlice.actions

									export default counterSlice.reducer
								ㄴ state에서 name에 해당하는 필드가 추가된다.
								ㄴ createSlice()의 인자로 넘긴 객체에 담긴 정보를 가지고 slice가 만들어진다.
								ㄴ name필드는 action의 type에서 앞부분에 해당하고, reducers필드의 키값들은 뒷부분에 해당한다.
									ㄴ 해당 앞부분과 뒷부분이 일치하는 action이 dispatch되면 slice에 정의된 reducer가 호출된다.
								ㄴ slice는 자동으로  action creator를 생성해준다. (*slice명*).actions.(*reducers필드의 타입명*)이 action creator함수이다.
									ㄴ ex) counterSlice.actions.increment()
							ㄴ 내부적으로 'Immer'라는 라이브러리를 사용하여 reducer에서 반환 state의 불변성을 유지하도록 보장해준다.
								ㄴ 따라서, redux toolkit의 createSlice(), createReducer()안에서는 state의 불변성 보장을 위해 별도의 작업을 해 줄 필요가 없다.
								ㄴ 인자로 받은 state를 변경시키기만 하면 알아서 불변성을 보장하며 새 state를 반환해준다.
						ㄴ thunk )
							* Redux middleware<button>더보기</button>
							<pre>
								ㅡ dispatch의 동작을 커스텀 하게 해주는 리덕스 에드온.
								ㅡ Express, Koa 등에서 '미들웨어'란, 프레임워크가 request를 받고 response를 만들어내는 사이에 끼워 넣을 수 있는 코드를 말한다.
								ㅡ 미들웨어의 가장 큰 특징은, 체인형으로 구성 가능하다는 것이다. 즉, 여러개의 미들웨어들을 독립적으로 붙여 구성 할 수 있다.
								ㅡ 리덕스 미들웨어도 이와 유사하다. 'action'을 dispath하고 reducer가 실행되기 사이에 중간지점을 끼워넣는다.
								ㅡ 일반적으로 logging, 비동기 작업 등에 자주 사용한다고 한다.
							</pre>
							ㄴ 개요 )
								ㄴ thunk는 'redux-thunk' 라이브러리의 미들웨어로, 리덕스에서 가장 흔히 사용되는 비동기 미들웨어이다.
								ㄴ 비동기 로직을 담을 수 있는 리덕스 함수.
							ㄴ 사용법 )
								ㄴ 다음 형식에 맞는 plain js function을 정의한다
									ㄴ dispath, getState를 받아 비동기 로직을 수행하는 내부 함수와 이 함수를 반환하는 외부함수로 구성된다고함.
									ㄴ ex)
										const logAndAdd = amount => {//내부함수를 반환하는 외부함수.
										return (dispatch, getState) => {//dispatch, getState를 인자로 받는 내부함수.
											const stateBefore = getState()
											console.log(`Counter before: ${stateBefore.counter}`)
											dispatch(incrementByAmount(amount))
											const stateAfter = getState()
											console.log(`Counter after: ${stateAfter.counter}`)
										}
										}

										store.dispatch(logAndAdd(5))
								ㄴ 정의한 thunk함수를 dispath()의 인자로 넘겨준다.
									ㄴ ex) store.dispatch(logAndAdd(5))
									ㄴ 당연히, thunk함수에 인자를 넘길 수도있다.
								ㄴ thunk함수를 dispatch함으로써 thunk함수가 실행되고, thunk함수 내에서 원하는 로직을 수행한 뒤, 인자로 받은 dispatch()를
									이용해 dispatch해주면 된다.
								ㄴ 보편적으로, 관련 'action'이 있는 slice파일에 같이 정의하여 해당 'action'들을 사용할 수 있게 한다고 함.
								ㄴ 보편적으로, state에 'status', 'error'와 같은 이름의 필드를 두어서 비동기 작업의 결과상태를 저장해둔다.
							ㄴ Redux toolkit의 createAsyncThunk() )
								ㄴ ?????
								ㄴ 생성될 action type을 나타내는 문자열과 'Promise'또는 데이터를 반환하는 함수를 인자로 받는다.
									ㄴ ex)
										export const fetchPosts = createAsyncThunk('posts/fetchPosts', async () => {
										const response = await client.get('/fakeApi/posts')
										return response.posts
										})
									ㄴ 첫번째 인자는 createAsyncThunk가 자동으로 생성할 action의 type의 앞부분이다.
										ㄴ 비동기 수행 결과에 따라, 'posts/fetchPosts/pending', 'posts/fetchPosts/fulfilled' 등이 붙는다.
									ㄴ 자동으로 생성되는 action에는 비동기요청에 대한 상태값 등 여러 메타정보가 포함된다.
									ㄴ 요청 성공시, 두번째 인자 함수에서 반환하는 데이터가 action의 payload에 포함되어 reducer에 전달된다.
									ㄴ 두 번째 인자는 실행할 비동기 로직이 포함 된 함수이다.
									ㄴ
								ㄴ 일반적으로 두번째 인자인 함수에서는 ajax을 이용하여 async/await문으로 데이터를 받아온다함.
							ㄴ redux tookit의 configureStore안에 자동으로 포함되어 있다함.
							ㄴ thunk를 standard 사용법대로 사용하기를 권장한다함.
							ㄴ ????? 그냥 형식만 지키면 thunks라는 건지, 왜 이걸 이용해 비동기 로직을 넣으라는 건지 모르겠음. 그냥 일반함수같은데?
							ㄴ ????? 추가 문서 확인 필요
						ㄴ 리액트, 리덕스 )
							ㄴ React-Redux library에는 ㅣㄹ액트 컴포넌트가 리덕스 store와 상호작용할 수 있게해 주는 커스텀 훅들이  들어있다.
							ㄴ 리액트에서는 리덕스 store에 직접 접근할 수 없기 때문에????? 훅을 사용한다.
							ㄴ useSelector 훅 )
								ㄴ 리덕스 'store'에서 필요한 데이터를 추출할 수 있게 해주는 훅.
								ㄴ 리덕스에서는 state에서 필요한 데이터를 가져와주는 함수를 'selector'라는 용어로 불렀다.
									ㄴ ex) export const selectCount = (state) => state.counter.value;
								ㄴ useSelector훅에 리덕스의 'selector'를 넘겨주면 'selector'함수를 store.getState()를 인자로 넘기며 호출하여 결과값을 반환해 준다.
									ㄴ ex) useSelector(selectCount)
								ㄴ 사전에 정의된 'selector'뿐만 아니라 useSelector 훅 인자에 'selector'함수를 정의해도 된다.
									ㄴ ex) useSelector( state => state.counter.value )
								ㄴ 'action'이 dispatch되거나 redux store가 업데이트 되면, useSelector가 'selector'를 재실행하고, 결과값이 다를 경우,
									useSelector가 컴포넌트가 리렌더링 되도록 해준다.
							ㄴ useDispatch 훅 )
								ㄴ ex) const dispatch = useDispatch()
								ㄴ 리덕스 store의 dispatch메소드를 반환해주는 훅. 반환받은 dispatch를 사용하면된다.
							ㄴ 리액트 state와 리덕스 store
								ㄴ 어플 전체에서 사용되는 값들은 리덕스 store에 저장하는게 맞지만, 특정 컴포넌트들만 관심있는 값들은 컴포넌트 state에만 존재하는 게 맞다.
							ㄴ 리액트에 redux store를 제공하는 법 )
								ㄴ 리액트 앱 상위에서 react-redux의 'Provider'를 사용하여 store를 넘겨준다.
									ㄴ ex)
										import store from './app/store'	//단순하게 configureStore()를 통해 store를 생성하고 export하는 js파일.
										import { Provider } from 'react-redux'
										import * as serviceWorker from './serviceWorker'

										ReactDOM.render(
										< Provider store={store}>
											< App />
										< /Provider>,
										document.getElementById('root')
										)
									ㄴ App 하위의 리액트 컴포넌트들에선 useSelector, useDispatch등을 사용하여 redux store와 상호작용 할 수 있다.
				</pre>
				ㅡ
			</pre>
			ㅇ Mobx<button>더보기</button>
			<pre>
				ㅡ 공식 홈페이지 참고 (https://mobx.js.org/README.html)
				ㅡ 설치 및 설정<button>더보기</button>
				<pre>
					ㄴ npm install --save mobx, yarn add mobx
					ㄴ Babel 사용시 )
						ㄴ 바벨최소버전 7.12
						ㄴ ["@babel/plugin-proposal-class-properties", {"loose" : false}]
					ㄴ TypeScript 사용시 )
						ㄴ 컴파일러 옵션 중, "useDefineForClassFields" : true
					ㄴ js버전이 오래된 경우 )
						ㄴ Mobx는 호환성과 최적화를 위해 프록시를 사용한다.
						ㄴ 'Proxy'가 지원되지 않는 js버전의 경우, Mobx는 ES5와 호환되는 버전의 구현체로 변경될 수 있다.
							ㄴ import { configure } from 'mobx'
								configure({ useProxies: 'never' })
						ㄴ 이러한 오래된 버전의 예로는, Edge이전의 인터넷익스플로어, 6이전의 Node.js, 10이전의 iOS, RN 0.59이전의 안드로이드 등이 있다.
					ㄴ mobx의 'decorators'
						ㄴ @observable 과 같은 문법?을 mobx에서 'decorator'라 부르는데, 6버전부터 지양한다고한다. 표준 js와의 호환성을 위하여.
				</pre>

				ㅡ 핵심 개념들<button>더보기</button>
				<pre>
					ㄴ 전체적인 뷰?

					ㄴ Observable state<button>더보기</button>
					<pre>
						ㄴ 프로퍼티, 객체, 배열, map, set 데이터들이 observable 가능하다.
						ㄴ 프로퍼티마다 어노테이션을 명시함으로서 observable 설정을 할 수 있다.
						ㄴ array, map, set같은 컬렉션들은 자동으로 observable이 된다.
						ㄴ 주요 어노테이션
							ㄴ observable : state에 저장되는 값들.
							ㄴ action : state를 수정하는 메소드
							ㄴ computed :
						ㄴ makeObservable )
							ㄴ makeObservable ( (*타겟데이터*), (*어노테이션정보*), (*옵션*) )
								ㄴ (*타겟데이터*) : 어떠한 js object도 가능. class 인스턴스 포함.
							ㄴ (*타겟데이터*)의 존재하는 properties
							ㄴ 일반적으로 makeObservable은 클래스의 constructor에서 사용되면서 (*타겟데이터*)에 this를 넣는다.
							ㄴ ?????
						ㄴ makeAutoObservable )
							ㄴ makeObservable과 유사.
							ㄴ makeAutoObservable( (*타겟데이터*), (*override*), (*옵션*) )
							ㄴ 디폴트로, 모든 properties를 추척한다.
							ㄴ (*override*)인자를 통해 makeObservable에서 하던 것 처럼 properties들을 개별적으로 어노테이션으로 명시할 수 있다.
								ㄴ false를 사용하여 추적대상에서 완전히 제외시킬 수 있다.
							ㄴ 함축된 규칙들 )
								ㄴ 모든 프로퍼티들은 observable이다
								ㄴ 모든 getter는 computed이다.
								ㄴ 모든 setter는 action이다.
								ㄴ 모든 prototype 함수는 autoAction이다.
								ㄴ 모든 prototype의 generator함수는 flow이다.
								ㄴ (*override*)에 false로 표시된 멤버는 아무 어노테이션이 붙지 않는다.
							ㄴ 상속되는 클래스에서는 사용할 수 없다.
						ㄴ observable )
							ㄴ observable어노테이션은 함수로 사용될 수도 있다.
							ㄴ observable( (*타겟데이터*), (*override*), (*옵션*) )
							ㄴ (*타겟데이터*)에 오는 객체는 모든 멤버가 observable이 되며, (*override*)를 통해 개별적으로 선언 할 수 있다. (makeAutoObservable과 유사하게)
							ㄴ observable함수에서 반환되는 객체는 'Proxy'가 된다. 이후에 그 객체에 추가되는 properties들이 똑같이 observable이 됨을 의미한다.

						ㄴ 가능한 어노테이션 목록 )<button>더보기</button>
						<pre>
							ㄴ observable, observable.deep )
								ㄴ
						</pre>

						ㄴ 유의사항<button>더보기</button>
						<pre>
							ㄴ
						</pre>

						ㄴ (*옵션*) <button>더보기</button>
						<pre>
							ㄴ
						</pre>


					</pre>

					ㄴ Actions <button>더보기</button>
					<pre>
						ㄴ state를 수정하는 어떠한 코드조각을 의미.
						ㄴ action은 'transaction'안에서 수행된다. 따라서 수행되는 중에 어떠한 observer도 업데이트 되지 않는다.
						ㄴ action 이외의 부분에서 state를 수정하는 것이 불가하다.
						ㄴ 'state를 수정하는 함수'에서만 'action'어노테이션이 사용되어야 한다. 조회나 탐색, 정렬 등은 해당되지 않는다.
						ㄴ action wrapping function )
							ㄴ action을 이벤트 핸들러로 사용하려는 경우 등을 위해, action은 어노테이션 뿐만 아니라 함수로서 호출하여 action을 만들 수 있다.
							ㄴ ex)
								const ResetButton = ({ formState }) => (
									< button
											onClick={action(e => {
											formState.resetPendingUploads()
											formState.resetValues()
											e.stopPropagation()
										})}
									> Reset form < /button>
								)
							ㄴ 인자와 함께 action함수를 호출 할 수 있으며, 이는 action으로 wrap한 함수를 반환한다.
						ㄴ ????? action.bound )
							ㄴ
						ㄴ runInAction( (*함수*) )
							ㄴ 즉시 호출될 임시 action을 생성할때 사용.
							ㄴ ex)
								import { observable, runInAction } from "mobx"

								const state = observable({ value: 0 })

								runInAction(() => {
									state.value++
									state.value++
								})
						ㄴ ????? action의 상속
							ㄴ prototype에 정의된 action들만 subclass에서 overriden될 수 있다.
						ㄴ 비동기 action )
							ㄴ
						ㄴ flow 어노테이션 )
							ㄴ async, awati에 대한 대안이다.
							ㄴ ?????
						ㄴ

					</pre>

					ㄴ Computeds <button>더보기</button>
					<pre>
						ㄴ computed 어노테이션, computed( (*옵션*) ) 어노테이션, computed( (*함수*), (*옵션*) ) 함수
						ㄴ ~~~~~
						ㄴ 권장 규칙 )
							ㄴ side effect나 다른 observable을 업데이트해서는 안된다.
							ㄴ 새로운 observable을 생성하거나 반환하지 말아라.
						ㄴ (*옵션*) )
							ㄴ
					</pre>

					ㄴ Reactions <button>더보기</button>
					<pre>
						ㄴ ?????
						ㄴ 다음의 api들은 직접 사용되는 일이 매우 드물다. 보통 다른 mobx관련 라이브러리에 (mobx-react 등) 추상화되어 들어있다.
							하지만 mobx이해를 위해 다룬다고함.
						ㄴ 가장 단순한 방법으로 autorun이 있고, 그 이외에 'reaction', 'when'이 있다.
						ㄴ Autorun )
							ㄴ autorun( effect: (reaction) => void )
							ㄴ 관찰중인 것들이 변화하면 매번 실행될 함수를 하나 인자로 받는다.
								ㄴ 관찰중인 것들이란, 앞에서 나온 observable, computed 들
							ㄴ autorun을 생성할 때, 최초로 한 번 실행된다.
						ㄴ Reaction )
							ㄴ reaction( ()=> value, ( value, previoutValue, reaction ) => {sideEffect}, option? )
							ㄴ autorun과 유사하나, observable에 대한 좀 더 세밀한 추적과 실행이 가능하다.
							ㄴ 첫번째 인자인 함수는 두번째인자인 함수에서 사용될 데이터를 반환한다.
							ㄴ 두번째 인자인 함수는 이 반환받은 데이터를 가지고 원하는 로직을 작성하여 실행할 수 있다.
							ㄴ autorun과 달리, 맨 처음 생성시 한번 실행되지 않는다.
						ㄴ When )
							ㄴ when ( ()=> boolean, ()=> void, (*옵션*) 또는 when ( ()=> boolean, (*옵션*) )
							ㄴ 첫번째 함수가 관찰되고 있다가, true를 반환하면 두번째 인자의 함수가 호출된다.
							ㄴ 두번째 함수 인자가 없으면 when은 'Promise'를 반환한다.
						ㄴ Rules )
							ㄴ reaction은 action이 끝난 직후에 동기적으로 실행된다.
							ㄴ autorun은 인자로 넘어온 함수에서 '동기적'으로 실행되는데 사용되는 값들만 추적한다.
							ㄴ autorun, reaction, when으로 전달된 함수들은 그것들이 관찰 중인 객체들이 모두 garbage로 수집될때 그제서야
								garbage로 수집된다. 또는 이들이 반환하는 disposer()함수를 호출하면 된다.
							ㄴ Reaction을 사용할 만한 상황
								ㄴ ????? 직접적인 인과관계가 없는 곳에만 사용하라??
									ㄴ input값들이 입력된 form 을 submit하는 경우와 같이 제한적인 소수의 이벤트, action에 reaction을 사용하는 것보다,
										직접 필요한 effect를 호출하는 게 낫다.
									ㄴ input값들을 매번 입력할 때마다 필요한 로직같은건, 매번 effect를 호출하는 것 보다는 reaction을 사용하는게 낫다.
								ㄴ reaction 안에서는 다른 observable을 업데이트해서는 안된다.
									ㄴ reaction안에서 업데이트 할거면 그 값은 'computed'로 annotated되는 게 맞다.
								ㄴ reaction은 다른 reaction과 독립적이어야 한다.
									ㄴ mobx는 reaction들간의 실행 순서를 보장하지 않는다.
									ㄴ 어떤 reaction이 다른 reaction에 의존적이라면, 두 reaction을 하나로 합치는게 낫다.
						ㄴ (*옵션*) )
							ㄴ ~~~~~

					</pre>
				</pre>

				ㅡ MobX & React <button>더보기</button>
				<pre>
					ㄴ ex)
						import { observer } from 'mobx-react-lite' //또는 'mobx-react'

						const (*컴포넌트명*) = observer( (*props*) => (*리액트컴포넌트*) )
					ㄴ observer )
						ㄴ observer는 리액트의 HoC이다.
						ㄴ 리액트 컴포넌트 렌더링에 사용되는 observable한 모든 데이터를 자동으로 관찰한다.
						ㄴ 관찰되고 있는 값이 변경되면 자동으로 리렌더링 된다.
						ㄴ 컴포넌트 안에서 사용되나, 렌더링 중 사용되지 않는 값들이 변하면 리렌더링을 하지 않는다
						ㄴ 꼭 인자로 넘어간 데이터가 아닌 컴포넌트의 state나 해당 파일의 전역데이터나 리액트의 context에 대해서도 렌더링에 사용된다면 자동으로 관찰하고 리렌더링해준다.
						ㄴ 지역 컴포넌트에 대해 mobx observable을 사용하기보다는, 여러 컴포넌트 사이에서 공유되는 데이터들에 대해 사용하기를 권장한다.
						ㄴ observer는 사용된 해당 컴포넌트에서만 적용되고 그 하위의 컴포넌트에는 자동으로 적용되지 않는다. 따라서 observerable이 사용되는 모든 컴포넌트에 observer를
							붙여주어야 한다.
						ㄴ observer이 아닌 하위 컴포넌트에 observable을 전달하려면 이를 plain js 객체로 변경한 뒤 전달하라고 한다.
							ㄴ ????? 왜 그래야 하는지는 잘 모르겠다. 그냥 observable을 넘겨도 관찰되고 리렌더링 안될뿐이지 오류가 뜨거나 하지는 않는다.
						ㄴ 하위 컴포넌트로 callback함수를 props으로  전달하려 할때, 이 callback함수에 대해서도 관찰이 유지되고 리렌더링이 되기를 바란다면, 그냥 전달하는 것이 아닌,
							< Observer/>로 컬백함수를 감싸서 전달하면 된다. 그럼 해당 콜백함수 안에서의 observable에 대해 관찰이 유지되고 리렌더링이 된다.
							ㄴ ex)
								// WRONG: GridRow.onRender won't pick up changes in todo.title / todo.done
								//        since it isn't an observer.
								return < GridRow onRender={() => < td>{todo.title}< /td>} />

								// CORRECT: wrap the callback rendering in Observer to be able to detect changes.
								return < GridRow onRender={() => < Observer>{() => < td>{todo.title}< /td>}< /Observer>} />
						ㄴ ????? observer는 객체 참조를 전달해 주어 observer안에서 이 객체 참조에 대해 역참조를 하여 동작할 때 가장 잘 동작한다고 한다.
							ㄴ 이는 역참조를 미리 하여 최소한 원시값같은 작은 단위의값을 전달하는게 좋은 react-redux와는 다른 방식이라함.
					ㄴ 최적화 )
						ㄴ ~~~~~
				</pre>
				ㅡ 팁 <button>더보기</button>
				<pre>
					ㄴ data store<button>더보기</button>
					<pre>
						ㄴ 'store'라는 코드모음?을 분리하여서 어플 전체에서 재사용하기 좋고, 테스트하기 좋은 모듈?같은 것을 만들 수 있다.
						ㄴ 일반적으로 '도메인 store', 'UI store'로 분류된다.
						ㄴ 도메인 store )
							ㄴ 어플에서 사용하는 모든 데이터를 저장하는 store를 의미. todo item, use, book, order 등.
							ㄴ 하나의 도메인 스토어는 보통 하나의 도메인을 맡는다. book 도메인 스토어, order 도메인 스토어 등등.
							ㄴ
					</pre>
				</pre>

				ㅡ ex)<button>더보기</button>
				<pre>
					import React from "react"
					import ReactDOM from "react-dom"
					import { makeAutoObservable } from "mobx"
					import { observer } from "mobx-react"

					// Model the application state.
					class Timer {
						secondsPassed = 0

						constructor() {
							makeAutoObservable(this)
						}

						increase() {
							this.secondsPassed += 1
						}

						reset() {
							this.secondsPassed = 0
						}
					}

					const myTimer = new Timer()

					// Build a "user interface" that uses the observable state.
					//observer에 의해 감싸진 부분 안에서 mobx에 의해 이 요소가 timer.secondsPassed란 값에 의존한다는게 자동으로 체크가 되고
					// 이 값이 변할때마다 자동으로 렌더링을 한다고한다.
					const TimerView = observer(({ timer }) => (
						< button onClick={() => timer.reset()}>Seconds passed: {timer.secondsPassed}< /button>
										))

					ReactDOM.render(< TimerView timer={myTimer} />, document.body)

					// Update the 'Seconds passed: X' text every second.
					setInterval(() => {
						myTimer.increase()
					}, 1000)

				</pre>
				ㅡ 이진희님 mobx 코드
					ㄴ 여러 store에 observable객체를 정의하여 store겸 observable로 사용하고 있는 듯 하다.

			</pre>

			ㅇ React Native <button>more</button>
			<pre>
				ㅡ 개요 )
					ㄴ ??? react 기반의 앱 개발 도구?
					ㄴ ??? java로 안드로이드 개발하고 swift로 ios개발하듯, react native로 앱 개발
					ㄴ
				ㅡ ~~~
				ㅡ 'view'라는 react component를 중심으로 앱상의 화면을 구성.
					ㄴ ImageView, TextView 등, 여러 view 위에 화면 요소들이 구성.
				ㅡ use debugging
					ㄴ 안드로이드 > 설정 > 디바이스정보 > 소프트웨어정보 > 빌드번호
				ㅡ ~~~
				ㅡ Expo<button>more</button>
				<pre>
					ㄴ 개요 )
					ㄴ react-native의 'react-native-create-app' 라이브러리가 통합된 것.
					ㄴ ~~~
					ㄴ standalone app 설치
						ㄴ android
							ㄴ 프로젝트 루트 디렉토리에서 expo build:android 명령
							ㄴ 패키지명 입력, 키?관리 등 물어보는 것 체크.
							ㄴ 빌드 중, 보이는 url로 expo의 빌드 진행 상황 페이지로 들어갈 수 있고, 빌드 완료 후
								apk앱을 다운받을 수 있다.
							ㄴ 모바일 기기에서 이를 다운 후 설치.
								ㄴ 설치시 플레이스토어를 통해 받은 앱은 아니라 여러가지 경고창이 뜸.
							ㄴ 완료. 앱 실행.

				</pre>

				ㅡ React Native CLI를 통한 시작 )
					ㄴ nodejs(14이상), jdk(11이상) 설치.
						ㄴ 설치 안 되어 있을 시, 'chocolatey' 이용 추천한다함
					ㄴ 안드로이드 스튜디오 설치
						ㄴ 다운
						ㄴ 세팅 )
							ㄴ react native app 빌드에는 android sdk 12가 필요하다함.
								하여 이를 사용하도록 설정
							ㄴ ~~~
					ㄴ react native cli
						ㄴ react native cli 모듈을 글로벌로 설치하고 관리하기보다, npx react-native (*명령어*) 사용 추천한다함.
						ㄴ 그때그때 적절한 버전의 모듈을 사용해줌.
					ㄴ 프로젝트 생성 )
						ㄴ npx react-native init (*플젝명*)
					ㄴ 기기에서 실행
						ㄴ 실 기기에서 실행 )
							ㄴ 1. 안드로이드폰 > 설정 > 디바이스정보 > 소프트웨어정보 > 빌드번호 7번 클릭
							ㄴ 2. 설정 > 개발자옵션 항목 추가됨.
							ㄴ 3. 설정 > 개발자 옵션 > use디버깅 on
							ㄴ device와 use연결
							ㄴ 4. cmd에서 adb devices 명령. 장치에서 알림창 허용하고, 연결된 장치목록 확인.
								ㄴ 장치 목록이 없을 시,
									ㄴ 연결 잭이 정상적인지 확인. 종류에 따라 안 되는 잭이 있다?
							ㄴ 프로젝트 루트 위치에서 npx react-native run-android 실행. (그전에 npx react-native start 먼저???)
								ㄴ 오류 뜰 경우, 프로젝트 루트/android에서 gradlew clean 후, npm install 로 재설치 후 npx react-native run-android 재실행.
						ㄴ virtual device

				ㅡ webview 설정
					ㄴ 해당 프로젝트 루트 위치에ㅓㅅ npm install react-native-webview 실행
					ㄴ 앱 재시작
				ㅡ apk, aab 생성
					ㄴ 프로젝트 루트 / android / app / src / main 에 'assets' 폴더 생성
					ㄴ 프로젝트 루트 위치에서 다음 명령 실행.
						npx react-native bundle --platform android --dev false --entry-file index.js --bundle-output android/app/src/main/assets/index.android.bundle --assets-dest android/app/src/main/res/
					ㄴ 프로젝트 루트 / android 에서 gradlew assembleDebug 실행.
					ㄴ 플젝루트 / android / app/build/outputs/apk/debug 에 apk 생성.
					ㄴ 디바이스기기로 옮긴뒤 실행하여 앱 설치.
					ㄴ aab는 위의 gradlew assenbleDebug대신, gradlew bundleRelease 명령.
						/android/app/build/outputs/bundle/release 하위에 aab파일 생성.

				ㅡ splash screen 적용 <button>more</button>
				<pre>
					ㄴ android
						ㄴ 스플래시 이미지 만들기
							ㄴ https://appicon.co/#image-sets 에서 파일넣고 'generate' 클릭. 결과 알집파일 내의
								drawable-mdpi 등 폴더들 잘 보관.
						ㄴ 이미지 원본파일을 /android/app/src/main/res/drawable에,
							위에서 받은 폴더들을 /android/app/src/main/res에 위치시킴.
							원본파일명 기억.
						ㄴ npm i react-native-splash-screen --save
						ㄴ App.tsx에 'import SplashScreen from "react-native-splash-screen";' 추가.
						ㄴ 플잭root/android/app/src/main/res에 'layout'폴더 추가
							& launch_screen.xml 파일 추가 & 내용 다음 입력
							< ?xml version="1.0" encoding="utf-8"?>
							< RelativeLayout xmlns:android="http://schemas.android.com/apk/res/android"
								android:orientation="vertical" android:layout_width="match_parent"
								android:layout_height="match_parent">
								< ImageView android:layout_width="match_parent"
								android:layout_height="match_parent"
								android:src="@drawable/(*/android/app/src/main/res/drawable에 있는 스플래시파일명. 확장자 제외*)"
								android:scaleType="centerCrop" />
							< /RelativeLayout>
						ㄴ 플젝root/android/app/src/main/res/drawable에 splashscreen.xml 추가 & 다음 내용 입력
							< ?xml version="1.0" encoding="utf-8"?>
							< layer-list xmlns:android="http://schemas.android.com/apk/res/android">
								< item>
									< bitmap
											android:gravity="center"
											android:src="@drawable/(*/android/app/src/main/res/drawable에 있는 스플래시파일명. 확장자 제외*)" />
								< /item>
							< /layer-list>
						ㄴ 플젝root/android/app/src/main/java/com 하위의 MainActivity.kt 파일에 다음 추가.
							java아닌 코틀린 파일임 유의.

							import android.os.Bundle; // here
							// react-native-splash-screen >= 0.3.1
							import org.devio.rn.splashscreen.SplashScreen; // here
							// react-native-splash-screen < 0.3.1
							//import com.cboy.rn.splashscreen.SplashScreen; // here

							// MainActivity class 내에
							override fun onCreate(savedInstanceState: Bundle?) {
								SplashScreen.show(this) // here
								super.onCreate(savedInstanceState)
							}
						ㄴ App.tsx에 스플래시 코드 추가.
							import SplashScreen from "react-native-splash-screen";

							// useEffect() 등 안에서..
							// 3초 후, 스플래시 화면 꺼지도록.
							setTimeout(()=>{
								SplashScreen.hide();
								console.log("splash hide ")
							}, 3000);
						ㄴ 참고
							ㄴ https://velog.io/@chloedev/React-native-Splash-Screen-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0-iOS-android
							ㄴ https://velog.io/@2ast/React-Native-android-app-icon%EA%B3%BC-splash-screen-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0
							ㄴ https://ssilook.tistory.com/entry/React-Native-RN-Android-Splash-%EC%9D%B4%EB%AF%B8%EC%A7%80-%EC%A0%81%EC%9A%A9%ED%95%98%EA%B8%B0
							ㄴ https://medium.com/@svbala99/set-up-splash-screen-in-react-native-for-ios-and-android-2023-dbedb87fe75e
				</pre>

				ㅡ ios 해당
					ㄴ 백그라운드 상태 장시간 구동시, 빈화면으로 멈춤
						ㄴ ios webview의 경우, 메모리부족해지거나 하면 앱이 웹뷰를 종료한다함.
						ㄴ webview의 onContentProcessDidTerminate 속성에 함수부여하여
							메모리부족으로 종료될시 호출가능.
			</pre>
		</pre>
		기타<button>더보기</button>
		<pre>
			ㅇ 웹팩<button>더보기</button>
			<pre>
				ㅡ https://joshua1988.github.io/webpack-guide/webpack/what-is-webpack.html#%EB%AA%A8%EB%93%88%EC%9D%B4%EB%9E%80 참조
				ㅡ 모듈과 모듈 번들링 )
					ㄴ 모듈 : 내가 아는 그 모듈. 함수같이 하나의 기능을 하는 단위같은것. 함수가될수도, 하나의 소스코드전체가 될수도.
					ㄴ 웹팩의 모듈 : 웹 어플리케이션을 구성하는 모든 자원(html, css, image, font 등등)을 말한다.
					ㄴ 모듈 번들링 : 이러한 모듈들을 하나의 파일로 병합, 압축해주는 과정을 말한다.
				ㅡ ~~~~~
			</pre>
			ㅇ 이미지 포멧<button>more</button>
			<pre>
				ㅡ ~~~~~
				ㅡ svg <button>more</button>
				<pre>
					ㄴ ex)
						< svg viewBox="0 0 300 100" xmlns="http://www.w3.org/2000/svg" stroke="red" fill="grey">
						< circle cx="50" cy="50" r="40" />
						< circle cx="150" cy="50" r="4" />

						< svg viewBox="0 0 10 10" x="200" width="100">
							< circle cx="5" cy="5" r="4" />
						< /svg>
						< /svg>
					ㄴ 그래픽을 그래는데 사용되는 xml 언어.
				</pre>
			</pre>
			ㄴ 웹앱, 웹뷰, 하이브리드앱, 네이티브 앱
				ㄴ 웹앱 : 모바일 웹앱이라 하지만 그냥 웹 어플리케이션 말함. 걍 웹사이트.
				ㄴ 네이티브앱 : ios, android 등 특정 모바일os 기반으로하는 순수 모바일 어플리케이션.
				ㄴ 웹뷰 : 네이티브앱 안에 들어가 있는 웹브라우저. html의 iframe처럼 일종의 네이티브앱의 컴포넌트.
				ㄴ 하이브리드앱 : 기본적으로 웹앱이나 네이티브앱으로 wrap하여 일부 네이티브앱처럼 동작하는 앱.
					ㄴ 네이티브앱처럼 설치, 모바일os단 일부 기능 사용 가능 등.
					ㄴ 웹뷰를 사용하여 만들 수 있음.

		</pre>
		ㄴ Web Workers API 
			ㄴ 개요 
				ㄴ 스크립트 실행을 메인 실행 스레드와 분리되어 별도로 백그라운드상에서 돌아가는 스레드에서 실행할 수 있게 해주는 api.
					주된 이유는 작업량이 큰 작업을 별도 스레드에서 돌려, 메인스레드가 작업중이라 UI가 블락되는 일이 없게하기 위함. 
				ㄴ ??? js의 'Worker'클래스의 객체를 의미. 
				ㄴ worker thread 내부에서 대부분의 코드 실행 가능. 
					ㄴ 일부 불가능. 
						ㄴ DOM조작, Window객체의 디폴트 메소드, 프로퍼티 등. 
			ㄴ ~~~ 
			ㄴ 참조 
				ㄴ https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API

	</pre> 

	<br>back-end<button>더보기</button>
	<pre>
		서버단<button>더보기</button>
		<pre>
			ㅇ 정적 vs 동적 웹사이트
				ㅡ 바뀌지않고 고정된 사이트를 정적 웹사이트.
				ㅡ 요청에 따라 필요할때 동적으로 생성되어 전달되는 페이지를 동적 웹사이트라함.( 가령 html탬플렛에 사용자에 따라 적절한 db를 입력하여 반환하거나)
					이때 사용되는 코드는 서버에서 실행되어야하고 이런 코드를 만드는것을 '서버 사이드 프로그래밍' 이라고한다.
				ㅡ 서버사이드 프로그래밍은 다양한 언어로 작성이 가능하다(PHP, Python, Ruby 등등)

			ㅇ 서버측 프로그래밍의 쓰임
				ㅡ 개별 사용자에 맞게 효율적 정보전달, 사용자 경험 향상.
				ㅡ 항목이 많고 데이터가 많아졌을때, 그 각각에 대해 모두 정적페이지를 만드는건 매우 비효율. 이럴때 쓰인다.
				ㅡ 편안한 사용자 경험을 위해 사용자의 정보를 저장하거나 하는데 사용
				ㅡ 사용자만 접근할수있는 정보제공
				ㅡ 특화된 알림기능
				ㅡ 정보 분석 수집.

			ㅇ 서버사이드측 작동방식
				ㅡ 웹 브라우저는 링크를 클릭하거나, form을 전송하거나, 검색을 하는 등을 할대 HTTP request라는것을 서버에 전송.
				ㅡ 이 request에 포함되는내용들은 URL,  메소드, 매개변수가 있다.
				ㅡ 메소드의 정류에는
					ㄴ GET : 특정 리ㅣ소스를 얻는다.
					ㄴ POST : 새 리소스를 만든다.
					ㄴ HEAD, PUT, DELETE, TRACE, OPTION, CONNECT, PATCH 등이 잇다.
				ㅡ 매개변수에는
					ㄴ ex) http://mysite.com ? name = Fred&age=11 과 같이 GET방식에서 물음표(?)뒤에 붙어서 전달되는것들을 말한다.
				ㅡ 요청에 대한 응답시에는 요청 성공여부를 나타내는'HTTP Response status code'를 포함하여 보낸다. (ex)200은 성공, 404는 not Found 등)

			ㅇ 서버란?
				ㅡ 웹페이지 : html페이지 하나를  의미.
				ㅡ 웹 사이트 : 관련있는 웹페이지들의 그룹.
				ㅡ 서버 : 일종의 저장소역할을 하는 컴퓨터같음. client에 해당하는 컴퓨터들이 접근하고 쓸수있는 정보를 저장하고, 제공하고, 더 나아가 그 정보에 적당히 처리도해주고
					client관리도하는 그런컴퓨터.
				ㅡ 사람들이 호스팅하거나 직접서버를 만들어 이 서버에 웹페이지나 정보를 올리면 다른 클라이언트가 접속할수있다.
				ㅡ WAS(Web Application Server) : 서버는 서버인데 '웹 컨테이너'라는게 추가되어 다양한 기능도 가능한 서버를 말한다.

			ㅡ 웹 서버
				ㄴ iis, 아파치, nginx 등
				ㄴ 경로 )
					ㄴ 웹서버는 클라이언트로부터온 url을 파일시스템의 자원이나 프로그램 이름으로 매핑할 수 있다.
					ㄴ 정적 요청의 경우, 웹서버의 루트 디렉토리를 기준으로 상대경로로 매핑되고
				ㄴ 웹 서버는 커널모드와 유저모드로 나뉘어져 있을 수 있다.
				ㄴ 웹서버는 load limit를 가진다. ip주소 하나당 모통 2~80000개의 연결.
			ㅡ 어플리케이션 서버
				ㄴ 웹 서버와 같이 그냥 똑같은 서버인데 하는 일에 따라 조금씩 다르게 부르는 정도인 듯 하다.
				ㄴ 웹 서버는 http의 정적인 파일들을 다루는 서버,
				ㄴ 앱 서버는 http뿐만 아니라 다른 것들도, 그리고 동적인 파일들을 다루는 서버를 말한다.
			ㅡ 웹 브라우저
				ㄴ www의 정보에 접근하기 위한 일종의 소프트웨어 어플리케이션.
				ㄴ 유저가 특정 요청을 보내면 웹서버로부터 해당 content를 받아 화면에 뿌려주는 기능을 한다.

			ㅇ 가상 호스트
				ㅡ 하나의 서버에서 여러개의 호스트가 있는것처럼 사용하게 해주는 기술.
				ㅡ 가령, 어떤 url로 요청이들어오면 이에 해당하는 가상호스트가 있을시, 이 가상호스트의 conf내용들을 적용해 처리하는 식.
				ㅡ 아파치의 경우, httpd.conf파일에 < VirtualHost>를 설정함으로서 가상호스트 설정이 가능하다.

			ㅇ 서버 동작 방식
				* nic란?
					ㄴ nic, network interface card. 통상 '랜카드'
					ㄴ 컴퓨터가 네트워크를 통해 데이터를 주고받을 수 있게해주는 하드웨어.
						ㄴ 랜선 꽃는곳 바로 뒤에 들어있는 카드.
					ㄴ osi계층에서 물리계층에 해당한다.
				* nic 드라이버란?
					ㄴ 드라이버란 os와 장치가 커뮤니케이션하게해주는 프로그램.
					ㄴ nic드라이버는 osi 계층에서 데이터링크층과 네트워크층에 해당한다.
				* 인터럽트
					ㅡ 아는 그대로고,
					ㅡ 하드웨어인터럽트의 경우, 어떤 칩이 있어서 이를 통하여 인터럽트의 발생을 알린다함.
				* 소켓 인터페이스
					ㅡ 컴퓨터 통신을 위해 커널단에서 제공하는 api.
				ㅡ 네트워크로 데이터가 들어오면 랜카드가 인터럽트를 발생시키고, 이를 통해 요청이 처리가 된다.
				ㅡ 내부적으로 소켓 인터페이스를 사용한다.
				ㅡ tcp를 통해 특정 포트로부터 listening하고 있는걸 '서버'라고 한다. 여기서 어떤 프로토콜이 적용되었느냐에따라 어떤서버인지 달라지는것.(ftp server, http server...)
					ㄴ https://stackoverflow.com/questions/38712164/difference-between-socket-and-web-server-example
					ㄴ ex) http요청을 받아서 처리해주는 httpd라는 '데몬프로그램'이 listening을 하고있다가 요청이 들어오면 이를 처리해준다.
						http프로토콜 패킷형식에 맞게 패킷을 분석하여 처리해준다. (헤더부분의 method부분엔 무슨 스트링값이들어있는지(GET인지 POST인지) 등등)
				ㅡ 서버 주소 www vs non-www
					ㄴ 큰 차이는 없으나,
					ㄴ subdomain 사용하는 경우, root 페이지에 www를 붙이면 서브도메인과 엄연히 구분되어
						클라이언트단에서 쿠키 사용 등이 용이하다는 약간의 장점.
					ㄴ www까지 붙이기 귀찮다는 약간의 단점.

			ㅇ Apache Server<button>더보기</button>
			<pre>
				ㅡ https://httpd.apache.org/docs/ 참조.
				ㅡ 직접 컴파일해서 사용해야하지만 그러지 못하는 사람들을 위해 많은 바이너리 실행파일 배포 페이지들이 있다.
					ㄴ 내경우 Apache Lounge에서 다운받았다.
				ㅡ 아파치 서비스 실행)
					ㄴ 먼저 서비스 설치를 해야하고 이는 httpd.exe -k install 로 가능. (아파치의 bin폴더안에서해야한다)
					ㄴ 서비스 시작 종료는 httpd.exe -k start, stop

				ㅇ centos7에서 아파치 )
					ㅡ yum으로 설치하였고
					ㅡ /etc/httpd안에 서버 설정파일들이 들어있음
						ㄴ /etc/httpd/conf/httpd.conf가 설정파일
						ㄴ 이 외에도 log, module등에 대한 것들이 들어있다.
					ㅡ /var/www/html가 기본적인 DocumentRoot이고 이는 요청들어오면 기본적으로 소스 찾는 위치.
						ㄴ DocumentRoot는 /etc/httpd/conf/httpd.conf에서 설정할 수 있다.
					ㅡ 관련 명령어 )
						ㄴ 아파치 서버 실행 : systemctl start httpd
						ㄴ 아파치 서버 재시작 : systemctl restart httpd
						ㄴ 아파치 서버 상태확인 : systemctl status httpd

				ㅇ 아파치 파일 구성 )
					ㅡ conf 파일 )
						ㄴ 지시자 : http://httpd.apache.org/docs/2.4/mod/directives.html 참조.


				ㅇ 아파치 톰캣 연동
					ㅡ http://tomcat.apache.org/connectors-doc/, https://tomcat.apache.org/connectors-doc/webserver_howto/apache.html 참조

					ㅡ 아파치의 경우 mod_jk, IIS의 경우 ISAPI redirector 등의 모듈이 존재. 이를 이용해 연동.
					ㅡ 톰캣과 다른 웹서버를 연동할 수 있는 플러그인을 제공하고 있으며, AJP라는 프로토콜을 사용하여 아파치 웹서버로 들어오는 요청을 톰캣 컨테이너에게 보낸ㄴ다.

					ㅡ worker 란?  웹서버를 대신해 서블릿이나 다른 컨텐츠들을  실행시켜주기위해 대기하고있는 톰캣 인스턴스라고 한다.
						ㄴ 일반적으로 여러개의 worker를 둔다고한다. 이유는..
							ㄴ We want different contexts to be served by different Tomcat workers to provide a development environment where all the developers share the same web server but own a Tomcat worker of their own.
							ㄴ We want different virtual hosts served by different Tomcat processes to provide a clear separation between sites belonging to different companies.
							ㄴ We want to provide load balancing, meaning run multiple Tomcat workers each on a machine of its own and distribute the requests between them.
						ㄴ worker에 대한 정의는 workers.properties라는 파일에서 설정된다.
					ㅡ 설정하기 )
						ㄴ 자동설정?? )
							ㄴ 자동적으로 톰캣연동 설정이 가능하다고 한다. 이를 Tomcat auto-configure이라고함.
							ㄴ 설정을 위해 conf.properties파일에 들어갈 명령어 => Include c:/Apache/Apache24/conf/jk/mod_jk.conf-auto
						ㄴ 커스텀 설정 )
							ㄴ 기본설정 )
								JkWorkersFile ${SRVROOT}/conf/workers.properties	=> worker가 정의된 파일을 가리켜주는 지시자.
								JkLogFile ${SRVROOT}/logs/mod_jk/mod_jk.log		=> mod_jk가 로그를 기록할 파일을 가리키는지시자
								JkLogLevel error			=> 로그 레벨설정. info : 스탠다드 로그정보, error : 에러기록, debug : 모든 정보.
								JkLogStampFormat "[%y-%m-%d %H:%M:%S.%Q]"	=> 로그기록할때 시간기록 형식 설정하는 지시자

							ㄴ??? forwarding 옵션들 )
								ㄴ forwarding과 관련된 여러 옵션들을 설정 할 수 있다.
								ㄴ JkOption +ForwardURIProxy
								ㄴ JkOption +ForwardURICompat
								ㄴ 등등..
							ㄴ 톰캣으로 보낼 uri 할당 )
								ㄴ JkMount (*uri prefix*) (*worker이름*)
								ㄴ uriworkermap.properties 설정할때와 비슷한 형식.
							ㄴ 아파치 서버가 처리할 파일들 설정 )
								ㄴ JkUnMount 지시자를 통해 톰캣이 아닌 아파치 서버가 처리할 파일들(보통 static파일들)을 설정해줄수있다.
								ㄴ JkUnMount 형식은 JkMount와 같다.
								ㄴ 보안상의 이유로 일단 모든 url을 JkMount로 설정하고 JkUnMount로 제외시켜주는 방식을 사용하라한다.
							ㄴ Alias, no-jk, JkAutoAlias 등등..
						ㄴ ???mod_jk 빌드 )
							ㄴ ...
					ㅡ workers.properties configuration파일 )
						ㄴ mod_jk의 worker에 대해 정의하는 파일로, 필수적으로 잇어야 하는 파일이다.
						ㄴ 기본 )
							ㄴ (*이름*)  = (*값*) 형태
							ㄴ 주석은 해쉬태그 #
						ㄴ http://tomcat.apache.org/connectors-doc/reference/workers.html
							ㄴ 위링크에 자세한 프로퍼티들이 나와있음.
							ㄴ 대략 worker.list 로 worker인스턴스를 선언?하고, 이에 해당하는 directive들을 설정하여 worker를 설정하는방식.
						ㄴ ex)
							worker.list= worker1 =>worker1이란 워커 선언
							worker.worker1.type=ajp13	=>아래로쭉 worker1에 대한 directive들을 설정하고 있다.
							worker.worker1.port=8009
							worker.worker1.socket_timeout=180
							worker.worker1.reply_timeout=180000
					ㅡ uriworkermap.properties 파일)
						ㄴ 기억하던대로, 어떤 uri요청이들어오면 처리를 넘겨줄지 설정하는 파일이다.
						ㄴ http://tomcat.apache.org/connectors-doc/reference/uriworkermap.html
						ㄴ 아파치에선 conf.properties파일 안에서 JkMount 지시자를 통하여 설정하여도 된다.
					ㅡ ??? status worker )
						ㄴ 요청을 forward하는 기능이 아닌 런타임시에, configuation정보나 상태를 가져오거나 이를 동적으로 변경하는 기능을 한다함.


			</pre>

			ㄴ Nginx server<button>more</button>
			<pre>
				ㄴ ~~~~~
				ㄴ 설정 파일<button>more</button>
				<pre>
					ㄴ 주석 ) '#' 뒤로 오는 내용은 주석 취급.
					ㄴ
					ㄴ ex )<button>more</button>
					<pre>
						user  nginx;
						worker_processes  auto;

						error_log  /var/log/nginx/error.log notice;
						pid        /var/run/nginx.pid;

						events {
							worker_connections  1024;
						}

						http {
							include       /etc/nginx/mime.types;
							default_type  application/octet-stream;

							log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
											'$status $body_bytes_sent "$http_referer" '
											'"$http_user_agent" "$http_x_forwarded_for"';

							access_log  /var/log/nginx/access.log  main;

							sendfile        on;
							#tcp_nopush     on;

							keepalive_timeout  65;

							#gzip  on;

							include /etc/nginx/conf.d/*.conf;  # 해당 위치의 *.conf 형태의 파일을 모두 이 위치에 포함시킴.

							server {  # server directive. 하나의 가상 서버에 대한 설정을 나타냄.
									# nginx 서버가 어느 포트를 listening할지. 'default_server' 입력시, 가상서버들 중 request와 매칭되는 서버가 없을시 이 디폴트 서버가 요청을 처리.
									listen 80 default_server;
									server_name divlab.io;  # ???해당 ip로 들어온 request가 어떤 도메인명을 타고 왔는지를 체크하여 여기에 명시된 도메인인 경우 매핑시킨다.

									# location = /favicon.ico {
									#         access_log off; log_not_found off; }

									location /static {  # url이 '/static' 형태로 들어올 시, 응답을 어느 위치에서 찾아서 반환해줄지 설정.
											alias /opt/deepqapps/static;
									}

									# location /adm {
									#       alias /opt/branddesign/bdak/media/adm/data;
									# }

									# location /media {
									#       alias /opt/branddesign/bdak/media;
									# }

									# location / {
									#       proxy_set_header Host $http_host;
									#         proxy_set_header X-Real-IP $remote_addr;
									#         proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
									#         proxy_set_header X-Forwarded-Proto $scheme;
									#         proxy_pass http://unix:/tmp/gunicorn.sock;
									# }

									location / {  # url이 일치하는게 없으면 이 기본형 '/'에 매핑된다.
											proxy_pass http://divlab.io:8888;  # 프록시 설정. 여기에 매핑된 요청을 해당 주소로 보내준다.
											# 위 row제거후 이 row사용시, location에 대한 요청 들어오면 해당 url로 리다이렉트시킴.
											# $request_uri는 url뒤의 모든 인자 포함.
											#return 301 https://divlab.io$request_uri
									}
							}
							server {
								listen 443 ssl;  #
								server_name bbdlab.kr;

								ssl_certificate /etc/nginx/chain.crt;  # 도메인 인증서-체인인증서-루트인증서의 결합파일.
								ssl_certificate_key /etc/nginx/www_bbdlab.kr.key;  # 인증서 신청 때 생성한 crs와 같이 나온 개인키. (암호화 해제되어 있어야 한다)

								#ssl_session_cache shared:SSL:1m;  # ???
								#ssl_session_timeout 5m;  # ???

								#ssl_ciphers HIGH:MEDIUM:!SSLv2:!PSK:!SRP:!ADH:!AECDH;
								ssl_prefer_server_ciphers on;

								location / {
										proxy_pass http://127.0.0.1:8000;
								}
								error_page 500 502 503 504 /50x.html;
								location = /50x.html {
										root /usr/share/nginx/html;
								}
							}
						}
					</pre>
					ㄴ request와 가상서버 매핑 방식
						ㄴ request의 header의 'host'만을 보고 이 요청을 처리할 가상서버 결정.
						ㄴ host의 ip, port를 먼저 보고 매칭되는 가상 서버를 찾고 그 다음 server_name을 매칭시킴.
						ㄴ ~~~
						ㄴ http://nginx.org/en/docs/http/request_processing.html 참고.
						ㄴ listen 지시자 오른쪽에 'default_server' 입력시 해당 포트에 대해 매핑 실패시 이 디폴트 서버로 매핑.
							ㄴ ex ) listen 80 default_server;
							ㄴ 명시적 default_server 없을시, 맨 위의 설정값이 디폴트서버가 됨.

					ㄴ server_name
						ㄴ http://nginx.org/en/docs/http/server_names.html 참고.
					ㄴ ssl 설정<button>more</button>
					<pre>
						ㄴ 필요한 파일은 'ssl_certificate', 'ssl_certificate_key' 속성에 경로를 넘겨줄 두개의 파일.
							인증서 파일과 개인키
						ㄴ 개인키는 인증서 신청시 csr파일과 함께 만들어진 개인키를 말함.
						ㄴ 인증키 파일은 '도메인 인증서' - '체인 인증서' - '루트 인증서' 순서로 구성되어야 한다.
							ㄴ ??? 순서는 인증서 종류?마다 다른 것 같다.
							ㄴ 대략 형식이 다음과 같은데
								-----------BEGIN CERTIFICATE------------
								IIDdTCCAl2gAwIBAgILBAAAAAABFUtaw5QwDQYJKoZIhvcNAQEFBQAwVzELMAkG
								A1UEBhMCQkUxGTAXBgNVBAoTEEdsb2JhbFNpZ24gbnYtc2ExEDAOBgNVBAsTB1Jv
								b3QgQ0ExGzAZBgNVBAMTEkd~~~~~~~~
								-----------END CERTIFICATE--------------
								-----------BEGIN CERTIFICATE------------
								MIIETTCCAzWgAwIBAgILBAAAAAABRE7wNjEwDQYJKoZIhvcNAQELBQAwVzELMAkG
								A1UEBhMCQkUxGTAXBgNVBAoTEEdsb2JhbFNpZ24gbnYtc2ExEDAOBgNVBAsTB1Jv
								b3QgQ0ExGzAZBgNVBAMTEkdsb2Jhb~~~~~~~~~~
								-----------END CERTIFICATE--------------
							ㄴ  -----------END CERTIFICATE--------------
								-----------BEGIN CERTIFICATE------------
								위 부분이 다음과 같이 옆으로 붙어있거나
								-----------END CERTIFICATE-------------------------BEGIN CERTIFICATE------------
								다음과 같이 한 줄 떨어져 있지 않도록 주의해야함.
								-----------END CERTIFICATE--------------

								-----------BEGIN CERTIFICATE------------
						ㄴ ssl 인증서 신청. 인증서 파일 및 개인키 확보 )
							ㄴ ssl서비스를 가비아 등의 업체에서 구매하고 필요한 정보를 전달하여 신청, 인증서 발급 과정을 통해
								ssl설정에 필요한 인증서파일, 개인키 등을 얻을 수 있다.
							ㄴ 이 인증서 파일들은 가비아 등 ssl 업체에 인증서를 구매 및 신청하여 받을 수 있다.
							ㄴ 신청 방법이나 전달받을 인증서 파일들의 형태는 업체별로 상이하다. 각각 확인 필요.
							ㄴ 대략 공통적으로 아주 간략하게 다음의 과정으로 진행된다.
								1. csr, 개인키를 생성하여 ssl 인증 업체에 전달하여 신청,
								2. 인증 업체에서 인증서 파일들을 반환.
								ㄴ 1번은 서버에서 openssl등의 명령어로 직접 생성할 수도, 업체 사이트에서 form으로 입력할 수도 있다.
								ㄴ 1번 csr 생성시 대략 다음의 정보를 입력하여 csr파일을 생성한다.
									Country Name ( 국가코드) [] : KR
									State or Province Name ( 지역 ) [] : Seoul
									Locality Name ( 시/군/구 ) [] : Seocho
									Organization Name ( 회사명 ) [] : 회사명 Inc
									Organizational Unit Name ( 부서명 ) [] : Develop Team
									Common Name ( 서비스도메인명 ) [] : www.domain.com
									Email Address [] : 현재 도메인 소유자의 이메일 주소
								ㄴ 2번은 인증서 파일들이 묶음으로 올 수도, 낱게로 올 수도 있다.
							ㄴ 리눅스 서버, 가비아 신청의 예를 들자면,
								서버에서 openssl 명령어로 인증서 개인키, csr(인증서 요청파일)을 생성,
								가비아에서 ssl서비스 결재 후 위 파일들 전달하여 신청,
								가비아에서 도메인 인증서, 체인 인증서, 루트 인증서 반환.
						ㄴ SNI 설정 관련
							ㄴ nginx -V 명령어 입력시, 중간에 "TLS SNI support enabled"라는 문구 존재시, SNI 기능을 지원하는 상태.
								ㄴ 지원하지 않는다면 다음과 같은 경고문구 존재.
									nginx was built with SNI support, however, now it is linked
									dynamically to an OpenSSL library which has no tlsext support,
									therefore SNI is not available
					</pre>

					ㄴ default server 막기
						ㄴ ip로 직접 쳐서 들어오는 시나리오가 있는게 아니면
							requset가 아무 server_name과도 매칭되지 않는 경우, 보낼 디폴트 가상 서버를 설정하는게 좋다.
						ㄴ default_server를 명시적으로 설정하지 않을시, 가장 첫번째 가상서버가 default server가 되므로
							의도치 않게 해당 가상서버로 연결될 수도 있곡 헷갈리지 않게 명시적으로 설정하는게 좋다.
						ㄴ 아무런 서버로 매칭시키지 않고 리젝하려면
							server {
								listen 80 default_server;
								server_name _;
								return 444;
							}
							이런식으로 default_server로서 요청을 받게하고 에러를 반환하면됨.
						ㄴ ssl 디폴트의 경우도 마찬가지. 단, ssl server이면 인증서 설정이 필수로 되어야하므로
							openssl 명령어 등으로 임시로 하나 만들어 설정할 수 있도록.
							server {
								listen 443 default_server ssl;
								server_name _;

								ssl_certificate /etc/nginx/temp_ssl.crt;
								ssl_certificate_key /etc/nginx/temp_ssl.key;

								return 444;
							}
						ㄴ

				</pre>

				ㄴ gunicorn 연동<button>more</button>
				<pre>
					ㄴ ~~~~~
					ㄴ nginx에서 프록시 설정으로 요청을 gunicorn 포트로 넘겨줌으로서 연동.
					ㄴ
				</pre>

			</pre>

			* WSGI, python web server gateway interface
				ㅡ 웹 서버와 파이썬 어플리케이션(또는 파이선 프레임워크)간의 커뮤니케이션, 호출을 어떻게 하는지
					그 방식에 대한 협약, 관례, 정의된 스펙이다.
					ㄴ 배경 )
						ㄴ 이전에는 파이썬의 프레임워크들이 각각 특정 웹 서버를 사용해야 해서 프레임워크와
							웹 서버 선택에 있어서 제약이 존재.
						ㄴ 자바의 servlet과 같이 서버와 프레임워크 사이에 스펙을 정의하여 이를 준수하는
							웹 서버와 프레임워크는 서로 제약 없이 어느 것을 선택하더라도 사용이 가능하도록
					ㄴ 웹 서버로부터 요청을 받아서 파이썬 어플리케이션에 전달해 주는 미들웨어에 대한 스펙.
				ㅡ 파이선 표준 WSGI에 대해서는 공홈의 'PEP 3333'에 자세히 나와있다.
			* CGI, WAS, Servlet 등..<button>more</button>
			<pre>
				ㅡ 모두 웹 서버로 들어온 요처에 대해 동적인 결과물을 반환해 주기 위한 기술이다?
				ㅡ CGI, Common Gateway Interface 
					ㄴ ~~~~~
					ㄴ 서버가 동적인 결과를 위해 외부 프로그램을 실행해야 하는데, 이 때, 이 외부 프로그램을
						실행하고 데이터를 넘겨주고 하는 '서버와 외부 프로그램간의 커뮤니케이션 방식'에 대해
						스펙을 정한 것.
						서버가 받은 요청의 추가 데이터를 어떤 방식으로 외부 프로그램에 넘겨줄지에 대한 협약.
						ㄴ 가령, 'http get메소드 요청에서 url 뒤에 오는 쿼리스트링은 'QUERY_STRING'환경변수에
							저장해둔다' 등. 이렇게 정해 두면 외부 프로그램은 정해진 곳에서 데이터를 찾으면 되므로.
						ㄴ 그 전에는 서버마다 다른 방식으로 커뮤니케이션을 하여 서버에 따라 공통적으로 실행 가능한
							프로그램을 개발하기 어려웠다함.
					ㄴ 이슈
						ㄴ 초기의 CGI프로그램들(cgi를 따르는 프로그램들)은 웹 서버의 'security context'??? 안에서 실행되었는데,
						이로 인해 유저 인풋값을 제대로 보안 처리하지 못 할 경우 악성 명령어가 웹 서버에서 그대로
						실행된다는 문제점이 있었다.
						ㄴ 하여, 웹 서버에서 새로운 프로세스를 생성하여 cgi프로그램을 실행시키고 처리가 끝나면
							프로세스를 죽이는 방식으로 변경되었다.
						ㄴ 새 프로세스를 생성하고 죽이는 방식 때문에, cgi프로그램은 필요 이상의 cpu와 메모리를
							할애하였고, request가 많아지면 쉽게 과부하에 걸렸었다.
						ㄴ 다음과 같은 방법으로 보완하였다고 한다.
							ㄴ ~~~~~ https://en.wikipedia.org/wiki/Common_Gateway_Interface#Using_CGI_scripts
			</pre>
			ㄴ Gunicorn 
				ㄴ unix에서 사용 가능한 WSGI server. 
				ㄴ 구조 
					ㄴ 'pre-fork worker model'
					ㄴ 하나의 master process 시작, 이 프로세서가 'worker'로서 child process 생성. request가 들어오기 전에 미리 worker process들을 만들어둚(pre-forked) 
					ㄴ master process의 역할은 worker proces들의 수가 설정된 개수만큼 유지되는 것. 
						중간에 worker process가 죽으면 새로운 worker process를 생성. 
					ㄴ worker process의 역할은 요청을 받아서 처리하는 것.
					ㄴ master process 
						ㄴ worker process들을 관리하는 프로세스. 
						ㄴ 자식 프로세스들이 보내는 신호를 받고, 이에 대해 적절한 처리를 하는 로직에 대해 루프를 돌고있는 프로세스. 
							ㄴ 자식 프로세스들은 TTIN, TTOU, CHLD 등의 시그널을 보냄. 
							ㄴ 이에 따라 적절히 worker의 수를 늘리거나 줄이거나 재시작시킴. 
					ㄴ worker class
						ㄴ worker의 유형 의미. 
						ㄴ 목록 
							ㄴ sync worker 
								ㄴ 한번에 하나의 request를 처리하는 유형. 
								ㄴ ??? 영구적 connection을 지원안함? response 보낸 후 연결 끊음. 
				ㄴ ~~~ 
				ㄴ configuration 
					ㄴ 우선순위에 따라 여러 곳으로부터 설정값 읽어들임. 
						ㄴ 1. command line arguments
						ㄴ 2. 
						ㄴ configuration file 
							ㄴ 설정 파일을 따로 만들고 이 안의 내용을 설정값으로 적용. 
							ㄴ 'gunicorn.conf.py'라는 이름의 파일. 파이선 소스파일. 
							ㄴ ??? module path 위에 있을 필요 없다? 
							ㄴ read만 가능하면 됨. 
							ㄴ 특별한 문법 없이, 파일 내에 설정값을 변수로 선언하면 gunicorn이 이를 적용한다. 
							ㄴ gunicorn command line 옵션으로 설정 파일을 지정 가능. 
					ㄴ 설정 목록 
						ㄴ config 
							ㄴ --config (*파일 path*)
							ㄴ 
						ㄴ ~~~

						ㄴ workers 
							ㄴ??? worker process의 수.
							ㄴ default는 1.
							ㄴ 권장값은 (2 * core수) + 1 
								ㄴ??? 동시에 처리하는 request의 수가 (2* core수)+1 인게 권장인 것. 
									따라서, threads를 사용하는거면 threads의 수와 workers의 수가 합쳐서 (2*core수)+1이 되는걸 권장한다함. 
							ㄴ ??? gunicorn은 몇백, 몇천개의 request 처리에 4~12개의 worker만 있으면 된다? 
						ㄴ threads 
							ㄴ ??? worker process당 thread의 수. 
								각 worker process들이 메모리를 공유하며 여러 스레드들을 생성하여 처리. 
						ㄴ timeout 
							ㄴ --timeout (*int값*) 
							ㄴ 디폴트 30 
							ㄴ ??? worker silent?를 이 설정값 초만큼 기다림. 초과시 worker를 죽이고 재시작. 
								ㄴ request를 받은 뒤 이 시간동안 응답을 완료하지 않은 worker를 죽인다함. 
							ㄴ 0으로 설정시 무기한 취급. 즉 worker silent를 무기한 대기함. 
						ㄴ keepalive 
							ㄴ --keep-alive (*int값*)
							ㄴ 디폴트 2
							ㄴ ??? keep-alive connection에서 request를 기다릴 시간 (초) 설정. ??? keep-alive connection? 
						ㄴ ~~~
				ㄴ 참고 
					ㄴ https://docs.gunicorn.org/en/stable/index.html
					ㄴ https://guidebook.devops.uis.cam.ac.uk/notes/gunicorn-tuning/
					ㄴ https://loadforge.com/guides/deploying-flask-applications-with-gunicorn-and-nginx-for-scalability	

		</pre>

		Servlet<button>더보기</button>
		<pre>
			기본<button>더보기</button>
			<pre>
				ㅇ 서블릿이란?
					ㅡ 웹 어플리케이션(동적 웹페이지를 만드는데 쓰이는 프로그램)을 프로그래밍하는데 쓰이는 기술을 말함.
					ㅡ '서블릿 클래스'라고하는 클래스를 이용하여 프로그래밍을 하며
					ㅡ 핵심문법은 다음과같다.
						ㄴ 서블릿 클래스는 javax.servlet 패키지의 Servlet인터페이스를 구현해야한다.(보통 편의를 위해 이를구현하는 javax.servlet.http.HttpServlet클래스를상속)
						ㄴ 서블릿 클래스안에 doGet()또는 doPost()메소드를 선언하고 이 안에 클래스가 호출되었을때 할일을 정의해야한다. 이 두 메소드는 두개의 인자를받아야하는데 첫번째는
							javax.servlet.http.HttpservletRequest, 두번째는 javax.servlet.http.HttpServletResponse이다. 예외처리또한 java.io.IOException과
							javax.servlet.ServletException을 던져야한다.
						ㄴ 위 두 메소드의 두번째 인자에 대해 getWriter()를 호출하면 PrintWriter라는 스트림 객체가 반환되고 이 객체에 대해 print,println등을 사용하여 웹브라우저로
							html코드를 출력시킨다. 이런식으로 동적페이지를 브라우저에 반환한다.
					ㅡ 서블릿 클래스는 일반자바와 똑같이 javac.exe에 의해 컴파일 되며 컴파일결과물은 웹서버의 폴더에 저장해야한다. 그리고 웹서버에 url과함게 서블릿 클래스를 등록하고나면
						후에 웹브라우저로부터 url이 전달되면 서버는 그에 해당하는 서블릿 클래스를 호출한다.
					ㅡ "서블릿 클래스" --(인스턴스화)--> "서블릿 객체" --(초기화)--> "서블릿"
						ㄴ 위순서로 진행되며, 인스턴스화와 초기화는 웹컨테이너가 자동으로 처리해준다.

				* CGI, Common Gateway interface
					ㅡ 개요 )
						ㄴ 서블릿 이전에 동적 웹 컨텐츠를 만들기위해 쓰이던 기술.
						ㄴ 이 기술을 통해 웹서버가 특정 요청들을 외부의 프로그램으로 전달하게 되고, 그 프로그램의 결과값은 클라이언트로 보내지게된다.
					ㅡ CGI는 좋지않은 라이프 사이클을 가지고 있다고한다.
						ㄴ 웹서버가 CGI로 보내져야하는 요청을 받으면 새로운 프로세스를 생성하여 CGI프로그램을 돌려야 한다함.
						ㄴ 모든 요청에 대한 이러한 과정은 당연히 자원을 많이먹어 부하가큼.
						ㄴ 또한 별개의 프로세스를 사용하기때문에 웹서버와 상호작용이 불가하다함.
					ㅡ FastCGI
					ㅡ ...

				ㅇ 서블릿 장단점
					ㅡ 장점)
						ㄴ 자바로 만들엇기때문에 자바의 장점인 '이식성'
							ㄴ 자바로 만들었기때문에 jvm위에서 동작하며,
							ㄴ 다른 CGI와 달리 매번 새 프로세스를 생성하는게 아니라 jvm위에서 쓰레드를 생성하여 처리하기때문에 부학 적다.
							ㄴ portable하다한다. os에 관계없이 대부분의 웹서버에서 지원을 한다함.
						ㄴ 네트워크 보안 용이
						ㄴ 프로그래밍 언어 수준의 '멀티스레드 지원'
					ㅡ 단점)
						ㄴ print를 이용해 html코드를 만들어야해서 매우복잡하고 이해도 어렵고 유지보수도 어렵고 디자이너와의 협업도 어려움.

				ㅇ 서브릿의 멀티스레드/ 싱글스레드
					ㅡ 서버는 여러 사용자로부터 동시에 요청을 받을수있고 이를 처리하기위한 방법으로 멀티/싱글 스레드 모델이 있다.
					ㅡ 멀티스레드 모델)
						ㄴ 서블릿 클래스가 서블릿을 단 하나 만들며,
						ㄴ 멀티스레드를 이용해 요청들을 처리.
						ㄴ 멀티스레드이므로 데이터충돌이 일어날수있지만 서블릿이 하나이기때문에 시스템자원과메모리효율이 좋다.
						ㄴ 멀티스레드이므로 이 모델에서 서블릿클래스에 멤버변수 사용 지양.
					ㅡ 싱글 스래드 모델)
						ㄴ 서블릿 클래스가 서블릿을 여러개 만듦.
						ㄴ 따라서 스레드는 하나면되고 각각의 서블릿들이 각자의 요청들을 처리.
						ㄴ 멀티스레드모델의 장단점의 반대이면서,
						ㄴ 사용자가 늘어날수록 단점이 너무 심각해져 현재 폐용화.

				ㅇ 서블릿 클래스 상속구조
					<img src="image/서블릿 클래스 상속구조.png" style="height:300px; width:auto;">

				ㅇ 서블릿 클래스 만들기
					import javax.servlet.http.*;
					import javax.servlet.*;
					import java.io.*;	=>필요한 클래스, 인스턴스들을 가져와준다.

					public class (*서블릿클래스이름*) extends HttpServlet {		=>웹컨테이너가 요청에따라 메소드를 호출할수있게 public으로 선언. 그리고 서블릿클래스는
																				앞에나온대로 HttpServlet을 상속해줌.
						public void do(*Get 또는 Post*)(HttpServletRequest (*변수명.request*), HttpServletResponse (*변수명.response*))
																							=>doGet이나 doPost중 하나를	오버라이딩해야하며, 매개변수형식도 지켜야함.
							throws ServletException, IOException {		=> 던져야하는예외들도 지켜야함.
							~~~
							(*서블릿에서 실행할내용들*)	=>메소드 내용들로 서블릿이 호출되었을때 할 작업들을 작성해주고.
							~~~
							PrintWriter (*변수명.out*) = response.getWriter();	=> 앞서나온내용대로 PrintWriter 객체를 받아 html코드를 출력해 브라우저로 반환해줌.
							out.println("< html>");
							~~~~
						}
					}

				ㅇ 서블릿 클래스 컴파일하기
					ㅡ javac으로 그냥 컴파일하면되는데 코드에서 사용된 import된것들은 표준라이브러리에 없는것들이므로 추가해주어야한다.(tomcat에 jsp-api.jar, servlet-api.jar에 들어있다)
					ㅡ 방법1)
						ㄴ 이클립스에서 프로젝트명 오른쪽클릭 - Properties - Java Build Path - Libraries - 'Add External JARs' - tomcat폴더에 lib에있는 위 jar들 추가.
					ㅡ 방법2)
						ㄴ jdk에서 외부라이브러리들을 저장하는곳인 jdk - jre - lib - ext 폴더에 해당 jar들을 복사해줌.
					ㅡ 방법3)
						ㄴ javac 명령어입력시 옵션으로 -cp를 주어 라이브러리 경로를 전달해줌.

				ㅇ 서블릿 클래스 설치하기
					ㅡ tomcat을 이용
					ㅡ webapps폴더 안에 'WEB-INF'라는 이름의 폴더를 만들고 그안에 'classes'라는 폴더를 만들고 이곳에 서블릿 클래스파일을 저장하면된다.

				ㅇ 서블릿 클래스 등록하기
					ㅡ 서블릿은 jsp와 달리 파일을 폴더에 갖다놓기만하면되는게 아니고 따로 '등록'의 과정을 거쳐야 사용할수있다.
					ㅡ 웹 어플리케이션의 DD(deployment descipter)라는 파일에 등록을하는데 WEB-INF폴더 안에 'web.xml'이란 파일로 위치와이름이 정해져있다.
						이 파일을 위 정확한 위치에 생성하고 작성하고 서블릿을 그 안에 등록해야 등록이 완료된다.
					ㅡ xml파일만들기)

						< web-app xmlns = " (*파일작성에 사용된 문법의식별자*) " version = "(*버전정보*) ">	=>< web-app>은 html파일의 < html>같은것. 루트엘리먼트.
																									=>잘모르겟지만 xmlns와 version 속성은 필수라한다.
							< servlet>
								< servlet-name> (*이름a*) < /servlet-name>	=>여러 서블릿들이 등록될텐데 이들을 구분하기위한 식별자역할을한다.
								< servlet-class> (*패키지명을 포함한 서블릿 클래스이름*) < /~~>
							< /servlet>
							< servlet-mapping>
								< servlet-name> (*이름a*) < /~~>	=>위에 < servlet>안에있는 < servlet-name>과 연결된다.
								< url-pattern> (*url*) < /~~>		=> 전체 url이 아닌 서버도메인, 포트, 웹 어플리케이션 폴더이름을 제외한 나머지를 입력한다.
							< /~~>
						< /web-app>

					ㅡ 대략적인 동작방식)
						ㄴ 설정해둔 url을 요청받으면 이 DD파일에서 같은 url을 찾는다.
						ㄴ 찾으면 해당 url이 있는 < url-pattern>과 같이있는 < servlet-name>의 값을 확인하고 < servlet>안에서 이와 같은 값의 < servlet-name>을 찾는다.
						ㄴ 찾은 < servlet-name>과 같이있는 < servlet-class>를 실행시킨다.
					ㅡ 새로운 서블릿을 작성하게되면 똑같은 방식으로 < servlet>, < servlet-mapping>요소를 작성해 등록하면된다.

				ㅇ 서블릿 클래스에서 한글인코딩)
					ㅡ 서블릿에서 브라우저로 페이지를 반환할때 한글을쓰려면 인코딩을 해주어야한다.
					ㅡ doGet, doPost의 매개변수 response에 대해 setContentType()을 호출하여 브라우저로 응답하는 페이지의 한글을 인코딩해준다.
					ex)	response.setContentType("text/html; charset=UTF-8");	=>text/html은 이문서의 내용이 text형이고 html문법으로 작성됨을 의미. UTF-8은 인코딩할문자셋.

				* 웹 어플리케이션 개발하기 팁)
					ㅡ 먼저화면 구성을 생각하고
					ㅡ 각각의 url을 미리정한뒤 코딩을 시작한다.

				* html의 form요소
					ㅡ < form>요소에 action속성값으로 url을 정해두면
					ㅡ < form>안에 여러값들을 입력받은뒤 < input type="submit">을 통해 값들을 해당 url로 매개변수로 붙여 요청을 보낼수있다.
					ㅡ ex)	< form action="(*url*)" method = (*GET방식 또는 POST방식*) >
								< input type="text" name="id">
								< input type="submit">	=>id란 이름의 파라미터가 요청url에 매개변수로 붙어서 전달된다.
							< /form>
					ㅡ 보낸 값들은 서블릿에서 doGet,doPost메소드의 첫번째인자 request에대해 getParameter("(*넘겨받은 값의 name속성값*) ")을 통해 가져올수있다.
					ㅡ 다양한 form 형태들)
						ㄴ < form>태그로 입력할수있는 형태는 다양하다. < input type=(*타입*)>에서 타입도 다양하고 이외에도 radio, checkbox, < select>등등.
						ㄴ 구체적으로 어떤식으로 데이터가 받아지는지 그냥 그때그때 검색해보고, 대략적으론 다음과같다.
							ㄴ name속성값이 다르면 각각의 name속성값에 해당하는 value값들이 반환되고, name속성값을 공통으로 쓰는 타입의 경우 그 입력된 값들이 모두 반환된다.

				ㅇ Get방식과 Post방식
					ㅡ 위처럼 form태그를 통해 값을 전송할때 url뒤에 붙여서 전송하면 GET방식이다.
						ex) http://mysite.com ? name = Fred & age=11 	=> 이런식으로 ?뒤에 (*name속성값*) = (*전달되는값*) 형태로 붙어서온다.
						ㄴ 정보가 url뒤에 붙어서 보이므로 보안에 취약하고
						ㄴ url의 길이에 제한이 있어 전송할데이터가 커지면 중간에 짤릴가능성이있다.
					ㅡ Post방식은 전송할 데이터를url뒤에 붙여전송하는게 아닌 서버쪽에 저장한뒤 이를 가져와 쓰는방식이다.
					ㅡ < form>태그에서 method라는 속성값으로 이 방식을 선택할수있다. 'GET'이나 'POST'를 값으로 주면된다. 디폴트는 GET이다.
					ㅡ 어떤 방식을 사용한 요청이냐에따라 서블릿에서 doGet()이호출될지, doPost()가 호출될지 결정된다.
					ㅡ Post방식의 경우 데이터를 서버에서 가져오는것이므로 이 과정에서 한글이 깨질수있으므로 doGet,doPost의 첫번재인자 request에 대해 setCharacterEncoding("(*글자셋*)")을호출.
					ㅡ GET방식의 경우 url뒤에 붙어오는 한글인자를 post방식처럼 인코딩해주지못하므로 다름방법사용.
						ㄴ tomcat폴더에서 conf - server.xml에 들어가서 port속성값이 8080인 < connector>요소에다가 URIEncoding = (*글자셋*) 속성을 추가해준다.

				ㅇ 서블릿을 이루는 것들
					ㅡservlet 인터페이스)
						ㄴinit(), destroy(), service()메소드가 대표적으로 존재하고, 컨테이너에 의해 이 메소드들이 호출된다.
						ㄴinit()에선 인스턴스화ㅗ된 서블릿이 초기화되고, 나머진아는그대로.
					ㅡHttpServlet 추상클래스)
						ㄴ보통 서블릿을 만들면 이것을 상속해 만듧. http프로토콜을 반영하기 위해 service()를 재정의한 서블릿. 때문에 이 service()는
						http request와 http response만을 인자로 받는다
						ㄴdoGet(), doPost(), doDelete(), doPut(), service()등의 메소드가 존재하고 추상클래스이므로 이들중 하나를 오버라이딩해야함.
						ㄴ하지만 이 메소드중 하나인 public void service()는 request를 protected void service()로 보내주고 여기서는
						해당 request의 타입에 맞게 doGet,doPost()등의 메소드로 request를 보내주는 기능을 하므로  이 두 service()는 오버라이딩할 필요가 없다.
					ㅡGernericServlet 추상클래스)
						ㄴ프로토콜 독립적인 서블릿클래스로, Servlet인터페이스를 구현하며 HttpServlet 추상클래스의 부모클래스이다.

				ㅇ 서블릿 라이프 사이클
					<img src="image/서블릿 라이프사이클.jpg" style="height:800px; width:auto;">
					ㅡ 초기화시 init()호출, 웹브라우저의 호출, 작업시 service()호출, 폐기시 destroy()를 호출한다.
					ㅡ여러 요청이 들어온다고 서블릿을 여러개 인스턴스화 하는게 아니라 하나만 인스턴스화해놓고, 스레드를 새로만들어서 요청마다 사용하는식이다.
					ㅡ서블릿 클래스를 인스턴스화하고 init()을 호출하는과정까지가 '로딩'이라하고 init()수행하는게 '초기화'라고함. 최초 요청 전에 서블릿은
						항상 로딩되고 초기화된다고함.
					ㅡ서블릿 인스턴스화는 그냥 '객체'가 되기만했을뿐이고 init()를 통해 여러가지 서블릿으로서의 권한, 기능 등을 부여받아야 '서블릿'이 되는것이다.
						ex) ServeltContext를 통해 dispatch를한다던지 log를쓸수있다던지 등의 권한,기능.
					ㅡ init()또한 service()처럼 두종류가있다. ServletConfig객체를 넘겨주는것과 없는것. 인자를넘겨주는 init()는 컨테이너가
						인자를 넘겨주며 호출하며, 이 메소드안에서 인자가 없는init()를 호출하게된다. 개발자가 오버라이딩하는 메소드도 인자가 없는 init()이다

			</pre>
			요청,응답과 페이지 전환<button>더보기</button>
			<pre>
				* HTTP 응답
					HTTP/1.1 ~~				=>시작행 : 응답결과가 정상인지 에러인지, 어떤에러인지에 대한 정보를담고있다.
					Server : Apache ~~		}
					(*이름*) : (*값*)			}	=> 헤더 : 여러가지 정보를 담고있다. (쿠키라던가 )
					~~~					}

					< HTML>					=> 바디 : 출력할 html문서 본문이 온다.
						~~~


				ㅇ 서블릿 요청과 응답
					ㅡ 응답으로 무얼전송하나)
						response로 html파일을 보내고 싶으면 HttpServletResponse의 getWriter()로 PrintWriter객체 받아서 출력하면 그내용이
						http 응답에서 body부분에 씌여전송되며, 바이너리 파일을 보내고싶으면 HttpServletResponse의 getOutputStream()으로
						ServletOutputStream객체 얻어서 이걸로  출력하면 http응답에 html페이지가 아닌 파일이 전송되게 됨.
						즉, response에 html페이지만 전송하는것은 아니며, 웹에서 파일다운받는것을 이런식으로 할수도 있다. (그냥 WAS없이 링크를 걸어서
						서버에서 바로 보내주는게 간단하긴하지만)
					ㅡ 응답의 헤더에 값을 설정할수있다.
						ㄴsetHeader("(*헤더이름*)", "(*값*)") : 헤더 이름과 값을 추가합니다. 같은이름이 있으면 해당 값을 대체합니다.
						ㄴaddHeader("(*헤더이름*)", "(*값*)") : 헤더 이름과 값을 추가합니다. 같은이름이 있으면 해당 이름에 값을 하나더 추가합니다.
						ㄴex) setContentType("text/html") == setHeader("content-Type", "text/html" ==> 둘다 완전똑같은 의미.
							헤더에 contentType항목에 text/html값을 추가하는기능.
					ㅡ요청에 대한 응답을 누가할지 정할수 있다. 리다이렉트(redirect)와 디스패치(dispatch)방법이있다.
						ㄴredirect)
							ㄴ대표적으로 sendRedirect(" (*url*) ")
								ㄴ 인자로 넘긴 url로 서버에 웹자원을 다시요청하라는 명령을 브라우저에게 보내는 메소드.
								ㄴ 이 메소드가 실행되면 기존 url이 지워지고 다시요청한 url로 대체되며, 브라우저에 히스토리에도 남지않는다.
								ㄴsendRedirect("(*url*)")에서 url부분은 상대경로 지정이 가능하며 이경우, 컨테이너가 알아서 webapp의 디렉터리 경로를
								추가한다. 단, url이 '/'로 시작할경우 webapp까지만의 경로를 추가하는것으로 재작성한다.
								ㄴ이 메소드는 response에 쓰기작업을 하는것과 동시에 될수없다. 응답메세지에 데이터가 보내지면서 다른 url로 이동하라고 할수는
								없다는것. 때문에 html페이지 쓰기 등의 작업이 있어선안된다.
						ㄴdispatch)
							ㄴ서블릿 상에서 바로 다른 웹컴포넌트로 제어를 넘기는 방식.
							ㄴ대표적으로 forward(). forward()는 POST방식으로 넘겨줌.

				ㅇ forward()
					ㅡ 개요) 한 페이지안에서 다른 페이지 호출하는 기능을한다.
					ㅡ 기본)
						ㄴ javax.servlet.RequestDispatcher 인터페이스에 들어있는 메소드이다. 이 객체를 생성해야 호출가능하다.
						ㄴ 이 객체는 꼭 request의 getRequestDispatcher(" (*이동할페이지url*) ")을 통해 얻어야한다.
						ㄴ 위 getRequestDispatcher() 호출시 인자넘길때, '/'로 시작하면 현재디렉토리가아닌 웹어플리케이션 디렉토리부터 시작한다.
						ㄴ forward()의 인자는 첫번째가 request, 두번째가 response이다. ex) forward(request, response);
					ㅡ 동작 방식)
						ㄴ 메소드를 호출하는 페이지의 request를 이동할 페이지의 request로 전달하며 페이지를 불러온다. 요청을 다른페이지로 넘긴다고보면된다.
						ㄴ 이동된 페이지로 제어흐름이 넘어가며 메소드를 호출한페이지로 다시돌아오지않는다.
					ㅡ ex)
						RequestDispatcher dispatcher = request.getRequestDispatcher("/home");
						dispatcher.forward(request,response);
					ㅡ 추가사항)
						ㄴ 서버에서 직접 호출하는것이므로 sendRedirect()와 달리 같은 서버의 디렉토리 안에서만 자원을 호출할수있다.

				ㅇ include()
					ㅡ forward()와 비슷한 기능을 한다. 다른점은 이동한 페이지를 실행후, 제어흐름이 다시 메소드를 호출한 페이지로 돌아온다.
					ㅡ forward()와 같이 RequestDispatcher인터페이스에 정의된 메소드이고 사용법도 같다.
					ㅡ jsp의 include 지시자와 결과가 유사하나, 동장방식이 다르다고한다.
						ㄴ


			</pre>
			주요 객체들과 메소드들<button>더보기</button>
			<pre>
				ㅇ Scope 영역
					ㅡ 개요)
						서블릿에서 사용되는 객체들은(원래있는 객체든 정의한객체든) 정해진 영역 안에서만 사용이 가능하다. 이를 객체의 스코프라고하며, 4가지 영역이 있다.

					1. page영역)
						ㅡ 하나의 request에 대해 대응되는 하나의 jsp에 해당하는 영역. pageContext에 해당한다.
					2. request 영역)
						ㅡ 하나의 요청을 처리하는데 쓰이는 모든 웹 컴포넌트에 해당하는 영역.( forward()나 include()등을 사용시 요청을 그대로 넘겨주기때문에 해당 요청에 대한 처리는
							계속 이어진다). HttpServletRequest 객체에 해당한다.
						ㅡ request의 setAttribute()로 저장하는 속성과 form등으로 전달되는 request parameter는 다른것이다.
					3. session 영역)
						ㅡ 하나의 세션이 생성되고 종료될때까지의 해당하는영역. 하나의 웹브라우저당 하나의세션 객체가 생성된다. HttpSession 객체에 해당한다.
					4. application 영역)
						ㅡ 하나의웹 어플리케이션 전ㄴ체 영역에 해당한다. 하나의 클라이언트에 대한 영역인 세션영역가 달리 해당 웹 app에 접속하는 모든이들이 공유하는 영역.
							하나의웹app당 하나의 application 객체 생성. ServletContext 객체에 해당한다.

					ㅡ 속성 저장)
						ㄴ 각 영역에 해당하는 객체들은 '속성'들을 가질수있으며 해당 객체가 존재하는동안 사용할수잇다. 데이터 교류 목적으로 주로 쓰인다.
						ㄴ 메소드들) 형태가 모든객체들에서 대동소이하다.
							ㄴ setAttribute( "(*이름*)", (*값*) ) : 속성을 저장. (*값*)은 Object형태로 저장된다.
							ㄴ getAttribute( "(*이름*)")) : (*이름*)에 해당하는 속성 반환. Object형태로 반환되므로 사용을 위해서 형변환필요.
							ㄴ removeAttribute( "(*이름*)" ) : (*이름*)에 해당하는 속성 삭제
							ㄴ getAttributeName() 등등

				ㅇ 그 외에 주요 객체들
					ㅡ ServletConfig 인스턴스
						ㄴ서블릿 당 하나 할당.
						ㄴ서블릿의 init()의 인자로 넘어가, 초기화시 여러 정보를 서블릿으로 넘겨주기 위해 쓰이는 객체.
						ㄴServletContext에 접근하기 위해서도 사용

					ㅡ ServletContext 인스턴스
						ㄴ웹 어플리케이션당 하나 할당. AppContext라고 생각하면 좀 기억하기쉬움.
						ㄴ컨테이너와 상호작용하기위한 여러 메소드들이 정의되어있음.
						ㄴ 컨테이너에 의해 웹 어플리케이션이 배포되는 시점에서 생성된다.
						ㄴ 컨텍스트 초기화 파라미터를 가진다.

			</pre>
			세션, 쿠키<button>더보기</button>
			<pre>
				ㅡ 개요)
					페이지간의 데이터 전달을 위한 기술. 쿠키는 브라우저쪽에 데이터를 저장. 세션은 서버쪽에 저장.

				ㅇ 쿠키
					ㅡ 서버에서 브라우저로 작은 크기의 정보를 보내는 기술을 말하며, 정보는 브라우저쪽에 저장된다.
					ㅡ 세션기술과유사하게 클라이언트와 서버간에 연결유지기능을한다.
					ㅡ 브라우저가 서버로 요청을 보낼때 기본적으로 쿠키정보를 같이 보내게 된다.
					ㅡ Cookie클래스가 쿠키를 말한다.

					ㅡ 쿠키 만들기)
						ㄴ ex)	Cookie c - new Cookie( "(*쿠키이름*)", " (*쿠키값*) ");

					ㅡ 쿠키 저장하는법)
						ㄴ 생성한 쿠키를 브라우저로 보낼 response에 붙여 브라우저쪽에 저장한다.
						ㄴ ex)	response.addCookie( (*쿠키객체*) );
						ㄴ http 응답 메세지에 헤더부분에 쿠키정보가 추가되어 전달된다.

					ㅡ 쿠키 조회)
						ㄴ 브라우저로부터 전달받은 쿠키를 읽을수있다.
						ㄴ 넘어온 쿠키들중에서 특정 쿠키를 찾는 메소드는 따로 존재하지않는다. getCookie()를 통해 쿠키정보를 읽어오면 반환값은 Cookie형 배열이다.
						ㄴ Cookie객체의 getName()을 이용하여 하나씩찾아봐야한다.
						ㄴ Cookie객체의 getValue() : 쿠키값을 반환한다.
						ㄴ ex)	request.getCookie()

					ㅡ 쿠키 수정)
						ㄴ 저장과 똑같은 방식으로 하면된다. 브라우저상에 같은 이름의 쿠키가 추가되면 기존의 것을 대체한다.

					ㅡ 쿠키 삭제)
						ㄴ 쿠키 수명 : 쿠키는 수명이란것을 가지고있으며, 브라우저에 종료에 상관없이 이 값에따라 생존과 소멸이 결정된다.
						ㄴ 삭제는 이 수명값을 0으로 만드는것으로 진행된다.
						ㄴ setMaxAge( (*초단위 정수*) ) : 쿠키 객체의 메소드.

					ㅡ 쿠키 전송범위)
						ㄴ 브라우저는 서버로 url을 보낼때 url에 모든 쿠키정보를 붙여서 보낸다고했는데 특정url에 대해서만 쿠키를 보내게 설정할수있다.
						ㄴ 쿠키 객체에 대해 setPath(" (*url*) ")으로 설정가능하다. (이메소드에서 url은 webapps폴더가 시작위치이며, '/'로 시작하고 끝나야한다)
						ㄴ 해당 쿠키는 설정한 url로 요청을 보낼때만 쿠키정보가 넘어간다.
						ㄴ url뿐만 아니라 특정 서버, 도메인으로도 설정가능.

				ㅇ 세션
					ㅡ 쓰임새)
						ㄴ http프로토콜에서는 한번 요청에 대한 응답이 되면, 서버와 클라이언트간 연결이 끊긴다(stateless)
						ㄴ 로그인 등과 같이 지속적인 연결이 필요할때 이 세션기술을 이용할수있다.

					ㅡ 기본)
						ㄴ 클라이언트가 처음 요청을 할때 컨테이너는 해당클라이언트에게 고유한 세션id를 생성해주고 이를 응답을통해 전달한다.
						ㄴ 이 세션 id는 쿠키기술로 클라이언트측에 저장이되며
						ㄴ 다음번 요청시부터 이 쿠키로 저장되어있는 세션id를 같이 보내는 방식으로 서버와 클라이언트간의 연결이 지속된다.
						ㄴ 세션은 자동으로 생성되는듯함. 그냥 반환받아서 쓰는거고

					ㅡ HttpServletRequest에 대해 getSession()을 호출하면 HttpSession객체 반환(세션을 반환). 이 객체를 사용하여 다양한 세션기술들을 사용할수있다.
						ㄴ 세션에 있는 데이터들은 같은 webapps안의 폴더에 있는 웹자원끼리 공유. 이 범위안에 다른페이지에서 세션을 만들시 이미 진행중인 세션이 있을경우 기존세션을 반환해줌.
							이 외의 범위에서 세션만들면 별개의 세션반환.
					ㅡ 메소드들)
						ㄴ isNew() : session에 들어있는메소드로, 해당세션이 새로생긴것인지 아닌지 boolean반환.
						ㄴ getSession(boolean형) : 그냥 세션을 얻는 getSession()과 다르게 인자값으로 false를 넘기면 이미 존재하는 세션을 반환해주며, 없는경우 null반환.
						ㄴ setAttribute( " (*이름*)", (*값*) ), getAttribute("(*이름*)"), removeAttribute("(*이름*)"), invalidate() 등이 있다.

					ㅡ 세션 제거)
						ㄴ 사용되지 않는 세션은 서버에 남아 자원을 소모하고있기때문에 적절하게 제거되어야한다.
						ㄴ 특정 조건을 만족하는 세션은 컨테이너에 의해 비활성화라고 판한되고 제거된다.
							ㄴ 일정시간이 지남( 타임아웃)
							ㄴ 개발자가 세션객체에 대해 invalidate()를 호출
							ㄴ 어플리케이션이 다운됨( 문제가 생겨서 또는 undeploy되는 경우 )
						ㄴ 세션 타임아웃 설정하기)
							ㄴDD에 설정하며 < web-app>안에 중첩해서 정의.
								< session-config>
									< session-timeout> (*분단위 숫자*) < /session-timeout>
								< /session-config>
							ㄴ 해당 세션객체에대해 setMaxInactiveInterval( (*초단위 숫자*) ) 호출.
								ex) session.setMaxInactiveInterval(20*60);

				ㅇ url재작성
					ㅡ 세션id가 있어야 세션을 유지시킬수 있다. 세션id는 쿠키기술로 클라이언트쪽에 저장된는데 만약, 클라이언트가 쿠키기술을 막아놨다면 세션을 저장할수가 없다.
					(이런 클라이언트들은 "Set-Cookie" response 헤더부분을 무시한다). 이럴때쓰이는게 url재작성이다.
					ㅡ 이는 페이지상의 요청으로 보낼 모든 url에다가 'jsessionid'라는 세션id정보를 추가하여 세션을 유지시키는 방법이다.
						ex) < a href="http://~~~.com;jsessionid=~~~~"> 이런식으로.
						ㄴ해서 이런 링크를 눌러 요청을 보낼때마다 해당 클라이언트의 세션id가 url뒤에 따라가기때문에 세션을 유지시킬수있다.
						ㄴ 단점은 세션id가 url로 노출되기때문에 보안에 좋지않다.
					ㅡ HttpServletResponse의 encodeURL(" (*URL*) ")
						ㄴ url재작성을 편리하게해주는 메소드로서, 해당 클라이언트가 쿠키기능을 제공하는지아닌지를 판단하여 제공한다면 그냥 url부분의 경로를 반환하고
							제공하지않는다면 url끝에 세션id를 붙여서 반환해준다.
					ㅡ HttpServletResponse의 encodeRedirectURL(" (*URL*) ")
						ㄴ 페이지 redirect를 하면서 url재작성으로 세션id를 넘겨주고 싶을때 사용.
					ㅡ 부가설명)
						ㄴ url재작성 규칙은 벤더마다 다르다. 톰캣처럼 ~~;jsession=~~이런형태가 아닐수있다.
						ㄴ 정적인 페이지에선 사용이안됌.


				ㅇ 세션이동, 직렬화
					ㅡ .....<!--  p292부터 나오는 내용부분인데 아직 이해못함. 나중에정리 -->

			</pre>
			컨테이너<button>더보기</button>
			<pre>
				ㅡ컨테이너의 이점
					ㄴ통신지원)
						서블릿과 웹서버가 대화하는 방법을 API로서 제공한다. 따라서 개발자가 서버와 어떻게 통신하는지를 신경쓸 필요가없이 서블릿의 비즈니스 로직만
						신경쓰면된다.
					ㄴ라이프 사이클 관리)
						서블릿 클래스를 적절하게 로딩, 인스턴스화, 초기화하고 적절한 메소드를 호출하고 가비지컬렉션으로 제거하는등의 작업을 컨테이너가 알아서해줌.
					ㄴ 멀티스레딩 지원)
						새 요청이 들어올때마다 알아서 스레드릴 생성하여 요청을 처리해준다.
					ㄴ 선언적인 보안관리)
						잘은 모르겟지만 보안관련 내용을 직접 클래스 안에 하드코딩할 필요가없다함.
				ㅡ컨테이너 작동방식(대략)
					ㄴ요청이 들어오면 HttpServletRequest, HttpServletResponse 객체를 생성
					ㄴ 요청 메세지를 분석하여 어떤 서블릿이 필요한지 알아낸다음 스레드생성하여 해당서블릿으로 request,response객체 넘김
					ㄴ 해당 서블릿에서 service()실행하여 적절하게 doGet()이나 doPost()실행
					ㄴ 실행결과를 response에 실어서 보냄
					ㄴ request,response 객체 소멸
				ㅡ컨테이너가 요청과 서블릿을 연결하는 방법
					ㄴ 알고있는 web.xml을 이용한다. 이를 배포서술자(DD, Deployment Descriptor)라고 한다.
					ㄴ 구조를 간단히 봤을때,
						< servlet>
							< servlet-name>(*내부에서만 사용하는 이름*)< /servlet-name>
							< servlet-class>(*패키지를포함한 실제 클래스명*)< /servlet-class>
						< /servlet>
						< servlet-mapping>
							< servlet-name>...< /servlet-name>
							< url-pattern>(*클라이언트쪽에서 요청할때쓰는 서블릿이름*)< /url-pattern>
						< /servlet-mapping>
						이런식으로 url-pattern에 있는이름으로 요청이들어오면 servlet-name의 이름으로 해당 클래스를 찾아서 그 서블릿을
						실행하는 방식으로 연결된다.
					ㄴ 이점은 보안강화와 나중에 변경사항발생시 이 DD만 수정하면된다는점에서 유연성이 좋음.


			</pre>
			초기화 파라미터<button>더보기</button>
			<pre>
				ㅡ 서블릿 시작시 설장하는 값으로, c언어,자바의 고정 상수정의 비슷한거.
				5-1. 서블릿 초기화 파라미터
					ㅡ doGet(), doPost()가 request 인자를 받듯이, 서블릿도 처음에 받을수 있는 초기화 파라미터라는 인자가 있다.
					ㅡ 초기화 파라미터 설정하기 )
						DD에 입력을 하며, < servlet>요소 안에
						< init-param>
							< param-name> (*초기화 파라미터 이름*) < /param-name>
							< param-value> (*초기화 파라미터 값*) < /param-value>
						< /init-param>
						와 같이 입력을 하여 설정한다.
					ㅡ 컨테이너는 DD를 읽어(물론 이안에 초기화파라미터 정보가 있으며 같이읽는다) 서블릿당 하나씩 생성되는 ServletConfig을 만들어
						여기로 정보를 넘겨주며(물론 초기화 파라미터도 같이 넘겨진다)
					ㅡ  이후 서블릿 인스턴스를 생성하고 init()를 호출할때 이 ServletConfig객체를 넘겨준다. 당연히, init()실행후에
						초기화파라미터를 사용할수 있따.
					ㅡ 따라서 초기화파라미터를 이용하여 서블릿의 내용을 수정하려면, 서블릿을 종료했다가 다시 초기화되도록해야한다. 하지만 서버를
						종료하는것은 실제 서비스에 있으서 좋은방법이아니고 이를 위해 redeploy기능을 이용하면 되지만, 이것역시 조심해야함.
					ㅡ 파라미터 사용하기)
						ㅡ 서블릿 초기화 파라미터는 ServletConfig객체 안에있으므로 이 객체를 얻는 Servlet인터페이스의 getServletConfig()를
							사용해 객체를얻고, 이 ServletConfig객체에 대해 getInitParameter(" (*파라미터이름*) ")을 사용하여
							파라미터를 얻는다.
				5-2. 컨텍스트 초기화 파라미터
					ㅡ 서블릿 초기화 파라미터와 같은 초기화 파라미터인데, 서블릿당 하나씩 생기는 ServletConfig객체에 들어있는 초기화 파라미터가 아닌
						웹 어플리케이션당 하나씩 생성되는 ServletContext객체에 들어있는 초기화 파라미터이다.
					ㅡ 설정하기)
						DD에 서블릿 초기화파라미터와 조금 다르게 < servlet>요소와 동등한 구조상 위치에서
							< context-param>
								< param-name> (*초기화 파라미터 이름*) < /param-name>
								< param-value> (*초기화 파라미터 값*) < /param-value>
							< /context-param>
						이런 형식으로 써준다.
					ㅡ 사용방법)
						ㄴ ServletContext객체에 초기화파라미터가 존재하므로 getServletContext()를 통해(request, GenericServlet 등
							여러 객체들에서 상속되는 메소드임) ServletContext객체를 반환받아 getInitParameter(" (*파라미터이름*) ")을 사용한다.
						ㄴ 당연히 웹어플리케이션에 있는 모든 웹자원에서 사용이 가능하다.

				*J2EE?
					ㅡ java 2 enterprise edition 으로, 기업환경에서 어플리케이션을 만들기위한 기술들을 담아놓은 에디션을 말함.
					이거말고도 standard edition, micro edition 등등이 있음.
					ㅡ 이 안에 jsp, servlet, java bean 등의 기술들이 들어가있는것.
					ㅡ 해서 이 J2EE에 완벽하게 부합하는 어플리케이션 서버는 웹컨테이너뿐아니라 EJB(enterprise java bean)이 있어야
						한다함. 근데 톰켓서버는 웹컨테이너밖에없어서 완벽한 j2ee서버가 아니라고함.

			</pre>
			리스너<button>더보기</button>
			<pre>
				* 리스너란?
					ㅡ 특정한 이벤트가 발생했을때 이를 처리하는 함수나 객체를 말하며, 이벤트 핸들러 라고도 한다.
					ㅡ ex) 마우스클릭 이벤트, 종료 이벤트 등등. 서블릿에선 웹어플리케이션 배포 이벤트, 서블릿의 종료이벤트 등.
					ㅡ 서블릿/jsp환경에서는 이 환경에서의 이벤트가 존재하며, 이에 대응하는 리스너들이 존재한다.
					ㅡ 이벤트 소스 : 이벤트가 발생한 대상(근원지)를말하며, 키보드 마우스 서블릿 등을 말함.

				ㅇ 서블릿/jsp에서의 이벤트,리스너 종류
					: 웹환경에서는 서블릿의 초기화와 종료, 세션 생성,종료 각각에서 속성값 추가,변경,제거 등에 관한 이벤트들이 있다.
							ㅡ이벤트소스 ServletContext인 경우)
					ㄴServletContextListener, ServletContextEvent : 웹어플리케이셔의 시작,종료이벤트에대한것들.
					ㄴServletContextAttrubuteListener, ServletContextAttributeEvent
						:ServletContext에 속성 추가,제거,수정시 발생.
					ㅡ이벤트소스 HttpSession인 경우)
						ㄴHttpSessionListener, HttpSessionEvent : 세션의 시작,종료에관한것
						ㄴHttpSessionAttributeListener, HttpSessionBindingEvent : HttpSession에 속성 추가...에관한것
					ㅡ 이벤트 소스 ServletRequest인 경우)
						ㄴServletRequestListener, ServletRequestEvent : 클라이언트요청으로인한 ServletRequest생성,응답,제거에관한것
						ㄴServletRequestAttributeListener, ServletRequestAttributeEvent : ServletRequest에 속성 추가,제거,수정에관한것.
					ㅡ위에서 ~~Event로 끝나는 객체들에는 해당 이벤트소스를 반환해주는 메소드가 정의되어있으며, 해당이벤트 발생시 컨테이너는 이 객체들을 생성하여전달함.
						ex) ServletContextEvent안에 getServletContext().
					ㅡ 위에서 ~~Listener로 끝나는 객체들 안에는 해당이벤트 발생시 호출되는 메소드들이 선언되어있다.

				ㅇ 리스너 동작과정(간략)
					ㅡ 개발자가 리스너를 구현하고 등록해놓으면
					ㅡ 컨테이너가 관리를하다가
					ㅡ 해당이벤트 발생시 해당 리스너에게 알려줌
					ㅡ 리스너에서 해당 메소드가 실행

				ㅇ 리스너 등록방법
					ㅡweb.xml에 등록하며
					ㅡ < web-app>에 중첩해서 정의(< web-app>아래에 정의한다는말).
					ㅡ 순서는 (지켜야하는지잘모르겟지만) < filter-mapping>과 < servlet>사이에 정의.
					ㅡ 형식은
						< listener>
							< listener-class> (*리스너클래스 이름(패키지명까지)*) < /listener-class>
						< /listener>

				ㅇ ServletContextListener 인터페이스
					: 웹환경에서의 리스너중 하나.
					ㅡ 구성 메소드들)
						ㄴ public void contextInitialized(ServletContextEvent sce): 웹어플리케이션 시작시 호출.
							웹어플리케이션의 모든 필터,서블릿의 초기화 이전에 호출되는메소드.
						ㄴ public void contextDestroyed(ServletContextEvent sce): 웹 어플리케이션 종료시호출.
							웹어플리케이션의 모든 필터,서블릿 종료후에 호출되는메소드.
					ㅡ 리스너 구현 예시)
						public void contextInitialized(ServletContextEvent event){
							ServletContext context = event.getServletContext();	=>ServletContext객체를 얻음.
							String dogBreed = sc.getInitParameter("breed");		=>ServletContext객체로부터 컨텍스트초기화파라미터를 얻음.
							Dog d = new Dog(dogName);							=>저장하고자하는 Dog객체를 파라미터로부터 받은정보로 생성
							sc.setAttribute("dog", d);							=>생성한 객체를 ServletContext객체에 속성값 저장.
						}
					ㅡ  ServletContex
						ㄴ 컨텍스트가 초기화되면(웹어플리케이션이 배포되면), 컨테이너가 이를 이벤트로서 알아차리고 ServletContextEvent를 생성하여
						ㄴ SerlvetContextListener에게 전달
						ㄴ 리스너의  contextInitialized()실행.

							ㅇ 속성값들의 데이터 충돌문제
								ㅡ ServletContext, 세션 등의 객체에 저장하는 속성값들은 여러 서블릿 또는 스레드에서 접근이 가능하기때문에 데이터충돌문제를 일으킨다.
								ㅡ 때문에 동기화를 시켜주어 최대한 안전함을 보장해야함. synchronized()를 이용.
								ㅡ request객체의 속성과 지역변수만이 안전하다.
							ㅇ 개요)
								ㅡ 초기화파라미터는 xml을 이용하므로 문자열만 사용이가능한데, 문자열이 아닌 db데이터나 객체를 초기화하고싶을때 이 기능을 구현해주는 것을 리스너라한다.
								ㅡ 서블릿은 어느서블릿이 가장먼저 호출될지 보장할수없으므로 일반 자바 클래스에 리스너를 정의를한다.
							ㅇ 기능)
								ㅡ 컨텍스트가 초기화되는걸(웹어플리케이션이 배포) 알아차리고,
								ㅡ ServletContext 로부터 컨텍스트초기화 파라미터를 읽어들여 db에 이 읽어들인 검색명으로 검색을하여
								ㅡ 검색한 데이터를 객체로 '속성'에 저장한다.
								ㅡ 이후 컨텍스트가 종료되면 이를 알아차리고 db와의 연결을 끊을수 있어야한다.

								ㅡ 컨테이너는 DD를 참고하여 리스너를 실행시킨다.
							ㅇ 문법)
								ㅡ 리스너 클래스는 javax.servlet.ServletContextListener 인터페이스를 구현해야한다.
									이 인터페이스 안에는 contetInitialized(ServletContextEvent), contextDestroyed(ServletContextEvent)가있다.

			</pre>
			기타<button>더보기</button>
			<pre>
				ㅇ 서블릿에서의 오류처리
					1. try-catch문으로 catch부분에 html출력 =>구조가 기형적.
					2. try-catch문으로 catch부분에 forward()사용.
					3. DD를 이용한 오류처리.
						ㄴ DD에 오류와 해당오류에 짝지어진 url을 등록하여 해당오류발생시 짝지어진 url로 이동하도록 할수있다.
						ㄴ	< error-page>
								< exception-type>(*패키지를포함한 예외클래스이름*)< /~~>
								< location>/(*웹어플리케이션부터시작하는url*)< /~~>
							< /error-page>
								=> 해당 예외클래스발생시 바로아래에 짝지어진 url로 이동.
						ㄴ < exceptino-type>대신에
							< error-code>(*http상태코드*)< /~~>
							를 써넣으면 해당 에러코드발생시 이동할 url을 설정할수있다.
								ㄴ 마찬가지로 exception객체를 넘겨주며 사용하기위해서는 역시 isErrorPage에 true를주어야함.

				* 바인딩 : request나 세션 객체등에 속성값을 설정해는것을 말함.
				* 분산 웹 어플리케이션?
					ㅡ 컨테이너가 클라이언트의 요청을 몇몇 JVM으로 분산하여 넘기는 환경이 있다고함. 즉, 어플리케이션이 다중 JVM에서 구동되는것.
						ㄴ 즉, 어떤 요청은 vm1로 보내고 또다른건vm2로 보내고 이런식.
					ㅡ 이럴경우, 어플리케이션의 ServletContext, ServletConfig 등은 JVM당 하나씩 생성된다.
					ㅡ 하지만 Session의 경우는 VM과 상관없이 웹어플리케이션당 하나만 생성되고 VM을 이동하며 작동한다.
				* 직렬화(Serialization)
					ㅡ 객체나 데이터 등을 외부시스템에서도 사용,전송,저장 할수있도록 바이트형태로 변환하는것을 말함.
					ㅡ  자바에선 java.io.Serializable 인터페이스를 구현하는 객체는 직렬화가 가능하다.

			</pre>
		</pre>

		JSP<button>더보기</button>
		<pre>
			ㅇ JSP란?
				ㅡ 문법구조상 서블릿과는 반대로 html코드안에 자바코드가 삽입. =>서블릿의 단점해결.
				ㅡ 서블릿과 달리 컴파일이나 등록과정 필요없음. 서버의 폴더에 저장하기만하면된다.
				ㅡ html문서사이에 jsp문법의 코드가 삽입되는 형태로 작성된다.
				ㅡ 실행과정 )
					ㄴ 웹 컨테이너가 jsp페이지 전체를 서블릿 클래스의 소스코드로 변환한다.
					ㄴ 이후 서블릿 클래스가 작동하는 그대로 진행된다.(컴파일, 인스턴스화, 초기화)
				ㅡ 문법종류)
					1. < % (*내용*) %> 을 사용하는 문법. (스크립틀릿과 지시자,선언부, 표현식이 있다)
					2. $ { ( * 내용*) } 을 사용하는문법. 익스프레션 언어(EL)이라고한다.
					3. < c:fi>, < jsp:forward>등과 같은 xml태그형태의 문법. 액션같은것들.

			ㅇ jsp vs servlet? 뭘써야?
				ㅡ 둘다 장단이 있으므로 둘다쓰인다

			ㅇ 스크립팅 요소
				ㅡ 스크립틀릿과 표현식, 선언부를 말함.
				ㅡ 스크립틀릿)
					ㄴ < % ~~ %>사이에 자바 '명령문'을 넣어서 사용.
					ㄴ 이 부분은 브라우저로 전송되지않으며 서버쪽에서 처리한다.
					ㄴ 서블릿으로 변환시, 안에 내용인 자바명령문들은 그대로 자바명령문이된다.
				ㅡ 표현식)
					ㄴ < %= ~~ %> 사이에 자바'식'을 넣어서 사용.
					ㄴ 이 '식'은 상수나 변수, 연ㄴ산식,메소드 등이 될수잇다.( 명령문 안된다. '식'이다)
					ㄴ 그냥 스크립틀릿을 사용해도 되지만, jsp페이지에 자바코드가 들어가는것을 지양하므로 이를이용해 원하는값들을 뿌려주는식으로 사용된다.
					ㄴ 이역시 서버쪽에서 처리된다.
					ㄴ 서블릿으로 변환시, '식'은 그 식의 결과를 출력하는 명령문으로 변환된다.
				ㅡ 선언부)
					ㄴ < %! ~~~ %> 사이에 자바코드를 쓰며, 변수선언이나 메소드선언을 작성한다.
					ㄴ 서블릿으로변환시, 서블릿클래스의 멤버변수, 멤버함수가 된다.(멀티스레드모델에서는 멤버변수 사용안된다했으므로 변수선언할거면 반드시 final, static을붙여준다)

			ㅇ 지시자
				ㅡ jsp페이지를 서블릿 클래스로 변환할때 필요한 정보를 전달하는 기능을 한다.
				ㅡ page지시자, include, taglib지시자가 있다.
				ㅡ 형식)
					< %@(*지시자이름*) (*속성*)="(*속성값*)" ~~~ %>
					ㄴ 여러속성값들을 설정한다.
				ㅡ page 지시자)
					ㄴ jsp페이지 전체에 적용되는 정보기술에 쓰이는 지시자이다.( 문자인코딩, 응답페이지의 컨텐츠타입, 페이지가 내장세션객체를가질것인지 등)
					ㄴ 대표적 속성들)
						ㄴ import : 자바의 import처럼쓰인다. 기본적으로 포함되는것들은 java.lang, lavax.servlet, javax.servlet.http, javax.servlet.jsp이다.
						ㄴ isThreadSafe : 생성될서블릿클래스가 '싱글스레드모델'일지 결정해줌. 디폴트는 true로 싱글스레드모드사용안함을 의미.
						ㄴ contentType : jsp가 생성하는 문서종류와 브라우저로 전송할때 쓰이는 인코딩타입을 설정한다. 서블릿으로 변환시 response.setContentType()의 인자로넘어간다.
							ex)	< %@page contentType="text/html; charset=UTF-8"%>
						ㄴ isELIgnored : 페이지를 서블릿으로 변환할때 EL표현식을 무시할건지 결정
						ㄴ isErrorPage : 현재페이지가 jsp오류처리용페이지인지 결정
						ㄴ errorPage : 현재페이지에서 잡지못한 예외를 보낼 오류페이지 url을 설정.

				ㅡ taglib지시자)
					ㄴ jsp문법 세가지중 마지막인 xml태그 '액션'을 사용할때 쓰인다.
						ㄴ 더 정확히는, 기본적으로 제공되는액션과 라이브러리를 설치해야 사용가능한 액션이 있는데 후자의 사용을 위해 쓰인다.
					ㄴ jsp에서 이용가능한 태그라이브러리를 정의

				ㅡ include 지시자)
					ㄴ 현재 jsp페이지에 다른 jsp페이지나 html페이지를 불러올때 사용한다.
					ㄴ 불러온 페이지는 현재페이지으 일부가된다.
					ㄴ file속성값으로 상대경로 url을 설정하여 불러온다
						ex)	< %@include file="./aaa.jsp" %>
					ㄴ 지시자가 입력된 그 위치에 불러온 파일이 삽입된다.
					ㄴ 여러 jsp페이지에 공통적으로 포함되어야하는 코드가 있을때 쓰면 좋음. 문서머리말이나 네비게이션같은.

			ㅇ jsp 주석
				ㅡ html, java, jsp의주석 모두사용가능하다.
				ㅡ 처리는 각각 조금씩다르다.
					ㄴ html주석) 서블릿 클래스 변환시 그대로 html형식으로 출력된다.
					ㄴ 자바 주석) 서블릿클래스변환시 주석이 그대로 서블릿 클래스 안으로 들어간다.
					ㄴ jsp주석) < %-- ~~~ --%>형태로 작성하며, jsp에서만 의미가있으므로 html에 출력되지도, 서블릿클래스에 남지도않는다.

			ㅇ jsp코드의 서블릿 변환
				ㅡ jsp선언문을 제외한 jsp의 내용들은 모두 서블릿의 service()메소드 안으로 들어가게된다.(service()는 GET,POST방식 둘다 처리해주는 메소드)
						ㄴ jsp선언문( < %! ~~ %> )안에 선언되는 변수나 메소드는 service()안이 아닌 서블릿의 멤버변수,멤버메소드가 된다.
				ㅡ html코드는 out.println()형식으로 출력된다
					ex)< html>< head> => out.prinlnt("< html>< head>");
				ㅡ 스크립틀릿 안의 자바코드는 그대로 자바코드가 된다.
					ex) < % int count=0; %> => int count=0;
				ㅡ 표현식안에 있는 내용은 그대로 out.println(" ~~ ")안의 내용으로 바뀐다.
					ex) < %= count %> => out.println(count);
				ㅡ jsp코드 서블릿 변환과정)
					ㄴ 지시자가있는지보고 정보확인
					ㄴ HttpServlet의 하위클래스 생성
					ㄴ import속성가진 page지시자있으면 맨위에 import문 삽입.
					ㄴ 선언문부분은 서블릿의 service()위에 선언해줌.
					ㄴ _jspService()라는 이름의 service()메소드를 만듦. _jspService()는 서블릿의 부모클래스에서 정의된
						service()메소드에서 호출되는 메소드임.당연히 HttpServletRequest, ~~Response를 매개변수로받음.
						이메소드에서 jsp의 내장객체도 선언해준다.

			* jsp에서 파일읽기,쓰기

			ㅇ JspPage와  HttpJspPage 인터페이스
				1. JspPage 인터페이스
					ㅡ jsp페이지에 쓰이는 서블릿이 만족시켜야하는 기능들을 구현해놓은 인터페이스
					ㅡ 보통 구현은 이 인터페이스가 아닌 하위인터페이스인 HttpJspPage터페이스가 쓰인다.
					ㅡ jspInit()과 jspDestroy()가 있으며, 각각 init()와 destroy()에 의해 호출된다. 이들은 재정의가 가능하다.
				2. HttpJspPage인터페이스
					ㅡ JspPage인터페이스와 똑같은데 추가로 _jspService()가있으며, 서블릿의 service()와 같은 역할을한다.
					ㅡ service()에서 호출되며, 재정의될수 없다.
					ㅡ  jsp파일은 컨테이너에의해 HttpJspPage 인터페이스를 구현한 서블릿 클래스로 변환이 된다.
					ㅡ  HttpJspPage인터페이스는 JspPage인터페이스를 구현한다.

			ㅇ jsp 전체 흐름
				ㅡ jsp파일이 작성되어 웹어플리케이션에 배포.
				ㅡ jsp파일은 그냥 저장되어있음.
				ㅡ 사용자가 jsp파일을 요청하면, 컨테이너가 jsp파일을 java소스코드로 변환.
				ㅡ 그 java소스코드르 ㄹ컴파일하여 class파일로 만듦. (이 과정은 jsp페이지당 한번만일어나며 이 이후로는 일반 서블릿과 똑같이 작동한다)
				ㅡ 컨테이너가 해당 서블릿클래스를 메모리로 로딩.
				ㅡ 컨테이너에 의해 인스턴스화 되며 jspInit()호출.
				ㅡ 요청이 들어오면 _jspService()호출하여 샐행.

			ㅇ jsp 내장객체)
				ㅡ 선언을 하지않아도 쓸수있는 jsp가 이미가지고있는 객체들이다.
				ㅡ 모든내장객체들은 서블릿/jsp api에 일대일매핑된다.
				ㅡ종류)
					서블릿에서..				jsp에서..
					ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ
					JspWriter				out
					HttpServletRequest		request
					HttpServletResponse		response
					HttpSession				session
					ServletContext			application
					ServletConfig			config
					JspException			exception
					PageContext				pageContext
					Object					page

			ㅇ jsp의 초기화 파라미터
				ㄴ 서블릿에서와 마찬가지로 DD에 정의하여 설정할수있다.단, jsp페이지 등록은 < servlet-class>가 아닌 < jsp-file>태그를 이용한다.
					ex) < servlet>
							< servlet-name> ~~< /servlet-name>
							< jsp-file> /(*jsp페이지이름.jsp*) < / jsp-file>	  => 서블릿의경우와 다른부분.
							< init-param>
								< param-name> ~~ < / param-name>
								< param-value> ~~ < / param-value>
							< /init-param>
					< /servlet>
						~~~~...
				ㄴ 이렇게하면 서블릿에서의 초기화파라미터와 같은원리로 ServletConfig객체에 초기화파라미터가 저장되게되고 서블릿에서와 같은 방식으로 사용하면된다.

			ㅇ pageContext와 jspContext 추상클래스
				ㅡ pageContext 추상클래스)
					ㄴ jsp페이지와 일대일 매핑되는 내장객체로, 내장객체중 가장먼저 생성되어 다른내장객체들을 생성.
					ㄴ 다른 내장객체를 구하거나 흐름을 제어하거나(forward(), include()) 에러데이터를 구하는 기능을 하는 메소드들이있다.
					ㄴ 스코프 영역을 나타내는 정수값에 대한 상수정의가 되어있고, 그 외에도 여러 상수정의가 멤버변수로 되어있다.
					ㄴ jspContext 추상클래스를 상속한다.

				ㅡ jspContext 추상클래스)
					ㄴ pageContext의 상위클래스이다.
					ㄴ 모든종류의 스코프영역에엤는 속성 접근,생성 및 스트림객체생성 등다양한 메소드들이 있다.
						ex) pageContext.getAttribute( (*속성이름*), (*스코프 정수*) ) : 해당 스코프에서 속성이름에 해당하는 속성값 반환.
							스코프정수부분에는 말그대로 스코프를나타내는 정수를 입력해야하는데 pageContext 클래스의 멤버변수로 상수정의가 되어있음.
							SESSION_SCOPE, APPLICATION_SCOPE 등등.
						ex) pageContext.findAttribute( (*속성이름*) ) : 속성이름에 해당하는 속성값을 찾는다. 찾는 스코프범위는 작은것부터
							큰것순으로 찾는다(page, request, session, application순서).

			ㅇ jsp페이지에서의 오류처리
				1. try-catch문을 이용하여 catch문 부분에서 html출력	=> 구조가 기형적이다.
				2. try-catch문에서 catch에 forward등을 사용하여 오류를 처리하는페이지를 따로만듧.
				3. page지시자에 errorPage속성값으로 url을 쓰면 오류발생시 해당url로 이동함.
					ㅡ 이동하면서 exception이라는 jsp내장객체를 전달함.
					ㅡ 이동된페이지에서는 page지시자에 isErrorPage속성값을 true로 줌으로써 exception내장객체 사용이 가능하다.(exception객체는 java.lang.Throwable이다.)

			ㅇ jsp페이지에서 스크립틀릿 사용못하게하는방법.
				ㄴDD에 정의한다.
					< web-app>
						< jsp-config>
							< jsp-property-group>
							< url-pattern>*.jsp< /url-pattern>  =>jsp파일형식에 대해 와일드카드(*)를 사용했으니 모든 jsp페이지에 대해적용.
							< scripting-invalid>			=> 스크립틀릿 사용을 못하게하는부분. 이부분을 true로 설정해주면 스크립틀릿 사용x.
								true
							< /scriptiog-invalid>
							< /jsp-property-group>
						< /jsp-config>
						.....

			ㅇ jsp와 mvc패턴
				ㅡ mvc패턴에서 jsp페이지는 뷰를담당하고있으며, 여기에는 최대한 자바코드를 사용하지않는것이 좋음. 협업 및 유지보수측면에서.
				ㅡ 그래도 어쩔수없이 최소한의 자바코드가 필요할수있는데 이는 액션태그(자바빈같은)나 EL등을 이용하여 처리해준다.

			ㅇ 자바 빈
				ㅡ jsp페잉지에서 쓰이는 자바의 클래스의 일종
				ㅡ 정해진 문법에 맞게 클래스를 정의해야 빈으로서 쓰일 수 있고, jsp에서 태그를 이용해 쓰인다.
				ㅡ 로직과 뷰를 분리하여 심플하게 페이지를 만들고 재사용성을 높이기위해 사용된다.
				ㅡ 빈클래스의 규격을 보면 알겟지만 데이터 객체를 위한 클래스를 만드는 것에 가깝다.
				ㅡ jsp에서의 태그는 < jsp: ~~~/>등을 이용해 bean을끌어다쓴다.
				ㅡ 문법)
					ㄴ자바빈 규격은
						1. private로 선언된 멤버변수들
						2. set(*대문자로시작하는 변수이름*)((*설정할값*)), get(*동일*)() 형태의 getter, setter메소드들. public선언이어야함.
						3. 인자가없는 public생성자가 있어야한다.
						4. getter의 리턴값과 setter의 인자의 자료형은 같아야한다.

					ㄴ사용하는법은
						1. < jsp:useBean id="(*빈이름*)" class="(*패키지포함 자바빈클래스명*)" scope="(*사용범위*)"/> : 자바빈 객체를 생성하기위한 코드.
						2. < jsp:setProperty name="(*위에서 설정한 빈id*)" property="(*프로퍼티명*)" value="(*저장할값*)"> : 자바빈 프로퍼티의 값을
							저장하는 액션.
						3. < jsp:getProperty name="(*위에서설정한빈id*)" property="(*프로퍼티명*)"> : 자바빈 프로퍼티값을 가져오는 액션.

				ㅡ 자바빈 특징1. 쓰려는 자바 빈 객체가 없는경우 자바 빈 작동방식)
					ㄴ < jsp:useBean ~~>은 해당스코프에 id로 설정한 이름의 속성값이 없으면 해당객체를 직접 생성하고 속성값으로 설정한다. 서블릿으로변환되는코드를보면 다음과같다.
						< jsp:useBean id="person" class="foo.Person" scope="~~"/>는 아래와같이변환된다.

							foo.Person person = null;
							synchronized(request){
								person=(foo.Person)~~context.getAttribute("person", 스코프범위);
								if(person==null){
									person=new foo.Person();
									~~context.setAttribute("person", person, 스코프범위);
								}
							}
					ㄴ < jsp:useBean ~~>의 몸체부분에 다른 자바빈액션을 삽입하면 해당객체가 없을경우에 실행할것들을 정해놓을수 있다. 있으면 그냥건너뛰고.
					ㄴ < jsp:useBean>에 type속성을 부여하면, 객체가 없어서 새로 생성할때 부여한 속성값인 클래스를 참조변수의 타입으로,
						class로 부여한 클래스를 실제로 생성하는 타입으로 지정할수가있다.
							ex) < jsp:useBean ~~ type="foo.Person" class="foo.Enployee" ~~>
									변환되면 아래와같다.
								foo.Person person=null;	=>참조변수 타입은 type의 속성값으로.
								if(person==null){
									person = new foo.Employee();	=>실제생성하는 객체타입은 class의 속성값으로.
								}
								물론 이런식으로 설정을하려면 자바문법대로 두클래스가 상속관계이어야한다.
					ㄴ class속성없이 type만 사용할경우, 해당클래스가 스코프범위안에있을시 문제없지만 아닌경우 예외발생한다함.(이부분이해x)

				ㅡ 자바 빈 특징2. 스코프속성의 디폴트값)
					ㄴ < jsp:useBean>과 < jsp:setProperty>액션에는 scope속성이 있는데 이것의 디폴트 값은 page이다.
				ㅡ 자바 빈 특징3. 페이지로부터 파라미터를 받아 사용할수있다.
					ㄴ < jsp:setProperty>의 param 속성 : 클라이언트로부터 받은 파라미터를 바로 자바 빈값으로 사용하고싶을때 사용.
						속성값으로 넘어온 파라미터의 name을 쓰면 해당 값이 저장되게된다.
					ㄴ param속성을 쓰지않고도 넘어오는파라미터의 name값이 빈의 프로퍼티 이름과 같으면, < jsp:setPropery>에 value값을
						비워두면 컨테이너가 자동으로 넘어온파라미터의 값을 저장시킨다.
					ex) 넘어오는 파라미터의 name이 "dog"일때,
						< jsp:setProperty name="AA" property="dog" />
						이러면 넘어오는 dog란 name의 파라미터가 빈에 저장됨.
				ㅡ 자바 빈 특징 4. 자동형변환
					ㄴ 프로퍼티 자료형이 무엇이든 자바 빈태그에 의해 알아서 변환이 된다.
					ㄴ 자바빈 액션만을 이용해서 프로퍼티를 set하면 자동으로 형변환을 해주지만 중간에 스크립틀릿이 들어간경우 자동형변환x.
					ex) < jsp:setProperty ~~~~ value="< %=request.getParameter(~~)%>"/> =>이런식으로쓰면 자동형변환x.

		</pre>

		EL<button>더보기</button>
		<pre>
			ㅡ https://docs.oracle.com/javaee/6/tutorial/doc/gjddd.html 에 자세히 나와있다. 참조.
			ㅇ EL (Expression Language) 개요
				ㄴ jsp페이지코드 안에 자바 코드를 넣는건 지양하는추세라함. 프로그래머가 아닌사람들이 못알아보기때문.(디자이너같이)
				ㄴ 그래서 나온 대안이 EL.
				ㄴ 다른곳에있는 자바코드를 호출하는데 그 기능이있다.
				ㄴ ex) el표현식 ${applicationScope.mail}은
					스크립틀릿 < %=application.getAttribute("mail")%>와 동일하다

			ㅇ EL 기본
				ㅡ el에는 eval-expression과 literal-expression이 있으며 이둘을 합성한 composite expression이 있다.
					ㄴ 전자가 $ { }나 #{ }을 말하는것같고 후자는 아직안배운것같다.
				ㅡ eval-expression에는 ${}를 사용하는것과 #{}을 사용하는것이 있는데, 이 둘은 그 안의 식이 실행되는 시점을 제외하고는 차이점이 없는것같다.
					${}는 즉각적인 실행, jsp페이지가 컴파일될대 바로 컴파일되고 jsp페이지가 실행될때 바로실행된다. #{}는 해당 값이 필요로하기 전까지는 평가되지않는다고한다.
					'defferd-evaluation'이라고한다.
				ㅡ EL의 기능)
					ㄴ 동적으로 자바빈이나 여러 데이터들, 내장객체 안에있는 어플리케이션 데이터를 읽어오는기능
					ㄴ 자바빈이나 form요소같은 데이터를 쓰는기술
					ㄴ 임의의 static, public메소드를 호출하는기능
					ㄴ 연산자를 동적으로 수행하는기능
				ㅡ ${}, #{} 둘다 해당되는지는 모르겠지만 ${}은 서버단에서 EL식이 모두 변환이되어 완전한 html문서가 만들어지고 클라이언트로 보내지기때문에
					한번 처리가되어 보내지면 변경되지 않는다. 클라이언트입장에선 EL이 아니라 그냥 글자값과다름없음.
					ㄴ 서버단에서 처리가 되고 클라이언트로 넘어가기때문에 물론 javascript에서도 사용이 가능하다.
					ㄴ 추측 ) el이 먼저 해석되고 그다음에 jsp가 처리되는 순서가 아닐까 싶다.

			ㅇ EL 사용법
				ㅡ ${ (*expression*) }형태이고,
				ㅡ EL의 rvalue, lvalue는 다음의 객체들과 그 속성, 프로퍼티들을 가리킬수있다.
					ㄴ 자바빈 컴포넌트
					ㄴ 컬렉션
					ㄴ 자바 se enumerated type
					ㄴ 내장객체
				ㅡ 이것들을 가리키기위해 객체의 이름을 expression부분에 쓰면된다.
				ㅡ 컨테이너는 표현식 안에잇는 변수를 PageContext.findAttribute( (*표현식안의변수명*) )의 방식대로 찾는다. page,rquest, session, application범위순으로
					찾으며 없으면 null을 반환.
				ㅡ bean이나 enum객체, 컬렉션, 내장객체들의 속성이나 프로퍼티를 기리키려면 도트연산자(.)와 [ ]를 이용하면 된다. 이것들 뒤에 프로퍼티나 속성의 이름이 오면된다.
					ex)	${customer.address["street"]}
				ㅡ 그냥 속성이름을써도되고, 속성이름이 중복되거나하면 내장객체로 스코프를지정한뒤 속성이름을써도된다.
				ㅡ [ ]사이에는 String literal을 쓰며, ""나 ''를써도된다. 도트(.)와 [ ]를 섞어써도된다.
				ㅡ []연산자를쓸때는 안에""을써주어야하며(ex)["~~~"]), ""을쓰지않을경우 해당이름과 같은 속성값을찾아 그값을 넣어준다. 없으면 null.
					ex) ${musicMap[Genre]	=>Genre란 이름의 속성값을찾아 넣어줌.

				ㅡ 빈을 사용할경우. 빈 객체를 저장한 속성에다가 빈의 프로퍼티를  입력하면 getter,setter를 자동으로 호출해준다.
					ex) ${ (*빈 객체가 저장된 속성이름*). (*빈의 프로퍼티*) } => 이러면 빈의 해당프로퍼티에 대한 getter을 자동호출하여 값나오는듯.
						ㄴ 이를 이용하면 jsp 빈 액션태그를 사용하는것 보다 심플하고 더 많은 기능 사용가능.
				ㅡ enum객체의 프로퍼티를 호출하려면, enum객체 안에 bean의 get(*속성이름*)()같은 메소드가 존재해야한다.
				ㅡ 배열이나 리스트의 경우) int로 변환될수있는 literal값이나 따옴표없는 int값이 들어간 [ ]를 이용하여 접근가능.
					ex)	${customer.orders[1]}, ${customer.orders.socks} (socks가 int로 변환된다고 가정)
				ㅡ Map형의 경우) string literal key를 이용해 접근가능하다. (강제는아니라고한다?)
					ex)	${customer.orders["socks"]}

				ㅡ rvalue표현은 객체가 아닌값도 가리킬수있다고한다. 산술연산결과값이나 문자값 등등
					ex)	${"literal"}, ${customer.age+20}, ${true}, ${453} 등
				ㅡ el에서의 자료형 약속)
					ㄴ Boolean : true나 false로 표현
					ㄴ Integer : 자바와 똑같이
					ㄴ Floating-point : 자바와 똑같이
					ㄴ String : 큰따옴표("")나 작은따옴표('')로 둘러싸인것. (큰따옴표를 쓰려면 \", 작은따옴표는 \', 역 슬래쉬는 \\)
					ㄴ Null : null

				ㅡ 표현식 안에 또다른 표현식을 넣는것도 가능.
				ㅡ EL은 자바가 아니며, 당연히 자바문법을따르지도않는다. 비슷해 보이기는 한다.

				ㅡ el내장객체들은 pagContext를 제외하고 모두 map형 객체이다. ServletRequest와 같은 실제 객체가 매핑되어있는 맵이 아닌 단순히 해당 범위의 속성들이
					매핑되어있는 맵. 속성의 참조 그 이상의 기능은 없다.
				ㅡ ServletRequest, HttpSession등의 실제객체에 접근하려면 자바 빈인 pageContext가 프로퍼티로 해당 객체들을 가지고있으므로 이를통해접근하면된다
					ex)${pageContext.request.~~~}  =>.request를 하면 빈인 pageContext가 가지고있는 ServletRequest객체가 반환된다.
				ㅡ EL 내장객체로는 pageScope, requestScope, sessionScope, applicationScope, param,paramValues, header,
					headerValues,cookie, initParam, pageContext가 있다.
					ㄴ param : < form>을 통해 받은 데이터를 가져올때 사용. ex)	${param.(*name속성값*)} 또는 ${param["(*name*)"]
					ㄴ paramValues : < form>에서 한 name에 대해 값이 여러개일때사용. ex)	${paramValues.(*name*)[(*index*)]
					ㄴ header : http요청 메세지에 있는 http헤더값 가져올때쓰임.
					ㄴ pageContext : 유일하게 bean형태이다. PageContext객체의
					ㄴ 내장객체 cookie는 cookie다음으로 쿠키이름을 주면 해당 쿠키가 나옴.
						ex) ${cookie.(*쿠키이름*).value} =>쿠키이름에해당하는 값 출력.
					ㄴ 내장객체 initParam은 initParam다음으로 초기화파라미터이름을 주면 해당 파라미터가 출력.
						ex) ${initParam.(*파라미터이름*)}

			ㅇ EL함수 사용하기
				1. 사용할 함수를 만든다
					ㄴ 일반 자바클래스안에 public static형 메소드를 만든다.
					ㄴ 필수는 아니지만 보통 어떤값을 얻기위해EL에서 함수사용하므로 리턴값이 있는게 보통이고 인자는 상관없다.
				2. DD처럼 태그라이브러리서술자(TLD, Tag Library Descriptor)을 만든다.
					ㄴ 문법은 다음과 같다.
						< taglib ~~>
						< tlib-version>~~~< /~~>
						< uri> (*jsp지시자 taglib에서 사용할 uri이름*) < /uri>
						< function>
							< name> (*jsp에서 함수를 호출할때쓸 이름*) < /name>
							< function-class> (*패키지를포함한 실제클래스*)< /~~>
							< function-signature>(*실제 메소드*)< /~~>
						< /function>
						< /taglib>
					ㄴ 저장위치는 WEB-INF폴더 아래.(.tld형식)
				3. jsp에 taglib지시자를 입력.
					ㄴ ex) < %@ taglib prefix="(*이름*)" uri="(*TLD에서설정한 uri*)"%>
					ㄴ prefix는 일종의 이름공간. 함수이름앞에 붙여줌
						ex) ${ (*prefix*): (*함수이름*)()}
				4. 함수를호출하는 EL작성
					ex) ${ (*prefix*): (*함수이름*)()}

			ㅇ EL연산자
				ㄴ 뷰를 위해 el을쓰는것이므로 지양ㅎ해야하지만 기능은 존재한다.
				ㄴ el에서 null은 출력값으로선 아무것도없는것이고,
					산술연산으로선 0,
					논리연산으로선false이다.

			ㅇ EL의 include
				ㄴ 머리말, 꼬리말같이 똑같은내용이 반복되는경우 include를  통해 구현하여 재사용할수있다.
				ㄴ 이를사용하면 url에있는페이지가 위문장이 있는부분에 삽입된다.
				ㄴ jsp 지시자를이용)
					< %@ include file=" (*페이지url*) " %>
					작동과정)
					1.컨테이너가 include지시자가있는 페이지를 요청받는다.
					2. 컨테이너가 include지시자를보고 포함하려는 페이지의 코드를 그대로 지시자가있는부분에 복붙한다.
					3. 복붙된 코드를 .java파일로 만들어 컴파일하여 서블릿을만든다.
					4. 그다음부턴 서블릿 라이프사이클..
					ㄴ이런과정이기때문에 한번 코드가 삽입되어 서블릿이만들어지면 재배포하거나하는게 아닌이상 포함하려는페이지가 변경되어도 그내용이 반영되지않는다.
					ㄴ 또한 포함되는부분에 < html>, < head>등의 태그가있을시 복붙되면 중복이되므로, 이런 재사용할페이지를 만들땐 이를고려해서 코딩을해야한다.
						(저런태그들을 없애주는등)
				ㄴ 표준액션을 이용)
					< jsp:include page=" (*페이지url*) "/>
					작동과정)
						1.  해당액션부분에 런타임시동작하는 함수호출문삽입.
						2. 일반페이지처럼 .java로 변환되고 컴파일되어 서블릿이됨.
						3. 요청이들어와 실행시 아까의 함수가 실행됨.
						4. 그함수는 포함하려는페이지에 대해 RequestDispatcher를만들어 이것의 include()를통해 반환받은 응답페이지를 그대로
							삽입하는방식으로 작동한다.
							ㄴ이런과정이기때문에 포함하려는페이지내용이바뀌어도 실행할때마다 요청해서 응답받은내용을 포함시키기때문에 그 내용이 반영될수 있다.
							ㄴ 이 액션태그는 몸체를 가질수 있으며, 몸체에 요청파라미터 값을 추가할수있다.
					ex) < jsp:include ~~>
						< jsp:param name="~~" value="~~"/> =>요청파라미터를 넘겨줌.
						< /jsp:include>

			ㅇ forward 액션
				ㄴ < jsp:forward page=" (*페이지url*) "/>
				ㄴ forward가있으면 응답에 쓰여진것들이 모두취소된다. 즉 forward이전에 어떤출력문이 있었든간에 다 무시되고 페이지를넘어간다는말.

			ㅇ jsp페이지에서 EL을 사용못하게하는방법
				ㄴ jsp에서 스크립틀릿사용못하게하는방법과 같이 DD에정의한다. jsp의경우와 똑같고 < scripting-invalid>부분만 다르다.
					< web-app>
						< jsp-config>
							< jsp-property-group>
							< url-pattern>*.jsp< /url-pattern>  =>jsp파일형식에 대해 와일드카드(*)를 사용했으니 모든 jsp페이지에 대해적용.
							< el-ignored>				=> EL사용 못하게하는부분.
								true
							< /el-ignored>
							< /jsp-property-group>
						< /jsp-config>
				ㄴ 저 값은 디폴트가 false이고 이는 el을 사용한다는것을 의미한다.
				ㄴ 저렇게 true로 바꾸어주면 el식인 ${ ~~} 을 더이상 el로 인식하지 않는다.

		</pre>

		표준액션<button>더보기</button>
		<pre>
			ㅇ 액션태그
				ㅡ 원래 html태그에는 없는 기능으로서 jsp에 의해 제공되는 태그들이다.
				ㅡ 표준액션 태그와 커스텀 액션 태그로 나뉜다.
					ㄴ 표준액션태그 : jsp에서 바로 쓸수있는 기본 액션들. < jsp:~~> 형태로 시작한다.
					ㄴ 커스텀 액션 태그 : 별도의 라이브러리를 설치해야 사용가능한것들. 또는 직접 만들거나.
				ㅡ 액션태그들은 jsp문법이 아닌 xml문법을 따른다.

			ㅇ 표준 액션태그들
				ㅡ < jsp:include> : jsp의 include()와 같은 기능을 한다.
				ㅡ < jsp:forward> : forward()와 같은기능.
				ㅡ Bean과관련된 액션들)
					1. < jsp:useBean id="(*빈이름*)" class="(*패키지포함 자바빈클래스명*)" scope="(*사용범위*)"/> : 자바빈 객체를 생성하기위한 코드.
					2. < jsp:setProperty name="(*위에서 설정한 빈id*)" property="(*프로퍼티명*)" value="(*저장할값*)"> : 자바빈 프로퍼티의 값을 저장하는 액션.
					3. < jsp:getProperty name="(*위에서설정한빈id*)" property="(*프로퍼티명*)"> : 자바빈 프로퍼티값을 가져오는 액션.

		</pre>

		JSTL<button>더보기</button>
		<pre>
			ㅡ 개인적인 간단개요)
				ㄴ 뷰(View)를 담당하는 jsp페이지에서 자바코드를쓰지못하다보니 생기는 제약이있는데, 이 jstl을이용해서 좀더 동적이고 다양한 기능을 구현할수있는
					jsp페이지를 만드는데 쓰이는것 같다.
				ㄴ 한마디로 동적인 뷰 jsp페이지를 만들기위한 도구들?
			ㅡJSP 표준 태그 라이브러리(JSP Standard Tag Library)로, JSP페이지 안에서 쓸수있는 커스텀 액션과 함수를 제공함.
			ㅡ대표적으로 간단한프로그램로직구현, 다른jsp페이지호출, 날짜시간숫자의 포맷,  db입력조회생성등, xml문서처리, 문자열처리함수호출 등등의 기능을한다.
			ㅡex) < fmt:formatNumber value="1.323" patter="#.00"/>
			ㅡ이 jstl은 5개의 라이브러리로 나뉘어지며 각각의 접두어가 붙는다.
					ㄴ코어 ) 변수선언, 실행흐름제어, 페이지이동 등의 기능제공. 접두어는 'c'. uri는 http://java.sun.com/jsp/jstl/core
				ㄴ포매팅 ) 숫자,날짜,시간을 포매팅, 다국어 기능지원. 접두어는 'fmt'. uri는 http://java.sun.com/jsp/jstl/fmt
				ㄴ데이터베이스 ) db관련기능 제공. 접두어는 'sql'. uri는 http://java.sun.com/jsp/jstl/sql
				ㄴxml처리 ) xml문서처리관련 기능. 접두어는 'x'. uri는http://java.sun.com/jsp/jstl/xml
				ㄴ함수 ) 문자열처리함수 제공. 접두어는 'fn'. uri는 http://java.sun.com/jsp/jstl/functions
			ㅇ 코어 라이브러리<button>더보기</button>
			<pre>
				ㅡ 속성 var로 저장된값은 자바변수가 아닌 속성명으로서 저장되는것.
				ㅡ scope속성은 디폴트가 page범위이다.
				ㅡ < c:set>
					ㄴ bean 프로퍼티나 맵형태의 값을 저장하는데 쓰인다.
					ㄴ ex) < c:set var="(*변수명*)" value="(*할당할값*)" scope="(*스코프*)"/>	=>jsp의 setAttribute()와 비슷한기능.
								또는,
						< c:set target="(*빈또는 맵객체*) property="(*해당프로퍼티*)" value="(*할당할값*)"/>	=>이건 빈이나 맵객체에 값저장하는기능.
					ㄴ target에 빈이나 맵의 속성이름이 아닌 객체 자체가 들어가야한다는점 주의. 또한, property값은 빈의 경우 프로퍼티이름이 되고, 맵의 경우 '키'값이 된다.
								ex)
							< %Member member = new Member(); %>

							< %-- member.setName("원종천1")과 동일 --%>
							< c:set target = "< %=member%>" property = "name" value = "원종천1"/>
							< %=member.getName()%> < %--값 원종천1 출력 --%>

							< c:set var = "m" value = "< %=member%>"/>
							< %-- member.setName("원종천2")와 동일--%>
							< c:set target = "${m}" property = "name" value = "원종천2"/>
							${m.name} < %-- 값 원종천2 출력 --%>

							< % Map< String, String> prop = new HashMap< String, Stiring>();%>
							< %--prop.set("host", "localhost")와 동일 --%>
							< c:set target = "< %=prop%>" property = "host" value = "localhost"/>
							< %=prop.get("host")%> < %-- 값 localhost 출력 --%>
								=>이런식으로 맵객체 자체를 target에 넣어줌. 근데 맵객체란게 키값하고 값으로 이루어진거고 키값도 property속성으로 써줄건데
								이걸사용하는게 의미가 있는지싶긴함.
					ㄴ value값을 이 태그의 몸체부분에서 작성해도된다.
						ex) < c:set ~~>
							(*value값*)
							< /c:set>
					ㄴ value로 null을 주게되면 해당 속성을 삭제됨.
					ㄴ var속성과 target속성을 동시에 사용할수는 없다.
					ㄴ scope속성에는 page, request, session, application이 올수 잇다.
				ㅡ < c:remove/>
					ㄴ jsp의 removeAttribute()와 같은역할.
					ㄴ < c:set>을 이용해 저장한 변수를 삭제함.
					ㄴ ex) < c:remove var="(*변수명*)"/>
					ㄴ 변수명 부분에는 문자열이 와야함.
				ㅡ < c:out/>
					ㄴ jsp의 표현식과 같은역할
					ㄴ ex) < c:out value="(*변수명*)" default="(*기본값*)" escapeXML="(*참,거짓*)"/>
					ㄴ escapeXML속성 true이면, <,>,&,',"을 문자그대로 출력한다.
				ㅡ < c:if/>
					ㄴ else구문이 없는 if문비슷한거.
					ㄴ ex) < c:if text="(*조건문*)" var="(*변수명)*" scope="(*스코프*)"
							(*참일경우 실행할부분*)
						< /c:if>
					ㄴ 조건문부분의 참거짓결과를 scope범위의 var변수명으로 속성값저장가능하다
				ㅡ < c:choose/>, < c:when/>, < c:otherwise/>
					ㄴ 자바의 switch문같은것. if~else문이 없어서 이것 대용으로 주로쓰임.
					ㄴ ex) 	< c:choose>
								< c:when text="(*조건문*)">
									(*해당조건만족하면실행할부분*)
								< /c:when>
								< c:when text=~~>
								~~
								< /c:when>
								....
								< c:otherwise>
									(*아직까지만족하는조건없을때실행할부분*)
								< /c:otherwise>
							< /c:choose>
				ㅡ < c:forEach/>
					ㄴ 반복문역할.
					ㄴ var속성에 부여한 변수에다가 반복문의 값을 하나씩 자동으로 매핑함.
					ㄴ 여기서 var은 태그안에서만 유효.
					ㄴ 정수반복이나 자바의 컬렉션(Iterator나 Enumeration클래스)반복을 지원한다.
					ㄴex)	< c:forEach var="(*변수명*)" varStatus="(*추가속성값이름*)" begin="(*정수시작숫자*)" end="(*정수 끝숫자*)" step="(*정수증가값*)">
								(*반복실행할부분*)
							< /c:forEach>
								이게 정수반복. 아래는 컬렉션에대한 반복.
							< c:forEach var="(*변수명*)" items="(*컬렉션*)" varStatus="(*추가속성값이름*)" begin="(*시작인덱스*)" end="(*끝인덱스*)" step="(*인덱스증가값*)">
								(*반복실행할부분*)
							< /c:forEach>
					ㄴ varStatus는 값으로 부여한 이름을 통해 여러 속성값들을 반복문몸체부분에서 호출할수있다.
						ex) ~~~ varStatus="aaa"~~>
							aaa.current	=>현재 item
							aaa.index	=>0부터시작해서 세는 인덱스값
							aaa.count	=>1부터시작해서 세는 인덱스값
							aaa.first	=>첫번째값 여부
							aaa.last	=>마지막값 여부
							aaa.begin	=>begin속성의 값
							aaa.end		=>end속성의 값
							aaa.step	=>step속성의 값

				ㅡ < c:forTokens/>
					ㄴ 문자열을 주어진 '구분자'로 나누어 반복문실행.
					ㄴex)	< c:forTokens var="(*변수명*)" items="(*컬렉션*)" delims="(*구분자*) varStatus="(*추가속성값이름*)"
								begin="(*시작인덱스*)" end="(*끝인덱스*)" step="(*인덱스증가값*)">
								(*반복문실행하는부분*)
							< /c:forTokens>

				ㅡ < c:import>
					ㄴ include()기능. < jsp:include>와 같은방식으로 동작한다.(조금더 좋다고함)
					ㄴ < c:import url="(*url*)">
					ㄴ 현재 웹어플리케이션이 아닌 외부자원도 포함가능하다고 한다.
					ㄴ < c:param> 태그를 이용하여 포함시킬페이지로 요청을 보낼때 파라미터를 넘겨줄수있다.
						ex)	< c:param name="(*파라미터이름*)" value="(*파라미터 값*)"/>
					ㄴ 파라미터를받는 포함될페이지에서는 이를
						${ param.(*파라미터이름*)}으로 사용할수있다.

				ㅡ < c:url>
					ㄴ url을 만들어주는 태그.
					ㄴ ex) < c:url value="(*url*)" var="(*변수명*) scope="(*스코프*)"/>
					ㄴ url속성값에 해당하는 url을 적절하게 만들어줌.
					ㄴ 브라우저가 쿠키지원을하지않아서 세션id저장이 안될때 자동으로 url재작성을하여 jsessiond값을 붙여서 생성해줌.
					ㄴ var속성을 주지않으면 해당위치에 생성된url이 삽입된다.
					ㄴ var과 scope속성을 설정할경우 생성한 url을 scope영역의 var변수명으로 속성값저장해줌.
					ㄴ 몸체부분을가질수있으며, 이부분에 < c:param>을 이용해 url뒤에 붙을 파라미터를 설정할수잇음.
						ex) < c:url value="/userSearch.do" var="url">
								< c:param name="name" value="홍길동" />
								< c:param name="page" value="3" />
							< /c:url>
							=> url 맨뒤에 ~~?name=홍길동&page=3 이런식으로 추가됨.
					ㄴ 이 태그는 url인코딩은 해주지않는다. 하지만 < c:param>을 이용해 파라미터를 넘기면 해당파라미터에 대해 url인코딩을 자동으로 해준다.

				ㅡ < c:catch> 태그)
					ㄴ jsp태그로, try~catch문과 비슷하게 작동한다.
					ㄴ	< c:catch var="(*변수명*)">
							(*예외발생예상부분*)
						< /c:catch>
						=>이런식으로 catch태그로 감싸진부분에서 예외발생시, var에 exception객체가 저장된다.
					ㄴ 이 exception객체가 저장된 변수var을 통해 jsp의 page지시자에서 isErrorPage가 true가 아니어도 exception객체를 사용할수있다.
					ㄴ 이 태그는 try~catch문과 같이 감싸진부분에서 예외가 하나라도발생하면 그 뒤 나머지부분을 전부생략하고 < /c:catch>부분으로 넘어가는방식으로 동작한다.

				ㅡ 그외에도  < c:catch>, < c:redirect>, < c:out>등이 있다.
			</pre>
				*url 인코딩
					ㅡ 브라우저에서 파라미터를 보낼때, url뒤에 파라미터가 추가되는방식으로 전달되는데 이때 파라미터로서 불완전한문자가 있으면 문제가 된다. (가령, 스페이스,공백문자같은건
						url에 사용할수없는 등) 이때 이런식의 불안전문자, 예약 문자등을 다른문자로 바꾸어주는것을 'url인코딩'이라고 한다.  (공백문자를 '+'로 바꾸어주는 식으로)

			ㅇ 포매팅 라이브러리 : 같은 날짜를 2011년2월12일 이라 표현하거나 2011/2/12라고표현하거나, 0.55이거나 55%이거나 처럼 다양한 포매팅 요구사항을
				충족시킬수있는  라이브러리제공. 또는 국제화를 지원하는 커스텀액션제공.
				ㄴ국제화
					< fmt:message>, < fmt:setLocale>, < fmt:bundle>, < fmt:setBundle>, < fmt:param>, < fmt:requestEncoding>
				ㄴ포맷팅
					< fmt:timeZone>, < fmt:setTimeZone>, < fmt:formatNumber>, < fmt:parseNumber>, < fmt:parseDate>
			ㅇ SQL 라이브러리
				ㄴ DB접근
					< sql:query>, < sql:update>, < sql:setDataSource>, < sql:param>, < sql:dateParam>
			ㅇ XML라이브러리
				ㄴ코어 xml액션
					< x:parse>, < x:out>, < x:set>
				ㄴ xml흐름제어
					< x:if>, < x:choose>, < x:when>, < x:otherwise>, < x:forEach>
				ㄴ 변환 액션
					< x:transform>, < x:param>


		</pre>

		커스텀태그<button>더보기</button>
		<pre>
			커스텀태그란?<button>더보기</button>
			<pre>
				ㅡ사용자 정의 액션태그로서, 원하는 기능을 가진 함수를 만들듯이 액션태그를 만들어 사용할수있다.
				ㅡ 개인적인 개요)
					ㄴ jstl만으로 부족할때 직접태그를 만들어 사용할때씀.
					ㄴ 로직과 연결시키지않고 그냥 뷰적인 부분에 한해 유용하게 쓰인다함. 여러번 출력하는등.
					ㄴ jstl과 비슷하거나 여기에 속행있다고 생각하면 될듯???
					ㄴ
			</pre>
			자바클래스를 이용한 커스텀 태그 만들기<button>더보기</button>
			<pre>
				ㅡ 두가지 형식으로 만들수 있다) '클래식'과 '심플'
					ㄴ 심플형태가 최근에 나온건데 이를사용하면 대부분원하는것을 다할수있어서 클래식은 거의안쓰임.
					ㄴ 클래식으 쓰일때는 이미클래식형태로 만들어져서 그걸 유지보수할때 정도라고함.

				ㅇ 사용의 전체적인 방식은
					1. 원하는 동작을 수행할 클래스를 만든다.
					2. 해당클래스를 TLD파일에 등록하며 페이지에서 사용하기위한 여러가지 설정을 해준다.
					3. 페이지에서 지시자를통해 해당 커스텀태그를 사용할것이라 선언해준뒤, 만든 태그를 호출하여 사용한다.

				ㅇ 커스텀 태그 사용하는방법
					ㅡ 형식은 다음과같다.
						< %@ taglib prefix="(*prefix*)" uri="(*tld에서 지정한uri*)"%>	=>taglib지시자로 사용할 커스텀 태그를 설정.
							~~
						<(*prefix*):(*태그이름*) (*속성*)="(*속성값*)"/>	=>TLD에서 설정한 데이터를 토대로 커스텀태그 호출.
					ㅡ 여러 커스텀태그를 사용하려면 taglib지시자를 여러개 정의해야함.

				ㅇ TLD파일 등록하는법
					ㅡ 전체적인구조는 다음과같다.
						< tlib-version>~~~
						< short-name>(*아마 tld파일의이름?*)< /short-name>

						< uri> (*jsp지시자 taglib에서 사용할 uri이름*) < /uri>

						< tag>
							< description>< /~~>
							< name>(*태그이름*)< /~~>
							< tag-class>(*태그사용시 컨테이너가호출할 클래스*)< /~~>
							< body-content>(*태그몸체에 관한 설정*)< /~~>

							< attribute>	=>태그의 속성들을 설정하는부분. 속성하나당이 < attribute>태그를 하나 설정해야함. 여러개면 여러개설정.
								< name>(*속성이름*)< /~~>
								< required>(*참거짓값*)< /~~>	=>속성이 필수인지.
								< rtexprvalue>(*참거짓값*)< /~~>	=>속성값을 어떤식으로 표현할지설정.
							< /attribute>
						< /tag>

						ㄴ< name>, < tag-class>, < body-content>는 필수항목이다.
						ㄴ< rtexprevalue>는 속성값이 런타임시 실행(평가)할건지, 변환시 실행할건지 결정하는 태그라고한다.(뭔소린지..)
							ㄴ false이면 String형태만 가능하며, true이면 el표현식, 스크립팅,< jsp:attribute>표준액션으로 표현이가능하다.
							ㄴ 디폴트값은 false. 태그를 정의하지않으면 디폴트설정.
						ㄴ < body-content>는 커스텀태그의 몸체에 무엇이들어갈지를 결정하는부분이다.
							ㄴ 들어갈수있는값으로 empty, scriptless, tagdependent, JSP가 있다.
							ㄴ empty는 몸체가없음을뜻함.
							ㄴ scriptless는 스크립팅(스크립틀릿, 스크립팅표현식, 선언문)이 올수없다는뜻이다.
							ㄴ tagdependent는 태그몸체를 그냥 텍스트로 취급한다.
							ㄴ JSP는 JSP안에 들어갈수있는것이라면 무엇이든지 가능하다는뜻.
						ㄴ < uri>는 url이 아니며, 그냥 커스텀 태그 라이브러리에 붙여주는 유일한 이름일 뿐이다. url형식으로 써있어도 그냥 이름으로서의 기능일뿐.
							동일한 웹어플리케이션 내에서 이 uri가 겹쳐선 안된다. 그러다보니 관습적으로 사용하는게 도메인 이름일뿐이며, 외부로 배포할것이아니라면 굳이 이렇게쓸필요없다.

						*< jsp:attribute>
							ㅡ 태그에 속성을 설정하는 방법의 일종
							ㅡ 태그의 몸체부분에 삽입되어 속성을 정의할수있으며,
							ㅡ 커스텀태그에서 < body-content>가 empty로 설정되어 몸체가 없다고 설정되어있어도 사용가능하다
							ㅡ ex) 	< AAA:aaa>
										< jsp:attribute name="(*속성이름*)"> (*속성값*) < /~~>
									< /AAA:aaa>
								=>부여하려는 속성이 여러개면 < jsp:attribute>를 여러개 써서 각각 속성값들을 주어야함.

				ㅇ TLD파일의 위치
					ㅡ 컨테이너가 사용자정의태그를 사용하기위해 tld파일을 읽어올때 찾아보는 정해진 위치가 있다.
					ㅡ WEB-INF아래, 또는 WEB-INF안의 디렉토리 아래. 만약, JAR파일로 배포했다면, WEB-INF아래 lib아래 JAR아래에 있는 META-INF아래, 또는 META-INF안의 디렉토리 아래.
						이렇게 네군데이다.

				ㅇ 커스텀 태그 핸들링 클래스 만들기
					ㅡ 커스터태그 호출시 실행되는 클래스를 커스텀태그 핸들링클래스라고한다.
					ㅡ 해당클래스는 SimpleTagSupport클래스를 상속받는다.
					ㅡ doTag()는 해당태그가 실행되면 컨테이너에의해 실행되는메소드로, 사용자가 이를 오버라이딩하여 원하는 작업을 수행한다.
					ㅡ set(*대문자로시작하는 속성이름*)( String (*속성이름*))은 역시 컨테이너에 의해 태그실행시 태그의 속성값들을 가져와 저장해주는 메소드이다.
						메소드이름은 자바빈의 getter,setter과 같은방식으로 설정된다.
					ㅡ 태그핸들링클래스의 일생)
						1. 컨테이너에 의해 클래스 로드를 통해 심플 태그 클래스 .class파일이 가져와짐.
						2. 클래스 인스턴스화로 태그핸들러 디폴트 생성자 실행.
						3. setJspContext(JspContext)호출. 태그핸들러 객체가 pageContext 참조객체를 가짐.
						4. 다른태그 내부에서 커스텀태그가 실행되었다면 setParent(JspTag)호출. 부모태그와 통신이가능해짐.
						5. 속성이있다면 setter호출.
						6. < body-content>값이 empty가 아니라면 setJspBody(JspFragment)호출. 태그몸체에 접근가능.
						7. doTag()호출.

				ㅇ 심플 형태의 커스텀 태그핸들링 클래스
					ㅡ SimpleTagSupport는 SimpleTag인터페이스를 구현하며, SimpleTag인터페이스는 JspTag인터페이스를 상속받는다.
						(각각 어떤메소드를가지고있는지는 api찾아보기)
					ㅡ 심플 태그 핸들러 클래스는 매번 호출때마다 인스턴스를 새로생성하여 작동한다. 캐시에 저장되거나 하는 재사용은 이루어지지않는다.
						클래식 태그 핸들러는 재사용된다고함.

					ㅡ 커스텀 태그 몸체에있는 내용을 사용하고싶으면 TLD에 < body-content>값이 empty가 아니어야하고, 태그핸들링클래스 내부에선
						getJspBody().invoke( (*커스텀태그몸체읽은뒤출력할곳*) ) 을 사용하여 써야한다.

				ㅇ 클래식 형태의 커스텀 태그핸들링 클래스
					ㅡ 커스텀태그를 호출하는 jsp페이지, 등록하는 TLD페이지에서는 심플태그핸들링 클래스를 사용할때와 차이점이없고 핸들러 클래스 코드상에서만 차이가있다.
					ㅡ 클래식 태그핸들러 클래스는 Tag, IterationTag인터페이스를 구현해야하며 보통 이를 구현하는 TagSupport 클래스를 상속받아 만든다.
					ㅡ 클래식 태그핸들러클래스는 컨테이너가 재사용을한다. 인스턴스 멤버변수에 주의.
					ㅡ doStartTag(), doEndTag()메소드를 오버라이딩하여사용. 심플태그클래스의 doTag()같은것. 작동방식은 메소드 이름그대로. 태그 시작할때 실행되는
						doStartTag(), 이후 태그몸체처리하고, 끝날때 doEndTag().
						ㄴ 이외에도 doAfterBody()가있다. 몸체가 실행된 이후에 호출되는메소드. (이 메소드에서 EVAL_BODY_AGAIN을 반환한느것을 통해 몸체부분을 반복할수있다.)
						ㄴ doStartTag()는 SKIP_BODY, doAfterBody()는 SKIP_BODY, doEndTag()는 EVAL_PAGE가 디폴트 리턴값이다.
						ㅡ 오버라이딩한 메소드들은 컨테이너가 다음에 어떤동작을 수행할지 정수형태의 미리정의된값을 반환해야함.
						ㄴ SKIP_BODY : 몸체가 있더라도 실행하지말고 바로 doEndTag()를 실행하라는 값
						ㄴ EVAL_PAGE : 태그를끝내고 페이지뒷부분을 실행하라는값.
						ㄴ EVAL_BODY_INCLUDE : 몸체를 실행시키라는값.
						ㄴ EVAL_BODY_AGAIN : 몸체한번더실행시키라는값.
						ㄴ EVAL_BODY_BUFFERED : BodyTagSupport 클래스를 상속한경우사용가능. 이클래스의 메소드를 실행시키라는값.
						ㄴ ex)	~~~
							return SKIP_BODY;	=>이렇게반환해주면 컨테이너가 반환값에 해당하는동작을취한다.
						ㅡ 클래식 커스텀태그클래스의 메소드 동작순서)
							<img src="image/클래식 커스텀태그 클래스 메소드순서.jpg" style="height:600px; width:auto;">
						1. doStartTag() : 태그 시작할때
							EVAL_BODY_INCLUDE리턴시)
								1-1. 몸체실행정수를 리턴했으면 몸체실행.
								1-2. doAfterBody() : 몸체실행후.
							EVAL_BODY_BUFFERED리턴시)
								1-1. setBodyContent() :
								1-2. doInitBody() :
						2. doEndTag() : 태그 끝날때
						3. 원래 페이지 실행.

				ㅇ 커스텀태그의 동적속성 전달
					ㅡ 커스텀태그에서 속성이 많을경우, 이것들을 일일이 setter메소드로 정의하게되면 코딩이 길어지게 되는데, 이에대한 해결책으로 커스텀태그에서 속성을 전달시 이를
						동적으로 설정해주는 기능이 있다
					ㅡ DynamicAttributes 인터페이스를 이용하면 동적 속성전달이 가능하다. 이 인터페이스의
						setDynamicAttribute( (*uri*), (*속성이름*), (*속성값*) ) 메소드를 이용하면된다
						ㄴ 이 메소드는 해당 커스텀태그의 TLD에서 attribute로 정의되지않은 속성이 커스텀태그로 전달되면 그 속성이름과 값을 인자로 받으며 호출되는 메소드이다.
						ㄴ 매개변수 (*uri*)는 속성의 네임스페이스라고한다. (*디폴트 네임스페이스면 null이라한다.)
						ㄴ uri, 속성이름은 String형이고 속성값은 Object형이다.
					ㅡ 호출되기만 하므로 메소드를 정의해서 사용해야함.
					ㅡ 일반적으로 동적 속성은 name/value 쌍으로 속성을 저장하기좋은 hashmap형태로 저장한다고한다.
					ㅡ 이를 사용하려면 TLD에서 < dynamic-attribute>를 < tag>아래에 추가하고 true값을 설정해주어야한다.
					ㅡ 심플 태그 클래스와 클래식 태그 클래스 둘다 동작한다.
					ㅡ 태그파일로도 사용할수있다.
						ㄴ 똑같은 원리로 동작하며,
						ㄴ tag지시자에서 dynamic-attribute속성을 추가하고 속성값으로 동적 속성을 받을 hashmap형 변수이름을 정해주면 동적속성이 추가될시 이 hashmap변수로 저장된다.
							속성이름은 hashmap의 'key'라는 이름으로 속성값은 'value'란 이름으로 저장된다.
					ㅡ 주의)
						ㄴ 물론 동적속성을 사용하더라도 기본적인 속성을 설정할수있다. (TLD에서 < attribute>를 사용해서..) 이경우 일반적인 setter메소드를 정의하여 속성값을 받아주어야한다.

				ㅇ BodyTagSupport 클래스
					ㅡ 커스텀태그의 몸체부분을 가지고 어떤 작업을 하고자 할때 사용한다고함.
					ㅡ IterationTag 인터페이스를 상속하는 BodyTag 인터페이스를 구현하는 클래스이며, TagSupport 클래스를 상속한다.
					ㅡ setBodyContent(), doInitBody()가 새롭게 추가되며, doStartTag()에서 EVAL_BODY_BUFFERED를 리턴하면 setBodyContent()가 실행되고 이 메소드 이후에 doInitBody()가 실행된다.
					ㅡ 정확히 무슨 기능을 하는지 잘모르겟다....

				ㅇ 협업태그
					ㅡ 커스텀태그가 부모자식의 구조로 있을때 상위,하위태그사이에 통신을 할수잇는 기능이 존재한다.
					ㅡ 자식태그가 부모태그에 접근)
						ㄴ SimpleTag인터페이스와 Tag인터페이스에있는 getParent()메소드로 부모태그에 접근할수잇고 이를통해 부모의 태그와 통신할수있다.
						ㄴ findAncestorWithClass( (*시작태그*), (*찾고자하는태그핸들러클래스*) )를 이용해 부모를넘어선 조상커스텀 태그 클ㄹ래스를 바로찾을수있다.
					ㅡ 부모태그가 자식태그에 접근)
						자식태그쪽에서 getParent()로 부모태그클래스에 접근한 다음 자신을 부모태그클래스에 등록해둔다.
					ㅡ getParent()의 반환형을 보면 알수있지만 심플커스텀태그 클래스는 같은 심플커스텀태그클래스는 물론 클래식 커스텀태그 클래스도 부모태그로 가질수있다.
						ㄴ클래식 커스텀 태그 클래스는 같은 클래식 태그클래스밖에 부모로 가질수없다.

				ㅇ 커스텀태그 핸들러 클래스와 PageContext
					ㅡ 커스텀태그핸들러클래스는 서블릿도, jsp도 아니기때문에 내장객체접근이 바로는안되지만 PageContext에 대한 참조를 가지고있어서 필요한 내장객체를 사용할수있다.
					ㅡ 클래식커스텀태그 클래스의경우 PageContext, 심플커스텀태그 클래스의 경우 JspContext이다.

			</pre>
			태그파일을 이용한 커스텀 태그 만들기<button>더보기</button>
			<pre>
				ㅇ 태그파일이란?
					ㅡ jsp문법을 이용해 개발한 커스텀태그이며, 간단하여 내부용?으로 사용된다고한다.
					ㅡ jsp페이지처럼 작성을 하며, 태그파일만의 지시자를 가진다.

				ㅇ 태그파일 만들기??
					ㅡ jsp파일의 일종이므로 만드는것도 jsp페이지와 거의 유사.
					ㅡ 지시자는 태그파일만의 지시자 사용.
					ㅡ 작성후 파일의 확장자를 '.tag'로 저장.
					ㅡ 파일의 이름이 커스텀태그의 이름이 된다.
					ㅡ jsp파일이기도하므로 jsp의 내장객체 사용가능. (단, ServletContext는 없고 대신 JspContext를 사용해야함)

				ㅇ 태그파일의 지시자들
					ㅡ jsp의 지시자와 똑같이 < %@ (*지시자*) ~~ %> 형식을 사용한다.

					ㅡ taglib : 태그파일에서 사용할 태그라이브러리를 명시할때 사용. 문법은 jsp페이지와동일.
					ㅡ include : 태그파일에 특정파일을 포함시킬때사ㅏ용. 포함될파일은 태그파일에맞는문법으로 작성해야함.(?)

					ㅡ variable : EL변수로 사용될 변수에 대한 정보를 지정.

					ㅡ attribute 지시자 : 태그파일이 커스텀태그로쓰일때 입력받을 속성명시.
						ㄴ attribute 지시자 속성들)
							ㄴ description : 속성에 대한 설명
							ㄴ name : 속성 이름, 태그 파일 내에서 스크립트 변수나 EL변수의 이름으로 사용, 각각의 attribute 디렉티브는 name 속성의 값이 달라야한다. tag 디렉티브(dynamic-attributes), variable 디렉티브(name-given) 속성과 값이 같으면 에러가 발생한다.
							ㄴ required : 속성의 필수 여부를 지정, 필수일 경우 true 아닌 경우 false를 값으로 지정, 기본값은 false
							ㄴ rtexprvalue : 속성 값으로 표현식을 사용할 수 있는지의 여부를 지정, 기본값은 true
							ㄴ type : 속성 값의 타입을 명시, int 등의 기본 데이터 타입은 명시할 수 없고 java.lang.Integer 와 같은 래퍼 타입을 사용, 기본값은 java.lang.String
							ㄴ fragment : < jsp:attribute> 액션 태그로 속성값을 전달할 때 true로 지정, true일 경우 rtexprvalue은 자동으로 false, type은 javax.servlet.jsp.tagext.JspFragment가 된다.
						ㄴ  전달한 속성값 사용법)
							attribute지시자로 전달한 속성은 지시자의 name속성값을 태그파일 안에서 스크립트요소나 EL식으로 변수처럼 사용할수있다.
						ㄴ 전달한 속성값의 생존범위)
							이렇게 부여된 속성값은 모두 tag생존범위이다. tag생존범위란 태그범위내, 태그파일 안에서만 유효한것.
						ㄴ 커스텀태그 몸체 전달하기)
							전달하려는 속성값이 많다면 태그의 몸체를 통째로 넘기는 방법도 있다.
							1. tag파일의 tag지시자에 body-content속성값으로 empty대신 tagdependent 또는 scriptless로 설정한다.
							2. 태그파일에서 < jsp:body/>를 이용해커스텀태그의 몸체내용을 그대로 가져온다.
							ㄴ 커스텀태그의몸체를 전달하려할때 몸체에는 일반텍스트, EL, < jsp:include>만 올수있다. 스크립트요소는 x.

						ㄴ 속성 fragment가 true일경우)
							ㄴ attribute지시자의 fragment 속성값이 true이면, jsp에서 이 커스텀태그로 속성값을전달할때 < jsp:attribute>액션태그를 사용해야한다.
							ㄴ < jsp:attribute>의 몸체에는 텍스트, EL, < jsp:include>액션태그를 사용할수있다.(스크립트코드는x)
								*< jsp:attrubute>
								ㅡ 몸체에는 텍스트, EL, < jsp:include>액션태그를 사용할수있다.(스크립트코드는x)
								ㅡ 속성으로
								ㄴ name : 속성의 이름. 필수.
								ㄴ trim : 속성값 좌우의 공백문자들을 제거할지의 여부. 기본값은 true.
							ㄴ 이렇게 설정한 속성값은 태그파일에서 < jsp:invoke> 액션태그를 이용해 사용가능.
								*< jsp:invoke>
								ㅡ ~~~~~~~~~~~~~~~

					ㅡ tag지시자 : jsp페이지의 page지시자와 같은역할. 태그파일의 정보를 표시.
						ㄴ 속성들)
							ㄴ display-name : 태그 파일을 도구에서 보여줄 때 사용될 이름을 지정, 기본값은 확장자 ".tag"를 제외	한 태그 파일의 나머지 이름이다.
							ㄴ body-content : 몸체 내용의 종류를 입력, empty, tagdependent, scriptless 중 한가지를 사용, 기본값은 scriptless
							ㄴ dynamic-attributes : 동적 속성을 사용할 때, 속성의 < 이름,값>을 저장하는 Map 객체를 page 범위에 속성에 저장할 때 사용할 이름을 명시, EL에서 변수이름이로 사용할 수 있다.
								( JSP 페이지의 pageContext 와 비슷하게 jspContext 기본 객체를 지원한다. )
							ㄴ description : 태그에 대한 설명
							ㄴ import : 사용할 자바 클래스를 지정
							ㄴ pageEncoding : 페이지 자체의 캐릭터 인코딩을 지정
							ㄴ isELIgnored : page 표현 언어를 지원할 여부를 지정
							ㄴ deferredSyntaxAllowedAsLiteral : #{ 문자가 문자열 값으로 사용되는 것을 허용 여부를 지정
							ㄴ trimDirectiveWhitespaces : 출력 결과에서 템플릿 텍스트의 공백 문자를 제거할지의 여부를 지정

				ㅇ  태그파일 위치 ( 컨테이너가 태그파일을 찾는 위치)
					ㅡ WEB-INF아래에 tags폴더 또는 그 하위폴더에 위치.
					ㅡ 또는 WEB-INF/lib에 JAR파일로 배포되었다면, JAR파일 META-INF/tags폴더 또는 그 하위폴더에 위치.

				ㅇ  사용방법)
					ㄴ jsp페이지에서 taglib지시자이용.
					ex)	 <%@ taglib prefix=" (*prefix*) tagdir=" (*tag파일이있는 위치*) " %>
						~~
						<(*prefix*) : (*tag파일 이름*) ~~> ~~ < /~~>
						ㄴ 커스텀 태그 몸체에 스크립팅요소(js, 표현식)을 사용할수없다.

			</pre>
			기타<button>더보기</button>
			<pre>
				*JspFragment 클래스
					ㅡ jsp코드를 나타내는 객체.
					ㅡ 심플 태그핸들러나 < jsp:attribute>액션의 몸체부분에 쓰인다.
					ㅡ 내용으로 스크립팅요소를 사용할수없다.
					ㅡ invoke( (*java.io.Writer*) ) 메소드가 정의되어있어서 내용을 해당 Writer로 출력한다.

				ㅇ SkipPageException
					ㅡ 심플태그핸들러에 의해던져지며,
					ㅡ 페이지의 나머지부분이 처리되지않도록한다. 중단시킨다.
					ㅡ 이 예외를던지면 이후에 부분의 처리를중지하고 지금까지처리한부분만 응답으로 넘김.
					ㅡ 태그를 직접호출한 페이지으작업만 중지한다.

				ㅇ 클래식 태그핸들러 클래스
					ㅡ 오버라이딩한 메소드에서 던지는 예외도 JspException 하나이다. IOException은 따로 처리해주어야한다.
			</pre>


		</pre>

		웹 어플리케이션 배보<button>더보기</button>
		<pre>
			ㅡ 웹 사이트 배포란?
				개발된 사이트를 일반사용자가 사용할수있도록 프로덕션 서버에 올리는 작업을 말한다.
			ㅡ 배포의 주요 토픽세가지)
				ㄴ 웹어플에 어느 위치에 개발한 것들을 저장하는가
				ㄴ 컨테이너는 웹어플에 어느위치에서 자원을 찾는가
				ㄴ 웹 어플 컨텐츠를 어떻게 요청하면 되는가

				* 배포 툴이나 ANT빌드 스크립트? 를 이용하면 쉽게 배포할수있다고함
				ㅡ 하지만 내부적으로 어떻게 ㄷ동작하는지는 알아야하지않을까.

			* 아카이브 파일
				ㅡ 뭔가를 저장한다는 뜻으로, 압축파일을 의미한다.
				ㅡ zip, rar, jar, war, ear 등등의 확장자가 있다.

			* jar파일이란
				ㅡ 일종의 자바 프로젝트 압축파일이다. 자바프로그램이나 자료등을 패키징하는 기능.
				ㅡ 아카이브 파일의 일종. 여러개의 파일을 하나의 파일로 묶어놓은것. 디렉토리정보를 가진채 들어있다.
				ㅡ zip파일 압축 알고리즘을 기반으로 만들어져 알짐과같은zip프로그램과 호환가능하다.
				ㅡ jar cf (*압축된파일의 이름*) 이런식으로 압축을하고, far xf (*압축풀려는파일이름*) 을 이용해 압축을 푼다.
				ㅡ 압축을 풀면 META-INF란 폴더가생기며 안에 manifest.mf파일이 생겨있는데 이는 jar파일의 사용메뉴얼이나 스펙등의 내용을 담고있다고보면된다.

			*WEB-INF/lib 폴더
				ㅡ jar파일을 넣어둘수있는 폴더.
				ㅡ 이곳에 .jar파일을 넣어두면 이 파일을 classpath에 추가한것처럼 사용이 가능해짐.
			* WEB-INF폴더
				ㅡ 웹 어플리케이션용으로 따로만들어진폴더.
				ㅡ 자원이 노출되지 않도록 만든 폴더.

			ㅡ WAR파일
				ㄴ Web Application ARchive.
				ㄴ 자바에서 웹관련 자원을 모으는 jar파일이다.
				ㄴ jar, war 모두 그냥 파일을 패키지화하여 저장하는파일로, 프로젝트에서 라이브러리로 추가하기만하면 그 파일을 사용할수있다. 톰켓에 있는 .jar파일들을
					라이브러리 추가해서 프로젝트만들던것처럼.
				ㄴ 웹 어플리케이션에선 웹 어플리케이션 디렉토리 자체를 압축하는것이 아닌 웹어플리케이션 디렉토리'에서' 압축을 실행한다.
					ㄴ 따라서 압축한war파일과 웹어플리케이션의 이름이 같지않고, 컨테이너가 이를 매핑해야하는데 이 매핑하는 방식이 컨테이너마다 조금씩 다르다고한다
						(톰캣의 경우 war파일과 웹어플리케이션의 이름을 일치시켜준다고함)
				ㄴ war파일이라고 다른 웹어플리케이션 구조와 거의 다를건 없고 그대로 저장되어 옮겨짐. 차이점이라고는 META-INF라는 폴더하 하나 추가되며,
					안에 MANIFEST.MF파일이 추가됨.
				ㄴ 배포방법)
					ㄴ webapps폴더에 war파일을 옮겨놓기만하면 톰켓이 알아서 해당 웹어플리케이션 폴더를 만들어 압축을푼다고함.

			ㅇ 자원의 위치
				ㅡ 유저에 의해 직접 접근되어도 상관없는 자원은 웹 어플리케이션 폴더 아래에 두는식으로,
				ㅡ 직접접근하면 안되는 자원은 WEB-INF나 META-INF아래에 두면된다. 이 두폴더 아래에있는 자원들은 직접 요청될수 없다.

			ㅇ DD를 통한 서블릿 매핑 방법
				ㅡ < url-pattern>을 통해 요청받는데 이 url-pattern은 실제 구조가 아닌 만들어낸 가상/논리 구조이다.
				ㅡ url-pattern을 ' /Beer/* ' 이런식으로 디렉토리까지만 설정할수있고, ' *.do ' 와같이 확장자까지만 설정할수있다.
				ㅡ url-pattern을 통해 매핑하는 방법)
					1. 우선 요청받는 url과 완전히 패턴이 일치하는 < url-pattern>을 찾아 매핑
					2. 디렉토리가 일치하는 패턴을 찾아 매핑
					3. 확장자가 일치하는 패턴을 찾아 매핑

			ㅇ 환영파일 설정하기
				ㅡ 위와같은 url-patten으로도 일치하는 파일을 찾지못할경우 연결시켜줄 '환영파일'을 설정할수있다.
				ㅡ DD에 < web-app>아래에 < welcom-file-list>태그를 입력한다
					ㄴ < web-app>
						< welcome-file-list>
							< welcome-file> (*환영파일이름*) < /~~>
							< welcome-file> (*환영파일이름*) < /~~>
						< /~`>
					< /~~>

				ㅡ 작동방식)
					일치하는 파일을 못찾으면 해당 url-pattern의 위치에 welcome-file-list목록에 있는 파일이있는지찾는다. 위에서부터 찾으며, 찾으면 그 페이지 반환.
				ㅡ 사용자가 정확한 자원이름을 입력하지않아도 사이트에 들어올수잇게하는데 쓰인다.

			ㅇ 최초 요청이 아닌 배포시점에 서블릿 초기화하기
				ㅡ 서블릿은 보통 최초 요청시 초기화된다. 이경우 클라이언트쪽에서 이작업을 해야하므로 부담이된다.
				ㅡ DD에서 < load-on-startup>을 이용하여 배포되는시점에서 서블릿을 초기화하도록 설정할수있다.
				ㅡ 사용법)
					< load-on-startup> (*정수*) < /~~>	=>양수일경우 배포시점에서 초기화하도록 설정. 여러개가 초기화되어야하는경우 정수가 작은것이 먼저 초기화됨.
				ㅡ 팁)
					모든 서블릿을 배포시점에서 초기화하는게 좋은것만은 아니다. 거의 안쓰이는 서블릿, 다른서블릿들이 아주 많다는점, 서블릿이 얼마나 오래 메모리에 있어야하는지
						등을 고려해야한다.



		</pre>

		웹 보안<button>더보기</button>
		<pre>
			기본<button>더보기</button>
			<pre>
				ㅡ 보안은 컴포넌트에 의해 제공된다.
					ㄴ 컴포넌트는 '선언적 보안'과 '프로그램적 보안'을 제공한다.

				ㅡ 거의 대부분의 보안관련설정은 선언적으로 이루어진다고한다. 이유는 대략..
					ㄴ 선언적 보안에쓰이는xml은 모르는사람이 없으니까
					ㄴ 서블릿을 더 유연하게쓸수있어서
					ㄴ 유지보수가 쉬워서
					ㄴ 컴포넌트기반 개발을 할수있어서 등등..

				ㅡ 보안의 주요 이슈 4가지
					ㄴ 인증
					ㄴ 인가
					ㄴ 기밀성
					ㄴ 무결성

				ㅡ 역할정보(Role) 설정방법)
					ㄴ 컨테이너마다 이를 설정하는 형태가 다르다고한다.
					ㄴ 톰캣의 경우 conf폴더의 "tomcat-users.xml"이란 파일 안에 저장되어있다. 이를 "톰캣 메모리 상주 영역(Realm)"이라 한다고한다.
						근데 보통 이거 안쓰고 DB같은거 사용한다함.
					ㄴ "tomcat-users.xml"파일은 모든 어플리케이션에 적용되는 내용이 들어있다.
					ㄴ 이 파일안의 역할정보 표현 형식은 다음과 같다.
						< tomcat-users>
							< role rolename="~~~"/>		=>역할의 이름을 설정한다.
							< role rolename="~~~"/>
							< user name="~~~" password="~~~" roles="~~, ~~"/>	=>사용자의 이름과 비밀번호를 설정하고 역할을 부여한다.
						< /tomcat-users>
					ㄴ DD에 < security-role>요소
						< security-role>
							< role-name> ~~~~ < / role-name>	=>컨테이너가 '역할정보'를 이 요소의 값과 매핑한다.
						< /security-role>
				ㅡ '인증'메커니즘을 사용하려면 DD에 다음과같은내용이 있어햐한다.
					< login-config>
						< auth-method>BASIC< /auth-method>
					< / login-config>

			</pre>
			선언적 보안<button>더보기</button>
			<pre>
				ㅡ DD와 Annotation에 보안 요구사항을 나타내는 방식의 보안방법이다.
				ㅇ 예시)
					< security-constraint>
						< web-resource-collection>	=>보호받을 자원들의 컬렉션을 선언하고있다. 여러개 사용할수있다.
							< web-resource-name>Protected Area< /web-resource-name>		=>필수 입력사항이다.
							< url-pattern>/security/protected/*< /url-pattern>
							< http-method>PUT< /http-method>	=> 이요소를 등록하지않으면 모든 메소드에대해 제약을건다는 의미가된다. 반대로 등록한다면, 여기에 등록하지않은 모든 메소드를 허용한단의미.
							< http-method>POST< /http-method>
						< /web-resource-collection>		=>이렇게 작성하면, "/security/protected/*"인 url에 대한 HTTP PUT메소드와 POST에 대해 제약을 건다는 의미가된다.

						< auth-constraint>		=>위 컬렉션에 접근권한을가질 role이름을 설정하고있다. < security-constraint>안에 모든 < web-resource-collection>에 대해 적용된다.
													역시 옵션항목으로, 관련url에 대해 인증을 실시하라고 컨테이너에게 전달하는의미. 없으면 url에대해 인증없이도 접근가능.
							< role-name>manager< /role-name>	=>이 요소는 옵션항목으로, 값에 해당하는 '역할'은 접근을 허용하라고 컨테이너에게 전달하는기능.
																	만약 하나도 없다면 어떤 사용자도 접근이 안된다는의미가된다. 값으로 '*'가오면 모든사용자 접근가능. 값은 대소문자를 구분함.
						< /auth-constraint>

						< user-data-constraint>		=>	전송되는 데이터의 무결성과 기밀성을 설정하기위한 요소.
							< transport-guarantee> (*NONE, INTEGRAL, CONFIDENTIAL중 하나*) < />	=>	NONE은 데이터보호를 안하겟단의미. INTEGRAL은 무결성보장하겟단의미,
																									CONFIDENTIAL은 기밀성을 보장하겟단의미. (일반적인 컨테이너는 SSL을사용하기때문에
																									INTEGRAL, CONFIDENTIAL 둘중 무엇을써도 무결성과 기밀성을 보장해준다함)
						< /user-data-constraint>
					< /security-constraint>

					<!-- Security roles used by this web application -->
					< security-role>		=>어플리케이션에서 사용할 role들을 선언하고있다.
						< role-name>manager< /role-name>
					< /security-role>
					< security-role>
						< role-name>employee< /role-name>
					< /security-role>

				ㅡ 자원의 단위로 제약을 거는게 아니라 HTTP요청(메소드)단위로 제약을 거는것이다.

				ㅡ 같은 자원에 대해 두개이상의 < security-constraint>가 정의되어있다면, 두 < auth-constraint>의 내용에 따라 접근제어가 달라진다.
					ㄴ 둘중 한 < security-constraint>에 < auth-constraint>가 정의되어있지않다면(누구나 접근가능하단의미의 경우), 어떤 '역할'이든 접근가능하다.
					ㄴ 둘중 한   < security-constraint>에 < auth-constraint>의 내용이 없다면(< role-name>이 없다는 얘기로, 누구도 접근이 안되는경우), 누구도 접근할수없다.
					ㄴ 이 외의 경우에 어떤 '역할'이 등록되어있으면 어느쪽의 < security-constraint>이든 등록된 '역할'들은 모두 접근가능하다.

				ㅇ 인증의 4가지 방식
					ㅡ 컨테이너가 제공하는 방식이 4가지가 있고, 이들간의 가장 큰 차이는 '이름과 패스워드 정보를 얼마나 안전하게 전송하느냐'이라한다.
						1. BASIC : 로그인 정보를 '인코딩'(암호화하지는 않은상태) 형태로 전송. 인코딩방식인 base64는 잘알려진방식이기때문에 별로 안전하지않다.
						2. DIGEST : 보다 안전하게 전송함.
						3. CLIENT-CERT :  '공인 키 인증(PKC)'를 이용하여 매우 안전한 형태로 로그인정보를전달. 단점은 클라이언트가 시스템에 로그인하기전에
								인증서를 가지고있어야한다는것. 보통환경에서 가지고있기는 드물기에 비즈니스환경에서 주로쓰는방식.
						4. FORM : 위 세가지 방식과 달리 로그인정보를 넣기위한 방법으로 표준 팝업 폼을 사용하지않음. 자신만의 로그인폼을 제공하는방식이며,
								가장 보안이 약한방식. 로그인정보가 HTTP요청 형식으로 암호회되지않고 서버로 전송됨.
					ㅡ 각 방식을 사ㅏ용하는법은 DD의 < web-app>요소 아래에 < login-config>를 이용해 설정.
						ex)	< login-config>
								< auth-method> (*BASIC, DIGEST, CLIENT-CERT, FORM 중 하나 *) < /auth-method>
							< /login-config>
					ㅡ BASIC, DIGEST, CLIENT-CERT방식은 이 방식이 지원이 된다면 컨테이너가 알아서 처리해준다.
					ㅡ FORM방식을 사용할경우 < login-config>안에 추가로 설정해야할것들이있다.
						ㄴ 개요) 	1. 사용자가 로그인할 폼 페이지를 작성한다.(html이나 jsp)
							2. 로그인 실패시 보여줄 오류페이지를 html로 작성한다.
							3. < login-config>에 이둘을 묶어준다.
						ㄴ DD에 설정 ex)
							< login-config>
								< auth-method>FROM< />
								< form-login-config>	=>FORM방식 사용시 추가로 설정할 부분.
									< form-login-page> (*로그인 페이지url*) < />
									< form-error-page> (*로그인실패시 오류페이지 url*) < />
								< />
							< />
						ㄴ 로그인페이지 작성)
							~~~
							< form method="~~" action = " j_security_check " >	=>컨테이너와의 협업을위해 action은 저값이어야함.
								< input type="text" name="j_username">	=>사용자이름에 해당하는 input의 name값도
														j_username으로 정해져있음.
								< input type="password" name="j_password">	=> 비밀번호도 마찬가지.
								< input type="submit">
							< />
						ㄴ 에러페이지는 그냥 만들면된다.

				ㅇ '안전이 보장된 전송 계층 연결'
					ㅡ 이를 사용하면, FORM방식을 사용해도 전송되는 데이터의 '무결성'과 '기밀성'을 지킬수 있다.
					ㅡ 보통 SSL기반 HTTPS를 사용하여 이를 사용하게된다.
					ㅡ 그냥 HTTP요청과 달리 HTTPS요청은 강력한 보안처리가 되기때문에 요청의 내용을 제 3자가 볼수 없다.
					ㅡ < user-data-constraint>의 < transport-guarantee>를 이용하여 설정한다.
					ㅡ 보안방식 과정)
						ㄴ < transport-guarantee>가 NONE인경우)
							1. 클라이언트가 요청을보냄
							2. 컨테이너는 요청한 자원에대해 전송보장방식을 확인, NONE이란것을 확인.
							3. 컨테이너는 클라이언트에게 401응답을 보내 로그인정보를 물어봄.
							4. 로그인정보가 보호되지 않은 형식으로 컨테이너에게 날라오고, 컨테이너는 클라이언트가 권한이있는지확인하고 요청햇던 자원을
								보내줌.
						ㄴ < transport-guarantee>가 INTEGRAL이나 CONFIDENTIAL인경우)
							1. 클라이언트가 요청을보냄
							2. 컨테이너는 요청한 자원에 대해 전송보장방식을 확인, INTEGRAL(CONFIDENTIAL)임을 확인.
							3. 컨테이너는 클라이언트에게 301 Redirect응답을 보내어 "안전한 방식으로 다시요청할것을 요청"
							4. 클라이언트는 HTTPS와 같은 안전한 전송방식으로 같은 요청을 다시보냄.
							5. 컨테이너는 요청한 자원에 제약이 걸려있음을 확인하고 401응답을 보냄.
							6. 클라이언트는 로그인정보를 보냄(보안연결을 통해 전송되어 안전하게전송됨).
						ㄴ 즉, 전송보장방식이 설정되어있으면 컨테이너는 보안연결이 되어있지않으면 요청을 받지않는것.

				ㅡ DD에서 사용되는 요소들은 다음과 같다.
					1. < security-constrain>
						ㄴ URL매핑을 사용해서 자원의 컬렉션에 대한 접근권한을 정의한다. 여러개 사용할수있다.
						ㄴ 하위 요소로 다음이 있다)
							1-1. < web-resource-collection> : 보안규제가 적용되어야할 자원집합이나 HTTP 메소드를 선언하는요소.
								ㄴ < web-resource-name> :
								ㄴ < url-pattern> : 보호받을 요청url을 나열하는 요소. 입력하는 request URL은 호스트이름과 포트이름이후에 나오는 URL의 일부를 말한다.
									ex)	/cart/* 라고 썼으면,
										http://localhost:8080/myapp/index.xhtml => 보호되지않음
										http://localhost:8080/myapp/cart/index.xhtml => 보호됨.
								ㄴ http-method 또는 http-method-omission : 어떤메소드가 보호되어야하고 아닌지를 명시한다. HTTP메소드는 다음상황중 하나 아래있을때 web-resource-collection에 의해 보호된다.
									ㄴ 컬렉션에 명명된 HTTP메소드가 없는경우. 이는 모든 메소드가 보호되고있음을 의미한다.
									ㄴ 컬렉션이 < http-method>에 HTTP메소드를 명명하고있는경우,
									ㄴ If the collection contains one or more http-method-omission elements, none of which names the HTTPmethod
							1-2. < auth-constraint> : 컬렉션에대한 접근이 허가되어야하는 role들을 선언하는요소.
								ㄴ < role-name>하위요소가 있고, 이는 인가받을 권한이있는 role이름들을 명시하는요소이다. 여러개 사용할수있다.
								ㄴ 내용으로오는 role 이름은 < security-role>의 이름중하나와 일치하거나, 모든 role을 의미한느 예약 '*'이어야한다.
								ㄴ role name은 대소문자를 구분한다.
								ㄴ The roles defined for the application must be mapped to users and groups defined on the server, except whendefault principal-to-role
									mapping is used.
								ㄴ??? 서블릿의 경우, @HttpConstraint, @HttpMethodConstraint어노테이션이 rolesAllowed요소를 받는다.
							1-3. < role-name> : 여기서 사용되는 < role-name>은 < security-role>의 < role-name>중 하나와 일치해야한다. 또는 특별하게
									예약된 role-name인 '*'이어야한다(어플리케이션의 모든 role을 지칭하는 이름).
							1-4. < user-data-constraint> : 클라이언트와 컨테이너간 통신되는 데이터가 어떻게 보호되어야하는지를 하위요소인 < transport-guarantee>를통해 나타내는 요소.
									< transport-guarantee>는 NONE, INTEGRAL,CONFIDENTIAL의 값중하나를 가질수있다.
									ㄴ < transport-guarantee>하위요소를 가진다. 이요소는 모든 보호받는 url pattern과 http메소드가 HTTPS같은 보호받는 transport-layer 연결을 사용하도록하는데 쓰인다.
									ㄴ 내용으로 올수있는것으론, CONFIDENTIAL, INTEGRAL, NONE이 있다. 앞의 두개의 사용은 보통 SSL사용의 요청과 < web-resource-collection>에있는 URL패턴에 해당하는
										요청에대해 SSL을 적용시키는걸 의미한다.
									ㄴ CONFIDENTIAL : 다른 개체가 전송되는 내용을 보지못하도록 데이터가 전송되는게 요구될때 사용한다.
									ㄴ INTEGRAL : 데이터가 변경되지않으면서 서버와 클라이언트사이를 전송되는게 요구될때 사용한다.
									ㄴ??? NONE : 연결이 보호받지 않을지라도 어떠한 연결위에서의 보호받는 요청도 컨테이너가 수용함을 의미한다.
					2. < login-config요소>
						ㄴ < auth-method> : 인증 메커니즘을 설정한다. BASIC, DIGEST, FORM, CLIENT-CERT, 또는 vendor-specific 인증스키마를 값으로가진다.
						ㄴ < realm-name> : 인증스키마에 사용될 realm name을 가리킨다.
						ㄴ < form-login-config> : FORM 기반 로그인 메커니즘사용시 사용되어야할 login과 에러페이지를 명시한다.
					3. < security-role요소>
						ㄴ security role을 정의한다.
						ㄴ < role-name> : 값으로 security role의 이름을 지정한다.


				ㅡ tip)
					ㄴ 자원에 누구도 접근못하게하는 경우는 보통 클라이언트로부터 접근은 막아야하지만 같은 어플리케이션에잇는 컴포넌트로부터는 허용해야하는 경우사용된다. dispatch해야
						하는경우처럼.

			</pre>
			프로그램적 보안<button>더보기</button>
			<pre>
				ㅡ 코딩안에, 프로그램적으로 보안을 하는 방법이다.
				ㅡ 선언적 보안만으로 충분치 않을때 유용하게 쓰인다.
				ㅡ EJBContext 인터페이스와 HttpServletRequest 인터페이스의 메소드를 통하여 구현한다.
				ㅡ HttpServletRequest 인터페이스의 메소드들)
					ㄴ authenticate( (*HttpServetResponse형 인자*) ) : caller를 대상으로 '인증'을 실행한다. 로그인창이뜨고, 사용자 이름과 비밀번호를 입력하게한다.
					ㄴ login :
					ㄴ logout :
					ㄴ getRemoteUser : 유저가 인증받았다면 해당 유저를반환. 인증받지않았다면 null반환. (잘사용안된다함)
					ㄴ isUserInRole( (* DD의 < role-name>값에 해당하는 문자열*) ) : remote user가 특정 role인지를 확인. 인자로 넘어가는 문자열은
						< security-role-ref>의 하위요소인 < role-name>의 값을 말함. (< security-constraint>의 < role-name>이 아니라)
						선언적 보안처럼 HTTP요청 레벨에서 보안을하는게 아니라 메소드 내에서 보안작업을 하는데 쓰인다. 이 메소드를 이용해 '역할'에따라 다른 작업을 할수있다.
						이 메소드를 사용하려면 먼저 '인증'을 거쳐야함. 아되어있으면 false반환. 해당 역할이 맞으면 true반환.
					ㄴ getUserPrincipal : 현재 인증받은 사용자의 java.security.Principal 객체를 반환. (EJB에서 주로사용하는거라함)

				ㅡ < securty-role-ref>
					ㄴ '역할'을 가상의, 임시 이름으로 사용할수있게해주는 요소이다.
					ㄴ isUserInRole()은 인자로넘어온 '역할'이름을 < security-role>보다 이 요소에서 먼저 찾아서 매핑한다.
					ㄴ DD에 선언되는 < servlet>의 하위요소이다.
					ㄴ 어플리케이션에 정의된 security role과 위에 나온 메소드 isUserInRole( role )의 인자로넘어가는 role name을 매핑해준다.
					ㄴ ex)
						< servlet>
							< security-role-ref>
								< role-name> (*isUserInRole()의 인자로 넘어갈 문자열 role name*) < /role-name>
								< role-link> (*security role중 하나의 이름.*) < /role-link>
							< /security-role-ref>
						< /servlet>
						~~~
						< security-role>
							< role-name> (*security role이름*) < /~~>
						< /security-role>
						=>컨테이너가 isUserInRole()의 인자로 받은 문자열을 < role-name>에서찾아 해당하는 < role-link>의 이름을 < security-role>의 < role-name>에서 찾아 매핑한다.
							ㄴ 이 요소 선언없이 isUserInRole()가 호출되면, 컨테이너는 이 메소드의 인자로넘어온 role name을 모든 security role리스트와 비교한다.
								(근데 이렇게사용하는건 이 요소를통해 얻을수있는 유연성(서블릿컴파일을 다시할필요없이 role name을 바꿀수있는등)을 가지지못한다고한다)

			</pre>
		</pre>

		MVC패턴<button>더보기</button>
		<pre>
			ㅡ MVC 패턴
				ㄴ 간단하게 말해, 로직부분과 뷰부분을 나누어서 깔끔하고 재사용성 등을 좋게하는 방법론 같은것.
				ㄴ 컨트롤러, 뷰, 모델 세부분으로 나뉘며, 뷰는 보여지는결과부분, 모델은 로직담당부분 컨트롤러는 이둘을 연결하고 컨트롤하는
				부분이라고 보면되겟다.
			ㅡ대략적인 MVC 아키텍쳐 동작과정
				1. 클라이언트가 페이지를 요청
				2. 컨테이너는 어떤서블릿인지 알아내어 해당 서블릿에게 요청을 보냄.
				3. 서블릿(컨트롤러역할)은 java파일(모델역할)을 호출하여 필요한 정보를 얻고
				4. request객체를 만들어 jsp파일(뷰역할)로 forward시킴.
				5. jsp파일에서 클라이언트로 보내줄 결과를 컨테이너로보내면 컨테이너는 결과를 클라이언트에게 출력해줌.
			ㅡ 개발을 하는데 있어서 정형화된 디렉토리 구조 형식이 있는듯하다.
				이런식(https://www.oreilly.com/library/view/head-first-servlets/9780596516680/httpatomoreillycomsourceoreillyimages2244157.png.jpg)
			ㅡ 웹 개발 디렉토리 구조가 있고, 이를 배포하려면 사용할 컨테이너가 지정하는곳으로 디렉토리의 일부를 복사해주는것으로 끝난다고함.
				ex)내가 서블릿 컴파일한 서블릿클래스 파일을 톰켓의 WEB-INF/classes폴더 안으로 넣어주어야 작동하는것처럼.
			ㅡ 컨트롤러가 자바프로그램에서 핸들러같은느낌인가? 뷰는 뭔지알겟고. 컨트롤러와 모델이 헷갈림.
				요청을 컨트롤러(서블릿)이 받아서 자바파일(일반클래스, 모델)을 호출해 처리하고 뷰담당인 jsp페이지로 넘기는 방식?컨트롤러는 방금말한 과정처럼
				전체적인 흐름을 관리하고?
			ㅡ <strong>실습을하는데 서버가 서블릿을 찾지못해 중단.mvc패턴은 대략 위에 나온내용이 전부임(여기서 간단하게만본다햇음).<br>
				xml파일도 이상없어보이고, 서블릿 자바파일도, 디렉토리구조도 똑같지만 404오류가 계속뜸. 이클립스로 옮겨서실행해봐도<br>
				똑같음. 몇시간붙잡고있었지만 노답. 추후해결바람</strong>


		</pre>

		필터와 래퍼<button>더보기</button>
		<pre>
			Filter<button>더보기</button>
			<pre>
				ㅡ 필터란?
					ㄴ 컨테이너와 서블릿 사이에서 요청과 응답을 가로채어 어떤 처리를 해주는 일종의 자바 컴포넌트. (그림 추가 "필터란.jpg)
					ㄴ 서블릿은 필터에 의한 처리를 전혀 알지못함. 별개로 분리되어있음.
					ㄴ 컨테이너는 언제 필터를 실행할지를 DD에 선언된 필터에 대한 정보를 보고판단.
					ㄴ '배포자'가 url패턴과 호출할 필터를 매핑한다.  프로그래머가 아닌 '배포자'가 결정하는것.
					ㄴ 'Filter' 인터페이스를 통해 만들어진다. ( 사용하는 Filter, FilterChain 인터페이스는 javax.servlet 패키지안에있다)
					ㄴ 필터는 '모듈식'으로 DD에 설정한다.
						ㄴ 필터 하나는 하나의 완전한 컴포넌트이다.
						ㄴ DD에 선언한 내용을통해, 여러 필터의 적용순서를 설정하거나, 이 순서에하 한두개를 빼는 식의 설정이 가능하다.
					ㄴ 서블릿과 마찬가지로 생명주기가있다. ( init(), destroy(), doFilter() )

				ㅡ 필터 예제
					import java.io.*;
					import javax.servlet.*;
					import javax.servlet.http.HttpServletRequest;

					public class BeerRequestFilter implements Filter{	=>모든 필터는 반드시 이 인터페이스를 구현해야함.
						private FilterConfig fc;

						public void init( FilterConfig config ) throws ServletException{	=>inti()는 반드시 구현해야한다. 일반적으로 여기서 config객체를 내부에 저장ㅎ한다.
							this.fc=config;
						}

						public void doFilter ( ServletRequest req, ServletResponse resp, FilterChain chain )	=>	doFilter()에서 실제 처리하고자하는 작업을 정의한다.
																											역시 필수구현. 주의점은 인자가 HttpSrevletRequest,
																											Response가 아니라는점. 그냥ServletRequest,Response이다.
							throws ServletException, IOException {
							HttpServletRequest httpReq = (HttpServletRequest)req;	=>HttpServletRequest로 형변환해서 사용가능.
							~~~
						}

						public void destroy() {		=>destroy()역시 반드시구현해야한다. (코딩할내용은 보통 없다함)
							~~
						}
					}

				ㅡ 필터의 생명주기
					ㄴ 반드시 구현해야하는 init(), doFilter(), destroy()가생명주기.
					ㄴ init() : 컨테이너가 필터를 인스턴스화할때 호출됨. 위 예제와 같이 FilterConfig객체를 저장하는것이 전부.
					ㄴ doFilter() : 컨테이너가 현재요청에 필터를 적용해야겟다고판단하면 호출됨. 필터의 기능을 구현하는곳.
					ㄴ destroy() : 컨테이너가 필터 인스턴스를 삭제하려고할대 호출. 인스턴스가 삭제되기전에 뭔가 청소작업이 필요하면 여기에정의.

				ㅡ FilterChain 인스턴스
					ㄴ 필터는 모듈형태이기때문에, 서블릿은 필터가 적용되었는지 아닌지 모르고, 필터도 누가 자신을 불럿는지, 다음에 누가 적용되는지 모르고,
						모듈처럼, 블록처럼 여러개를 섞어서, 순서대로 사용할수있다햇다.
					ㄴ 이때 이 순서를 설정하는것이 FilterChain이다. DD에 선언된 내용대로 순서가 설정된다.
					ㄴ 여기에서 doFilter()가 있는데 이 메소드는 다음호출할 필터가 무엇인지 파악하여 그 필터의 doFilter()를 호출하는 기능을한다.
						다음 실행할 체인이없으면 서블릿을 실행한다.

				ㅡ 여러필터적용의 경우 동작과정)
					ㄴ 예를들어 filter A와 B가 적용된다고하면, 컨테이너는 A를 먼저 실행시키고 FilterChain.doFilter()가 나오면 다음실행될 필터B로 흐름을
						넘겨준다. 같은방식으로 B에서 서블릿으로 실행흐름이 넘어가고, 서블릿 servicer()가 완료되면 흐름이 다시 B로 돌아오고,
						B가완료되면, 흐름이 다시 A로 돌아와 A가 완료됨으로서 컨테이넌는 응답을 완료한다.

				ㅡ 필터 정보 선언하기)
					ㄴ 1. 필터 정의하기  2. 필터와 필터링할 자원 매핑   3. 필터순서 설정
					ㄴ 필터 정의하기)
						< filter>
							< filter-name> (* *) < />	=>필수입력사항.
							< filter-class> (*  *) < />	=>필수입력사항.
							< init-param>				=>옵션입력사항. 여러개가능.
								< param-name> (* *)< /  >
								< param-value> (* *) < /  >
							< / >
						< / >
					ㄴ 매핑하기)
						< filter-mapping>
							< filter-name> (* *) < />		=>필수입력사항. 연결된 < filter>를 찾는데 쓰임.
							< url-pattern> (* *) < />		=>필수( < url-pattern>이나 < servlet-name>둘중하나는 꼭이서야함) 해당 url에 필터를 적용.
							< servlet-name> (* *) < />		=>필수. 해당 이름을 가진 서블릿에 필터적용.
							< dispatcher> (*REQUEST, INCLUDE, FORWARD, ERROR 중 하나*) < /> =>	각각, 클라이언트가 요청한경우, include를통해, forward를 통해,
																							error핸들러를 통해 요청이 들어온경우에도 필터를 적용한다는의미.
																							이 요소는 0~4개까지 사용할수있고 없을경우 디폴트는  REQUEST.
						< />
					ㄴ 컨테이너가 필터순서정하는규칙)
						ㄴ 하나의 자원에 여러필터가 적용되어있을경우, 해당하는 모든 필터를 적용시켜 실행한다.
						ㄴ 순서는 먼저 < url-pattern>으로 적용되는 필터 다음 < servlet-name>으로 적용되는 필터적용. < url-pattern>으로 적용되는 필터중에선,
							DD에 먼저 정의된 매핑이 먼저 적용.

				ㅡ 요청필터와 응답필터)
					ㄴ 응답필터는 따로 없고 doFilter()에서 FilterChain.doFilter()실행 전에 처리하는부분을 요청필터, 이후에 처리하는 부분을 응답필터로서 사용된다.
						서블릿이 실행되고 제어흐름이 다시 돌아오면서 서블릿이만든 응답에 대해 처리를 하는 방식.
					ㄴ 문제는 서블릿 실행중에 서블릿 출력스트림에서 내보내는 응답이 필터로 돌아오지않고 바로 클라이언트쪽으로 넘어간다는점. 해서,
						필터에서 흐름을 받아도 응답은 이미 넘어간 상태가된다.
					ㄴ 이를 해결하기위해, 필터에서 서블릿으로 흐름이 넘어갈때, 실제 response객체가 아닌 새로만든 가상의 response를 넘겨주어 서블릿에서
						처리된 응답결과가 클라이언트로 바로넘어가지 않도록하는 방법을 사용한다. (당연히 이 가상의 response는 HttpServletResponse를
						구현해야한다)
					ㄴ ex)
						~~(*요청필터에서 처리할 내용*)~~
						(*직접만든 래퍼클래스 이름*) (*참조변수*) = new (*직접만든래퍼클래스 이름*)( (*실제 response*) );	=>실제 response를 감싸는 래퍼 response를 만드는 부분.
						chain.doFilter( request, (*참조변수*) ); 		=>다음으로 실행할 서블릿에게 새로만든 response객체를 넘겨주는 부분.
						~~(*응답필터에서 처리할 내용*)~~

				ㅡ tip)
					ㄴ 필터로 정의하면 좋은것들)
						ㄴ '요청필터'의 경우 : 보안관련 내용, 요청 헤더와 바디 포맷팅 수정, 요청 감시 및 기록
						ㄴ '응답필터'의 경우 : 응답스트립 압축, 응답스트립에 내용추가 및 수정, 완전히 다른 새로운 응답 만들기.

			</pre>
			Wrapper<button>더보기</button>
			<pre>
				ㅡ 개요)
					ㄴ 개인적인 개요)
						ㄴ 상속과 비슷한거같다.
						ㄴ 감싸지는대상을 내부에 그대로 가지고있으면서 필요한부분만 수정. 나머지는 그대로 내부의 대상으로 위임하는방식.
					ㄴ 말그대로 어떤 클래스같은걸 감싸는 객체를 말함.
					ㄴ 어떤 클래스를 감싸서 자신에게 들어오는 모든 메소드호출을 자신이 감싼 객체로 돌리는 식으로 작동한다.
					ㄴ ServletRequestWrapper을 예를들면, 이 래퍼클래스 생성시 생성자의 인자로 ServletRequest객체를 전달하고, 이 래퍼클래스를 대상으로 getAttribute()를 호출하면,
						이 메소드가 재정의되지 않았다면 생성자인자로 전달한 객체의 getAttribute()가 호출되는식.
				ㅡ 위 필터에서, 응답필터를 처리하기도전에 응답결과가 클라이언트로 넘어가는문제해결을위해 새로 가상의 response객체를 만든다고했는데,
					(HttpServletResponse를 직접 구현하는건 어려우므로) 이때 이 래퍼를 이용하여 만든다.
				ㅡ 자바 썬에서는 이와 관련하여 4개의 래퍼를 제공한다.
					ServletRequestWrapper, HttpServletRequestWrapper, ServletResponseWrapper, HttpServletResponseWrapper

			</pre>
		</pre>

		파이썬<button>더보기</button>
		<pre>
			ㄴ 파이썬<button>more</button>
			<pre>
				ㄴ 설치<button>more</button>
				<pre>
					ㅡ centos7
						ㄴ centos7에 기본적으로 python 2.7.5 설치.
						ㄴ 압축 파일로 설치 )
							ㄴ 필요한 패키지 설치
								yum install gcc openssl-devel bzip2-devel libffi-devel -y
							ㄴ 파이썬 공홈 다운에서 원하는 버전 다운페이지 들어가 gzipped source tarball의 다운 링크 복사.
							ㄴ centos에서 wget으로 다운
								ex ) wget https://www.python.org/ftp/python/3.9.5/Python-3.9.5.tgz
							ㄴ 압축 해제 ex) tar -xvf Python-3.9.5.tgz
							ㄴ (*압축 해제 폴더*) 들가서 컴파일.
								ㄴ ex )
									cd Python-3.9.5/
									./configure --enable-optimizations
							ㄴ 설치. ex ) make altinstall
							ㄴ 설치 위치 확인. ex) which python3.9
						ㄴ 설치한 python과 'python' 명령어 연결
							ㄴ vi /root/.bashrc
							ㄴ ex )
								# User specific aliases and functions

								alias python="/usr/local/bin/python3.9"  # 'python'이란 별칭 설정. 값으로 python설치 경로.

								alias rm='rm -i'
								alias cp='cp -i'
								alias mv='mv -i'

								# Source global definitions
								if [ -f /etc/bashrc ]; then
										. /etc/bashrc
								fi
							ㄴ 별칭 적용. ex ) source /root/.bashrc
							ㄴ python -V 확인시 새로 설치한 버전 출력.

						ㄴ pip install시, ssl을 통하여 모듈을 받기 때문에 openssl, openssl-devel 패키지 설치 필요.
							ㄴ 적용 안 되었을시, SSLError 발생.
							ㄴ yum -y install openssl openssel-devel
						ㄴ 설치 후, 설정 변경하여 파이썬을 재컴파일해야 적용.
						ㄴ 설정 변경 및 재컴파일 )
							ㄴ (*압축 해제 폴더*) / Modules / Setup 파일을 편집.
							ㄴ '_socket socketmodule.c' 부분 주석 해제,
							ㄴ 다음 부분 주석 해제.
								SSL=/usr/local/openssl
								_ssl _ssl.c \
										-DUSE_SSL -I$(SSL)/include -I$(SSL)/include/openssl \
										-L$(SSL)/lib -lssl -lcrypto
							ㄴ (*압축 해제 폴더*) 에서 다시 'make altinstall'

				</pre>

				ㄴ 개요 )
					ㄴ 인터프리터형, 객체지향적 동적 타이핑(typing) 고수준 언어.
					ㄴ 들여쓰기를 사용하는 독특한 문법.
					ㄴ 배우고 사용하기 쉬움.
					ㄴ 실행속도가 느림
					ㄴ 다른 언어로 쓰인 모듈들을 연결하는데 자주 사용된다.
					ㄴ 수치 연산에 특화된 모듈들이 잘 되어있다. pyrex, Psyco, NumPy 등.

				ㄴ 표기법
					ㄴ ~~~~~

				ㄴ 어휘분석
					ㄴ ~~~~~
					ㄴ 식별자와 키워드 )
					ㄴ 리터럴 )
						ㄴ 포맷 문자열 리터럴 )
							ㄴ 'f'나 'F'를 앞에 붙인 문자열 리터럴.
							ㄴ 중괄호 {}를 중간에 추가하여 치환 필드를 포함할 수 있다. 이 중괄호 표현식 부분은 실행시간에 계산된다.
							ㄴ 중괄호 안 '표현식'에는 파이선 표현식이 온다.
								ㄴ 빈 표현식은 불가하다.

				ㄴ 데이터 모델 <button>더보기</button>
				<pre>
					ㄴ 객체
						ㄴ 파이선의 데이터를 추상화 한 것. 모든 데이터는 '객체(인스턴스)'나 '객체 간의 관계'로 표현된다.
						ㄴ 객체는 'identity', 'type', 'value'를 가진다.
							ㄴ identity : 메모리상의 객체의 주소 같은것. 한번 만들어진 후 변경되지 않는다.
								ㄴ is연산자는 객체의 아이덴더티를 비교.
								ㄴ id()함수는 아이덴터티를 정수로 표현한 값을 돌려준다.
									ㄴ CPython에선 값이 저장된 주소값. 
							ㄴ 형(type)
								ㄴ 객체가 지원하는 연산들과 가질 수 있는 가능한 값들을 정의.
								ㄴ type()함수는 객체의 type을 반환. 즉, 해당 객체가 어떤 클래스의 인스턴스인지.
								ㄴ 아이덴터티와 마찬가지로 변경되지 않음.
							ㄴ 값(value)
								ㄴ '가변'객체들은 값을 변경할 수 있다. '불변'객체들은 불가하다.
								ㄴ '가변'인지 '불변'인지는 '형'에 따라 결정된다. ex) 숫자, 문자열, 튜플은 불변. 리스트, 딕셔너리는 가변.
						ㄴ 명시적으로 없앨 수 없다. 참조되지 않으면 '가비지 컬렉터'에 의해 수거된다.
							ㄴ ??? 디버깅 기능이나, try-except문 사용시, 객체가 수거되지 않고 유지된다? 
							ㄴ 열린 파일이나 창 같은 '외부 자원'들을 참조하는 경우, 가비지 수거가 보장되지는 않으므로 보통 close()같은 명시적 제거 방법이 제공된다.
						ㄴ ??? CPython currently uses a reference-counting scheme with (optional) delayed detection of cyclically linked garbage, which collects most objects as soon as they become unreachable, but is not guaranteed to collect garbage containing circular references. See the documentation of the gc module for information on controlling the collection of cyclic garbage. Other implementations act differently and CPython may change. Do not depend on immediate finalization of objects when they become unreachable (so you should always close files explicitly). 
						ㄴ '컨테이너'
							ㄴ 다른 객체에 대한 참조를 포함하고 있는 객체.
							ㄴ 튜플, 리스트, 딕셔너리 등.
							ㄴ 컨테이너가 가변 객체를 가지고 있어서 가지고있는 객체들이 변경되더라도 각 객체들에 대한 아이덴터티는 변하지 않으므로
								이런 경우를 보고 컨테이너가 변했다(가변이다)라고 하지는 않는다. 컨테이너가 가진 객체들의 집합?이 변경되어야 가변이라고 한다.
					ㄴ '형(type)'의 종류<button>더보기</button>
					<pre>
						ㄴ None
							ㄴ 하나의 값만을 가짐. 하나의 객체만 존재.
							ㄴ 'None'이라는 내장 이름을 통해 접근 가능.
							ㄴ 여러 상황에서 값의 부재를 알리는데 사용.
							ㄴ 논리값은 false.
						ㄴ NotImplemented
							ㄴ 하나의 값만을 가짐. 하나의 객체만 존재.
							ㄴ 'NotImplemented'라는 내장 이름을 통해 접근가능.
							ㄴ 숫자 메소드, 비교 메소드에서 피연산자에 대해 연산이 안되면 이 값을 반환. (이후 인터프리터가 연산자에 따라 다른 대안 실행)
							ㄴ 논리 비교에 사용되어선 안됨.
						ㄴ Ellipsis
							ㄴ 하나의 값만을 가짐. 하나의 객체만 존재.
							ㄴ 리터럴 '...'이나 내장 이름 'Ellipsis'를 통해 접근 가능.
							ㄴ 논리값은 true.
						ㄴ number.Number
							ㄴ 숫자 계층의 최상위 클래스.
							ㄴ 숫자 리터럴에 의해 만들어지거나 산술연산, 내장 산술함수들의 반환 '형'
							ㄴ '불변'이다.
							ㄴ 숫자 표현의 한계. 
						ㄴ numbers.Integral
							ㄴ ~~~~~
						ㄴ numbers.Real
							ㄴ ~~~~~
						ㄴ numbers.Complex
							ㄴ ~~~~~
						ㄴ 시퀸스형들
							ㄴ ~~~~~
							ㄴ 불변 시퀸스
								ㄴ ~~~~~
							ㄴ 가변 시퀸스
								ㄴ ~~~~~
						ㄴ 집합형들
							ㄴ ~~~~~
							ㄴ 집합, Sets
							ㄴ 불변 집합, Frozen sets
						ㄴ 매핑들
							ㄴ ~~~~~
							ㄴ 딕셔너리, Dictionaries
								ㄴ ~~~~~
						ㄴ callable 형들
							ㄴ 함수 호출 연산이 사용가능한 type들.
							ㄴ 사용자 정의 함수
								ㄴ 함수 정의를 통해 생성.
								ㄴ ~~~~~
							ㄴ 인스턴스 메소드
								ㄴ ~~~~~
							ㄴ Generator 함수
								ㄴ ~~~~~
							ㄴ Coroutine 함수
								ㄴ ~~~~~
							ㄴ Asynchronous generator 함수
								ㄴ ~~~~~
							ㄴ 내장 함수 (Built-in 함수)
								ㄴ ~~~~~
							ㄴ 내장 메소드
								ㄴ ~~~~~
							ㄴ 클래스
								ㄴ ~~~~~
							ㄴ 클래스 인스턴스
								ㄴ ~~~~~
						ㄴ 모듈
							ㄴ import system에 의해 만들어짐.
							ㄴ 모듈 객체는 '딕셔너리' 객체로 구현되는 '이름 공간'을 가진다.
							ㄴ ~~~~~
						ㄴ 사용자 정의 클래스
							ㄴ 보통 클래스 정의로부터 생성.
							ㄴ ~~~~~
						ㄴ 클래스 인스턴스
							ㄴ ~~~~~
						ㄴ I/O 객체
							ㄴ ~~~~~
						ㄴ 내부 형(Internal types)
							ㄴ ~~~~~
							ㄴ 코드 객체
								ㄴ ~~~~~
							ㄴ 프레임 객체
								ㄴ ~~~~~
							ㄴ 트레이스백 객체(Traceback object)
								ㄴ ~~~~~
							ㄴ 슬라이스백 객체
								ㄴ ~~~~~
							ㄴ 스태틱 메소드 객체
								ㄴ ~~~~~
							ㄴ 클래스메소드 객체
								ㄴ ~~~~~
					</pre>
					ㄴ 특수 메소드 이름들<button>더보기</button>
					<pre>
						ㄴ 클래스에서 사전에 정의된 특정한 이름의 메소드를 구현하여 특정한 문법에 의해 실행될 로직을 구현 할 수 있다.
							ㄴ 클래스에 대한 연산자 오버로딩이라고 생각하면 된다.
							ㄴ 가령, 클래스의 인스턴스가 생성될 때 호출되는 __new__()함수가 있는데, 이 __new__이름의 메소드를 클래스에서 구현하여
								이 구현한 함수가 인스턴스 생성시 호출되도록 할 수 있다. (__new__()를 덮어쓴것)
						ㄴ 특정 메소드를 None으로 설정하는 것은 해당 연산이 제공되지 않음을 의미한다.
						ㄴ 기본적인 메소드 커스텀에 대해..
							ㄴ (*객체*).__new__(cls[,...])
								ㄴ 클래스 cls의 새 인스턴스 생성시 호출되는 메소드.
								ㄴ ~~~~~
								ㄴ 일반적인 사용은, 안에서 super().__new__(cls[,...])를 먼저 호출하여 인스턴스 생성후, 여기에 필요한 수정을 하는식.
								ㄴ ex)
									class bbb:
										a=1
										def __new__(cls):
											super().__new__(cls)
											print('in __new__()')

									bbb2 = bbb() #'in __new__()'가 출력됨.
							ㄴ (*객체*).__init__(self[,...])
								ㄴ __new__를 통해 새로운 인스턴스 생성후, 이를 반환해주기 이전에 호출되는 메소드.
								ㄴ ~~~~~
							ㄴ ~~~~~
						ㄴ 어트리뷰터 접근 메소드 커스텀에 대해..
							ㄴ 인스턴스의 어트리뷰트 참조 관련(읽기, 대입, 삭제)된 메소드들을 커스텀.
							ㄴ (*객체*).__getattr__(self, name)
								ㄴ 어트리뷰터 엑세스가 'AttributeError'로 실패시 호출.
								ㄴ ~~~~~
							ㄴ ~~~~~
							ㄴ 모듈 어트리뷰터 접근 메소드 커스텀에 대해 ...
								ㄴ ~~~~~
							ㄴ 디스크립터 구현
								ㄴ ?????
							ㄴ 디스크립터 호출
								ㄴ ?????
							ㄴ __slots__
								ㄴ ?????
						ㄴ 클래스 생성에 대한 커스텀...
							ㄴ ~~~~~
							ㄴ (*객체*).__init_subclass__(cls)
								ㄴ ~~~~~
							ㄴ ~~~~~
						ㄴ 인스턴스 및 서브 클래스 검사 커스텀
							ㄴ ~~~~~
						ㄴ 제네릭 형 흉내내기
							ㄴ ?????
						ㄴ 콜러블 객체 흉내내기
							ㄴ ?????
						ㄴ 컨테이녀형 흉내내기
							ㄴ ?????
						ㄴ 숫자형 흉내내기
							ㄴ ?????
						ㄴ with문, 컨텍스트 관리자
							ㄴ ?????

					</pre>
					ㄴ ??? 코루틴, Coroutines
						ㄴ ??? 일반 함수가 함숫 ㅣ작부터 종료시까지 쭉 멈춤없이 실행이 진행되는 것과 달리, 
							실행 흐름이 중간에 일시정지 되었다가 나중에 재시작될 수 있는 함수? 
							parallelism이 아닌 concurrency? 
							함수 정의 앞에 'async' 키워드를 붙여 코르틴 함수 정의? 
							함수 내에서 awiat키워드를 사용하여 그 지점이 일시정지 될 수 있고 나중에 그 지점부터 재시작 될 수 있게? 
							파이선 기본 라이브러리 'asyncio'와 같이 사용? asyncio의 task로 코루틴 등록해두고 
							여러 task를 실행시키면, 코루틴 내의 await를 만나 일시정지가 될때마다 다른 task를 수행함으로서 cocurrency 수행? 
							코루틴 하나만 실행하면 await에서 멈춰도 다른 실행할 것 없어 동작상 일반함수와 다를게 없음? 
						ㄴ ??? generator처럼, 실행흐름을 caller에게 넘기는 것?  
						ㄴ ??? generator 기반으로 만들어짐. 
							ㄴ generator가 실행 중, yield 키워드를 만나면 실행을 멈추고, 바깥으로 실행흐름을 넘긴 뒤, 
								나중에 generator의 다음을 가져오라는 호출이 떨어지면 멈춘지점부터 다시 실행하듯이, 
								coroutine도 await 키워드를 만나면 실행을 멈추고(???항상 멈추는건 아님?) 실행흐름을 다른코루틴에게 넘기고, 
								나중에 다시 실행하라는 호출이 떨어지면 멈춘지점부터 다시 실행? 

				</pre>

				ㄴ 실행 모델<button>더보기</button>
				<pre>
					ㄴ 프로그램 구조
						ㄴ 파이썬 프로그램은 '코드 블록'을 기준으로 만들어진다.
						ㄴ 파이썬 코드를 말하는 듯함. 모듈이 될 수도, 함수 바디가 될 수도, 스크립트 명령이 될 수도, 클래스 정의, 등등.
							ㄴ 코드블럭에서 다른 코드블록을 호출하여 실행시킬 수도 있다(함수호출)
						ㄴ ????? 코드블럭은 '실행 프레임'에서 실행된다. 프레임은 디버깅 등에 사용되는 정보를 가지고 있고, 다음 실행되어야 할 코드 블록이
							어느것인지 등을 결정한다.

					ㄴ 이름과 연결(binding)
						ㄴ '이름'은 '이름 연결 연산'을 위해서 만들어진다. '이름'으로 특정 대상을 가리키는 것.
						ㄴ 연결 대상 예)
							ㄴ 함수로 전달되는 형식 매개변수
							ㄴ import문
							ㄴ 클래스와 함수 정의 (정의하고있는 블록에 연결)
							ㄴ 대입, for루프 헤더, with문, except절의 as뒤
							ㄴ from ~~~ import * (모듈에 정의된 모든 이름 연결)
						ㄴ 이름이 블록 내에서 연결되면, 이름이 nonlocal이나 global로 선언되지 않는 이상, 그 블록의 지역변수가 된다.
						ㄴ 이름이 모듈 수준에서 연결되면, 전역변수이다.
						ㄴ 코드 블록에서 사용되지만, 해당 블럭에서 정의되지 않았고 전역변수도 아니라면 'free variable'이라 한다.
						ㄴ '이름'들은 다음의 규칙대로 결정된 binding을 가리킨다.
							* 스코프
								ㅡ 블럭 안에서 '이름'의 가시성을 정의한다. 즉, 특정 '이름'이 '보이는?'범위를 스코프라 하는 듯하다.
								ㅡ 가령, 지역변수 a가 블럭에서 정의되면, a의 스코프는 그 블럭을 포함하고, 그 블럭 안에서 a가 '보인다'(접근 가능하다).
									ㄴ 그 블럭 안에서 a란 '이름'으로 다른 binding을 만들지 않는 한.
								ㅡ '이름'이 결정될때, '이름'이 존재하는 코드 블럭이 포함되는 '가장 가까운 스코프'에서부터 '이름'을 검색한다.
									ㄴ 이렇게, 특정 코드블럭에서 볼 수 있는 스코프의 집합을 블럭의 'environment'라고 한다.
								ㅡ 발견되는 '이름'이 없다면 NameError 예외가 발생한다.
							ㄴ 코드 블럭 내에서 '어디에서건' 이름 연결 연산이 일어나면, 해당 코드 블럭 안에서의 그 이름의 사용은 모두 그 이름 연결으로 결정된다.
								ㄴ ex)
									q = 99
									def ccc():
										print(q)

									ccc()	#ccc()안에서의 q는 전역변수q가되어 99출력.
								ㄴ ex2)
									q=99
									def ccc():
										print(q)
										q=1

									ccc()	# ccc안에서 print()에서 q가 먼저 사용되고 q=1로 지역변수q를 생성하고있다.
											# 코드 블럭내에서 '어디에서건' 이름연결연산이 일어나면, 해당 코드블럭 안에서 그 연결을 사용한다 하였으므로,
											# print에서 사용하는 q는 q=1에 있는 지역변수 q를 의미하게되고, 이 q는 아직 바인딩이 안되었으므로 'UnboundLocalError'예외가 발생한다.
							ㄴ global 문
								ㄴ 해당 코드 블럭 전체에 적용되는 선언.
								ㄴ 나열된 식별자들이 전역범위에서 이름연결되어야함을 설정. 즉, 지정한 이름의 모든 사용은 '최상위 이름 공간'에 연결된 것을 가리키게됨.
									ㄴ ex)
										q=99
										def ccc():
											q=1
											print(q) #바로 위에서 연결된 1이 출력.
											def ccc2():
												global q #전역인 q=99가 연결된다.
												q = -99 #전역변수 q에 -99를 넣는다.
												print(q) # 전역변수인 q에 -99가 대입되었으므로 -99출력.
											ccc2()

										ccc()
										print(q) #전역변수 q가 ccc2()안에서 -99로 수정되었으므로 -99 출력.
									ㄴ '최상위 이름 공간'에서 검색한다는건, 전역 이름 공간, 즉, 모듈의 이름공간, 내장 이름공간, 모듈 내장 객체의 이름공간에 대한 검색.
								ㄴ 이 선언 없이도 free variable들이 전역을 조회할 수는 있지만, 값을 대입할 수는 없다.
									ㄴ ex)
										q=99
										def ccc():
											print(q) #ccc()호출시, ccc()안에서 q를따로 이름연결하지 않았으므로 전역스코프의 q에 조회하여 99가 출력된다.

										ccc()
										그러나 전역 q에 값을 대입하려는 경우,
										q=99
										def ccc():
											q=1 #이렇게 코드를 만드는 순간, 전역변수q에 1을 넣는게 아니라 지역변수 q가 생성되고 1이 대입된다.
											print(q) #출력도 당연히 지역변수q인 1이 나온다.

										ccc()
										print(q) #ccc()안에서 전역변수에 1을 넣은게 아니므로, 99가 그대로 출력된다.
								ㄴ ?????
							ㄴ nonlocal 문
								ㄴ 나열된 식별자들이 전역을 제외하고 가장 가까운 스코프에서 이미 연결된 변수를 가리켜야함을 선언.
								ㄴ ex)
									q=1
									def aaa():
										q=2
										def aaa2():
											nonlocal q 	#이름 q가 aaa()의 함수 블록의 q와 연결된다.
											q=99#2가 대입된q에 99가 들어간다. aaa2()안에서 q가 nonlocal로 선언되지 않았다면, aaa2()에서 q=99는 aaa2()의
												#지역변수 q에 99를 대입하고 aaa()의 q에는 그대로 2가 들어있다.
										aaa2()
										print(q)

									aaa()
							ㄴ 모듈의 이름공간은 모듈이 처음 import될 때 결정된다.
								ㄴ 메인 모듈의이름은 항상 '__main__'이다.
									ㄴ __name__ 이란 이름으로 조회가능하고, 대화형 스크립트나 모듈 자기자신의 이름은 항상 '__main__'이다.
							ㄴ ????? 클래스 정의의 이름 연결 연산
								ㄴ ????? 연결되지 않은 지역변수를 전역 이름공간에서
						ㄴ ?????
							ㄴ ?????
						ㄴ ~~~~~

				</pre>

				ㄴ 클래스<button>더보기</button>
				<pre>
					ㄴ 객체지향형 프로그래밍의 기본적인 기능들을 제공한다.
						ㄴ 상속 메커니즘 : 다중 상속, 오버라이딩, 등
					ㄴ 객체와 이름 )
						ㄴ 여러개의 '이름'이 하나의 객체에 연결될 수 있다. (일반적으로 별칭, aliasing이라고 불림)
					ㄴ 스코프와 이름공간
						ㄴ 흔히 사용되는, 변수의 영역?을 구분하는 namespace를 말하는 듯 하다.
							ㄴ 당연히, 동일한 '이름'이어도, 이름공간이 다르다면 사용가능.
							ㄴ (*이름공간이르며*).(*속성이름*)
							ㄴ 뒤에 오는걸 'attribute'라고 함.
							ㄴ 어트리뷰트는 읽기전용일 수도, 쓰기 가능할 수도 있다. 쓰기 가능할 경우 del문으로 삭제도 가능하다.
							ㄴ 파이선에선 대부분은 '딕셔너리'로 구현되어 있다함.
						ㄴ 이름공간은 생성 시기와 수명이 다를 수 있다.
							ㄴ 가령, 내장 이름들을 담는 이름공간은 인터프리터가 시작할때 생성되어 영원히 사라지지 않는 반면,
								모듈의 전역이름 공간은 모듈정의를 읽을 때 생성된다.
							ㄴ 함수의 지역 이름 공간은 함수 호출 시 생성되고, 함수가 복귀하거나 함수 내에서 처리되지 않는 예외 발생시 삭제된다.
					ㄴ 클래스 정의 )
						ㄴ ex)
							class ClassName:
								(*정의문*)
						ㄴ 정의 시작시, 새 '이름 공간'을 생성하고 이를 지역스코프로 사용. 정의 내의 모든 '이름'들이 이곳에 연결된다.
						ㄴ 클래스 정의가 종료되면, '클래스 객체'가 생성.
						ㄴ type 클래스 )
							ㄴ 내장함수로서, type( (*객체*) ) 를 호출할 시, 해당 객체의 type을 알려주는 함수이지만, type에 대한 다른 내용이 더있다.
							ㄴ 파이선의 모든 데이터들은 객체(인스턴스)라고 했다.
							ㄴ 모든 인스턴스, 클래스의 상위클래스? 라고 할 수있다??
								ㄴ 인스턴스의 __class__ 속성은 인스턴스가 속한 클래스가 무엇인지 알려준다.
								ㄴ 커스텀 클래스의 인스턴스, 내장 클래스의 인스턴스에 대해 __class__를 확인해보면 'type'클래스가 나온다.
							ㄴ type( (*클래스명*), (*상속할 클래스*), (*클래스의 어트리뷰트*) )
								ㄴ 인자를 가지고 새로운 클래스 객체를 생성하여 반환.
									ㄴ 위에 나온 클래스 정의문을 쓰면 이 함수를 호출하여 동작한다.
										ㄴ 	class (*클래스명*):
												(*클래스정의*)
											위의 클래스 정위문과 동일한 동작.
								ㄴ (*클래스의 어트리뷰트*)는 클래스가 가질 변수, 메소드들이 들어있는 'dict'
									ㄴ ex) Foo = type('Foo', (), {'bar':True})	#bar = true인 클래스변수를 가지는 Foo클래스 반환.
							ㄴ 모든 클래스들을 만드는 클래스, 모든 클래스들의 클래스라 하여 type을 '메타클래스'라고도 부른다.
							ㄴ 클래스의 '__metaclass__'라는 속성을 부여하여 클래스 객체 생성 동작을 커스텀 할 수 있다. 이를 '커스텀 메타클래스'라고 부른다.<button>더보기</button>
							<pre>
								ㄴ 클래스에 '__metaclass__'라는걸 설정하면 파이선은 해당 클래스 생성시, 이 속성에 부여한 클래스 또는 함수를 호출하여 클래스 객체를 생성한다.
								ㄴ ex)
									def upper_attr(future_class_name, future_class_parents, future_class_attr): #????? metaclass속성을 사용하면 자동으로 부여되는 인자들인듯하다.
									"""
										대문자로 변환된 속성의 리스트와 함께 클래스 객체를 반환합니다.
									"""

									# '__'로 시작하지 않는 모든 객체를 가져와 대문자로 변환합니다.
									uppercase_attr = {}
									for name, val in future_class_attr.items():
										if not name.startswith('__'):
											uppercase_attr[name.upper()] = val
										else:
											uppercase_attr[name] = val

									# `type`으로 클래스를 생성합니다.
									return type(future_class_name, future_class_parents, uppercase_attr)	#type()을 사용하여, 커스텀으로 생성한 uppercase_attr과 함께
																												클래스객체를 생성해주고있다.

									class Foo(metaclass=upper_attr):	#metaclass속성으로 클래스 또는 함수 전달. 이 라인에서 Foo 클래스 객체 생성시
																			upper_attr을 호출하여 여기서반환한 클래스객체를 생성한다.
										bar = 'bip'	#Foo클래스객체의 변수 bar.

									f = Foo()

									print(f.__class__) #Foo
									print(f.__class__.__class__) #type. metaclass를 사용했어도 결국은 type을 사용했으므로.
									print(f.BAR) 	#bip출력. 클래스 변수 bar가 upper_attr호출로 BAR로 바뀜.

								ㄴ 클래스 생성시 파이선의 __metaclass__ 참조 동작
									ㄴ Foo라는 클래스객체를 생성한다고 하면,
									ㄴ 파이선이 먼저 Foo클래스정의에 __metaclass__속성이 있는지 확인한다.
									ㄴ 있으면 해당 __metaclass__를 사용하여 클래스 객체 생성.
									ㄴ 없으면, '모듈 레벨'에서 __metaclass__를 찾는다. (파이선 3으로 넘어가면서 클래스바디의 __metaclass__속성을
										클래스 정의시 상위클래스 인자부분에 metaclass= (*메타클래스*) 형식으로 넣도록 문법이 변경되었는데,
										모듈레벨에서 metaclass찾는것도 변경되었는지는 모름)
									ㄴ 있으면 그거쓰고, 없으면, 기본인 type을 사용하여 클래스 생성.
								ㄴ 클래스의 상위클래스 인자에 'metaclass = (*메타클래스*)'를 넘겨주면 메타클래스를 사용하여 클래스객체를 생성한다.
									ㄴ ex) 	class Foo(metaclass = (*메타클래스 정의 클래스 또는 함수*) ):
												~~~~~
								ㄴ (*메타클래스 정의 클래스 또는 함수*)
									ㄴ 커스텀으로 클래스를 생성하는 '호출가능한' 무언가??가 오면 된다.
									ㄴ ????? 보통 type()을 호출하여 클래스를 생성하거나 다른 클래스를 생성하게된다.
									ㄴ 여기서 반환하는 클래스 객체가 생성되게 된다.
									ㄴ 위의 upper_attr()예제처럼 함수를 사용해 정의하지 않더라도 class를 정의하여 정의할 수 있다.
										ㄴ ex)
											class UpperAttrMetaclass(type):
												def __new__(upperattr_metaclass, future_class_name,
															future_class_parents, future_class_attr):	#__new__를 오버라이드하여 메타클래스의 기능을 넣는다.

													uppercase_attr = {}
													for name, val in future_class_attr.items():
														if not name.startswith('__'):
															uppercase_attr[name.upper()] = val
														else:
															uppercase_attr[name] = val

													return type(future_class_name, future_class_parents, uppercase_attr)
								ㄴ 메타클래스를 통해 할 수 있는 것들
									ㄴ 클래스 생성 가로채기
									ㄴ 클래스 수정
									ㄴ 수정된 클래스 반환
								ㄴ 보통 함수보다는 클래스형태로 메타클래스기능을 사용하는게 좋다고함.
									ㄴ ~~~~~
								ㄴ 거의 대부분의 경우에는 사용할 일이 없는 기능이다.
							</pre>
					ㄴ 클래스 객체 )
						ㄴ 두 종류의 연산을 지원. 'attribute참조', '인스턴스 생성'
						ㄴ 어트리뷰트 참조 )
							ㄴ (*클래스명*).(*어트리뷰트명*)
							ㄴ 클래스 정의시, 클래스의 '이름 공간'에 있던 모든 이름이 (*어트리뷰터명*)이 된다.
							ㄴ 대입도 가능하다.
							ㄴ 클래스 변수 )
								ㄴ 클래스에서 정의하고 있는 변수.
								ㄴ 클래스로도 접근이 가능하고 인스턴스로도 접근이 가능하다.
								ㄴ 클래스의 모든 인스턴스들이 공유하게 된다.
						ㄴ 인스턴스 생성 )
							ㄴ 인스턴스 만들기 연산 : ex) (*클래스명*)()
							ㄴ 함수호출처럼 클래스명을 호출해주면 인스턴스가 생성되어 반환.
							ㄴ ????? 인스턴스 만들기 연산은 빈 객체를 만든다.
							ㄴ __init__()라는 특수메소드를 통해 인스턴스 생성시 처리할 로직을 정의할 수 있다.
								ㄴ 인스턴스 만들기 연산 실행시, 자동으로 호출된다.
								ㄴ 이 메소드의 인자는 인스턴스 생성 호출시 넘어간 인자들이 들어간다.
									ex) (*클래스*)( (*인자1*), (*인자2*) )
										__init__( (*인자1*), (*인자2*) )
						ㄴ 함수를 꼭 내부에서 def로 정의를 통해 만들지 않아도 된다. 외부에서 정의된 함수객체를 변수 인자에 넣어도 되고 내부에서 정의한 함수를 변수에 넣어도 된다.
							ㄴ ex)
								def aFunc1():
									print('hello1')

								class AAA:
									def aFunc2():
										print('hello2')
									aFuncV1 = aFunc1 #AAA.aFuncV1()과 같이 호출 할 수 있다.
									aFuncV2 = aFunc2 #AAA.aFuncV2()와 같이 호출 할 수 있다.


					ㄴ 인스턴스 객체 )
						ㄴ 어트리뷰트 참조 연산만 가능하다.
						ㄴ 어트리뷰트가 두 종류가 있다. '데이터 어트리뷰트', '메소드'
							ㄴ 데이터 어트리뷰트 )
								ㄴ 인스턴스 변수로서, 해당 인스턴스에서만 접근 가능하다.
								ㄴ 따로 선언할 필요 없이, 인스턴스에 대고 대입하면 인스턴스변수가 생성된다.
									ㄴ ex)
										a = AAA()
										a.xyz = 123 #AAA클래스 정의시, xyz란 변수를 따로 선언하여 만들지 않았어도, 이 문장으로 xyz란 인스턴스변수가 생성된다.
							ㄴ 메소드 )
								ㄴ 인스턴스의 '함수 객체'를 의미.
								ㄴ 똑같은 함수이더라도, 클래스 객체의 함수와 인스턴스 객체의 함수는 구분되어있다. 인스턴스 객체의 함수를 '메소드 객체'라고 한다.
								* 메소드 객체
									ㅡ 메소드 객체는 호출시, 인스턴스의 객체가 자동으로 함수의 첫번째 인자로 전달된다.
										ㄴ ex) AAA의 인스턴스가 x에 들어있다고 한다면,
											x.aaa() #이는 곧, AAA.aaa(x)와 동일하다.
									ㅡ ????? 인스턴스객체와 클래스의함수 객체를 묶어 '메소드 객체'를 생성.
					ㄴ 클래스 객체와 인스턴스 객체 )
						ㄴ 클래스 변수, 인스턴스 변수를 생각해보면, 전자는 약간 java의 static변수같은 개념이다. 클래스에 정의해놓고 해당 클래스의
							모든 인스턴스에서 접근 가능한 변수. 후자는 해당 인스턴스에서만 접근 가능한 변수.
							ㄴ ex)
								class AAA:
									a = 1;

								aaa1 = AAA();
								aaa1.a2 = 2;
								aaa2 = AAA();
								aaa2.a3 = 3;

								print(aaa1.a)#클래스변수인 1 출력
								print(aaa1.a2) 	#인스턴스변수인 2출력
								print(aaa1.a3) 	#aaa1인스턴스에는 a3이란 인스턴스변수가 없다
								print(aaa2.a) 	#클래스변수인 1출력
								print(aaa2.a3) 	#인스턴스변수인 3출력
							ㄴ class 정의에서 self인자를 통하여 인스턴스 변수 정의도 가능하다
								ㄴ ex)
									class AAA:
										def aFunc(self):
											self.a1 = 1 #self를 통해 인스턴스변수 a1을 생성.

									aaa = AAA();
									print(aaa.a1) #아직 인스턴스변수 생성안되었으므로 에러.
									aaa.aFunc(); #함수호출되며 인스턴스변수 a1생성.
									print(aaa.a1) #인스턴스변수 a1인 1출력
						ㄴ 근데 파이선에서는 jvaa와 다르게 클래스를 선언하는게 아니라 클래스라는 객체 자체를 생성하는 것.
							ㄴ 인스턴스가 클래스변수에 접근하는건 단지, 인스턴스에서 해당 이름의 변수를 찾을 수 없을때, 그 인스턴스의 클래스 객체로
								거슬러올라가서 이름을 찾고 이를 반환해주는 것뿐.
						ㄴ 클래스 변수와 인스턴스 변수와 같으면 인스턴스 변수를 우선하여 참조한다.
						ㄴ 클래스 변수와 인스턴스 변수 모두 파이선에서는 데이터 은닉이 될 수 없다. 어디에서도 참조될 수 있다.따라서 사용에 주의를 해야 한다.
					ㄴ 상속 <button>더보기</button>
					<pre>
						ㄴ ex)
							class DerivedClassName ( BaseClassName ):
								~~~~~
							ㄴ BaseClassName 부분에 상위 클래스 이름이 오면 'DerivedClassName'은 그 상위 클래스를 상속.
							ㄴ 상위 클래스의 '이름'은 이 자식 클래스를 정의하는 스코프에 포함되어 있어야 한다.
						ㄴ 참조하는 어트리뷰트가 해당 자식 클래스에서 발견되지 않으면 상위 클래스를 참조하여 어트리뷰트를 찾는다.
						ㄴ ?????
						ㄴ 관련 내장 함수 )
							ㄴ isinstance( (*객체*), (*클래스*) ) : (*객체*)의 __class__가 (*클래스*)와 일치하면 true반환.
							ㄴ issubclass( (*하위클래스*), (*상위클래스*) ) : 첫번째인자가 두번째 인자의 하위 클래스이면 true반환.
						ㄴ 다중 상속 )
							ㄴ ex)
								class DerivedClassName ( Base1, Base2, Base3 ):
									~~~~~
							ㄴ ????? 다중상속의 다이아몬드 문제에 대한 해결책으로?? 위와 같이 baseclass들이 나열되어잇으면 왼쪽에서 오른쪽 순서대로
								참조를 검색하게 된다.
					</pre>
					ㄴ 파이선의 private 변수 )
						ㄴ 파이선에선 클래스 외부에서 접근 불가한 private변수 같은 것이 존재하지 않는다.
						ㄴ 다만, 관례에 의해서 특정한 패턴의 이름을 가진 변수들은 외부에 의해 접근되어서는 안되는 이름들로 여겨진다고함.
						ㄴ ?????
						ㄴ name Mangling )
							ㄴ '__name' 형태로 정의된 이름들은(변수이든 함수이든) '_classname__name'형태로 자동으로 변환된다.
								ㄴ ex)
									class AAA:
										__a = 1
										def __f1():
											print("in AAA's f1()")

									AAA.__a #__a라는 이름이 없다고 오류발생.
									AAA._AAA__a #1 출력.
									AAA.__f1() #__f1이란 이름이 없다고 오류 발생.
									AAA._AAA__f1() # "in AAA's f1()" 출력.
							ㄴ 완전하지는 않지만 이름을 이런식으로 바꾸어 private와 비슷한 효과를 주게하는 것.
							ㄴ 하위 클래스가 해당 변수를 재정의하는 것들 방지.
					ㄴ ????? 잡동사니
						ㄴ ?????
					ㄴ 이터레이터 )
						ㄴ __iter__와 __next__를 직접 정의하여 정의한 클래스가 iterator와 동작할 수 있게 한다.
						ㄴ ?????
					ㄴ 제너레이터 )
						ㄴ 일반 함수와 동일한데, 'yield'라는 키워드를 사용하여 이터레이터의 기능을 하는? '제너레이터 이터레이터'를 반환하는 함수.
						ㄴ ex)
							class AAA:
								def f1( data ): # f1이 '제너레이터'이다.
									for i in range(0, 10, 1): #0~10까지 반복하면서 3으로 나누어 떨어지는 경우 'yield'를 사용하여 해당 값을 내보내고있다.
										if i%3 == 0:			#다음번 반복실행시, 이전에 yield를 했던 부분부터 시작하게 된다.
											yield i

							for i in AAA.f1( range(0, 10, 1) ): #이렇게 '제너레이터'를 for문이나 next()를 사용해 반복할 수 있다.
								print(i) #0,3,6,9 출력.

				</pre>

				ㄴ import system<button>더보기</button>
				<pre>
					ㄴ 한 모듈 안에 있는 파이선 코드는 '임포팅'을 통해 다른 모듈에 있는 코드들에 대한 접근권을 얻는다.
						ㄴ 임포팅 이란? 한 모듈의 파이선 코드가 다른 모듈의 파이선 코드에서 사용될 수 있도록 하는 과정.
					ㄴ 임포트 방법
						ㄴ import문 (가장 보편적방법)
						ㄴ importlib.import_module()
						ㄴ __import__()
					ㄴ import 문 )
						ㄴ from절이 없는 경우 )
							ㄴ 과정
								ㄴ 모듈을 찾고, 로드하고, 필요하면 초기화합니다.
									ㄴ 찾는 과정은 적절한 인자들로 __import__()를 호출하는 것이다.
									ㄴ 이후, __import__()의 반환값으로 다음단계인 이름연결연산을 수행한다.
								ㄴ import문이 등장한 스코프의 지역 이름공간에 '이름'이나 '이름 공간'정의.
									ㄴ 모듈 이름 뒤에 'as'가 오면, as뒤에 오는 이름이 모듈과 연결됨.
									ㄴ ?????
						ㄴ from절이 있는 경우 )
					ㄴ __import__()
						ㄴ 파이선 내장함수.
						ㄴ 모듈을 찾고, 발견된다면 모듈을 만드는 연산만을 수행.
						ㄴ __import__(name, globals=None, locals=None, fromlist=(), level=0)
							ㄴ 주어진 globals, locals 함수를 이용하여 name을 적절하게 해석한다.
							ㄴ name으로 모듈을 결정한다. name에 해당하는 모듈이 결정되는게 아니라 해당 모듈의 최상위 패키지가 반환된다.
								ㄴ ex) import spam.ham 은 다음과 같이 호출되며 spam.ham이 아니라 최상위인 spam을 반환한다.
									__import__('spam', globals(), locals(), [], 0)
							ㄴ fromlist으로 서브모듈을 결정한다.
								ㄴ ex) from spam.ham import eggs, sausage as saus 는 다음과 같이 호출되며 spam의 eggs, sausage를 반환한다.
									_temp = __import__('spam.ham', globals(), locals(), ['eggs', 'sausage'], 0)
									eggs = _temp.eggs
									saus = _temp.sausage
						ㄴ ????? 구체적인 내부 동작은 아직 모름.

					ㄴ 모듈 검색과정에서 찾지 못한다면, ModuleNotFoundError 발생.
					ㄴ 모듈을 찾는 다양한 전략들이 존재. 커스텀 가능.
					ㄴ importlib )
						ㄴ 파이선 표준 라이브러리 중 하나. import system과 관련한 여러가지 api들을 제공한다.
					ㄴ 패키지 )
						ㄴ 서브 모듈이나 서브 패키지들을 포함할 수 있는 파이선 '모듈'. __path__ 어트리뷰트가 있는 파이선 모듈이다.
						ㄴ __path__ 어트리뷰트
							ㄴ 임포트시 서브 모듈을 검색할 위치가 문자열로 담겨있는 이터러블 데이터. 모듈 임포트시 sys.path와 기능이 유사하다.
								ㄴ sys.path : 모듈의 검색 경로를 지정하는 문자열 리스트.
							ㄴ 비어있을 수 있다.
						ㄴ 종류 )
							ㄴ 정규 패키지 )
								ㄴ 파이선 3.2 이하에서 존재하던 전통적인 패키지. __init__.py라는 파일을 가지는 디렉터리고 구현된다.
								ㄴ 임포트 될때, __init__.py가 실행됨.
								ㄴ ex)
									parent/
										__init__.py
										one/
											__init__.py
										two/
											__init__.py
										three/
											__init__.py
									ㄴ 위와 같은 패키지의 파일구조가 있다고할때, parent.one을 임포트하면 parent/__init_.py와 parent/one/__init__.py가
										실행된다.
							ㄴ 이름 공간 패키지 )
								ㄴ '포션'들의 집합체.
									ㄴ '포션'이란, 이름공간 패키지를 구성하는 하나의 디렉터리에 들어있는 파일 집합.
										ㄴ 파이선이 임포트시 검색하는 어떤 곳에도 위치할 수 있음?????
					ㄴ 검색 )
						ㄴ 임포트될 모듈의 '완전히 정규화된 이름'을 필요로 한다.
							ㄴ '완전히 정규화된 이름'이란, 네임스페이스안의 이름 입력시, (*네임스페이스*).(*이름*) 과 같은식으로,
								점을 이용해 모듈, 클래스, 함수에 이르는 모든 경로를 나타낸 이름.
						ㄴ 완전히 정규화된 이름의 최상위 모듈부터 차례대로 모두 임포트한다.
							ㄴ ex) aaa.bbb.ccc를 임포트하면, aaa임포트, aaa.bbb임포트, aaa.bbb.ccc를 임포트한다.
							ㄴ 중간에 하나라도 없다면 'ModuleNotFoundError'를 발생시킨다.
						ㄴ 모듈 캐시 )
							ㄴ 가장 먼저 검색하는 대상은 'sys.modules'이다.
								ㄴ 이는 모듈 이름과 이미 로드된 모듈을 매핑하는 '딕셔너리'이다.
								ㄴ 즉, 이미 임포트된 모든 모듈들의 캐시로서 기능한다.
							ㄴ sys.modules안에 이름이 있고, 그 이름이 현재 import하려는 모듈이면 검색이 완료된다.
							ㄴ 이름은 있으나 값이 'None'이면, 'ModuleNotFoundError'를 발생.
							ㄴ sys.modules에 쓰기 작업이 가능하다.
								ㄴ 키를 삭제하여 캐시목록에서 해당 모듈을 없앨 수 있다. (당연히 모듈 자체를 삭제하지는 않는다)
								ㄴ 다음 임포트때, 다시 그 모듈을 찾도록 한다.
								ㄴ None을 대입하여 다음 임포트때 'ModuleNotFoundError'가 발생하게 할 수 있다.
								ㄴ ?????
						ㄴ finder, loader )
							ㄴ 모듈이 sys.modules 안에 없으면 파이선의 임포트 프로토콜이 실행.
							ㄴ 임포트 프로토콜은 두가지 객체에 의해 동작한다. 'finder', 'loader'
							ㄴ finder )
								ㄴ 임포트될 모듈을 위한 'loader'를 찾으려하는 객체.
								ㄴ 두 종류의 finder 존재. '메타 경로 파인더', '경로 엔트리 파인더'
							ㄴ ?????
							ㄴ
							* ModuleSpec 클래스
								ㅡ 임포트 시스템에서 쓰이는 클래스. 모듈 임포트와 관련하여 모듈에 관한 여러 정보를 가지고 있는 클래스이다.
									ㄴ '정규화된 모듈 이름', 모듈의 '로더', 모듈 위치, 등의 정보를 담고있다.
								ㅡ 일반적으로 임포트된 모듈이름의 __spec__ 어트리뷰트를 통해 확인 가능하다.
								ㅡ 흔히 '모듈 스펙'이라고 말하는게 이 클래스의 인스턴스이다.
						ㄴ ????? 뭐 아무튼 '메타 경로 파인터'가 'sys.meta-path'를 사용해 모듈을 찾아준다는 내용.
					ㄴ 로딩 )
						ㄴ ?????
					ㄴ ?????
				</pre>

				ㄴ 표현식<button>더보기</button>
				<pre>
					ㄴ 말 그대로 표현식에 대해 설명. 리터럴, 식별자(파이썬에서 '이름'), 리스트, 어트리뷰트 참조, 호출 등등.
					ㄴ 산술 변환 )
						ㄴ ~~~~~
					ㄴ 아톰(Atoms)
						ㄴ ~~~~~
						ㄴ 리스트, 집합, 딕셔너리의 display
				</pre>

				ㄴ 단순문<button>더보기</button>
				<pre>
					ㄴ 흔히 하나의 코드 줄로 구성되는 단위를 의미. 그냥 표현식 하나일 수도, 대입문, 증감문, del, return문, raise, break, import문 등등.
				</pre>

				ㄴ 복합문<button>더보기</button>
				<pre>
					ㄴ 여러 절로 이루어져 코드를 구성하고, 다른 코드 부분에 영향을 주거나 제어하는 문.
					ㄴ ex) if, while, for, try, 함수정의 등
					ㄴ ~~~~~
					ㄴ try 문 )
						ㄴ ex)
								try:
									~~~~~
								except ( (*예외1*), (*예외2*), ... ):
									(*예외처리*)
								except ( (*예외3*), (*예외4*), ... ):
									(*예외처리*)
								~~~~~
								else:
									(*로직*)
						ㄴ 동작 과정 )
							ㄴ try 절 실행.
								ㄴ try절이란, try와 except사이의 문장들
							ㄴ 예외 발생 안하면 except절 스킵
							ㄴ 예외 발생시, 남은 try절 스킵후, except매칭 시작
							ㄴ 인자로 받은 예외가 발생하면 매칭. 이후 (*예외처리*)부분 수행.
							ㄴ 인자 예외 옆에 as키워드를붙이고 변수를 입력할시, 예외 처리 구문 안에서 해당 예외가 변수로서 들어간다.
								ㄴ ex)
									except E as a
										print(a);
								ㄴ 당연히, 해당 예외처리구문이 종료되면 해당 변수는 없어진다.
							ㄴ 인자가 없는 except절은 모든 예외와 매칭.
							ㄴ (*예외*)인자와 같은 클래스이거나 상위 클래스일 때 매칭된다.
							ㄴ else절 : 간단히말해, 예외가 발생하지 않으면 실행되는 부분.
								ㄴ 모든 except뒤에 위치해야함.
								ㄴ try절 실행에서 예외가 발생하지않고, try절에서 return, continue, break문이
									발생하지 않았으면 실행된다. 여기서 발생한 예외는 이전의 except절에서 처리되지 않는다.
							ㄴ finally 절 )
								ㄴ try문 전체 통틀어서 맨 마지막에 호출되는 절.
								ㄴ except에서 예외가 잡히든, 안잡히든, try, except절 어디서든 return, continue, break를 하든
									finally절이 있다면 항상 마지막에 한번 호출된다.
									ㄴ 따라서 try절에 return문이 있더라도 finally절에 return문이 있다면 덮어씌워진다.
								ㄴ else절과 마찬가지로 finally절 안에서 발생한 예외는 except절에서 처리되지 않는다.
									또한, try문에서 발생한 예외를 덮어씌워 예외를 발생시킨다. (????? 다른 '컨텍스트'로 설정된다고 한다)
								ㄴ try절에서 예외가 발생하고 이 예외가 except절에서 처리되지 않으면, 예외가 잠시 저장되었다가 finally절이
									실행된 후에 다시 발생된다.
					ㄴ with 문 )
						ㄴ
				</pre>

				ㄴ 메모리 관리 
					ㄴ reference counting 방식 이용. 
					ㄴ 객체를 참조하고 있는 곳의 개수를 카운트하고 있다가 0이 되면 메모리에서 해제. 
					ㄴ built-in module 'sys'의 getrefcount( (*객체*) ) 를 통해 참조 카운트 확인 가능. 
					ㄴ ex ) 
						import sys 
						a = [] 
						b = a 
						sys.getrefcount(a)  # 3 출력. a, b, getrefcount()의 매개변수.  

				ㄴ Global Interpreter Lock (GIL) <button>more</button>
				<pre>
					ㄴ CPython 사용시, 
						스레드 환경에 있어서, 파이선 인터프리터에 대한 lock. 
						프로세스 내에서, 이 락을 가진 스레드만 파이선 바이트코드를 실행할 수 있음. 
						(더 정확히는, 스레드가 CPython API를 호출하려면 이 lock이 있어야함)
						즉, 여러 스레드가 있어도 한 순간에 이 락을 소유하고 있는 스레드만 파이선 코드를 실행할 수 있음. 
					ㄴ 배경 
						ㄴ 파이선은 객체에 대한 메모리관리를 'reference counting'을 통해 수행. 
						ㄴ 멀티 스레딩 환경에서 여러 스레드가 이 참조 카운트를 동시에 변경하거나 하면 
							잘못된 메모리 free 또는 메모리 누수 등 발생 가능. 
							즉, 객체에 관련된 연산부분에서 이 참조카운트가 꼬일까봐. 
						ㄴ ??? 그렇다고 모든 객체에 lock을 거는식의 방법 사용시, 
							많은 락으로 인한 성능 저하나 데드락 가능성이 있음. 
						ㄴ 하여 인터프리터 자체에 락을 걸고, 이 락을 가지고 있는 스레드만 파이선 바이트코드를 실행하게함으로서 
							이러한 문제를 해결하려함. 
							ㄴ ??? 이렇게 하면 참조카운트가 꼬일 일이 없나? 딱 참조카운트 관련 연산을 할때 전환되는 일은 없나? 
								파이선 바이트코드 실행 단위라서 그런기준으로 끊기지는 않나? 
					ㄴ 파이선 동작상에서 락 해제 시점 
						ㄴ 한 스레드에서 일정 시간 수행 후 자동 해제되어 다른 스레드가 락을 얻을 수 있거나 
						ㄴ 락을 해제해주는 일부 코드를 실행하거나. sleep() 등.  
							ㄴ I/O 관련 코드? 
					ㄴ 이로 인한 이슈 
						ㄴ multi-threading을 통한 parallelism 사용 제한으로 인한 parallelism 구현 제약. 
						ㄴ 대안 
							ㄴ multiprocessing 
								ㄴ??? GIL은 인터프리터 프로세스당 하나의 스레드에 걸림. 
									python의 multiprocessing module을 이용하면, 분리된 새 인터프리터 프로세스가 생성되고 이걸로 실행시키기 때문에 GIL의 제약을 받지 않는다? 
							ㄴ GIL 해제 
							ㄴ ~~~ 
							ㄴ 코드상의 수정?  
								ㄴ 지향 
									ㄴ GIL를 잡지 않는 함수를 사용 
										ㄴ??? pandas, numpy? CPython을 덜 사용하도록 구현되었다함?
								ㄴ 지양 
									ㄴ pure python code를 사용 
									ㄴ 저수준 단에서 GIL를 해제할 수 있음에도 그렇게 구현되지 않는 라이브러리를 사용할 수록
					ㄴ??? 메모리 할당 이슈를 해결하기 위해 이런 기능이 있는 것뿐, 
						multi-threading program으로 개발하려면 다른 언어들과 마찬가지로 공유변수 등을 고려하여 thread-safe하게 개발해야함? 
					ㄴ 참조 
						ㄴ https://pythonspeed.com/articles/python-gil/
						ㄴ https://symphony.is/about-us/blog/a-deep-dive-into-gil-concurrency-and-parallelism-in-python
						ㄴ https://velog.io/@idnnbi/Python-GIL
						ㄴ https://www.linkedin.com/pulse/why-you-need-python-gil-how-works-zakhar-kravchenko-xjmqf
				</pre>

				ㄴ 표준 라이브러리<button>더보기</button>
				<pre>
					ㄴ 파이썬에서 기본적으로 제공하는 표준 라이브러리 목록
					ㄴ 내장 함수<button>더보기</button>
					<pre>
						ㄴ https://docs.python.org/ko/3/library/functions.html#built-in-funcs
						ㄴ ~~~~~
						ㄴ int(x)
							ㄴ x는 숫자 또는 문자열.
							ㄴ x로부터 만들어진 정수 객체 반환.
						ㄴ isinstance( (*객체*), (*클래스 정보*) )
							ㄴ (*객체*)가 (*클래스 정보*)에 해당하는 클래스의 객체이거나, 그 하위 클래스의 객체이면 true.
							ㄴ ex)
								class AAA:
									pass;
								class BBB(AAA):
									pass;

								bbb = BBB();
								isinstance(bbb, AAA); #True.
						ㄴ issubclass( (*클래스*), (*클래스정보*) )
							ㄴ
						ㄴ len( (*객체*) )
							ㄴ 객체의 길이 반환.
							ㄴ (*객체*)는 시퀀스, 컬렉션이다.
						ㄴ open()
							ㄴ 파일을 열고 해당 '파일 객체'를 반환.
							ㄴ ~~~~~
						ㄴ eval()
							ㄴ 파이썬의 '표현식'을 계산하는 함수.
							ㄴ 동적으로 생성된 파이선 표현식 '하나'를 계산하기위해 쓰임.
							ㄴ ex)
								x = 1
								eval('x+1') #2출력.
							ㄴ ~~~~~
						ㄴ exec()
							ㄴ 파이썬 코드를 실행시켜주는 함수.
							ㄴ 동적으로 생성된 파이선 코드를 실행하기 위해 쓰임.
							ㄴ ~~~~~
					</pre>

					ㄴ 내장 상수<button>더보기</button>
					<pre>
						ㄴ https://docs.python.org/ko/3/library/constants.html
						ㄴ ~~~~~
						ㄴ False : bool 클래스의 거짓값.
						ㄴ True : bool 클래스의 참값.
						ㄴ None :
					</pre>

					ㄴ 내장형 <button>더보기</button>
					<pre>
						ㄴ ~~~~~
						ㄴ 논리값 검사
							ㄴ 모든 객체는 논리값 검사 대상이 될 수 있다.
							ㄴ 객체가 False를 반환하는 __bool__(), 0을 반환하는 __len__()를 구현하지 않는한 True로 간주된다.
							ㄴ 따라서 다음의 객체들은 거짓으로 간주된다.
								ㄴ '거짓'형태의 내장 상수 : None, False
								ㄴ 0을 나타내는 숫자들 : 0, 0.0, 0j, Decimal(0), Fraction(0,1)
								ㄴ 빈 시퀸스와 컬렉션 : '', (), [], {}, set(), range(0)
						ㄴ 논리 연산
							ㄴ or : x or y 형태. 앞에 것이 참인지를 확인한다 생각하면 된다. x가 참이면 x반환, 아니면 y반환.
									'단일 회로 연산'이므로 왼쪽에서 부터 차례대로 연산하며, 더 확인해봐야할때만 다음 부분이 연산된다.
							ㄴ and : x and y 형태. 앞에것이 거짓인지를 확인한다 생각하면 된다. x가 거짓이면 x반환, 아니면 y반환.
									역시 '단일 회로 연산'.
							ㄴ not : not x 형태. x의 참 거짓값의 반대를 반환.
						ㄴ 비교
							ㄴ 흔히 아는 <, <=, >, >=, ==, != 와
							ㄴ is, is not이 존재. 이건 객체의 'identity'를 비교하여 동일한지 판별.
						ㄴ 숫자형
							ㄴ int, float, complex
							ㄴ ~~~~~
						ㄴ 이터레이터 형
							ㄴ ~~~~~
						ㄴ 시퀸스 형
							ㄴ list, tuple, range
							ㄴ 공통 연산
								ㄴ x in s : s의 항목중 하나가 x와 같으면 true.
								ㄴ x not in s : s의 항목 중 하나가 x와 같으면 false.
								ㄴ s + t : s와 t 이어붙이기.
								ㄴ s * n : s에 자기자신s를 n번 이어붙이기
									ㄴ s가 복사되는것이 아닌, 같은 객체가 여러번 참조되는 것.
								ㄴ s[i]
								ㄴ s[i:j] : 슬라이스
								ㄴ s[i:j:k] : i에서 j까지 k크기로 슬라이스
								ㄴ len(s)
								ㄴ min(s)
								ㄴ max(s)
								ㄴ ?????
								ㄴ s.count(x) : s에서 x의 개수.
							ㄴ 불변시퀸스, 가변 시퀸스
								ㄴ 불변시퀸스
									ㄴ
								ㄴ 가변시퀸스
									ㄴ ~~~~~
									ㄴ 가변 시퀸스 연산
										ㄴ x는 임의의 객체, t는 임의의 이터러블 객체.
										ㄴ ~~~~~
										ㄴ s[i] = x : i번째 값을 x로 대체
										ㄴ s[i:j] = t : i~j까지의 슬라이스를 t로 대체.
										ㄴ del s[i:j] : 해당 부분 제거
										ㄴ s.append(x) : 끝에 x를 추가
										ㄴ s.clear() : s의 모든 항목 제거
										ㄴ s.copy() : s의 얕은 복사
										ㄴ s.extend(t) : t으로 s를 확장
										ㄴ s.insert(i, x) : s[i:i] = [x]와 동일
										ㄴ s.pop(i) : i번째 인자를 반환하고 삭제. i의 디폴트는 -1로, 맨 마지막을 가리킴.
										ㄴ s.remove(x) : x와 같은 첫번째 항목을 제거.
										ㄴ s.reverse() : s의 항목들의 순서를 뒤집음.
							ㄴ 리스트 )
								ㄴ 일반적으로 동일한 성질의 항목들의 모음을 저장.
								ㄴ class list([iterable])
								ㄴ 생성 )
									ㄴ []
									ㄴ [ a,b,c ]
									ㄴ
								ㄴ ~~~~~
							ㄴ 튜플 )
								ㄴ 보통 성질이 다른 여러 항목들을 저장할때 사용. 성질이 같은 경우에도 사용할 수 있다.
								ㄴ 불변 시퀸스.
								ㄴ ~~~~~
							ㄴ range )
								ㄴ 숫자의 불변 시퀸스.
								ㄴ ~~~~~
							ㄴ 텍스트 시퀸스 )
								ㄴ 문자열을 의미.
								ㄴ class str
								ㄴ ~~~~~
							ㄴ ~~~~~
						ㄴ 집합 형
							ㄴ 자바의 set과 유사
							ㄴ 서로 다른 요소. 해시 가능한 객체. 순서 없음.
							ㄴ ~~~~~
						ㄴ 매핑 형 )
							ㄴ class dict
							ㄴ 자바의 map과 유사.
							ㄴ ~~~~~
						ㄴ 문자열 메소드<button>더보기</button>
							ㄴ (*문자열*).format( (*인자1*), (*인자2*), ... )
							ㄴ 'hello, {0}, {1}'.format( 'hehe', 'haha' ) #'hello, hehe, haha' 출력.
							ㄴ 인자로 받는 문자열에 인자 인덱스를 포함한 중괄호를 추가하여, 해당 중괄호 부분에 (*인자1,2,...*)부분의 값이 문자열로
								치환된 값이 들어간다.
							ㄴ '위치 인자'말고도 '키워드 인자'를 사용 할 수 있다.
					</pre>

					ㄴ 내장 예외 

					ㄴ 데이터 타입 
						ㄴ datetime <button>more</button>
						<pre>
							ㄴ ~~~ 
							ㄴ 비교 연산 
								ㄴ naive, aware datetime간 비교연산 불가. 
								ㄴ aware datetime간 비교연산은 타임존 달라도 알아서 맞춰 비교. 
							ㄴ timezone이 일반적으로 생각하는 시간, 30분단위 offset을 가지는게 아닌 분단위 offset을 가지는지 확인 필요. 
								ㄴ ex ) Asia/Seoul +0900이 아닌 +0826 등. 
								ㄴ 실제 시간에 가까운 더 정밀한 offset이라 하는데 눈에 띄지 않아 이슈가 될 가능성. 
								ㄴ https://stackoverflow.com/questions/11473721/weird-timezone-issue-with-pytz
						</pre>
						ㄴ zoneinfo <button>more</button>
						<pre>

						</pre>

					ㄴ 텍스트 처리 기능

					ㄴ 파일, 폴더 관련 
						ㄴ pathlib 
							ㄴ 

					ㄴ Concurrent Execution (병렬처리)
						ㄴ threading  모듈
							ㄴ low level 모듈인 '_thread' 위에서 스레드 관련 고수준 인터페이스 제공 모듈. 
							ㄴ ~~~ 
							ㄴ threading.excepthook
								ㄴ 클래스 함수? 
								ㄴ excepthook(args) 
								ㄴ 스레드 run() 내에서 handle되지 않은 예외 발생시 이 함수가 적절한 인자와 함께 호출됨. 
								ㄴ threading.excepthook = (*함수*) 형태로 오버라이드하여 사용하는식. 
								ㄴ ex ) 
									def hook(args): 
										print(args)
									
									threading.excepthook = hook 
							ㄴ 팁?
								ㄴ 스레드 실행 내에서 발생한 에러는 공유변수에 저장하는 식으도 처리 가능? 
								ㄴ run으로 실행할 함수 바디 전체에 try catch문 하나 두는게 좋다? 
								ㄴ 스레드들 종료될 떄까지 대기하는건 보통 join() 사용? 
							ㄴ 참고 
						
						ㄴ multiprocessing 
							ㄴ ~~~
							ㄴ 프로세스 시작 방식 
								ㄴ spawn 
									ㄴ ??? 부모프로세스가 새 파이선 인터프리터 시작 후, process의 run()실행을 위해 필요한 리소스만 상속받는다? 
									ㄴ 가능 platform 
										ㄴ POSIX, Window  
										ㄴ Windows, macOS에서 디폴트. 
									
								ㄴ fork 
									ㄴ ??? 부모 프로세스가 os.fork()를 사용하여 파이선 인터프리터 fork. 
										자식 프로세스는 부모의 모든 리소스 상속. 
									ㄴ ??? Note that safely forking a multithreaded process is problematic.
									ㄴ 가능 platform 
										ㄴ POSIX 
										ㄴ macOS를 제외한 POSIX에서 디폴트. 
								ㄴ forkserver 
									ㄴ ??? 프로그램 시작 후, 'forkserver' 선택하면, 한 서버 프로세스가 시작. 
										이후부터, 새 프로세스가 필요해질때마다 부모프로세스는 이 서버에게 새 프로세스 fork를 요청하여 생성하는 방식. 
									ㄴ ??? 이 서버 프로세스는 싱글 스레드라 안전하게 os.fork()를 사용할 수 있다? 
									ㄴ ??? 불필요한 리소스는 상속되지 않는다? 
									ㄴ 가능 platform 
										ㄴ ??? Available on Unix platforms which support passing file descriptors over Unix pipes. 

							ㄴ ex ) <button>more</button>
							<pre>
								def count_up(num, n, aaa): 
									for i in range(n):
										aaa[num-1] += 1 
										print(f"{str(num)}: {aaa[num-1]}") 
										time.sleep(0.0001)
								
								def select_query(num, n, ):
									db_conn = DBConnection()
									with db_conn:
										for i in range(n):
											try: 
												q1 = time.perf_counter()
												db_conn.cur.execute(
													"""
													select * from stock_invest_indicator_value 
													where indicator_id=27 and date>'2024-09-01' 
													"""
													# """
													# select * from kq_act_daily  
													# where occr_dt>'20220101' and closing_prc>100000 and updown_rate>10 
													# order by high_prc limit 500 
													# """
												)
												# time.sleep(0.1)
												# db_conn.cur.fetchall() 
												q2 = time.perf_counter()
												print(f"{str(num)})  / {q2-q1} seconds") 
											except Exception as e:
												print(traceback.format_exc())
								
								# Press the green button in the gutter to run the script.
								if __name__ == '__main__': 
								
									manager = multiprocessing.Manager()
									aaa = manager.list([0, 0, 0, 0,0,0,0,0,0, 0, 0, 0,0,0,0,0])
								
									process_list = []
									process_cnt = 2   
									for i in range(process_cnt):
									    process = multiprocessing.Process(target=count_up, args=(i+1, 3*10**2, aaa))
									    # process = multiprocessing.Process(target=select_query, args=(i+1, 10, ))
									    process_list.append(process) 
								
									for process in process_list:
									    process.start()
								
									for process in process_list:
									    process.join() 
										
								
							</pre>
							ㄴ Pool 
								ㄴ 
							ㄴ ~~~
							ㄴ 참고 
								ㄴ https://docs.python.org/3/library/multiprocessing.html#multiprocessing.set_start_method

						ㄴ ~~~ 
					
					ㄴ Networking and Interprocess Communication 
						ㄴ asyncio (Asynchronous I/O) <button>more</button>
						<pre>
							ㄴ ??? 코루틴 실행? await 만날 때마다 main? event loop? 로 실행흐름을 되돌려주고, 이벤트 루프가 알아서 
								다음 코루팅을 실행시킴? 
								다른 코루틴이 끝나거나 await되어 실행흐름을 되돌려주어야 event loop가 실행흐름을 다른 코루틴에게 할당할 수 있어, 
								다른 코루틴 실행 가능? 
							ㄴ asyncio.run()만 하면, 이벤트 루프에 하나의 코루틴만 실행되어, await하여도 다른 실행될 코루틴이 없어, 
								메인코루틴에게 실행흐름이 바로 돌아온다? 
							ㄴ 디폴트로, asyncio의 실행은 '단일 스레드'에서 실행. 
							ㄴ threading, multiprocessing 말고 concurrency를 수행하는 방법. 
								paralleism은 아님. 
							ㄴ ??? await 지점들 중, 언제 멈춰야 하는지는 뭘로 결정되나? await가 있다고 항상 멈추는건 아닌데. 

							ㄴ ~~~ 
							ㄴ 참고 
								ㄴ 
								ㄴ https://www.quora.com/I-cant-understand-how-Asyncio-in-Python-works-Coroutine-event-loop-and-Tasks-What-are-they-Can-you-spell-it-out
						</pre>

						ㄴ ~~~
					
					ㄴ 인터넷 데이터 처리 
						ㄴ email 
							ㄴ 개요 
								ㄴ email 메세지 자체에 대한 모듈. 즉, email을 구성 및 관리하는 기능이 들어있는 모듈. 
									전송 등에 대한 기능은 없음(이는 smtplib 모듈 등 이용)
								ㄴ RFC 와 최대한 호환되도록 구현되었다함. (RFC 5322, RFC 6532, FRC 2045, ...) 
								ㄴ RFC에 대한 상세 내용을 추상화. 
							ㄴ email 객체 
								ㄴ email모듈 내에서 이메일을 나타내는 객체로서, 주로 이를 이용하여 메일 생성, 내용추가, 삭제 등의 작업 수행. 
								ㄴ ??? email.message 
									ㄴ headers, payload(content)로 구성. 
										ㄴ headers는 RFC 5322, RFC 6532를 준수하는 필드명, 값 쌍. 
										ㄴ payload는 단순 텍스트일 수도, MIME type일 수도 있음. 
									ㄴ ??? header와 payload 쌍의 dict 리스트 형태? 
										payload는 또다른 EmailMessage의 리스트일 수도 있다? 
									ㄴ email.message.EmailMessage 
										ㄴ dict형태 interface? 
										ㄴ header name은 ASCII 값, dict의 value는 string. 
										ㄴ 
										ㄴ payload 
											ㄴ 단순 string 또는 bytes object 또는 EmailMessage의 list 가능. 
												ㄴ EmailMessage의 list인 경우, MIME형태. 
										ㄴ 생성자 
											ㄴ EmailMessage(policy=default) 
											ㄴ policy명시시, 해당 'policy'사용. 아님 '디폴트 policy'사용. 
										ㄴ 메소드 
											ㄴ set_content(*args, content_manager=None, **kw) 
												ㄴ 'content_manager'의 'set_content()'를 호출하여 message의 payload를 세팅하는 메소드. 
													content_manager의 set_content() 호출시 self인 Message객체를 인자로 넘김. 
													(*contentManager*).set_content(self, *args, **kw) 이런식으로. 
												ㄴ content_manager가 None인 경우, policy의 content_manager 사용. 
												ㄴ email.contentmanager의 소스 참고. 
													ㄴ 인자 데이터에 맞는 핸들러가 호출되는식. 
													ㄴ 핸들러에 따라 필수 인자 있을수도? 
														ㄴ ex ) 바이트 형태인 경우, maintype, subtype인자 필요. 
											ㄴ add_attachment() 
												ㄴ 개요 ) 
													현재 message객체의 payload에 또다른 message객체를 추가하는 메소드? 
													즉, message 유형이 multipart/mixed가 되도록? 한 메세지 안에 여러 메세지가 포함된 형태. 
												ㄴ 동작 방식 ) 
													현재 message가 'multipart/mixed'인 경우, 새로운 message객체를 만들고 
													이 새 message객체의 set_content()를 호출하며 add_attachment()의 인자들을 넘김. 
													그 후, 현재 message객체의 attach()를 호출하여 이 새 message객체를 현재 message객체에
													추가. 
													현재 message가 'non-multipart', 'multipart/related',  'multipart/alternative'인 경우, 
													'make_mixed()'호출 후, 위 과정 수행. 
													~~~ 
												ㄴ ex ) 
													server = smtplib.SMTP(~~~, 25)

													msg = EmailMessage() 
													msg["From"] = ~~~
													msg["To"] = ~~~

													file = open("~~~.xlsx", "rb") 
													# 컨텐츠 타입이 byte취급이라 maintype, subtype인자 없으면 에러뜸. 
													msg.add_attachment(file.read(), maintype="application", subtype="vnd.ms-excel")

													server.send_message(msg) 

													~~~ 
													html_content = """
													< !DOCTYPE html>< html>< body style='background-color: green; '>helloworld< /body>< /html>
													"""
													# 컨텐츠 타입이 text취급이라 subtype만 필요. 
													msg.add_attachment(html_content, subtype="html")

													server.send_message(msg) 

											ㄴ ~~~
							ㄴ ???parser 
								ㄴ??? 직렬화된 메일 메세지를 받아, EmailMessage object의 트리구조로 변환? 
								ㄴ ~~~
							ㄴ ???generator 
								ㄴ EmalEMessage object를 받아 직렬화형태로 변환. 
								ㄴ ~~~
							ㄴ policy 
								ㄴ object, parser, generator의 동작에 대한 설정을 하는 모듈. 
								ㄴ 기본적으로 email모듈의 컴포넌트들은 RFCs를 엄격히 준수하여 동작하도록 되어있는데, 
									이런 부분들은 RFCs와는 좀 다르게 커스텀 하고자 할때, email.policy의 Policy객체들을 전달하여 커스텀 가능. 
									email모듈의 여러 클래스의 생성자나 메소드의 인자로 Policy 객체를 넘기는 방식으로 
									해당 클래스와 메소드의 동작을 커스텀하는 방식. 
								ㄴ default policy 
									ㄴ policy를 별도설정하지 않을시 사용되는 정책 객체. 
									ㄴ 디폴트로, Compat32 policy 객체. 
								ㄴ ~~~
							ㄴ content manager 
								ㄴ ContentManager 객체 
									ㄴ 메소드 
										ㄴ set_content(msg, obj, *args, **kw)
											ㄴ msg에 obj를 payload로 추가하는 메소드. 
											ㄴ obj의 타입을 확인하여 적절한 핸들러를 호출하는식. 
												핸들러에서 msg에 obj를 저장하고 헤더 변경 등 msg에 적절한 처리를 하게됨. 
											ㄴ msg의 maintype이 'multipart'인 경우, TypeError. 
								ㄴ ~~~

							ㄴ 'compat32' API를 이용한 logacy  
								ㄴ 'compat32'라는 API를 이용한 이전 버전 기능으로서, 
									RFC 상세 내용에 대해 추상화를 하지 않고 더 낮은 수준에서의 커스텀이 가능하다함. 
							ㄴ 참고 
								ㄴ https://docs.python.org/3.9/library/email.html

					ㄴ 마크업언어 처리 도구<button>더보기</button>
					<pre>
						ㄴ 파이선에서는 구조화된 마크업 데이터를 처리할 수 있는 도구들을 제공.
							ㄴ 마크업에는 SGML(Standard Generalized Markup Language), HTML, XML이 포함되어 있다.
						ㄴ ~~~~~
						ㄴ html <button>더보기</button>
						<pre>
							ㄴ html 모듈.
							ㄴ ~~~~~
							ㄴ html 파서 )<button>더보기</button>
							<pre>
								ㄴ html모듈의 서브모듈.
								ㄴ html, xhtml문서를 파싱할 수 있는 'HTMLParser'클래스를 제공하는 모듈.
								ㄴ ~~~~~
							</pre>
						</pre>

					</pre>

					ㄴ 인터넷 프로토콜 관련 
						ㄴ smtplib 
							ㄴ ~~~
							ㄴ SMTP Object 
								ㄴ ~~~ 
								ㄴ 메소드 
									ㄴ sendmail 
									ㄴ send_message
										ㄴ sendmail()과 동일하게 메일전송 메소드인데, python내장모듈인 email의 
											email.message.Message객체를 이용해 sendmail()을 동작시켜주는 편의함수. 
											인자로 받은 email.message.Message로부터 적절히 메세지 내용을 처리하여 sendmail()을 호출해줌. 
										ㄴ ex ) 
											from email.mime.text import MIMEText

											with smtplib.SMTP(settings.MAIL_SERVER_HOST, 25) as server:
												msg = MIMEText("hello")
												msg['From'] = 'StockCosmos@deepq.kr'
												msg['Subject'] = "test"
												msg['To'] = ",".join(mail_list)

												server.send_message(msg)  # Message객체인 msg를 알아서 처리하여 메일전송. 
							
							ㄴ 실무 
								ㄴ sendmail 사용시 msg가 인터넷 표준(MIME, RFC 5322 등)에 맞도록 하기 위해 
									python 표준lib인 email.mime.text.MIMEText 등을 이용해야함. 
									표준에 안맞으면 상용 메일서버들에선 블락됨. 
				</pre>

				ㄴ 파이썬 인터프리터 <button>더보기</button>
				<pre>
					ㄴ 인터프리터 실행하기 )
						ㄴ python3.9 명령어를 실행하여 실행 가능하다.
						ㄴ python -c (*명령어들*) (*인자들*)  을 통해서도 사용 가능하다.
					ㄴ 종료하기 ) EOF문자( 윈도우에선 Ctrl+z )를 누르거나 quit()명령어 입력.
					ㄴ ????? 'GNU Readline' 라이브러리를 제공하는 시스템에서 줄 편집 기능으로 대화형 편집, 히스토리 치환, 코드 완성 등을 제공???
					ㄴ ????? 스크립트 파일 실행 후 대화형 모드로 들어가려면 스크립트 앞에 -i 옵션 전달.
					ㄴ 인자 전달 )
						ㄴ ?????
					ㄴ 대화형 모드 )
						ㄴ tty (콘솔이나 터미널)에서 명령을 읽는 것을 인터프리터가 '대화형 모드'로 동작한다고함.
						ㄴ 기본 프롬프트는 '>>>'이고, 여러줄이 이어지는 입력일 때의 보조 프롬프트는 '...'이다.
					ㄴ 디폴트로 파이선 소스 파일들은 UTF-8로 인코드 된 것으로 취급.
				</pre>

				ㄴ 주석 )
					ㄴ 해시문자, #로 시작하는 부분 뒤쪽으로 모두 주석취급.
					ㄴ ex)
						# this is the first comment
						spam = 1  # and this is the second comment
								# ... and now a third!
						text = "# This is not a comment because it's inside quotes."
				ㄴ 연산 )
					ㄴ 나누기 연산자(/)는 항상  float를 반환. 정수 나누기를 하려면 '//'연산자를 이용해야함.
					ㄴ '**'를 이용해 거듭제곱 연산 가능. ex) 5 ** 2 #25
				ㄴ 문자열 )
					ㄴ 작은따옴표나 큰따옴표로 표시.
					ㄴ 이스케이프 문자는 백슬래쉬 '\'이다.
					ㄴ 문자열 앞의 따옴표 앞에 'r'문자를 붙여 'raw string'을 만들 수 있다.
						ㄴ ex ) print( r'C:\some\name' ) # C:\some\name
					ㄴ 문자열 리터럴은 삼중 따옴표를 이용하여 여러줄로 될 수 있다.
						ㄴ ex)
							print("""\
							Usage: thingy [OPTIONS]
								-h                        Display this usage message
								-H hostname               Hostname to connect to
							""")
					ㄴ + 연산자로 이어붙이고, * 연산자로 반복가능하다.
						ㄴ 두개 이상의 문자열 리터럴이 연속해서 나오면 자동으로 이어붙여짐. (문자열 리터럴이 연속으로 나오는 경우만 해당. 변수는 안됨)
					ㄴ js의 문자열처럼 배열로 취급 될 수 있다.
						ㄴ ex) word = 'Python'  word[0]='P'
						ㄴ '문자'에 해당하는 별도의 자료형은 없다. 단순히 길이가 1인 문자열이다.
						ㄴ index가 음수이면 끝에서부터 결정.
						ㄴ 이를 이용해 '슬라이싱'도 가능하다.
							ㄴ ex) word[0:2] #'Py'. index 0 자리 부터 2자리 이전까지의 문자열 추출.
							ㄴ 슬라이싱에서 index 값을 주지 않으면 디폴트값이 잇다.
								ㄴ ex) word[ :2] #앞부분 디폴트값은 0. 뒷부분은 문자열의 길이.
						ㄴ 범위를 벗어나는 인덱싱은 오류이나, '슬라이싱'에서 범위를 벗어나는 인덱싱은 알아서 처리가 된다.
							ㄴ ex) word[100] #오류.       word[ :100] #'Python'
					ㄴ 문자열 리터럴은 '불변'이다.
					ㄴ 내장함수 len() : 문자열 길이 반환. len( (*문자열리터럴*) )

				ㄴ 제어 흐름 도구<button>더보기</button>
				<pre>
					ㄴ if )
						ㄴ ex)
							if (*판별식*):
								(*로직*)
							elif (*판별식*):
								(*로직*)
							...
							else:
								(*로직*)
						ㄴ 조건식 )
							ㄴ while, if에 오는 조건절에는 비교연산자 뿐만 아니라, 모든 종류의 연산자 사용이 가능하다.
								ㄴ in,not in, is, is not 등.
							ㄴ 비교는 여러개가 겹칠 수 있다.
								ㄴ a < b == c 와 같이 사용 가능.
							ㄴ not으로 true, false를 뒤집을 수 있다.
							ㄴ and, or으로 자바의 &&, ||의 기능을 할 수 있다.
							ㄴ 논리연산자는 '단락-회로(short-circuit)' 연산자이다.
								ㄴ 왼쪽부터 오른쪽으로 가다가 값이 결정되면 더 이상 계산하지 않음.
					ㄴ for )
						ㄴ ex) for (*item*) in (*컬렉션*):
									(*로직*)
						ㄴ 컬렉션에 대해? 반복하는 방식으로 동작.
						ㄴ c나 java처럼 반복횟수와 조건을 따로 설정하지 않음.
					ㄴ range() )
						ㄴ 수열을 반환하는 함수.
						ㄴ for에서 숫자들 순서로 반복하려할 때 편리.
						ㄴ ex) for i in range(5):
									print(i)
						ㄴ ex)
							range(5,10) #5,6,7,8,9
							range(0, 10, 3) #0,3,6,9
							range(-10, -100, -30) #-10,-40,-70
						ㄴ 리스트를 반환하는게 아닌, 'iterable'을 반환.
						ㄴ range()에서 리스트를 얻으려면 list( range(4) )를 호출.
					ㄴ 루프의 break, continue, else )
						ㄴ break는 가장 가까운 for, while 루프를 빠져나오게한다.
						ㄴ else 절 )
							ㄴ for이 'iterable'을 모두 돌렸거나 while에서 조건이 거짓이 되면 실행된다.
							ㄴ ex)
								for x in range(2,10):
									~~~~~
								else:
									~~~~~
							ㄴ break로 루프가종료되면 호출되지 않음.
						ㄴ continue )
							ㄴ 루프에서 다음 반복으로 넘어감.
					ㄴ pass 문 )
						ㄴ 아무것도 하지않고 그냥 넘어가는 문장.
						ㄴ ex)
							while True:
								pass
				</pre>

				ㄴ 함수<button>더보기</button>
				<pre>
					ㄴ ex) 	def (*함수명*) ( (*매개변수*) ):
								(*함수 바디*)
					ㄴ (*함수 바디*)
						ㄴ 첫번째 문장을 선택적으로 문자열 리터럴을 입력하여 함수에 대한 설명을 하는 'docstring'을 정의할 수 있다.
							ㄴ 다른 여러 곳에서 이 docstring을 볼 수 있다함.
							ㄴ 일반적으로 사용되는 관습 )
								ㄴ 첫줄은 함수의 목적을 짧고 간결하게 요약. 대문자로 시작하고 마침표로 종료.
								ㄴ 추가적인 설명이 있다면, 두번째 줄은 비워서 요약과 나머지 설명을 구분.
								ㄴ 나머지 설명에서는
					ㄴ 변수 범위
						ㄴ (*함수 바디*)에서의 지역 변수들과 매개변수들은 지역 심볼 테이블에 저장된다.
							ㄴ 따라서 매개변수들은 '값에 의한 참조'이다.
						ㄴ 변수는 지역 심볼 테이블, 전역 심볼 테이블, 내장된 이름 테이블 순으로 확인한다.
					ㄴ 함수 정의는 함수 이름을 심볼 테이블 안에 함수 객체와 연결한다. 인터프리터는 그 함수 이름이 가리키는 객체를 사용자 정의 함수로 인식한다.
						ㄴ 다른 이름의 변수 또한 동일한 함수 객체를 가리킬 수 있다.
							ㄴ ex) 	fib란 함수가 정의되었다면,
									fib #fib함수 객체를 가리킴.
									f = fib #f도 이제 fib함수 객체를 가리킴.
					ㄴ return문이 없는 함수는 'None'이라는 내장 정의된 값을 반환한다.
						ㄴ 인터프리터는 보통 'None'값을 출력하지 않는다.
					ㄴ (*매개변수*) )
						ㄴ 인자들의 기본값을 지정 할 수 있다.
							ㄴ ex) def ask_ol( prompt, retries = 4, reminder='Please try again'):
										(*body*)
							ㄴ 기본값은 함수 정의 시점에서의 스코프로, 함수정의할때 단 한번만 설정된다.
								ㄴ ex)
									i = 5
									def f(arg=i):
										print(arg)

									i=6
									f() #5가 출력된다.
								ㄴ 기본값이 리슽, 딕셔너리, 클래스 인스턴스일 경우, 함수 호출시마다 그 기본값이 유지되므로 주의가 필요하다.
									ㄴ ex)
										def f(a, L=[]):
											L.append(a)
											return L

										print(f(1)) # [1]
										print(f(2)) # [1,2]
										print(f(3)) # [1,2,3]출력.
						ㄴ 호출 시, 디폴트값이 정해져있는 인자는 넘기지 않아도 된다.
						ㄴ 매개변수 키워드 )
							ㄴ 함수 호출시, 매개변수 명을 키워드로 넘겨서 함수를 호출 할 수 있다.
							ㄴ ex) aks_ol('aaa')
									ask_ol('aaa', retries=11)
									ask_ol(prompt='aaa', retries=11)
							ㄴ 규칙 )
								ㄴ 키워드 인자는 키워드가 없ㄴ느 인자 뒤에 나와야 한다.
								ㄴ 키워드는 중복될 수 없고
								ㄴ 매개변수명으로 존재하는 키워드가 와야한다.
						ㄴ **(*매개변수명*) 형식의 매개변수
							ㄴ js에서 정의된 매개변수 이외의 인자들을 argument?인자가 모두 받듯이, 함수 호출 시, 정의된 매개변수에 대응되지 않는
								키워드 인자들을 담은 '딕셔너리(dict)'를 받는다.
								ㄴ ex) def cheeseshop( kind, *arguments, **keywords)
							ㄴ ?????
						ㄴ 매개변수 형식 지정 )
							ㄴ 함수 호출 시, 매개변수가 지정될 형식을 엄격하게 정해 놓을수 있다.
							ㄴ def f(pos1, pos2, /, pos_or_kwd, *, kwd1, kwd2):
								ㄴ '/'인자와 '*'인자는 매개변수 형식지정에 사용되는 선택적 인자이다.
								ㄴ '/'인자 앞부분의 매개변수들은 위치만으로 매개변수 지정이 가능해진다.
								ㄴ '/'인자와 '*'인자 사이의 매개변수들은 위치와 키워드 둘 다로 매개변수 지정이 가능하다.
								ㄴ '*'인자 뒷부분의매개변수들은 키워드만으로 매개변수 지정이 가능하다.
						ㄴ 임의의 인자 목록 )
							ㄴ 임의의 개수의 인자로 함수가 호출 될 수 있게하는 기능
							ㄴ 인자가 정해지지 않은 남은 인자들이 '튜플'이라는 자료구조로 묶여서 함수에 전달된다.
								ㄴ ex)
									def concat( *args, sep='/'):
										return sep.join(args)

									conat( 'earth', 'mars', 'venus' ) # earth/mars/venus
						ㄴ 람다 표현식 )
							ㄴ 이름없는 작은 함수를 만드는데 사용된다.
							ㄴ ex) lambda a, b: a+b
							ㄴ 함수 객체가 올 수 있는 곳에 사용될 수 있다.
					ㄴ 함수 어노테이션
						ㄴ ?????
				</pre>
				ㄴ 코딩 스타일
					ㄴ 탭 말고 스페이스바 4번으로 들여쓰기를 사용하라.
						ㄴ 스페이스 4개가 작은 들여쓰기, 큰 들여쓰기 사이의 철충안이라함.
						ㄴ ????? 탭은 혼란을 일으킨다함??
					ㄴ 79자를 넘기면 줄넘김을 ㅎ라
					ㄴ 함수, 클래스, 함수 내의 큰 코드블럭 사이에 빈줄을 넣어 분리
					ㄴ 주석은 별도의 줄에
					ㄴ docstring 사용
					ㄴ 연산자들과 컴마 뒤에 스페이스를 넣고, 괄호 바로 안쪾에 스페이스를 넣지 마라.
					ㄴ 클래스와 함수에 일관성있는 이름규칙. 관례는 클래스의 경우 UpperCamelCase, 함수의 경우 lowercase_with_underscores.

				ㄴ 자료 구조 <button>더보기</button>
				<pre>
					ㄴ 리스트
						ㄴ ex) squares = [ 1, 3,5 ]
						ㄴ 안의 값들은 자료형이 다를 수도 있지만 일반적으로 같다함.
						ㄴ 문자열처럼 인덱싱과 슬라이싱이 된다.
							ㄴ 슬라이스 연산은 원본 리스트가 아닌, 복사본을 반환해준다.
							ㄴ 슬라이스에 대입도 가능하다.
								ㄴ ex) squares[ : 2] = [9,9] #[9,9,5]
						ㄴ + 연산자르 이용한 이어붙이기 연산도 지원한다.
						ㄴ append()를 이용하여 항목을 추가 할 수 있다.
							ㄴ ex) squares.append(2*3) # [1,3,5,6]
						ㄴ '가변'이다.
						ㄴ 문자열 리터럴에 사용되던 len()을 리스트에도 사용가능ㅎ다.
						ㄴ 리스트 중첩도 가능하다.
							ㄴ ex) a=[1,2,3]   b=['x', 'y']
									c=[a,b] #[ [1,2,3], ['x','y'] ]
						ㄴ 메소드 )
							ㄴ append(x) : 리스트 끝에 항목을 추가.
							ㄴ extend( (*iterable*) ) : 리스트 끝에 iterable의 모든 항목 추가.
							ㄴ ~~~~~
						ㄴ 정렬과 비교가 없다. 여러 타입이 항목에 포함 될 수 있기 때문에.
						ㄴ 스택으로써 사용)
							ㄴ append()와 pop()을 사용하면된다.
						ㄴ 큐로써 사용 )
							ㄴ 가능은 하지만, 맨 앞에서 꺼내거나 붙이는 것은 모든 항목을 한칸씩 밀거나 당겨야 하기때문에 속도가 느려 적합치 않다.
							ㄴ 파이선 표준라이브러리의 collections.deque를 사용하라함.
						ㄴ 컴프리핸션???
						ㄴ del 문 )
							ㄴ 인덱스를 이용하여 리스트에서 항목을 제거
							ㄴ ex) del a[0], del a[ : 4] #리스트 a에서 해당 부분을 제거.
					ㄴ 튜플과 시퀸스 )
						* 시퀸스
							ㅡ ?????
							ㅡ 대표적 자료형 : list, tuple, range
						ㄴ 튜플은 쉼표로 구분되는 여러 값을 가지는 데이터형.
						ㄴ ex) t = 111, 222, 'hello'
						ㄴ 출력시 괄호로 감싸져서 출력된다. ex) ( 111, 222, 'hello')
						ㄴ '불변'이다.
						ㄴ 빈 괄호를 사용하여 빈 튜플을 만들 수 있다. ex) t = ()
						ㄴ 하나의 항목을 가지는튜플은 끝에 컴마를 붙여 만들 수 있다. ex) t = 111,
						ㄴ 패킹, 언 패킹 )
							ㄴ t = 111, 222, 'hello' 와 같은 예를 '튜플 패킹'이라 한다.
							ㄴ x, y, z = t 와 같은 예를 '시퀸스 언 패킹' 이라 한다.
								ㄴ 요소와 같은 개수가 와야한다.
					ㄴ 집합 )
						ㄴ 중복되는 요소가 없는, 순서 없는 컬렉션.
						ㄴ 생성 )
							ㄴ 중괄호 또는 set() 사용.
								ㄴ 빈 집합을 만드려면 set()을 사용해야함. 빈 중괄호 {}는 빈 '딕셔너리'를 만드는데 사용된다.
							ㄴ ex) 중괄호 이용.
								basket = {'aaa', 'bbb', 'aaa', 'ccc'}	#{'aaa','bbb','ccc'} 집합 생성.
							ㄴ ex) set() 이용.
								x = set('abcdef')	#{'a','b','c','d','e','f'}
								y = set('def')	#{'d','e','f'}
						ㄴ 집합 연산 )
							ㄴ - : 차집합. ex) x-y 	#{'a','b','c'}
							ㄴ | : 합집합.
							ㄴ & : 교집합.
							ㄴ ^ : XOR연산.
					ㄴ 딕셔너리 )
						ㄴ '키'로 인덱싱되는 자료형. java의 Map과 유사한듯하다. 키 : 값 쌍의 집합.
						ㄴ 생성 )
							ㄴ 중괄호 안에 (*키*) : (*값*) 쌍을 컴마로 구분하여 넣으면 생성 가능.
								ㄴ ex) 	tel = {'aaa':111, 'bbb':222}
							ㄴ 빈 중괄호는 빈 딕셔너리를 생성. ex) {}
						ㄴ ex) tel['ccc'] = 333
						ㄴ del 문을 사용하여 키값쌍 삭제가능. ex) del tel['aaa']
						ㄴ 이미 존재하는 키로 저장시, 덮어씌워짐.
						ㄴ 없는 키로 조회시, 에러.
						ㄴ list()에 딕셔너리를 인자로 넘길시, 딕셔너리의 키값목록을 삽입순으로 반환해줌.
						ㄴ in 키워드로 키값 확인 가능.
						ㄴ 가능한 키값 )
							ㄴ 문자열과 숫자는 항상 키값이 될 수 있다.
							ㄴ 튜플이 문자열, 숫자, 튜플만 포함한다면 키로 사용될 수 있다.
							ㄴ 튜플이 직간접적으로 가변 객체를 포함하면 불가.
					ㄴ 자료형들의 반복 )
						ㄴ 딕셔너리로 반복시, items()를 사용하면 키와 값을 동시에 얻을 수 있음.
							ㄴ ex)
								for k,v in (*딕셔너리*).items():
									~~~~~
						ㄴ 시퀸스 반복시, enumerate() 사용하면 인덱스와 값을 동시에 얻을 수 있음.
							ㄴ ex)
								for i,v in enumberate( (*시퀸스*) ):
									~~~~~
						ㄴ 둘 이상의 시퀸스 반복하려면, zip()으로 엔트리들의 쌍 생성 가능.
							ㄴ ex)
								for a,b in zip( (*시퀸스1*), (*시퀸스2*) ):
									~~~~~
						ㄴ 시퀸스를 거꾸로 반복하려면, reversed() 사용
							ㄴ ex) for i inreversed( (*시퀸스*) ):
										~~~~~
						ㄴ 시퀸스를 정렬하려면 sorted()사용
							ㄴ ex) for i in sorted( (*시퀸스*) ):
										~~~~~
						ㄴ 시퀸스에 대해 중복 요소 제거하려면 set()사용
							ㄴ ex) for f in sorted( set( (*시퀸스*) ) ):
										~~~~~
					ㄴ 시퀸스의 비교 )
						ㄴ 두 시퀸스 객체를 비교 할 수 있다.
						ㄴ ex)
							(1, 2, 3)              < (1, 2, 4)
							[1, 2, 3]              < [1, 2, 4]
							'ABC' < 'C' < 'Pascal' < 'Python'
							(1, 2, 3, 4)           < (1, 2, 4)
							(1, 2)                 < (1, 2, -1)
							(1, 2, 3)             == (1.0, 2.0, 3.0)
							(1, 2, ('aa', 'ab'))   < (1, 2, ('abc', 'a'), 4)
						ㄴ 첫번째 항목끼리부터 차례대로 비교하여 해당 항목에서 차이가 나면 바로 그결과를 결정.
						ㄴ 동일하면 다음 항목들끼리 비교, 시퀸스안에 시퀸스가 있을시, 재귀적으로 또 비교, 이런식으로 모든 항목을 비교.
						ㄴ 모든 항목이 같으면 동일.
						ㄴ 다 같은데 한쪾이 개수가 부족하면 그 시퀸스가 더 작은 것.

				</pre>

				ㄴ 모듈<button>더보기</button>
				<pre>
					ㄴ 여러 정의한 내용들을 파일에 넣고, 스크립트나 인터프리터의 대화형 모드에서 사용할 수 있고, 이러한 파일들을 '모듈'이라 한다.
					ㄴ 파일을 정의하고, import (*파일명*) 을 한뒤, (*파일명*).(*함수명*) 과 같이 사용하면, 해당 모듈에 있는 함수 등을 사용할 수 있다.
					ㄴ 모듈 파일 안에는 함수 정의뿐만 아니라 다른 실행 가능한 문장들도 포함되어있고 이것들은 모듈이 처음 import될 때(모듈이 초기화 될때?) 실행된다.
					ㄴ 모듈의 심볼 테이블은 그 모듈의 함수들의 전역 심볼 테이블로 사용된다. 물론 import한 모듈명을 이용해 이 모듈의 변수들에 접근가능하다.
					ㄴ 모듈역시 다른 모듈을 import할 수 있다. import되는 모듈의 이름은 import하는 모듈의 전역 심볼 테이블에 들어간다.
					ㄴ ????? 모듈의 이름을 import하는게 아닌 직접 선택적으로?? import하는 import문도 있다.
						ㄴ from (*모듈명*) import (*모듈의 함수 또는 변수*)
						ㄴ from (*모듈명*) import *
							ㄴ 모듈에서 정의하는 모든 이름들을 import.
						ㄴ import (*모듈명*) as (*별칭*) : 모듈이름을 별칭으로 지정하여 import.
					ㄴ 모듈 안에서 모듈의 이름은 전역변수 __name__을 이용해 접근가능하다.
					ㄴ 스크립트로 모듈 실행 )
						ㄴ python (*모듈명*) (*인자*) : 모듈 실행하는 명령어.
						ㄴ 모듈의 코드는 import할 때와 같이 실행된다.
						ㄴ __name__은 '__main__'으로 고정된다.
							ㄴ 모듈의 끝에 다음의 코드를 붙여서 파일이 import되고 스크립트로 사용될 수 있도록 하기위해서이다.
							ㄴ 	if __name__ == "__main__":
								import sys
								fib(int(sys.argv[1]))
						ㄴ 모듈을 import하면 코드는 실행되지 않는다. import (*모듈명*)
					ㄴ 모듈 검색 )
						ㄴ 특정 이름의 모듈이 import되면, 인터프리터는 우선 내장 모듈 중 같은 이름을 찾는다.
							없으면, sys.path 변수에서 주어지는 디렉토리 중에서 찾는다.
							* sys.path
								ㅡ 모듈의 검색 경로를 지정하는 문자열 리스트.
								ㅡ ?????
						ㄴ ?????
					ㄴ 컴파일된 파이선 파일
						ㄴ 모듈 로딩을 빠르게 하기 위해, 파이선은 각 모듈들의 컴파일된 버전을 '__pycache__'란 디렉토리에 '(*모듈명*).(*버전*).pyc'란
							이름으로 캐싱한다.
						ㄴ 소스의 수정시간과 컴파일 버전을 비교하여 재컴파일 필요 여부를 자동으로 결정한다.
						ㄴ ?????
						ㄴ 명령행에 직접 로드되는 모듈은 캐시검사를 하지 않는다.
						ㄴ 컴파일된 파일만 있고 소스가 없어도 캐시검사를 하지 않는다.
					ㄴ 표준 모듈들 )
						ㄴ 여러 표준 모듈들의 라이브러리가 기본으로 존재한다.
						ㄴ 이중ㅈ 몇몇은 인터프리터에 내장된다.
							ㄴ 'sys'모듈은 인터프리터에 내장된다.
								ㄴ sys.ps1, sys.ps2 : 기본 프롬프트, 보조 프롬프트를 정의하는 문자열
								ㄴ sys.path : 인터프리터의 모듈 검색 경로를 결정하는 문자열 리스트.
					* dir( )
						ㅡ 인자로 모듈명을 넘기면, 해당 모듈이 정의하는 이름들을 리스트로 반환.
						ㅡ 인자가 없으면, 현재 정의한 이름들을 나열. (내장함수, 변수들은 반환안함)
					ㄴ 패키지 )
						ㄴ 모듈들을 이름 공간으로 구조화하는 방법.
						ㄴ 이를 통해, 모듈의 이름이 다른 외부의 모듈명과 겹칠 걱정을 안해도된다. 패키지명만 다르면 다를테니까.
						ㄴ import )
							ㄴ import (*패키지1*).(*패키지2*). ... .(*모듈명*)
								ㄴ 이 경우 모듈을 사용하려면 앞의 패키지들을 모두 적어주어야 한다.
							ㄴ from (*패키지1*).(*패키지2*). ... import (*모듈명*)
								ㄴ 이 경우, 모듈명만으로 모듈 사용이 가능하다.
								ㄴ (*모듈명*)에 모듈 전체 말고, 각 이름을 따로 import할 수도 있다.
				</pre>

				ㄴ 입력과 출력 <button>더보기</button>
				<pre>
					ㄴ
				</pre>

				ㄴ 에러와 예외<button>더보기</button>
				<pre>
					ㄴ 문법예외, 실행중에 감지되는 에러를 '예외'라 한다.
					ㄴ ~~~~~
					ㄴ raise 문 )
						ㄴ java의 throw문과 비슷한 것. 특정 예외를 명시적으로 발생시킴.
						ㄴ
					ㄴ 예외 연쇄
					ㄴ 사용자 정의 예외 )
						ㄴ Exception 클래스를 직,간접적으로 상속하여 커스텀 예외 클래스를 만들 수 있다.
						ㄴ '클래스'이기 때문에, 일반 클래스가 할 수있는 모든 기능을 할 수 있지만, 일반적으로 에러 정보에 관한 몇가지 기능이나
							어트리뷰트만을 가진다.
					ㄴ finally 문 )
						ㄴ
					ㄴ with
				</pre>

				ㄴ 가상환경<button>더보기</button>
				<pre>
					ㄴ 파이썬 어플리케이션에서 표준 라이브러리가 아닌 외부 라이브러리를 사용할 경우, 이를 파이썬에 따로 설치해 주어야 한다.
						그리고 어플리케이션이 그 외부 라이브러리의 특정 버전을 요구하는 경우들이 있다. 이때, 어플A에서는 버전 1.0을 요구하는데
						어플B에서는 버전 2.0을 요구하는 등 요구하는 버전이 다른경우가 발생한다.
						파이썬에서는 이러한 문제를 'virtual environment'를 이용하여 해결한다.
						ㄴ 파이썬의 virtaul environment란?
							한 파이썬 어플이 같은 시스템 상에 있는 다른 파이썬 어플에 영향을 주지 않으면서 파이썬 패키지를 설치하고 업그레이드
							할 수 있게 해주는 cooperatively isolated runtime environment.
						ㄴ 어플이 각자의 가상환경을 가지고, 이곳에 필요한 패키지를 설치하거나 업그레이드 하는 것.
					ㄴ venv 모듈 )
						ㄴ 간단한 '가상환경'을 만들어주는 기능과 관련된 모듈.
						ㄴ????? 각 '가상환경'은 각자의 'site directory'를 가지며, system site directory와 분리될 수 있다
						ㄴ 각자의 site directory에 각자의 파이선 패키지들을 가질 수 있다.
						* site-packages : 파이선 패키지들이 저장되는 폴더라고보면된다. 보통 윈도우에선 Lib\site-packages에 위치해있다.
					ㄴ 가상환경생성
						ㄴ python -m venv (*경로를포함한 가상환경폴더명*)
							ㄴ ex) python -m venv ./sampleVirtualEnv
						ㄴ 해당 위치에 입력한 폴더명으로 가상환경이 생성된다.
						ㄴ 입력한 이름의 폴더가 생기며, pyvenv.cfg파일, Scripts폴더, site-packages폴더 등이 생긴다.
					ㄴ 가상환경 활성화
						ㄴ 가상환경 폴더의 Scripts/activate.bat을 실행시키면 된다.
							ㄴ ex) C:\Users\kai> .\sampleVirtualEnv\Scripts\activate.bat
						ㄴ 커맨드입력 맨 앞에 'prompt'가 바뀌어 현재 어떤 가상환경인지 알려준다.
							ㄴ ex) (sampleVirtualEnv) C:\Users\kai >
					ㄴ ~~~~~
				</pre>

				ㄴ 다른 구현체들 
					ㄴ 종류 
						ㄴ CPython 
							ㄴ C로 구현된 파이썬. 
							ㄴ 가장 널리 사용되는 파이썬 구현체. 
						ㄴ Jython 
							ㄴ java로 구현된 파잇너. 
						ㄴ Python for .NET
						ㄴ IronPython
						ㄴ PyPy
					ㄴ 구현체에 따라 동작이 약간씩 다르거나 standard보다 추가적인 부분 존재. 각 구현체의 문서 확인 필요. 

				ㄴ 참조 
					ㄴ https://docs.python.org/3.9/reference/index.html
					ㄴ https://docs.python.org/3.9/tutorial/index.html
			</pre>

			ㄴ Anaconda <button>더보기</button>
			<pre>
				ㄴ 패키지 관리, 가상 환경 관리 기능이 있는 데이터 과학용 파이선/R의 배포판..?
				ㄴ 기본 시작방법 )
					ㄴ 아나콘다 설치후,
					ㄴ anaconda prompt실행하고
					ㄴ conda create -n (*환경이름*) 으로 환경생성.
					ㄴ activate (*환경이름*) 으로 환경실행.
					ㄴ 맨앞 괄호 ()안에 환경이름이 바뀔것.
					ㄴ 여기서 python명령어 입력하여 파이선 실행.
				ㄴ 아나콘다 안에는 파이선이 포함되어있기때문에, 파이선이 이미설치되어있는데 아나콘다 설치시, 파이선의 환경변수 등이 충돌이 일어날 수도 있다.
					파이선을 삭제해야함.
					ㄴ 일단 나는 ㅇ나ㅏ콘다 설치과정에서 기존파이선을 사용할거냐고 물어보는창이있어 yes클릭.
				ㄴ ~~~~~
			</pre>

			ㄴ PyPI <button>더보기</button>
			<pre>
				ㄴ 
				ㄴ 참고 
					ㄴ 
			</pre>

			ㄴ 파이썬 라이브러리, 모듈<button>more</button>
			<pre>
				ㄴ Numpy <button>더보기</button>
				<pre>
					ㄴ Numpy란? )<button>더보기</button>
					<pre>
						ㄴ 대량의 다차원 배열을 효과적으로 다룰수 있게 해주는 라이브러리. 과학, 수학 분야에서 많이 사용.
						ㄴ 다차원 배열객체, 이로부터 파생되는 여러 객체(행렬 등), 배열에 관한 여러 연산기능을 제공.
						ㄴ 'ndarray'객체라는 핵심 객체를 중심으로 동작.
							ㄴ ndarray 객체란? 같은 데이터 타입인 요소들의 n차원 배열을 추상화한 객체.

						ㄴ numpy의 편리함, 효과?
							ㄴ 리스트의 곱을 예로들면, 파이선 리스트를 이용해 리스트간 곱셈을 하려면,
								c = []
								for i in range(len(a)):
									c.append(a[i]*b[i])
								위와 같이 코드를 작성해야한다. 근데 이것도 두 리스트의 길이가 다르면 빠지는 부ㅜㅂㄴ이 생긴다.
							ㄴ ~~~~~
							ㄴ numpy를 이용하면 다음과 같이 간단하게 작성할 수 있다.
								c = a * b
								ㄴ 이는 c언어만큼 빠르고 직관적으로 이해하기 쉽다.
								ㄴ 넘파이 연산자가 미리 만들어진 최적화되고 컴파일된 c언어 코드를 호출하여 동작하게된다. 따라서 파이선 루프문보다 훨씬 빠르다.
							ㄴ 이것이 numpy의 기본적인 두가지 기능. '벡터화', '브로드캐스팅'을 보여준다.
						ㄴ 벡터화와 브로드캐스팅
							ㄴ 벡터화 )
								ㄴ 각 요소들이 각각의 상응하는 요소들과 한번에 연산되는것? 아님 c언어 레벨에서 이런 연산을 시켜주는 것?
									ㄴ 위의 곱셈예시에서 반복문을 통해 각 요소를 하나씩 연산해주는게 아닌 numpy의 *연산을 통해 한번에 각 요소들을 연산하는 것.??
								ㄴ 이러한 작업들이 내부적으로 최적화된 컴파일된 c코드를 통해 동작한다.
								ㄴ 이를 통해 코드가 매우 간결해 진다.
							ㄴ 브로드 캐스팅 )
								ㄴ 형태가 다른 배열들도 알아서 조절하여 연산을 하게 해준다.
					</pre>

					ㄴ 개요 )<button>더보기</button>
					<pre>
						ㄴ n차원 배열을 어떻게 다루는지에 대해 배운다.
							ㄴ numpy에서 1,2, n차원 배열의 차이점에 대해
							ㄴ ~~~~~
						ㄴ 넘파이의 기본 객체는 동일한 타입의 다차원 배열이다.
						ㄴ 넘파이에서 '차원'은 'axes'(축)이라 불린다.
							ㄴ [1., 0., 0.]은 one axis, [ [1., 0., 0.], [0., 1., 2.] ]은 2 axis
						ㄴ 이 기본 배열을 ndarray, 또는 alias array라고 한다.
							ㄴ numpy.array와 파이선의 array와는 다르다.
						ㄴ ndarray의 속성
							ㄴ ndarray.ndim : axis의 개수.
							ㄴ ndarray.shape : 각 axis의 array의 개수를 나타내는 정수 튜플. 가령, n개의 row와 m개의 column인 행렬이 있으면 shape는 (n,m).
							ㄴ ndarray.size : 배열의 총 요소의 개수.
							ㄴ ndarray.dtype : 배열안에든 요소의 데이터 타입을 알려주는 속성.
							ㄴ ndarray.itemsize : 배열안에 든 각 요소의 바이트 크기.
							ㄴ ????? ndarray.data : 배열의 실제 요소들을 담고있는 버퍼?????
						ㄴ 배열 생성
							ㄴ array함수를 통해 파이선의 기본 list나 tuple을 사용하여 ndarray를 생성할 수 있다.
								ㄴ ex)
									a = np.array( (*파이선 시퀸스*) )
									a = np.array( [ [1,2,3], (4,5,6) ] ) # 결과는 array([ [1,2,3], [4,5,6] ])
									ㄴ '시퀸스'의 '시퀸스'는 2차원 배열로 변환한다.
								ㄴ dtype 파라미터를 넘겨 명시적으로 데이터 타입을 지정할 수 있다.
									ㄴ ex) a = np.array( [1,2,3], dtype=object )
							ㄴ 넘파이의 함수 이용하여 생성 )
								ㄴ np.zeros(), np.empty() 등의 함수로 배열을 생성할 수 있다.
								ㄴ ex)
									a = np.zeros( (*배열의 shape*) ) #넘겨진 shape에 맞는, 요소가 모두 0인 배열생성
									a = np.ones( (*배열의 shape*) ) #넘겨진 shape에 맞는, 요소가 모두 1인 배열 생성
									a = np.empty( (*배열의 shape*) ) #넘겨진 shape에 맞는, 요소가 랜덤값인 배열생성. ????? 랜덤값은 메모리의 상태에 따라 다름??
																		랜덤값의 디폴트 타입은 'float64'이다.
								ㄴ 위 예시의 함수들 모두 np.array()에서처럼 dtype파라미터를 통해 명시적으로 데이터타입지정가능.
								ㄴ arange()
									ㄴ arange()를 사용해, 파이선 내장함수 range()와 같은 숫자배열을 생성할 수 있다.
										ㄴ ex)
											a = np.arange( 0, 10, 0.5 )
									ㄴ 소수점으로 배열을 생성할 경우, 유동소수점 표현으로 인해 정확한 요소의 개수를 알기 어려우므로?????
										np.linspace()를 대신 사용한다.
										ㄴ ex) np.linspace(0,2,9) #0~2사이의 소수를 9개로 나누어 표현.
						ㄴ 배열의 출력
							ㄴ 마지막 axis는 왼쪽에서 오른쪽으로 출력
							ㄴ 마지막에서 두번째는 위에서 아래로
							ㄴ 그 이상의 axis는 한 줄을 띄워가며 위에서 아래로 출력.
							ㄴ ex)
								[[[ 0  1  2  3]
								[ 4  5  6  7]
								[ 8  9 10 11]]

								[[12 13 14 15]
								[16 17 18 19]
								[20 21 22 23]]]
							ㄴ 데이터가 너무 길면 numpy는 자동으로 중간을 생략.
						ㄴ 배열의 연산 )
							ㄴ 산술연산은 배열의 각 요소별로 적용된다.
								ㄴ * 연산의 경우도, 각 요소별로 적용된다. (보통 행렬에서의 연산과 달리. 행렬에서의 * 연산은 @을 이용하여 할 수 있다)
							ㄴ 새 배열이 생성되고 여기에 결과가 저장된다.
							ㄴ +=, *= 연산은 결과값으로 새 배열을 생성하지 않고 기존의 배열을 수정한다.
							ㄴ 다른 타입끼리의 연산인 경우, 결과 배열의 타입은 더 범위가 크거나 정교한 데이터 타입이 된다. 가령, 정수 배열과 실수배열의 연산이면 실수 배열이 결과가된다.
							ㄴ sum(), min() 등의 단항연산자들이 여러개 정의되어있다.
								ㄴ 이런 연산자들은 디폴트로 배열이 숫자의 리스트인것처럼 동작한다. n차원 배열이어도 1차원 배열처럼 취급하여 합을 구하거나 최솟값을 찾거나 한다는말.
								ㄴ 함수호출시 axis 매개변수를 넘겨서 어떤 axis를 기준으로 계산을 할지 결정할 수 있다.
									ㄴ ex)
										b = np.arange(12).reshape(3,4)
										b.sum(axis=0) # 결과는 array([12,15,18,21])
						ㄴ Universal 함수 )
							ㄴ numppy에서는 수학과 관련된 함수를 제공한다. sin, cons, exp등. 이런 함수들을 universal함수라한다.
							ㄴ 배열의 각 요소별로 적용된다.
						ㄴ 인덱싱, 슬라이싱, Iterating
							ㄴ 일차원 배열은 파이선의 시퀸스처럼 인덱싱, 슬라이싱, Iterating이 가능하다.
							ㄴ 다차원 배열은
								ㄴ axis별로 인덱싱이 가능하다. ex) b[2, 3] # axis=0에서 인덱스2, axis=1에서 인덱스3을 의미.
								ㄴ 슬라이싱도 동일하게 가능. ex) b[0:, 1:]
								ㄴ dots, ...)
									ㄴ '...'표기는 dots라 하여, 인덱싱에서 필요한만큼의 충분한 콤마(,)를 의미한다.
									ㄴ 해서 b[...]라고 하면, b[ : , : ]와 같이 axis수만큼의 :가 채워진다.
								ㄴ Iterating은 첫번째 axis를 기준으로 실행된다.
									ㄴ 모든 요소를 1차원으로 보고 실행하고 싶으면, 배열의 flat속성에 대해 반복하면 된다. '
										ㄴ ex)
											for e in a.flat:
												print(e) # 0,1,2,3, ... ,12
							ㄴ 배열을 이용한 인덱싱 )
								ㄴ 인덱싱은 정수 뿐만 아니라 또다른 배열을 이용하여도 할 수 있다.
									ㄴ ex) a = np.array([0,0,2])
											b = np.array( [1,2,3] )
											b[a] # 0번째, 0번째, 2번째 요소가 인덱싱되어 [1,1,3]반환.

											a = np.array([ [0,0], [1,2] ])
											b[a] # [ [1,1], [2,3] ] 반환.
								ㄴ 다차원 배열의 인덱싱의 경우, 인덱스로 넘겨주는 배열들의 shape이 동일해야한다.
									ㄴ ex)
										a = np.array([ [1,2,3], [4,5,6], [7,8,9] ])
										i = np.array([ [0,2], [2,1] ])
										j = np.array([ [1,1], [0,1] ])
										a[i,j] # [ [2,8], [7,5] ] 반환.
							ㄴ boolean 배열을 통한 인덱싱
								ㄴ ex)
									a = np.array([1,2,3])
									b = np.array([False, True, True])
									a[b] # array([2,3])출력.
								ㄴ 다차원 배열에도 적용가능하다.
								ㄴ 인덱싱 대상인 배열과 인덱스로 넘겨줄 boolean배열의 'shape'가 일치해야한다.
									ㄴ ex)
										a = np.array([ [1,2,3], [4,5,6] ])
										i = np.array([ [True,True,False], [False,False,True] ]) #이런식으로 shape가 일치해야한다. [1,2,6]이 반횐된다.
										또는
										i = np.array([ False, True ]) #이런식으로 일치해도 된다. a의 axix=0에서 두번째인덱스만 추출되어 [ [4,5,6] ]이 반환된다.
						ㄴ shape 조작 )
							ㄴ 값의 리스트는 같아도 axis에 따라 shape가 변화할 수 있다.
								ㄴ ex)
									똑같은 [1,2,3,4,5,6]이어도,
									[ [1,2,3], [4,5,6] ] #a.reshape(2,3)
									[ [1,2], [3,4], [5,6] ] #a.reshape(3,2)
									등과 같이 변경가능.
							ㄴ shape 변경 방법)
								ㄴ a.ravel() : shape를 1차원 배열로 변경.
								ㄴ a.reshape(6,2) : 6행 2열 형태로 변경.
								ㄴ a.T : 대각선 축 대칭으로 변환
						ㄴ 배열 이어붙이기 )
							ㄴ column_stack )
								ㄴ 배열을 컬럼을 추가하며 이어붙인다
								ㄴ hstack()과 동일하다.
								ㄴ ex)
									np.column_stack( (a,b) ) # 		[ [1,4],
																		[2,5],
																		[3,6] ]
							ㄴ row_stack )
								ㄴ
						ㄴ 배열 쪼개기 )
							ㄴ np.split( (*배열*), (*쪼개는방식정보*), (*축*) )
								ㄴ 기존의 배열을 특정 방식대로 '쪼개어' 쪼개어 나뉘어진대로 각각 조각이 새 배열이 되어 그 배열들의 배열을 반환해준다.
								ㄴ (*배열*)을 (*쪼개는방식정보*)대로 쪼개어 새로운 각 배열들을 만들고 그 배열들의 배열을 반환.
									ㄴ ex)
										a = np.array( [1,2,3,4] )
										np.split(a,2) #[1,2,3,4]를 2개로 쪼개므로 [1,2], [3,4]로 두개의 배열이 생성되고
														[ array([1,2]), array([3,4]) ]가 반환된다.
								ㄴ (*축*)은 어느 축을 기준으로 쪼갤지 선택하는 것. 옵션사항이고 디폴트는 0.
									ㄴ ex)
										a = np.array( [ [1,2,3], [4,5,6] ] )이라하면,
										np.split( a, 3, 1) #축이 1이므로, a의 축1부분 즉, [1,2,3], [4,5,6]을 쪼개게 된다. 3개로쪼갠다 했으므로
															각각 [1],[2],[3]과 [4],[5],[6]으로 쪼개지고 쪼갠대로 [ [1],[4] ], [ [2],[5] ], [ [3],[6] ] 세 배열이 생성되어
															배열로 반환.
							ㄴ hsplit( (*배열*), (*쪼갤개수*) ) : np.split()에서 (*축*)이 1인 것과 동일하다.
						ㄴ 배열의 복사 )
							ㄴ 배열과 관련한 연산들 중에는 새 배열이 생성되는 경우가 있고 아닌 경우가 있다.
							ㄴ 단순 할당은 객체를 복사하지 않는다.
							ㄴ (*배열*).view()는 같은 데이터를 참조하는 새 배열 객체 생성. 이를 'view'라하는듯하다.
								ㄴ ex)
									a = np.array([1,2,3])
									b = a.view()
									b[0] = -1
									a[0] # -1로 바뀌어있다.
								ㄴ 배열의 '슬라이싱'은 이런 'view'를 반환해주는 것.
							ㄴ (*배열*).copy()는 들어있는 데이터까지 복사하여 새 데이터와 새 배열객체 생성.
						ㄴ 브로드 캐스팅
							ㄴ 넘파이에서 서로 'shape'가 다른 배열들간의 산술연산을 할때, 이 배열들을 어떻게 다루는지에 대한 개념.
							ㄴ 개념적으로 간단히 설명하면, '특정한 조건'만족한다면, 넘파이가 '더 작은' 배열이 'broadcast'되어 서로 'shape'가 맞도록 한다.
								ㄴ 내부적으로 알아서 배열을 'stretched'하여 계산을 한다.
							ㄴ 이를 통해 '벡터화'가 되도록 해준다.
							ㄴ 브로드캐스팅이 되기 위한 '특정한 조건' )
								ㄴ 배열의 'shape'의 값들을 비교한다.
								ㄴ 두 배열의 shape에서 각 마지막 차원들의 값끼리 비교하기 시작하여 처음방향으로 이동하면서 비교한다.
									ㄴ shape의 길이가 같을 필요는 없다. 각 배열의 shape에서 마지막 항목끼리 비교하는 것.
								ㄴ 비교하고있는 두 차원의 값이 동일하거나, 둘 중 하나가 1이면 조건에 부합한다.
								ㄴ 조건에 부합하지 않으면 'ValueError: operands could not be broadcast together'라는 에러가 발생한다.
								ㄴ ex)
									a = np.array([[[ 1,2,3],
												[ 4,5,6]],

												[[ 7,8,9],
												[ 10,11,12]]]) #a.shape는 (2,2,3). a가 이렇다고 할때,
									b가 아래와 같을 때, a*b할때 조건 부합하는지 예시.
									b = np.array([0,1,2]) #b.shape가 (3,)이고, a의 맨 마지막 차원은 3, b의 마지막 차원은 3이므로 조건에 부합,
															b에는 더 이상 차원이 없으므로 브로드캐스팅 가능하다.
									b = np.array( [0] ) #b.shape 는 (1,). 맨 마지막 비교시 3과 1로 다르나, b의 차원이 1이므로 조건에 부합.
									b = np.array( [ [1,2] ] ) #b.shape는 (1,2). 맨마지막 차원의 값이 3과 2이므로 맞지않음. 오류발생
									b = np.array( [ [10,100,1000] ] ) #b.shape는 (1,3). 맨마지막 차원이 3으로 같고 그다음 차원은 2와 1이므로 1이 있어 부합.
									b = np.array( [ [10,100,1000], [-1,-1,-1], [-2,-2,-2] ] ) #b.shape는 (3,3). 맨마지막은 3으로 같으나 그 다음이 2,3이므로 맞지않음.
									b = np.array( [ [10,100,1000], [-1,-1,-1] ] ) #b.shape는 (2,3). 맨마지막이 3으로 같고, 그 다음도 2로 같아 부합.
						ㄴ ix_() 함수 )
							ㄴ ?????

					</pre>

					ㄴ 기본 <button>더보기</button>
					<pre>
						ㄴ Numerical Python. 숫자 데이터를 다루는데 사용되는 오픈소스 라이브러리.
						ㄴ ~~~~~
						ㄴ vector : 1차원 배열
						ㄴ matrix : 2차원 배열
						ㄴ tensor : 3차원 이상의 배열.
						ㄴ 위의 '개요'에서 다룬 내용 살짝 더 자세하게 반복.
						ㄴ ~~~~~

					</pre>

					ㄴ Array object<button>더보기</button>
					<pre>
						ㄴ ~~~~~
						ㄴ ndarray<button>더보기</button>
						<pre>
							ㄴ N-dimensional array
							ㄴ 같은 데이터 타입과 크기를 가진 item들의 다차원 배열.
							ㄴ 배열의 요소들의 데이터 타입은 각 ndarray마다 분리된 'data-type object'(일명 dtype)에 따로 정의되어있다.
							ㄴ ndarray의 내용물들은 파이선의 컨테이너들처럼 '인덱싱', '슬라이싱' 등을 통해 접근되고 수정될 수 있다.
							ㄴ 서로 다른 ndarray가 같은 데이터를 참조할 수 있다. ('view')
							ㄴ 파이선 '시퀸스'와의 차이점.
									ㄴ ndarray는 생성시 고정된 크기를 가진다. 사이즈 변경시, 기존 객체는 삭제되고 새 객체가 생성된다.
									ㄴ ndarray는 같은 타입의 데이터들만 담을 수 있다.
									ㄴ ndarray는 대량의 데이터에 대한 수학적 연산에 더 효과적이다.
									ㄴ 여러 수학, 과학 관련 파이선 라이브러리에서 ndarray를 사용하고 있다.

						</pre>
						ㄴ scalar<button>더보기</button>
						<pre>
							ㄴ 파이선에는 기본데이터 타입이 몇가지 없다. 정수타입하나, 실수타입하나 이런식.
							ㄴ 과학, 수학적인 계산이 필요한 경우, 더 다양한 데이터 타입들이 필요하고 numpy에서는 c언어의 데이터 타입에 근거하여
								24가지 새로운 데이터 타입을 정의하였고 이를 scalar라고 부른다.
							<img src="image/python%20dtype.png" height="413"/>
							ㄴ ~~~~~
						</pre>

						ㄴ dtype<button>더보기</button>
						<pre>
							ㄴ 배열에 할당된 메모리에 있는 바이트들이 어떻게 해석되어야 하는지를 나타내는 객체.
							ㄴ 다음의 정보를 가지고 있다.
								ㄴ 데이터 타입
									ㄴ numpy의 scalar 타입들 중 하나가 된다.
								ㄴ 데이터의 크기
								ㄴ 데이터의 바이트 순서(little endian, big endian)
								ㄴ ?????데이터 타입이 'structured data type'인
									ㄴ ?????
								ㄴ ?????
							ㄴ 인덱싱에 의해 배열에서 요소가 추출되면, 이 요소는 데이터 타입에 해당하는 파이선 객체가 된다.
							ㄴ ~~~~~
						</pre>

						ㄴ Indexing<button>더보기</button>
						<pre>
							ㄴ
						</pre>

					</pre>

					ㄴ 무제 <button>더보기</button>
					<pre>
						ㄴ 데이터 타입<button>더보기</button>
						<pre>
							ㄴ

						</pre>
						ㄴ 배열 생성
							ㄴ 다섯가지
							ㄴ 파이선 데이터로부터의 변환
							ㄴ 넘파이 배열 생성 함수 이용
							ㄴ 디스크로부터 배열 읽어들이기
							ㄴ raw 바이트로 배열생성
							ㄴ 특정 라이브러리 함수 사용
							ㄴ ?????
						ㄴ genfromtxt )
							ㄴ 표형태의 데이터로부터 배열을 생성할 수 있다.
					</pre>

				</pre>
				ㄴ Pandas<button>더보기</button>
				<pre>
					ㄴ 판다스란?
						ㄴ '관계형', '라벨형' 데이터를 잘 처리할 수 있게 해주는 데이터 구현체를 제공하는 파이썬 패키지.

					ㄴ data structures <button>더보기</button>
					<pre>
						ㄴ ????? Here is a basic tenet to keep in mind: data alignment is intrinsic.
							The link between labels and data will not be broken unless done so explicitly by you.
						ㄴ Series<button>더보기</button>
						<pre>
							ㄴ 어떠한 데이터 타입도 담을 수 있는 1차원의 라벨링 배열.
							ㄴ 축 라벨은 'index'라고 불린다.
							ㄴ 생성 )
								ㄴ s = pd.Series( (*data*), index=(*인덱스*) )
									ㄴ (*data*)
										ㄴ 스칼라값, 파이선 dict, ndarray가 올 수 있다.
									ㄴ (*인덱스*)
										ㄴ 축 라벨의 리스트. (*data*)가 무엇인지에 따라 몇가지 경우로 분류된다.
											ㄴ (*data*)가 ndarray인 경우 )
												ㄴ index는 (*data*)와길이가 같아야 한다.
												ㄴ index가 전달되지 않으면, 0부터 시작하는 정수인덱스가 자동으로 전달된다.
											ㄴ dict인 경우)
												ㄴ index가 전달되지 않으면, dict의 key값이 자동으로 label이 된다.
												ㄴ index가 전달되면, index의 값과 일치하는 key값이 매핑된다.
													ex)
														d = {'b':1, 'a':0, 'c':2}
														s = pd.Series(d, index=[0,1,2]) #index에 넘어온 0,1,2와 일치하는 dict의 key값이
																						없으므로, 출력은다음고 ㅏ같다.
																						0 NaN
																						1 NaN
																						2 NaN
							ㄴ Series는 ndarray와 유사하다.
								ㄴ Series는 numpy의 'ndarray'와 매우 유사하다.
								ㄴ 대부분의 Numpy함수에 ndarray대신 Series를 인자로 넘겨도 동작한다.
								ㄴ ndarray처럼 Series도 'dtype'속성을 가지고 있다.
									ㄴ dtype의 값은 numpy의 dtype값들을 포함하며 더 확장된 것들도 포함되어 있다.
								ㄴ Series.array
									ㄴ Series에서 'ExtensionArray'를 반환.
									ㄴ ?????
								ㄴ to_numpy(), numpy.asarray( (*Series*) )
									ㄴ Sereis로부터 numpy의 ndarray를 추출해 반환.
							ㄴ Series는 dict와 유사하다
								ㄴ 인덱스 label로 Series의 값을 다룰 수 있다는 점에서 고정크기의 dict와 유사하다.
								ㄴ index와 일치하는 label이 없으면, 예외발생.
									ㄴ get( (*label이름*) [, (*없을시 디폴트값*) ] ) 을 이용하면, label이 없을시 디폴트값 또는 None을 반환.
							ㄴ Series끼리의 연산을 하면, Series의 label에 따라 알아서 매핑이 되어 연산이 진행된다.
								ㄴ 연산중, 어느 한쪽에서 특정 label이 발견되지 않으면 NaN값이 할당된다.
							ㄴ Series는 name속성으로 이름을 가질 수 있다.
								ㄴ ex) s = pd.Series( data, name='noName' )
										s.name # 'noName'
						</pre>

						ㄴ DataFrame<button>더보기</button>
						<pre>
							ㄴ 여러 column을 가지는 2차원 레이블링 데이터 구조. column들은 서로 다른 유형의 데이터 타입일수 있다.
								ㄴ 스프레드 시트, sql테이블, Series의 dict을 생각하면 되ㅗㄴ다.
							ㄴ 생성 )<button>more</button>
							<pre>
								ㄴ 올 수 있는 데이터 타입 )
									ㄴ 1차원 ndarray, list, dict, Series의 dict
									ㄴ 2차원 numpy.ndarray
									ㄴ ????? Structured or record ndarray
									ㄴ Series
									ㄴ DataFrame
								ㄴ index와 column을 인자로 전달할 수 있다.
									ㄴ Sereies와 마찬가지로 인덱스가 일치하지 않으면 데이터를 버린다.
								ㄴ index는 여러 Series들의 합집합이 된다.
								ㄴ ex)<button>더보기</button>
								<pre>
									In [37]: d = {
									....:     "one": pd.Series([1.0, 2.0, 3.0], index=["a", "b", "c"]),
									....:     "two": pd.Series([1.0, 2.0, 3.0, 4.0], index=["a", "b", "c", "d"]),
									....: }
									....:

									In [38]: df = pd.DataFrame(d)

									In [39]: df
									Out[39]:
									one  two
									a  1.0  1.0
									b  2.0  2.0
									c  3.0  3.0
									d  NaN  4.0

									In [40]: pd.DataFrame(d, index=["d", "b", "a"])
									Out[40]:
									one  two
									d  NaN  4.0
									b  2.0  2.0
									a  1.0  1.0

									In [41]: pd.DataFrame(d, index=["d", "b", "a"], columns=["two", "three"])
									Out[41]:
									two three
									d  4.0   NaN
									b  2.0   NaN
									a  1.0   NaN
								</pre>
								ㄴ 데이터가 ndarray, list의 dict인 경우)
									ㄴ ndarrys, list의 길이가 모두 같아야 한다.
									ㄴ 생성시 index를 전달하려면, ndarray, list와 길이가 같아야한다.
									ㄴ ex)
										In [44]: d = {"one": [1.0, 2.0, 3.0, 4.0], "two": [4.0, 3.0, 2.0, 1.0]}

										In [45]: pd.DataFrame(d)
										Out[45]:
										one  two
										0  1.0  4.0
										1  2.0  3.0
										2  3.0  2.0
										3  4.0  1.0

										In [46]: pd.DataFrame(d, index=["a", "b", "c", "d"])
										Out[46]:
										one  two
										a  1.0  4.0
										b  2.0  3.0
										c  3.0  2.0
										d  4.0  1.0
								ㄴ structured or record ndarray인 경우 )
									ㄴ ?????
								ㄴ dict의 list인 경우 )
									ㄴ ~~~~~
								ㄴ tuple의 dict인 경우 )
									ㄴ ~~~~~
								ㄴ Series인 경우 )
									ㄴ 입력된 Series와 동일한 인덱스를 사용하고, 하나의 열을 가진 DataFrame이 된다.
								ㄴ namedtuple 리스트인 경우 )
									ㄴ ~~~~~
								ㄴ dataclass의 list인 경우 )
									ㄴ ~~~~~
								ㄴ 대체 생성자들 )
									ㄴ DataFrame을 생성하는 다른 방법들 설명.
									ㄴ (*DataFrame*).from_dict()
										ㄴ dict의 dict, 또는 array형태값의 dict를 인자로 받아서 DataFrame을 반환해줌.
										ㄴ ex)	pd.DataFrame.from_dict(dict([("A", [1, 2, 3]), ("B", [4, 5, 6])]))
											ㄴ dict([("A", [1, 2, 3]), ("B", [4, 5, 6])]) 에서 다음과 같은 dict 생성
												{'A': [1, 2, 3], 'B': [4, 5, 6]}
											ㄴ 위의 생성된 dict로 DataFrame을 생성.
											ㄴ dict의 키가 열 레이블에 되고, 인자로 orient='index'를 주면 키가 행 레이블이 된다
												ㄴ ex)
													In [66]: pd.DataFrame.from_dict(
													....:     dict([("A", [1, 2, 3]), ("B", [4, 5, 6])]),
													....:     orient="index",
													....:     columns=["one", "two", "three"],
													....: )
									ㄴ (*DataFrame*).from_records
										ㄴ tuples의 list 또는 structured dtype인 ndarray를 받아 DataFrame생성.
										ㄴ 생성된 DataFrame의 index가 structured dtype의 특정 필드일 수 있다는 점만 제외하고는
											일반 DataFrame 생성자와 동일하다.
								</pre>
							ㄴ 열 선택, 추가, 삭제 )
								ㄴ DataFrame을 index된 Series의 dict로 생각할 수 있다. 열의 선택, 추가, 삭제도 dict의 작업문법과 유사하다.
								ㄴ ex)
									df["three"] = df["one"] * df["two"]
									df["flag"] = df["one"] > 2
									del df["two"]
									three = df.pop("three")
									df["foo"] = "bar"
								ㄴ ndarray삽입시 df와 길이가 일치해야한다.
								ㄴ drop(labels=None, axis=0, index=None, columns=None, level=None, inplace=False, errors='raise')
									ㄴ 열 또는 행을 제거.
									ㄴ
							ㄴ 메소드 체인에서의 새 열 할당 )
								ㄴ (*df*).assign()
									ㄴ ?????
									ㄴ 인자로 받은 열을 df에 추가한 '새로운 df'를 반환한다.
									ㄴ 새로운 df를 반환하므로 메소드 체인이 가능.
									ㄴ ?????
							ㄴ 인덱싱, 선택 )
								ㄴ 기본 인덱싱 방법들 )
									ㄴ df[col] : 컬럼 선택.
									ㄴ df.loc[lable] : 라벨로 row선택.
									ㄴ df.iloc[label] : 위치로 row선택.
									ㄴ df[5:10]  : row 슬라이스.
									ㄴ df[bool_vec] : ????? boolean vector로 row선택.
							ㄴ 데이터 정렬과 연산 )
								ㄴ df간의 정렬은 자동으로 행과 열을 정렬한다.
								ㄴ df와 Series간의 연산은 디폴트로, df의 컬럼과 Series의 index를 매핑한다.
								ㄴ 스칼라 값과의 연산은 당연히 모든 데이터에 적용된다.
								ㄴ boolean 연산도 적용된다.
							ㄴ Transposing, 행열뒤집기)
								ㄴ df의 T속성에 접근하면 된다.
							ㄴ NumPy 함수 사용 )
								ㄴ Series와 df에 NumPy의 함수를 사용할 수있으며, 데이터는 숫자값이어야한다.
								ㄴ df와 ndarray는 인덱스의 의미와 데이터 모델이 많이 달라 서로 대체하기 어렵다.
								ㄴ ?????
							ㄴ 콘솔 출력 )
								ㄴ df가 크다면 콘솔에는 일부가 생략되어 출력된다.
								ㄴ to_string()을 사용하면 콘솔창의 크기에 상관없이 표형식으로 df가 출력된다.
						</pre>
					</pre>

					ㄴ 기본 필수 기능들<button>더보기</button>
					<pre>
						ㄴ 판다스에서 사용되는 data structure들에 대한 기본적인 기능들을 살펴본다.
						ㄴ head(), tail()
							ㄴ data structure의 맨 앞부분, 끝부분을 보여주는 메소드.
							ㄴ 인자로 숫자를 넘기면 맨앞에서 또는 끝에서 해당 개수만큼 데이터를 보여줌. 디폴트는 5.
						ㄴ 속성들,
							ㄴ 속성들 )
								ㄴ shape : ndarray의 shape와 동일
								ㄴ axis 정보
									ㄴ Series인 경우 : index
									ㄴ DataFrame인 경우 : index, columns
								ㄴ ~~~~~
								ㄴ
								ㄴ ~~~~~
								ㄴ ????? DataFrame의 한 컬럼안의 데이터들이 동일한 타입이 아닐 경우 해당 컬럼에 값을 할당할 수 없다??
								ㄴ Series.values나 DataFrame.values로 실제 들어있는 데이터에 접근 가능하나, 다음의 이유로 Series.array, Series.to_numpy()를
									사용하라고함
									ㄴ Series가 pandas의 extension type을 포함하고 있을 경우, Series.values가 ndarray를 반환할지 extension array를
										반환할지 알 수 없다. 그에 반해, Series.array는 항상 'ExtensionArray'를 반환하고 복사본을 반환하지 않는다.
									ㄴ ?????
							ㄴ to_numpy()를 통해 내부의 데이터들을 numpy array로 변환할 수 있다.
								ㄴ dtype 매개변수로 변활할 때 내부 데이터의 타입을 지정할 수 있다.
								ㄴ DataFrame의 경우, 컬럼마다 데이터형이 다른 경우, 각 컬럼마다 변환이 적용되고,
									한 컬럼 내에서도 타입들이 다른 경우, 모든 데이터를 포함할 수 있는 타입이 결정된다.
									ㄴ ex ) float, integer 타입이 섞여있으면, float으로 결정되는 등.
								ㄴ to_numpy()
									ㄴ 내부의 numpy array를 반환한다.
									ㄴ 기본적으로 반환되는 numpy array의 dtype은 common numpy dtype이다.
						ㄴ ????? Accelerated operations
						ㄴ 이진 연산
							ㄴ ~~~~~
							ㄴ DataFrame.add(), DataFrame.sub(), DataFrame.mul(), DataFrame.div(), DataFrame.radd(), DataFrame.rsub() 등등의 메소드들이 있다.
							ㄴ 고차 데이터와 저차 데이터 사이의 이진 연산시의 '브로드 캐스팅'
								ㄴ 연산대상에 Series가 있을 경우, Series가 중심이 된다. 위 연산 함수들에서 'axis'라는 키값의 매개변수를 넘겨서 Series가
									어떤 축을 기준으로 계산될지 결정할 수 있다.
								ㄴ ex)
									In [19]: df
									Out[19]:
											one       two     three
									a  1.394981  1.772517       NaN
									b  0.343054  1.912123 -0.050390
									c  0.695246  1.478369  1.227435
									d       NaN  0.279344 -0.613172

									In [20]: row = df.iloc[1]

									In [21]: column = df["two"]

									In [22]: df.sub(row, axis="columns")	#column축을 기준으로 연산하도록 설정.
									Out[22]:
											one       two     three
									a  1.051928 -0.139606       NaN
									b  0.000000  0.000000  0.000000
									c  0.352192 -0.433754  1.277825
									d       NaN -1.632779 -0.562782
								ㄴ 'axis'매개변수의 값으로는 'columns'와 'index'가 올 수 있다. 문자열이다.
								ㄴ Series와 Index는 파이썬 내장함수 divmod()에도 사용할 수 있다.
									ㄴ (*몫*), (*나머지*) = divmod( (*Series또는 Index*), (*나눌값*) )
									ㄴ (*Series또는 Index*)를 (*나눌값*)으로 나누어, (*몫*)에는 나눈 몫의 Series를 넣고 (*나머지*)에 나머지값들을 넣는다.
									ㄴ ex)<button>더보기</button>
									<pre>
										In [29]: s = pd.Series(np.arange(10))

										In [30]: s
										Out[30]:
										0    0
										1    1
										2    2
										3    3
										4    4
										5    5
										6    6
										7    7
										8    8
										9    9
										dtype: int64

										In [31]: div, rem = divmod(s, 3)

										In [32]: div
										Out[32]:
										0    0
										1    0
										2    0
										3    1
										4    1
										5    1
										6    2
										7    2
										8    2
										9    3
										dtype: int64

										In [33]: rem
										Out[33]:
										0    0
										1    1
										2    2
										3    0
										4    1
										5    2
										6    0
										7    1
										8    2
										9    0
										dtype: int64
									</pre>
									ㄴ (*나눌값*)을 배열로넘겨 항목마다 나눌값을 따로 설정할 수도 있다.
							ㄴ 연산시에 missing data 처리
								ㄴ 위의 연산 함수들에 'fill_value'키값을 가지는 매개변수를 넘겨서 값이 비어있는 데이터인 경우(NaN같은), 어떤 값을
									채워넣어 연산을 할지 결정할 수 있다.
								ㄴ ex) df.add(df2, fill_value=0)
						ㄴ 비교연산 )
							ㄴ Series와 DataFrame에는 eq, ne, lt, gt, le, ge 등의 비교연산 메소드가 존재한다.
							ㄴ 위의 연산 메소드들과 유사하게 동작한다.
							ㄴ ?????
						ㄴ Boolean 관련 함수
							ㄴ DataFrame.empty : 해당 DataFrame이 비었는지 아닌지 판별하여 bool값 반환. NaN도값이 있는것으로 취급한다.
							ㄴ DataFrame.any()
								ㄴ 어떤 한 요소라도 true이면 true 반환.
							ㄴ DataFrame.all()
								ㄴ 모든 요소가 true이면 true반환.
							ㄴ DataFrame.bool() : 요소가 단 하나이고 그 요소가 boolean값인 DataFrame이나 Series에서 사용할 수 잇는 함수.
													해당 boolean값이 뭔지 알려준다.
							ㄴ 이런 함수들을 boolean값을 점차줄여나간다하여 'boolean reduction'이라고 소개하고있다.
						ㄴ 동등성 비교 )
							ㄴ '==', equals() 사용가능
							ㄴ == : 각 요소별로 값을 비교하여 동등하면 true. 단, 값이 NaN인 경우 똑같이 NaN이어도 동등하지 않다고 판단
							ㄴ equals() : ==와 동일한 기능. 단, 값이 NaN으로 같으면 동등하다고 판단.
							ㄴ ex)

						ㄴ 값 비교 )
							ㄴ Series, DataFrame을 스칼라 값이나 array-like값과 '=='를 사용하여 비교할 수 잇다.
							ㄴ ndarray와 달리 길이가 다르면 오류발생.
						ㄴ ~~~~~
						ㄴ dtype <button>더보기</button>
						<pre>
							ㄴ 대부분의 경우에 pandas는 numpy의 array와 dtype을 사용한다.
							ㄴ 몇몇 경우에 pandas와 third-party 라이브러리는 numpy의 type을 확장한다.
							ㄴ 커스텀으로 확장된 type을 만들어 판다스에서 사용할 수 있다.
							ㄴ 확장된 type들의 리스트 <button>더보기</button>
							<pre>
								ㄴ
							</pre>
						</pre>

					</pre>
					ㄴ 인덱싱, selection <button>more</button>
					<pre>
						ㄴ

					</pre>

					ㄴ 무제 <button>더보기</button>
					<pre>
						ㄴ 데이터 구조와 분석에 사용되는 여러 도구를 제공해주는 오픈소스 라이브러리.
						ㄴ '관계형', '라벨형?' 데이터에 대해 데이터 구조를 표현해주는 파이선 패키지이다.
						ㄴ 두가지 판다스의 대표 데이터 구조 : Series(1차원), DataFrame(2차원)
						ㄴ Numpy위에서 구축되었다.
						ㄴ ?????
						ㄴ Series )
							ㄴ 1차원의 라벨이 붙은 배열
						ㄴ DataFrame )
							ㄴ 2차원의 라벨이붙은 사이즈가 변할 수 있는 표형태.
							ㄴ ex)
								import pandas as pd
								df = pd.DataFrame({
									'name':['aaa','bbb','ccc'],
									'age' : [1,2,3],
									'sex' : ['m','f','m']
								})
								df #0  aaa    1   m
									1  bbb    2   f
									2  ccc    3   m와 같이 출력된다.
								ㄴ 인자로넘긴 객체의 키값은 표의 컬럼이 된다.
							ㄴ 각 컬럼들은 'Series'이다.
								ㄴ ex)
									df['name'] # 	0    aaa
													1    bbb
													2    ccc 와 같이 출력된다.
						ㄴ Series, DataFrame에 대해 여러 함수를 호출 할 수 있다.
							ㄴ ex) df.max() # 	name    ccc
												age       3
												sex       m 와 같이 출력
									df['name'].max() # 'ccc'출력
							ㄴ ex) df.describe() 숫자형 데이터에 대해 간략한 정보를 제공
											age
											count  3.0
											mean   2.0
											std    1.0
											min    1.0
											25%    1.5
											50%    2.0
											75%    2.5
											max    3.0 와 같이 출력.
								ㄴ name, sex컬럼은 문자형 데이터라서 안나옴.
						ㄴ CSV파일로부터 데이터 읽기
							ㄴ
						ㄴ ????? 왜 하나 이상의 데이터 구조인가?
							ㄴ ?????

						ㄴ 표형식 데이터 읽고 쓰기 )
							ㄴ read_csv()
								ㄴ csv파일을 읽어주는 함수. DataFrame형식으로 읽어준다.
							ㄴ DataFrame의 맨 위 8줄 읽기.
								ㄴ (*DataFrame*).head(8)
							ㄴ (*DataFrame 또는 Series*).dtypes : 각 컬럼들이 어떤 데이터 타입으로 해석되는지를 확인할수 있는 속성.
							ㄴ ex) to_excel("titanic.xlsx", sheet_name="passengers", index=False) : 데이터를 엑셀파일로 내보낼 수 잇는 함수.
							ㄴ read_(*읽기대상유형*)(), to_(*쓰기대상유형*)() 함수는 각각, 대상 파일을 읽어들여 DataFrame 또는 Series로 만들거나 그 반대
								작업을 하는 함수.ex) to_excel(), read_csv()
							ㄴ DataFrame의 info() : DataFrame의 데이터에 대한 메타정보?를 알려주는 함수.
						ㄴ DataFrame의 하위 집합 다루기 )
							ㄴ (*DataFrame 또는 Series*).shape 속성 : row와 column의 개수정보를 가지고있는 속성.
							ㄴ ex) bbb = df[ df["age"] > 35 ]
								ㄴ DataFrame에다 중괄호로 조건을 붙여 특정 row들만 추출.
							ㄴ ex) bbb = df[ df['pclass'].isin([2,3]) ]
								ㄴ pclass라는 컬럼이 2,3인 row추출.
								ㄴ isin()은 row의 값이 인자로 넘어간 리스트 중에 있으면 true반환.
								ㄴ df[(df["pclass"] == 2) | (df["pclass"] == 3)] 와도 동일.
							ㄴ ex) bbb = df[ df['age'].notna() ]
								ㄴ notna() : 'age'컬럼이 not null인 row이면 true 반환.
							ㄴ ex) bbb = df.loc[ df['age'] > 35, 'name' ]
								ㄴ age컬럼이 35이상인 row들의 name을 추출.
								ㄴ loc[ (*row선택*), (*column선택*) ], iloc[ ~~~~~ ] :
								ㄴ 대입도 가능하다.
								ㄴ iloc[]는 인덱스로 접근할 수 있는 loc[]라고 보면 된다.
						ㄴ 그래프 그리기 )
							ㄴ import matplotlib.pyplot as plt
							ㄴ (*DataFrame*).plot()
								plt.show() #그래프 출력.
						ㄴ 새로운 컬럼 추가 )
							ㄴ ex) df['newColumn'] = df['name']+'New'
							ㄴ 위와 같이, 중괄호안에 새로 추가할 컬럼명을 넣고, 알맞은 column값들을 넣어주면 새로생김.
						ㄴ 컬럼명 수정 )
							ㄴ ex)
								renamedDf = df.rename(
									columns={
										'name' : 'name2',
										'age' : 'age2'
									}
								)
							ㄴ 컬럼명이 바뀐 새로운 DataFrame이 반환된다.
						ㄴ groupby() : 데이터를 그룹화하여 통계처리가 가능하게함.
							ㄴ
						ㄴ Categorical 데이터 타입 : 숫자이기는 하나, 카테고리 분류 숫자 같은 것이어서 평균값계산등이 의미가 없는 데이터들을 위한 타입.
						ㄴ value_counts()
						ㄴ df.sort_values(by='age'), df.sort_values(by=['pclass','age'])
						ㄴ DataFrame 재구성 )
							ㄴ ex)
																city country            location parameter  value   unit
								date.utc
								2019-04-09 01:00:00+00:00  Antwerpen      BE             BETR801       no2   22.5  µg/m³
								2019-04-09 01:00:00+00:00      Paris      FR             FR04014       no2   24.4  µg/m³
								2019-04-09 02:00:00+00:00     London      GB  London Westminster       no2   67.0  µg/m³
								2019-04-09 02:00:00+00:00  Antwerpen      BE             BETR801       no2   53.5  µg/m³
								2019-04-09 02:00:00+00:00      Paris      FR             FR04014       no2   27.4  µg/m³
								2019-04-09 03:00:00+00:00     London      GB  London Westminster       no2   67.0  µg/m³
								기본 표가 위와 같을때,
								no2_subset.pivot(columns="location", values="value") #pivot()을 이렇게 호출해주면,

								location                   BETR801  FR04014  London Westminster
								date.utc
								2019-04-09 01:00:00+00:00     22.5     24.4                 NaN
								2019-04-09 02:00:00+00:00     53.5     27.4                67.0
								2019-04-09 03:00:00+00:00      NaN      NaN                67.0
								위와 같이 location이 컬럼이 되고 value컬럼이 value값이 된다.
							ㄴ pivot()
								ㄴ 값을 재배치만 한다.
							ㄴ pivot_table() : 값을 집계를 하며 재배치하고자 할때 사용.
								ㄴ ex) air_quality.pivot_table( values="value", index="location", columns="parameter", aggfunc="mean" )
							ㄴ wide table, long table?????
							ㄴ 두 테이블 결합 )
								ㄴ concat() )
									ㄴ row또는 column을 기준으로 두 테이블을 합침.
									ㄴ 디폴트로는 추가하는 테이블의 row를 붙이는 식으로 동작한다고함.
						ㄴ

					</pre>


				</pre>
				ㄴ KoNLPy<button>more</button>
				<pre>
					ㄴ Korean Natural Language Processing (한국어 자연어 처리)
					ㄴ 한국어 텍스트로부터 의미 있는 정보를 처리하는 기술 제공.
					ㄴ 설치 )
						ㄴ window )
							ㄴ 	pip install --upgrade pip
								pip install jpype1
								pip install konlpy
							ㄴ 자바 모듈을 사용하기 때문에 JVM이 필요하다. 하여 자바 설치 필요.
							ㄴ 확인 사항 및 자주 일어나는 오류 )
								ㄴ konlpy에서 요구하는 버전 이상의 자바가 설치되어 있는지 확인.
								ㄴ 자바 설치 후, 환경 변수 추가 필요. JAVA_HOME 및 Path에 %JAVA_HOME%\bin
								ㄴ 자바와 파이썬의 bit수 일치하는지 확인.
								ㄴ konply DDL load fail시 'visual studio c++ redistributable(x86)'을 설치해라. 이유는 정확히 모른다.
								ㄴ Jpype를 못 찾을 경우 uninstall하고 다시 설치하거나 'https://www.lfd.uci.edu/~gohlke/pythonlibs/#jpype'에서
									알맞는 버전을 찾아 다운받은 후 install해라. 파일 이름 중 cp37은 파이썬 버전 3.7~~을 의미.
					ㄴ 형태소 분석, 품사 태깅 )
						ㄴ 글로부터 형태소, 어근, 접두사/접미사, 품사 등 언어의 구조를 파악하는 것.
						ㄴ 품사 태깅은 분석한 각 형태소들에 분석 결과를 표시하는 것?????
						ㄴ konlpy의 'tag package'의 클래스들에서 이러한 품사 태깅 기능을 제공한다.
							ㄴ 이 클래스들은 여러 '형태소 분석기'들의 wrapper 클래스이다. ex) '한나눔', '꼬꼬마', "코모란", "트위터", "MeCab"
						ㄴ 한국어 형태소 분석기별 품사 태그 목록 : https://docs.google.com/spreadsheets/d/1OGAjUvalBuX-oZvZ_-9tEfYD2gQe7hTGsgUpiiBSXI8/edit#gid=0
					ㄴ 형태소 분석기 비교 )
						ㄴ 속도 비교 )
							ㄴ Hannanum, Okt가 빠른 편이고, Kkma, Komoran은 좀 느리다.
								Mecab은 빠르다고 하나 윈도우 지원이 안되어 사용해보지는 못 했다.
						ㄴ 성능 비교 )
							ㄴ Hannanum, Kkma은 정확도가 좀 떨어지는 듯 했다. Okt, Komoran은 괜찮았다.
					ㄴ 말뭉치 )
						ㄴ 말뭉치를 사용하여 형태소 분석 및 품사 태깅을 한다.
						ㄴ 형태소 분석기별 사용하는 말뭉치 )
							ㄴ
					ㄴ KoNLPy 이외의 ㅎ여태소 분석기 라이브러리 )
						ㄴ https://konlpy-ko.readthedocs.io/ko/v0.6.0/references/ 참조.
						ㄴ C/C++ )
							ㄴ MeCab-ko, UTagger, MACH, KTS
						ㄴ Java/Scala )
							ㄴ twitter-korean-text, KOMORAN, KKMA, Arirang, HanNanum
						ㄴ Python )
							ㄴ KoNLPy, UMorpheme
						ㄴ R )
							ㄴ KoNLP
					ㄴ KoNLPy 구성 )
						ㄴ sub package )
							ㄴ tag Package )
								ㄴ ~~~~~
								ㄴ Hannanum Class <button>more</button>
								<pre>
									ㄴ class konlpy.tag._hannanum.Hannanum(jvmpath=None, max_heap_size=1024)
										ㄴ 인자 두개는 'jvm' 모듈의 init_jvm()메소드로 넘겨짐.
									ㄴ 자바의 형태소 분석기 라이브러리인 'JHannanum'의 Wrapper.
									ㄴ 메소드 )
										ㄴ analyze(phrase)
											ㄴ 분석결과로 가능한 후보들을 나열한다.
											ㄴ ex )
												>>> sample = '이곳에서는 형태소 분석된 결과와 nltk.chunk.regexp.RegexpParser 를 이용하여 간단하게 한국어 문장에서 명사구, 동사구, 형용사구를 찾는 법을 살펴보도록 하겠습니다.'
												>>> konlpy.tag.Hannanum().analyze(sample)
													[[[('이곳', 'npd'), ('에서는', 'jca')], [('이곳', 'npd'), ('에서', 'jca'), ('는', 'jxc')], [('이곳', 'npd'), ('에', 'jca'), ('서는', 'jxc')], [('이', 'nnc'), ('곳', 'nbu'), ('에서는', 'jca')], [('이', 'nnc'), ('곳', 'nbu'), ('
													에서', 'jca'), ('는', 'jxc')], [('이', 'nnc'), ('곳', 'nbu'), ('에', 'jca'), ('서는', 'jxc')]], [[('형태소', 'ncn')], [('형태', 'ncn'), ('소', 'ncn')]], [[('분석', 'ncpa'), ('되', 'xsvn'), ('ㄴ', 'etm')]], [[('결과', 'ncn'), ('
													와', 'jcj')], [('결과', 'ncn'), ('와', 'jct')]], [[('nltk', 'f'), ('.', 'sf')], [('nltk', 'f'), ('.', 'sy')]], [[('chunk', 'f'), ('.', 'sf')], [('chunk', 'f'), ('.', 'sy')]], [[('regexp', 'f'), ('.', 'sf')], [('regexp', 'f'), (
													'.', 'sy')]], [[('RegexpParser', 'f')]], [[('를', 'ncn')], [('를', 'nqq')]], [[('이용', 'ncpa'), ('하', 'xsva'), ('어', 'ecs')], [('이용', 'ncpa'), ('하', 'xsva'), ('어', 'ecx')], [('이용', 'ncpa'), ('하', 'xsva'), ('어', 'ef')
													]], [[('간단', 'ncps'), ('하', 'xsms'), ('게', 'ecc')], [('간단', 'ncps'), ('하', 'xsms'), ('게', 'ecs')], [('간단', 'ncps'), ('하', 'xsms'), ('게', 'ecx')], [('간단', 'ncps'), ('하', 'xsms'), ('게', 'ef')]], [[('한국어', 'ncn'
													)]], [[('문장', 'ncn'), ('에서', 'jca')]], [[('명사구', 'ncn'), (',', 'sp')], [('명사', 'ncn'), ('구', 'ncn'), (',', 'sp')]], [[('동사', 'ncn'), ('구', 'ncn'), (',', 'sp')], [('동사', 'ncpa'), ('구', 'ncn'), (',', 'sp')]], [[('
													형용사', 'ncn'), ('구', 'ncn'), ('를', 'jco')], [('형용', 'ncpa'), ('사구', 'ncn'), ('를', 'jco')], [('형용', 'ncpa'), ('사구', 'ncpa'), ('를', 'jco')]], [[('찾', 'pvg'), ('는', 'etm')]], [[('법', 'nbs'), ('을', 'jco')], [('법'
													, 'ncn'), ('을', 'jco')]], [[('살펴보', 'pvg'), ('도록', 'ecs')], [('살피', 'pvg'), ('어', 'ecx'), ('보', 'px'), ('도록', 'ecs')]], [[('하', 'pvg'), ('겠', 'ep'), ('습니다', 'ef')], [('하', 'px'), ('겠', 'ep'), ('습니다', 'ef')
													]], [[('.', 'sf')], [('.', 'sy')]]]
										ㄴ morphs(phrase) : 형태소 분석 결과를 나열.
											ㄴ ex)
												>>> konlpy.tag.Hannanum().morphs(sample)
													['이곳', '에서는', '형태소', '분석', '되', 'ㄴ', '결과', '와', 'nltk', '.', 'chunk', '.', 'regexp', '.', 'RegexpParser', '를', '이용', '하', '어', '간단', '하', '게', '한국어', '문장', '에서', '명사구', ',', '동사구', ',', '형
													용사구', '를', '찾', '는', '법', '을', '살피', '어', '보', '도록', '하', '겠습니다', '.']
										ㄴ nouns(phrase) : 형태소 분석 결과 명사만을 나열.
											ㄴ ex)
												>>> konlpy.tag.Hannanum().nouns(sample)
												['이곳', '형태소', '분석', '결과', '를', '이용', '간단', '한국어', '문장', '명사구', '동사구', '형용사구', '법']
										ㄴ pos(phrase, ntags=9, flatten=True, join=False) : '품사 태깅' 결과를 반환.
											ㄴ ex )
												>>> konlpy.tag.Hannanum().pos(sample)
													[('이곳', 'N'), ('에서는', 'J'), ('형태소', 'N'), ('분석', 'N'), ('되', 'X'), ('ㄴ', 'E'), ('결과', 'N'), ('와', 'J'), ('nltk', 'F'), ('.', 'S'), ('chunk', 'F'), ('.', 'S'), ('regexp', 'F'), ('.', 'S'), ('RegexpParser', 'F'), (
													'를', 'N'), ('이용', 'N'), ('하', 'X'), ('어', 'E'), ('간단', 'N'), ('하', 'X'), ('게', 'E'), ('한국어', 'N'), ('문장', 'N'), ('에서', 'J'), ('명사구', 'N'), (',', 'S'), ('동사구', 'N'), (',', 'S'), ('형용사구', 'N'), ('를', 'J
													'), ('찾', 'P'), ('는', 'E'), ('법', 'N'), ('을', 'J'), ('살피', 'P'), ('어', 'E'), ('보', 'P'), ('도록', 'E'), ('하', 'P'), ('겠습니다', 'E'), ('.', 'S')]

								</pre>
								ㄴ Kkma Class
									ㄴ Hannanum과 유사한 방식으로 사용하면 된다.
								ㄴ Komoran Class
								ㄴ Mecab Class
								ㄴ Okt Class

							ㄴ corpus Package )
						ㄴ 'data' 모듈 )
						ㄴ 'downloader' Module )
						ㄴ 'jvm' Module )
							ㄴ konlpy.jvm.init_jvm(jvmpath=None, max_heap_size=1024)
								ㄴ JVM(자바 가상머신)을 초기화하는 메소드.
								ㄴ 인자 )
									ㄴ jvmpath :
									ㄴ max_heap_size : 사용될 메모리 최대치. MB단위. defaul = 1024.
						ㄴ 'utils' Module )



					* !!!!! Mecab()클래스는 윈도우에서 지원되지 않음.

					ㄴ 무제 <button>more</button>
					<pre>
						ㄴ okt의 경우, 2.1버전 기준으로, org\openkoreantext\processor\util에 사전들이 txt문서로 정리되어 있다.
							이를 수정하여 형태소 분석의 결과를 조정할 수 있다.
					</pre>


				</pre>
				ㄴ Shapely<button>more</button>
				<pre>
					ㄴ ~~~
					ㄴ Geometric Object )
						ㄴ ~~~
						ㄴ 모든 생성자에서 숫자값들은 python의 'float'으로 변환된다.
						ㄴ ??? 위상학적 함축성이나 인스턴스의 유효성을 검증하지 않는다?
							ㄴ 'is_valid' predicate로 커스텀하면 된다함.
						ㄴ 공통 속성, 메소드들 )
							ㄴ ~~~
						ㄴ 클래스 )
							ㄴ Point )
								ㄴ Point( (*x좌표값*), (*y좌표값*) )  또는 Point( (*좌표값을 담은 튜플*) )
									ㄴ ex ) Point(0.0, 0.0), Point( (0.0, 0.0) )
								ㄴ ~~~
							ㄴ LineString )
							ㄴ LinearRing )
							ㄴ Polygon )
								ㄴ Polygon( (*순서대로정렬된 좌표 튜플 리스트*), [ (*polygon 내부 구멍을 나타낼 좌표튜플 리스트*) ] )
								ㄴ 유효한 polygon )
									ㄴ shapely는 입력값에 대한 검증을 하지 않으므로 잘못된 좌표값 입력으로 인해 유효하지 않은 polygon이 생성될 수 있고
										이로 인한 예외가 발생할 수 있다.
									ㄴ 유효한 polygon이라면, 첫번째 인자로 그려진 linestring과 두번째 인자로 그려진 linestring이 만나지 않거나 단 한점에서만
										만난다.
					ㄴ ??? 2차원 평면에 대한 라이브러리이기 떄문에 3차원좌표에 해당하는 z값은 Shapely안에서 무시된다.
				</pre>
				ㄴ Psycopg<button>more</button>
				<pre>
					ㄴ psycopg2<button>more</button>
					<pre>
						ㄴ ~~~
						ㄴ python pep의 'DB API 2.0'을 따르는 모든 db adapter라면, psycopg의 기본 사용법은 모두 동일하다.
							ㄴ pep의 'DB API 2.0'이란? pytho에서 db에 접근하는 모듈들의 통일을 위해 만들어진 스펙.
						ㄴ connect()
							ㄴ 새 db session을 생성 & 반환.
							ㄴ 새로운 'connection' 인스턴스 반환.
						ㄴ connection class
							ㄴ db session을 wrap하는 클래스. 즉, connection class의 인스턴스는 하나의 db session을 wrap하고 있다.
							ㄴ connection 인스턴스
								ㄴ cursor 인스턴스 생성하여 cursor()로 db command나 쿼리 실행.
								ㄴ commit(), rollback()으로 트랜잭션 종료.
						ㄴ cursor class
							ㄴ db와 상호작용하는데 사용.
							ㄴ execute(), executemany()로 command 전달.
							ㄴ fetchone(), fetchmany(), fetchall() 등의 메소드 또는 iteration으로 db로부터 데이터를 받아옴.
						ㄴ with statement와 함께 사용시,
							ㄴ connection에 with statement가 사용되면,
								ㄴ with block 내에서 예외 발생시 트랜잭션 자동 롤백.
									예외 없으면 자동 커밋.
								ㄴ with block이 종료되어도 connection close되지 않음. 따로 명시적으로 닫아야함.
							ㄴ cursor에 with statement 사용시
								ㄴ with block 종료와 함께 cursor와 연관된 리소스 해제.
								ㄴ 트랜잭션에는 영향 없음.
							ㄴ ex )
								conn = psycopg2.connect(host=constant.db_host, dbname=constant.db_db, user=constant.db_username,
									password=constant.db_password, port=constant.db_port)

								with conn:
									with conn.cursor(cursor_factory=RealDictCursor) as cur:
										try:
											update_new_video(conn, cur)

										# except 구문에서 뭘하든 with block끝나면 위에 설명된대로 동작함.
										except Exception as e:
											report_error()

								conn.close()  # 명시적으로 connectino 닫음.

						ㄴ sql query의 파라미터 할당 <button>more</button>
						<pre>
							ㄴ psycopg를 이용한 sql에 파라미터 입력.
								ㄴ cursor의 execute() 등의 메소드를 통하여 sql에 파라미터를 입력하여 그 sql을 실행시킬 수 있다.
									ㄴ ex )
										cur.execute("""
										...     INSERT INTO some_table (an_int, a_date, a_string)
										...     VALUES (%s, %s, %s);
										...     """,
										...     (10, datetime.date(2005, 11, 18), "O'Reilly"))
								ㄴ named parameter 방식도 가능.
									ㄴ ex )
										cur.execute("""
										...     INSERT INTO some_table (an_int, a_date, another_date, a_string)
										...     VALUES (%(int)s, %(date)s, %(date)s, %(str)s);
										...     """,
										...     {'int': 10, 'str': "O'Reilly", 'date': datetime.date(2005, 11, 18)})
								ㄴ sql string에 '%'를 사용하려면 '%%'을 입력.
									ㄴ ex ) cur.execute("select (%s %% 2) = 0 as even", (10, ))
								ㄴ positional 변수 바인딩 사용시, 파라미터값을 입력하는 매개변수에는 반드시 python sequence가 와야함.
									파라미터값이 하나라도.
									ㄴ ex )
										cur.execute("insert into numbers values (%s)", (*sequence 파라미터값*) )
										(*sequence파라미터값*)에 "bar", ("bar") 등이 와선 안됨.
										("bar", ), ["bar"] 등이 와야함.
								ㄴ 파라미터 placeholder에 sql용 따옴표를 쓰지 않는다. psycopg가 필요하면 알아서 넣는다.
									ㄴ ex ) cur.execute("insert into noname values ('%s')", (10, ))  // 이렇게 quote 하지 말란 것.
										값이 string이거나 하면 알아서 따옴표를 붙임.
								ㄴ query 변수만 파라미터로 바인딩 해야 한다. 테이블이나 필드명을 파라미터로 입력하려하면 안된다.
									(테이블이나 필드명을 파라미터로 입력시 여기에 quoting이 되버린다함)
								ㄴ 파라미터 바인딩을 사용하지 않고 직접 python string + 연산자나 %할당으로 sql 문자열을 만들어
									사용하는 것은 지양해야 한다.
									sql injection에 취약해지고,
									python 문자열 문법과 postgresql 문자열 문법간의 미묘한 차이 등을 직접 처리해야 한다.
									(파라미터 바인딩하면 psycopgy가 알아서 처리함)
									ㄴ 미묘한 차이의 예 )
										python에선 콤마(')는 쌍따옴표(")를 이용한 문자열 안에선 그냥 콤마로 취급되지만
										postgresql에서 콤마는 무조건 문자열값에 쓰인다. 하여, 쌍따옴표 내 콤마가 있는 문자열을
										파라미터 바인딩 없이 sql로 만들어 넘기면 postgresql에서 처리시 콤마 때문에 문법 오류뜸)
								ㄴ ??? 백슬래쉬, like 값???


							ㄴ python 데이터 타입과 postgresql 데이터 타입간 변환.
								ㄴ psycopg의 메소드들을 통해 sql query에 사용될 파라미터들 입력시,
									psycopg가 파라미터값의 파이선 데이터 타입에 따라 적절한 sql용 문자열로 변환하여 sql query에 입력한다.
									ㄴ ex )
										cur.execute("""
										...     INSERT INTO some_table (an_int, a_date, a_string)
										...     VALUES (%s, %s, %s);
										...     """,
										...     (10, datetime.date(2005, 11, 18), "O'Reilly"))

										변환된 sql은...
										INSERT INTO some_table (an_int, a_date, a_string)
										VALUES (10, '2005-11-18', 'O''Reilly');
								ㄴ 대부분의 python 표준 타입들은 변환이 된다.
									ㄴ 참고 ) https://www.psycopg.org/docs/usage.html#python-types-adaptation
										표준 파이선 데이터 타입과 postgresql 데이터 타입간 매핑.
									ㄴ constants 값 변환
										ㄴ ~~~
									ㄴ number 값 변환
										ㄴ ~~~
									ㄴ ~~~

							ㄴ sql에 값을 동적으로 할당하는게 아닌, 스키마나 키워드를 동적으로 할당하고자 하면,
								이 기능은 사용 못하고(값 할당에 쓸수있으므로), 그냥 동적으로 문자열을 생성해야함.
								일반적으로 sql문을 문자열 concat으로 생성하는게 권장되지는 않지만, 스키마와 키워드 등은
								가능한 값이 제한적이라 유저인풋을 바로 넣지않고 한번 적절히 변환함으로서 어느정도 보완가능.
						</pre>

					</pre>
				</pre>
				ㄴ apscheduler<button>more</button>
				<pre>
					ㄴ Advanced Python Scheduler 
					ㄴ pip install apscheduler
					ㄴ 실행할 파이선 코드를 queuing하여 특정한 스케줄에 따라 실행시키는 기능 제공. 
					ㄴ 용어
						ㄴ task : 실행할 파이선 코드. 함수, 클래스의 메소드, 람다 등. 
						ㄴ trigger : task가 언제 실행되어야 하는지를 계산하는 주체. 스케줄링된 시간을 계산하는 것. 
						ㄴ schedule : task, trigger를 합친 것. 
						ㄴ job : 실행할 task에 대한 요청. 'scheduler'가 'schedule'를 처리할때 자동 생성. 
							또는 유저가 명시적으로 직접 생성. 
						ㄴ data store : 'schedule', 'job'을 저장하는 곳. 
						ㄴ job executor : 'job'을 실행하는 주체. 
						ㄴ ??? event broker
						ㄴ ??? scheduler 
							ㄴ 이 라이브러리의 메인 interface. 
							ㄴ ??? data store, event broker, job executor를 가짐. 
							ㄴ task, schedule, job와 관련된 동작을 할 수 있는 메소드 제공. 
							ㄴ schedule처리, job생성, job의 next run time 업데이트 수행. 
					ㄴ ??? 두가지 방식 존재. 비동기, 동기. 
						ㄴ??? 실제로는 동기방식 scheduler도 내부적으로 비동기방식으로 동작하는 것. 
						ㄴ ??? 'asyncio', 'Trio'를 사용하는 경우, 비동기 scheduler를 사요요해야함? 
					ㄴ foreground, background에서 scheduler 실행 가능. 

				</pre>
				ㄴ yfinance<button>more</button>
				<pre>
					ㄴ 야후 finance페이지를 스크래핑하여 얻은 데이터들을 api를 통해 제공해주는 오픈소스. 
					ㄴ https://github.com/ranaroussi/yfinance?tab=readme-ov-file
					ㄴ 유의사항	
						ㄴ 단순 한 개인이 작성한 라이브러리이기 때문에, 데이터의 정확성이나 신뢰성을 보장하지 않는다. 
						ㄴ 당연히, 야후와 제휴된것도 아니기 때문에 법적으로는 개인적 용도로만 사용해야함. 
						ㄴ krx스크래핑하듯 페이지 스크래핑 기반이기 때문에, krx스크래핑 등과 마찬가지로 페이지 관련 오류 발생시 정상동작 안함. 
					ㄴ 코드를 보니, 내부적으로 모듈 내에서 데이터 요청시, 
						스크랩대상 사이트인 yahoo finance페이지가 자체적으로 페이지에서 사용하는 api들을 그대로 호출하여 데이터를 받아 반환하는식인듯 하다. 
					ㄴ 설치
						ㄴ pip install yfinance 
					ㄴ 사용법
						ㄴ Ticker
							ㄴ yfinace에서 중심적으로 사용하는 객체. 
								특정 종목 등에 매핑되어 이 객체의 메소드를 통해 주가, 재무데이터, 종목정보, 배당, 주주정보 등, 여러 데이터를 얻는다. 
							ㄴ ex ) 
								import yfinance as yf 

								msft = yf.Ticker("MSFT")  # 마이크로소프트웨어를 나타내는 ticker. 

								msft.info  # 종목정보
								msft.history(period="max")  # 주가정보
							ㄴ 각 메소드들의 호출형식, 반환형, 정확히 어떤 데이터를 반환하는지 등은 소스코드 보고 확인. 
							ㄴ 메소드 
								ㄴ ~~~
						ㄴ yfinance.download()
							ㄴ 여러 Ticker들에 대한 데이터를 한번에 받는 메소드. 
							ㄴ ??? thread 기능 제공. 
								ㄴ thread 사용하지 않으면 내부적으로 그냥 입력받은 ticker들에 대해 Ticker를 여러번 생성 & 메소드 호출하여 받아오는식인듯. 
				</pre>
				ㄴ python-magic <button>more</button>
				<pre>
					ㄴ https://github.com/ahupp/python-magic
					ㄴ 'libmagic' 라이브러리와 상호작용하는 python interface. 
					ㄴ pip install python-magic 
					ㄴ libmagic과의 인터페이스니까 당연히 리눅스에서 사용 가능? 윈도우는 일반적으로 없으니. 

				</pre>

			</pre>

			ㄴ Django<button>more</button>
			<pre>
				ㄴ ~~~~~

				ㄴ Migration <button>more</button>
				<pre>
					ㄴ ~~~
					ㄴ migration 꼬였을시,
						ㄴ migration, db를 모두 날리고 다시 만들거나
						ㄴ migrate --fake 이용
							ㄴ 과정 )
								ㄴ 현재 적용된 마이그레이션 현황 확인. manage.py showmigrations
								ㄴ manage.py migrate --fake (*앱이름*) zero  를 통해 적용된 마이그레이션을 fake로 모두 되돌림.
								ㄴ 되돌려졌는지 확인. manage.py showmigrations
								ㄴ migrations 폴더 하위의 '__init__.py'를 제외하고 마이그레이션 파일 모두 삭제.
								ㄴ 다시 마이그레이션 파일 생성. manage.py makemigrations (*앱이름*)
								ㄴ fake migrate. manage.py migrate --fake-initial
									ㄴ 새로 만든 마이그레이션 파일임에도 manage.py showmigrations를 보면 적용된 마이그레이션이라 표시되고
										이로인해 의존성 관련 오류가 뜰 수 있다.
										ㄴ 이 경우, django_migrations 테이블에 같은 이름의 이전 마이그레이션이 존재해서 인듯 하다?
										ㄴ 이를 삭제하든 하면, 적용되었다는 표시가 사라진다.
							ㄴ fake migrate를 하므로, db와 model이 불일치하는 부분이 없어야함.

				</pre>

				ㄴ manage.py <button>more</button>
				<pre>
					ㄴ ~~~
					ㄴ runserver )
						ㄴ django-admin runserver [addrport]
							ㄴ addrport : ip주소, 포트번호. ex ) 0.0.0.0:8000
								ㄴ 서버가 돌아갈 ip주소와 포트번호 설정.
								ㄴ 디폴트 ip는 127.0.0.1
									디폴트 포트는 8000
								ㄴ ip는 서버가 돌아갈 컴퓨터가 할당가능한 ip주소여야 한다.
									아님 실행시 'that IP address can't be assigned to'오류.
								ㄴ ip 127.0.0.1(localhost)사용시, 이는 내부용 ip이기 때문에 외부에서 접속 불가.
									외부접속하려면 0.0.0.0이나 내부ip(ex)192.168.0.23) 사용해야함. (필요시 포트포워딩은 당연하고)
						ㄴ ~~~
						ㄴ 상용 서버가 아닌 개발용 서버이기 때문에, 보안이나 성능에 대해 보장하지 않는다고 한다.
							ㄴ 오래 실행되면 혼자 꺼지는 이슈도 이와 관련된게 아닌가 싶다.
						ㄴ 옵션 )
							ㄴ --noreload : runserver 실행중에 파이썬 코드 변경시 자동으로 서버를 재시작하는 기능을 끄겠다는 옵션.
							ㄴ
					ㄴ custom command 정의 <button>more</button>
					<pre>
						ㄴ 'manage.py (*custom command*)' 형식으로 사용할 임의 django 명령어 정의 가능. 
						ㄴ 기본 사용법 
							ㄴ 임의의 django app 폴더 하위 > 'management' 모듈 생성. 그 하위에 'commands' 모듈 생성. 
							ㄴ 'commands' 모듈 하위에 '(*command name*).py' 파일 생성. 
							ㄴ 위 구조상의 'commands' 모듈 내의 '(*command name*).py' 파일이 각각 custom command가 된다. 
							ㄴ 'manage.py (*command name*)'으로 실행 가능. 
							ㄴ '(*command name*).py' 파일 내에 'django.core.management.base.BaseCommand'를 상속하는 'Command'란 이름의 
								클래스 정의하고, 이클래스에 몇가지 필수 오버라이드 메소드 및 옵션 메소드 구현하면, 
								custom command실행시 이 클래스의 메소드들이 실행되는식. 
							ㄴ 필수적으로 handle() 메소드 구현 필요. custom command 실행시 이 메소드가 메인으로 실행됨. 
							ㄴ handle() 외에도 인자 파싱 등 여러 오버라이드 가능한 메소드들 존재. 
					</pre>
					
					ㄴ ~~~
				</pre>

				ㄴ Model <button>more</button>
				<pre>
					ㄴ ~~~

					ㄴ Field<button>more</button>
					<pre>
						ㄴ model이 사용하는 field type, option 등에 대해 설명.
						ㄴ 공통 option<button>more</button>
						<pre>
							ㄴ ~~~
							ㄴ default <button>more</button>
							<pre>
								ㄴ 필드에 디폴트로 설정될 값.
								ㄴ 정해진 값 또는 callable이 올 수 있다.
									ㄴ callable인 경우, 새 object 생성시마다 호출된다.
									ㄴ 정해진 값인 경우, list, set 같은 mutable한 값은 올 수 없다.
										새로 생기는 object마다 이 정해진 list값이 똑같이 할당되므로
										하나의 list값을 모든 object들이 공유하게됨.
										ㄴ mutable object를 디폴트로 사용하고자 하면, callable을 사용하여 이 mutable object를
											반환하게 하라.
											ㄴ ex )
												default=list()
												또는
												def create_default():
													return {"email": "sejf@gmail.com"}

												contact_info = JSONField("ContactInfo", default=create_default)
											ㄴ lambda는 사용할 수 없다.
								ㄴ  ForeignKey 필드인 경우, model instance가 아닌 참조하는 필드의 값이 와야한다.
							</pre>

						</pre>
						ㄴ type <button>more</button>
						<pre>
							ㄴ ~~~
							ㄴ FileField
								ㄴ arguments )
									ㄴ upload_to
										ㄴ ??? 파일 저장될 경로 & 파일명? 
									ㄴ max_length 
								ㄴ primary_key 옵션 할당 불가.

							ㄴ 관계 필드
								ㄴ ForeignKey
									ㄴ ~~~
									ㄴ no_delete
										ㄴ ~~~
										ㄴ CASCADE
										ㄴ PROTECT
										ㄴ RESTRICT
											ㄴ
								ㄴ ManyToManyField 
									ㄴ ~~~ 
									ㄴ 관련 객체의 추가, 삭제, 생성. 
										ㄴ 해당 필드에 들어있는 'RelatedManager' 객체를 통해 가능. 
								ㄴ RelatedManager 
									ㄴ ForeignKey를 이용한 1:N 매핑의 1쪽에 해당하는 객체와 
										ManyToManyField를 이용한 N:M 매핑의 양쪽에 해당하는 객체에서 사용하는 역참조 manager. 
									ㄴ django.db.models.fields.related_descriptors에서 정의된 로컬 class로 정의되어있음. 
									ㄴ RelatedManager 
										ㄴ 1:N 매핑에서 1쪽에 해당하는 객체에서 사용하는 RelatedManager. 
									ㄴ ManyRelatedManager 
										ㄴ N:M 매핑에서 사용하는 RelatedManager. 
										ㄴ 메소드 
											ㄴ add() 
											ㄴ remove()
											ㄴ clear()
											ㄴ set()
											ㄴ create()
										ㄴ 참조 
											ㄴ https://docs.djangoproject.com/en/3.2/ref/models/relations/#django.db.models.fields.related.RelatedManager


							ㄴ postgresql 전용 타입
								ㄴ ArrayField
									ㄴ django.contrib.postgres.fields.ArrayField
									ㄴ 옵션
										ㄴ base_field
											ㄴ 배열의 원소 타입.
											ㄴ django Field class의 서브클래스이어야함. (ChartField, IntegerField 등)
											ㄴ 관계 필드(ForeignKey 등) 타입, 파일 필드(FileField 등) 불가.
											ㄴ ArrayField로 설정하여 다차원 배열형식도 가능.
											ㄴ 필수
										ㄴ size
											ㄴ 배열 크기 지정
											ㄴ 필수x.
									ㄴ 필드 쿼리
										ㄴ 'contains' lookup
											ㄴ 기본동작이 ArrayField에서 override됨.
											ㄴ 입력받은 값이 object data의 subset으로 될 수 있으면 필터링.
											ㄴ ex )
												A객체에 [1,2,3]
												B객체에 [1,3]
												C객체에 [4]가 각각 ArrayField필드에 있다하면

												~~~.object.filter(~~__contains=[1, 2])
												하면, 입력받은 값[1,2]는 A의 [1,2,3]의 subset이 될 수 있으므로 A필터링.
										ㄴ 'contained_by' lookup
											ㄴ 전용 새로운 lookup
											ㄴ object의 data가 입력받은 값의 subset이 될 수 있으면 필터링.
											ㄴ ex )
												A객체에 [1,2,3]
												B객체에 [1,3]
												C객체에 [4]가 각각 ArrayField필드에 있다하면

												~~~.object.filter(~~__contains_by=[1, 2, 3])
												하면, A의 [1,2,3]과 B의 [1,3]은 입력받은값 [1,2,3]의 subset이 될 수 있으므로 A,B 필터링.
										ㄴ 'overlap' lookup
											ㄴ 입력받은값 중 하나라도 겹치면 필터링.
											ㄴ ex )
												A객체에 [1,2,3]
												B객체에 [1,3]
												C객체에 [4]가 각각 ArrayField필드에 있다하면

												~~~.object.filter(~~__overlap=[1, 2])
												하면, 입력받은 값 1,2 중 하나라도 가지고 있는 A의 [1,2,3], B의 [1,3]이 필터링.
							ㄴ ~~~

						</pre>
						ㄴ Custom Field 
							ㄴ django models.Field 또는 기본 필드 타입들을 상속하여 커스텀 필드 정의 가능. 
							ㄴ ~~~ 
							ㄴ 오버라이드 메소드 
								ㄴ ~~~
								ㄴ from_db_value(self, value, expression, connection) 
									ㄴ db로부터 데이터를 패치해올 때마다 호출되는 메소드. 
									ㄴ ex ) 
										class CustomDateTimeField(models.DateTimeField):

											def from_db_value(self, value, expression, connection):  
												if isinstance(value, datetime):
													return value.astimezone(timezone(settings.TIME_ZONE))
												else: 
													return value 


					</pre>
					ㄴ 인스턴스 메소드<button>more</button>
					<pre>
						ㄴ __str__()
							ㄴ 객체에 대한 str( (*객체*) ) 호출시 호출되는 메소드.
							ㄴ 장고 admin 페이지에서 객체를 나타낼 때 str()호출을 통해 나타내므로, 이 메소드가 사용된다.
					</pre>
					ㄴ ??? model 쿼리 기능 ?
						ㄴ model을 통해 db의 데이터를 다루는 방법에 대한 내용. 
						ㄴ ~~~ 
						ㄴ 데이터 받아오기 
							ㄴ db로부터 데이터를 받아오려면(model의 object형태로) Manager를 통해 얻을 수 있는 QuerySet을 이용해 가능. 
							ㄴ QuerySet 
								ㄴ django에서 db로부터 데이터를 받아오는데 사용되는 객체. 
								ㄴ sql의 select와 유사한 기능. 
								ㄴ Model의 Manager을 사용하여 QuerySet을 얻을 수 있음.  
									ㄴ 각 Model은 'objects'라 불리는 QuerySet을 기본적으로 가짐.
									ㄴ ex ) 
										# BasicInfo의 Manager에서 all()을 호출하여 전체 row에 대한 QuerySet 획득. 
										BasicInfo.objects.all()  
								ㄴ filter
									ㄴ QuerySet으로 가져온 데이터 중 일부를 필터링하는데 사용되는 컴포넌트. 
									ㄴ sql의 select문에서의 where, limit과 유사한 기능. 
									ㄴ 0개 이상의 'filter'를 가질 수 있다. 
									ㄴ ex ) 
										BasicInfo.objects.filter(code="005930")  # code가 "005930"인 BasicInfo object들을 필터링. 
								ㄴ 
						
					ㄴ save()는 모델 인스턴스의 모든 컬럼을 update. 
						ㄴ save(update_fields=[(*컬럼이름*)])로 특정 컬럼만 update 가능. 
					ㄴ Manager <button>more</button>
					<pre>
						ㄴ Django model에 대해 쿼리 연산을 하게 해주는 인터페이스. 
						ㄴ ??? 그냥 queryset을 사용할 때 쓰이는 중간 인터페이스? 
							QuerySet을 반환하는게 주 역할? 
						ㄴ get_queryset~~()에서 QuerySet을 반환함. 
						ㄴ 각 Model은 'objects'라 불리는 QuerySet을 기본적으로 가짐.
						ㄴ Model class를 통해서만 접근 가능. 인스턴스에선 불가. 

					</pre>
					ㄴ 상속 
						ㄴ 
				</pre>

				ㄴ 다중 database <button>more</button>
				<pre> 
					ㄴ ~~~ 
					ㄴ django-admin 및 migrate 명령어들은 거의 대부분 하나의 database에 대해 동작. 
						하여 다중 db 사용시, 어떤 db에 대해 명령어를 수행할지 명시 필요. 
						ㄴ 대부분 '--database=(*db별칭*)' 으로 명시. 
							ㄴ ex ) 
								python manage.py migrate --database=second_db ~~~ 
						ㄴ 명시하지 않는 경우 'default' 별칭의 db에 대해 동작. 
						ㄴ 예외 
							ㄴ makemigrations 명령어 
								ㄴ ??? An exception to this rule is the makemigrations command. 
									It validates the migration history in the databases to catch problems with the existing 
									migration files (which could be caused by editing them) before creating new migrations. 
									By default, it checks only the default database, but it consults the allow_migrate() 
									method of routers if any are installed.
					ㄴ database route 
						ㄴ ~~~ 
						ㄴ default routing scheme 
							ㄴ???  The default routing scheme ensures that objects remain ‘sticky’ to their original database (i.e., an object retrieved from the foo database will be saved on the same database). The default routing scheme ensures that if a database isn’t specified, all queries fall back to the default database.
							ㄴ 장고 플젝 생성시, 자동으로 세팅. 
							ㄴ 여러 db를 사용하려면 database route를 커스텀 정의 및 설치 해야함. 
						ㄴ 4개의 메소드를 제공하는 class. 
							ㄴ db_for_read(model, **hints) 
								ㄴ 'model'타입 객체의 read연산을 어느 db를 사용해야할지 제안하는 메소드. 
								ㄴ hints 인자 
									ㄴ db선택에 사용될 추가적인 정보를 담은 dictionary. 
								ㄴ 제안할 db 없는 경우, None반환. 
							ㄴ db_for_write(model, **hints)
								ㄴ db_for_read와 거의 동일. write 연산에 대한 메소드.
							ㄴ allow_relation(obj1, obj2, **hints) 
								ㄴ ~~~ 
							ㄴ allow_migrate(db, app_label, model_name=None, **hints)
								ㄴ ~~~ 
						ㄴ ex )  <button>more</button>
						<pre>
							class NewsDataRouter: 

								route_app_labels = {"news_data", }

								def db_for_read(self, model, **hints): 
									# model의 app명이 'news_data'인 경우, NewsDataRouter가 'news_db' 별칭의 db를 제안. 
									# 아닌 경우, 아무것도 제안하지 않음.(None반환)
									if model._meta.app_label in self.route_app_labels:
										return "news_db"
									return None

								# def db_for_write(self, model, **hints):
								#     """
								#     Attempts to write auth and contenttypes models go to auth_db.
								#     """
								#     if model._meta.app_label in self.route_app_labels:
								#         return "auth_db"
								#     return None

								# def allow_relation(self, obj1, obj2, **hints):
								#     """
								#     Allow relations if a model in the auth or contenttypes apps is
								#     involved.
								#     """
								#     if (
								#         obj1._meta.app_label in self.route_app_labels
								#         or obj2._meta.app_label in self.route_app_labels
								#     ):
								#         return True
								#     return None

								# def allow_migrate(self, db, app_label, model_name=None, **hints):
								#     """
								#     Make sure the auth and contenttypes apps only appear in the
								#     'auth_db' database.
								#     """
								#     if app_label in self.route_app_labels:
								#         return db == "auth_db"
								#     return None 

							~~~  django내 코드에서, 
							'NaverNews' Model이 'news_data' app에 속해있다하면,

							# 'news_data'별칭인 db가 사용됨. 
							daum_news_qs = DaumNews.objects.filter(
								title__contains=keyword, date_num__gte=start_date_int, date_num__lte=end_date_int
							)

							# 'default'별칭인 db가 사용됨. 
							BasicInfo.objects.all() 
						</pre>	
						ㄴ hints 인자 
							ㄴ ~~~ 
						ㄴ 4개 모두를 정의할 필요 없음. 
						ㄴ DATABASE_ROUTERS settings값
							ㄴ 어떤 db가 사용되어야 하는지 결정할 때 사용될 database router들을 명시하는 설정값. 
							ㄴ router class명으로 이루어진 list. 
							ㄴ ex ) 
								~~~ in settings.py ) 
								DATABASE_ROUTERS = ['Qsee.settings.db_router.NewsDataRouter', ] 
						ㄴ django.db.router 
							ㄴ base router 
							ㄴ ??? 쿼리가 어느 db에 대해 실행되어야 하는지 결정되어야 할때, 사용됨? 
								base router가 model, hints와 함께 호출되며, 
								base router는 DATABASE_ROUTERS에 설정된 router class들에 대해 순서대로 db결정을 db가 제안될때까지 실행.  
								db 제안이 끝까지 없는 경우, hints 내의 instance의 instance._state.db 를 사용. 
								이것도 없는 경우, 'default' db 사용. 
					ㄴ 당연히 다중으로 연결하려는 db의 종류가 다르다면, 해당 db에 맞는 python module을 설치해야함. 
						ㄴ ex ) pip install mysqlclient  
						ㄴ 각 모듈 설치 및 유의사항은 각 모듈의 공식 문서 참조. 
							ㄴ 해당 db에 대한 추가적인 프로그램 설치가 필요할 수 있다. ex ) dnf install mysql-devel 등. 
					ㄴ ~~~

				</pre>

				ㄴ transaction <button>more</button>
				<pre>
					ㄴ ~~~
					ㄴ settings.py에 databases 설정에 'ATOMIC_REQUEST'=True 설정시,
						request 단위로 transaction이 묶임.
					ㄴ DRF의 exception_handler 기능을 view에 적용시,
						view에서 exception발생시, transaction rollback이 안되는 이슈.
						ㄴ exception handler가 view에서 발생한 예외를 받아 처리하기 때문으로 보임.
							ㄴ 예외가 발생해야 이를 인지하여 transaction을 rollback시키는데 예외를 처리해버리므로.
							ㄴ 다음과 같은 경우도 transaction rollback 안됨. 예외가 밖으로 던져지지 않고 내부에서 처리되기 때문.
								ex )
									@api_view(["GET"])
									def aaa(request):
										try:
											raise Exception

										exception Exception as e:
											return (*Response*)
						ㄴ 이 경우, DRF의 exception handler에서 명시적으로 rollback해주어야함.
							ex )
								from rest_framework.views import exception_handler, set_rollback

								def custom_exception_handler(exc, context):
									handlers = {
										# "ValueError": _handle_generic_error,
										# "AttributeError": _handle_generic_error,
										"CustomException": _handle_generic_error,
									}

									response = exception_handler(exc, context)

									exception_class = exc.__class__.__name__
									if exception_class in handlers:
										set_rollback()  # rollback시킴. db 설정에 'ATOMIC_REQUESTS'=True이어야 rollback함.
										return handlers[exception_class](exc, context, response)

									return JsonResponse({"success": 0, "status": 500, "message": "서버에러입니다. 관리자에게 문의 주세요."})
				</pre>

				ㄴ 서버 세팅<button>more</button>
				<pre>
					ㄴ Gunicorn )
						ㄴ 방법 )
							ㄴ gunicorn 설치
								ㄴ pip install gunicorn
							ㄴ 프로젝트 홈 디렉토리에서 gunicorn 실행 명령어 실행
								ㄴ ex )
									gunicorn (*프로젝트폴더명*).(*wsgi파일명*):application (*옵션들...*)

									gunicorn deepqapps.wsgi:application --bind 0.0.0.0:8888
								ㄴ 옵션 )
									ㄴ --bind : 포트 설정
										ㄴ ex ) --bind 0.0.0.0:8080
									ㄴ --daemon : 데몬으로 실행
							ㄴ gunicorn 종료 명령어 )
								ㄴ pkill gunicorn
							ㄴ 정적 파일 반환 )
								ㄴ gunicorn으로 정적 파일을 지원하려면 파이썬 'whitenoise' 모듈 필요.
								ㄴ pip install whitenoise
								ㄴ 장고 wsgi.py에 다음 설정 추가
									ㄴ ex )
										from whitenoise import WhiteNoise

										application = get_wsgi_application()

										application = WhiteNoise(application, root='/opt/deepq')
										application.add_files('/opt/deepq/static/', prefix='')

				</pre>

				ㄴ Form <button>more</button>
				<pre>
					ㄴ 장고에서 사용자 입력인 form과 관련된 많은 기번적 로직들을 자동으로 편리하개 처리해주는 요소
					ㄴ Form class
						ㄴ 앱상에서의 넌리적 객체를 medel이 표현하는 것처럼 사용지가 입략한 form을 표현하는 클래스.
						ㄴ 필드값은 input tag와 매핑된다.
						ㄴ ??? 필드 하나하나도 form class? 각 필드별로 유효성검증을 하고 데이터를 다룸?
						ㄴ ??? form의 필드는 html상의 ‘widget’으로 표현된다?
						ㄴ django template상에서 데이터를 view에 뿌리려면 ‘데이터를 받아오거’, view의 context로 넘기고, template에서 이를 렌더링함. 이와 유사하게 form도 렌더링함. 차이점은 midel 인스턴스는 내부에 데이터가 없느 경우 템플릿상에서 거의 하는게 없지만, form은 내부가 비어잇어도 템플릿상에서 유저가 이를 챠우게함으로서 사용할수있다. 물론 채워둘수도 잇다.
						ㄴ 이전 form 으로부터 데이터 받아올수도잇음.
						ㄴ Form 클래스들은 django.forms.Form 또는 django.forms.ModelForm 클래스의 하위 클래스들. 
						ㄴ django.forms.ModelForm 
							ㄴ django의 Model 을 추가하거나 수정할 때 사용하면 편리한 From. 
					ㄴ ex ) 
						from django import forms
						
						class NameForm(forms.Form):
							your_name = forms.CharField(label='Your name', max_length=100) 
						
						ㄴ charField 속성으로 유효성검증 가능.
						ㄴ ???브라우저로부터 받아오는시점에 장고가 알아서 유효성 검증?
						ㄴ form은 is_valid() 메소드 가짐. 각 필드에 대해 유효성 검증. 모두 유효할시 true반환하고 ? cleaned_data 속성에 데이터 저장함?
					ㄴ form에 맞게 적절한 input태그가 자동생성
						ㄴ submit 버튼은 알아서 넣어야함.
					ㄴ view단에서 request.POST등으로 Form 클래스의 인스턴스 생성 가능. is_valid() 등으로 안에 들은 데이터들 유효성 검증 가능. 
						이를 html로 보내는식으로 사용 가능. 
					ㄴ template에선 context 데이터 렌더링하듯, form class의 인스턴스를 html상에 {{ }}로 렌더링하면 
						그 자리에 적절한 input, label등에 해당하는 html 코드가 삽입됨. 
					ㄴ bound form, unbound form 
						ㄴ From 인스턴스는 'bound' 되어있거나 'unbound'되어있음. 
						ㄴ bound 
							ㄴ 데이터를 가지고 있는 것. 
							ㄴ 가지고 있는 데이터에 대해 유효성 검증이 가능. 
							ㄴ 가지고 있는 데이터들로 html상ㅇ에 form 렌더링 가능. 
						ㄴ unbound 
							ㄴ 데이터가 없이 비어있는 것. 
							ㄴ 데이터가 없으므로 유효성 검증 불가. 
							ㄴ 빈 데이터 상태로도 html상에 form 렌더링은 가능. 비어잇는 상태로 렌더링됨.  
						ㄴ form 인스턴스의 is_bound 속성 
							ㄴ 인스턴스가 bound인지 unbound인지 bool값으로 나타내는 속성. 
					ㄴ ??? form 인스턴스는 한번 생성되면 내부의 데이터를 변경할 수 없다? 
						다른 데이터를 가진 form이 필요하다면 새로 생성해야함. 
					ㄴ Form validating 	
						ㄴ django.forms.Form.is_valid() 
							ㄴ form의 유효성검증 결과 에러가 없는지를 판단. 없음 True. 
							ㄴ bound 인 form instance에 대해 호출가능.  
						ㄴ django.forms.Form.errors 
							ㄴ 필드들에 대한 validation 실패시 에러메세지를 dict형태로 가지고 있는 속성. 
							ㄴ ex ) {"name": '이 값이 최소 5 개의 글자인지 확인하세요(입력값 4 자).', "email": '이 필드는 필수 항목입니다.'}
							ㄴ is_valid()를 호출하지 않았어도, 이 속성에 접근시 validate가 되어있지 않다면 자동으로 유효성 검증이 진행. 
								errors 속성이 None으로 비어있는지로 판단. 
							ㄴ Form.errors.as_data() 
								ㄴ Form.errors와 key는 똑같고 value에 에러메세지가 아닌 유효성검증시 발생한 ValidationError 객체가 들어감.ㅏ 
								ㄴ ex ) 
									{'sender': [ValidationError(['Enter a valid email address.'])],
									'subject': [ValidationError(['This field is required.'])]}
							ㄴ Form.errors.as_json() 
								ㄴ ~~~ 
							ㄴ ~~~ 
						ㄴ django.forms.Form.full_clean() 
							ㄴ form에 대해 clean 수행. 
							ㄴ 모든 필드에 대한 clean, form전체에 대한 clean 등이 수행. 
						ㄴ django.forms.Form._clean_fields() 
							ㄴ 모든 필드에 대한 clean 수행
							ㄴ 각 필드에 대해, form 초기화시 넘어온 data, files 인자 등으로부터 필드의 widget에 맞는방식으로 값을 가져온후, 
								필드의 clean()을 호출. clean() 정상종료시 cleaned_data에 값 삽입, 오류시 form 에러 목록에 추가. 
							ㄴ 통과 못하는 경우, cleaned_data에 데이터가 없으므로 form.clean()에서 사용할 수 없음 유의. 
						ㄴ django.forms.Field.to_python() 
							ㄴ 값을 python상의 데이터타입으로 변환하여 반환. 
							ㄴ 보통 필드 class별로 오버라이드하여 정의됨. 
								ㄴ ex ) DecimalFiled이면, 들어오는 값에 대해, 빈값 확인, 형식 확인 등을하고 Decimal로 변환하여 반환하는 로직으로 
									오버라이딩 되어있는식. 
						ㄴ django.forms.Field.clean() 
							ㄴ 필드값에 대해 clean 수행. 
							ㄴ to_python()으로 값 변환 후, validate 후 반환 하는식으로 동작. 
						ㄴ validation은 단 한번만 진행된다함.  
					ㄴ Form initial
						ㄴ Form, form의 Field에 initial이란 속성으로 초기값 설정 가능. 
						ㄴ 실제 들어가는 데이터가 아닌 말그대로 초기값으로, template상에서 값이 들어간채로 렌더링. 
						ㄴ Form의 initial 
							ㄴ dict형태로 입력하여 설정 가능. 
							ㄴ 원하는 필드에 대해서만 설정 가능. 모든 필드 설정할 필요 없음. 
							ㄴ ex ) 
								form = TestForm(initial={"name": "test", "num": 10})
								ㄴ 이 form을 template상에서 렌더링하면, name, num input에 'test', 10이 미리 채워져잇음. 
						ㄴ Field 의 initial 
							ㄴ Form class 정의시, Field 정의부분에 속성으로 설정. 
							ㄴ 그냥 값 입력. 
							ㄴ ex ) 
								class TestForm(Form):
									name = forms.CharField(min_length=10, initial="hello")
									~~~ 
								ㄴ TestForm의 name필드는 initial이 설정되며, 값으로 'hello'를 가짐. 
						ㄴ ??? Form의 initial, Field의 initial이 모두 잇는경우, 
							나중에 설정된 것으로 취급된다함. ?Field는 Form class정의시 설정하는거고, Form은 인스턴스 생성시 설정하는 건데 
							무조건 Form의 inital이 나중에 오지 않나? 
						ㄴ 어떤 방법으로 initial을 설정하든, 
							Form인스턴스의 Field 인스턴스에 initial 속성에 설정한 초기값이 할당된다. 
							단, Form에서 설정한 경우, template에 갔다가 다시 제출되어 view로 들어온 경우, 
							이 데이터들에 대한 Form인스턴스를 만들면 이는 새로 생성한 것으므로 처음 설정한 initial이 없고 
							필드 인스턴스들에 initial 속성에 값도 없다.  
							Field의 initial속성으로 설정한 경우, form을 제출해 데이터를 받고 이 데이터로 Form인스턴스를 재생성하더라도 
							class정의상에 Field의 initial이 설정되어 있기때문에 필드 인스턴스들에 initial속성값이 존재한다. 
					ㄴ has_changed() 
						ㄴ Form, Field의 메소드. 
						ㄴ 함수명만 보면 데이터 변경여부를 확인해줄것 같지만, 
							단순히, 초기값(initial값)과 현재 데이터값이 같은지 아닌지만 판별하여 bool반환. 
						ㄴ 비교대상인 initial은 Field 인스턴스의 initial속성값. 
						ㄴ Field 인스턴스의 has_changed()는 해당 필드인스턴스의 initial값과 같은지 다른지를 판별. 
						ㄴ Form 인스턴스의 has_changed()는 단순히 form의 Field 인스턴스들의 has_changed()를 수행하고 
							이중 하나라도 True면 True를 반환하는 것. 
					ㄴ Form.changed_data 속성 
						ㄴ Form에서 has_changed()가 True인 필드들의 필드명 리스트 반환. 
					ㄴ Form.fields 속성 
						ㄴ Form인스턴스의 Field 인스턴스들이 들어있는 속성. 
						ㄴ dict형태로, key는 필드명, value가 Field 인스턴스. 
						ㄴ field 인스턴스에 접근하여 인스턴스의 여러 속성들 수정 가능. 
							ㄴ 필드의 label속성을 변경하여 form이 html에 렌더링될 때의 label값을 바꾼다거나 
							ㄴ 'base_fields'속성은 변경하면 안됨. 
					ㄴ Form의 데이터 cleaning 
						ㄴ 필드에 들어온 데이터가 어떤형식이든 결과 데이터를 일정한 형식으로 변환하는 것. 
							ㄴ ex ) field가 DateField이면, ‘2024-10-10’ 이런식으로 들와도 date 타입으로 변환해줌. 
					ㄴ From.cleaned_data
						ㄴ Form에 의해 validate, cleaning된 데이터들이 들어있는 dict.
						ㄴ Form에 대한 validate 완료 후에 접근 가능. 
						ㄴ validate를 통과한 필드에 대한 키,값 쌍만 존재. 통과 못한건 키-값쌍 없음. 
						ㄴ form의 Field 에 해당하는 키값만을 가짐. 
							ㄴ form 인스턴스 생성시, 필드에 해당하는 키 이외의 키를 가진 dict로 바인드를 해도,
								cleaned_data에는 필드에 해당하는 키만 존재.
							ㄴ Form class정의에 Field가 아닌 멤버변수 있어도 이는 cleaned_data에 포함되지 않음. 
						ㄴ required=False인 필드 데이터가 비어있어도 cleanded_data에 포함. 
							빈 값이 들어가있음. 
					ㄴ Form의 html output 
						ㄴ form에는 form자체를 html형식으로 출력하는 기능 존재. 
							이를 사용하여 html에 적절한 요소를 렌더링. 
						ㄴ firm을 html상에 어떤 형식으로 나타낼지 정할 수 있음.
							ㄴ 각 필드들이 table에 들어간 형태로 만들거나 여러 줄의 p 태그에 걸쳐 리스팅되는 형식이거나 등.
							ㄴ Form.as_table(), Form.as_p(), Form.as_ul() 등의 메소드를 통해 가능. 
						ㄴ form이 bound되어잇으면 html output에 적절한 값이 들어가있다.
						ㄴ css 설정 
							ㄴ ~~~ 
						ㄴ error 표시 
							ㄴ ~~~
						ㄴ ~~~
					ㄴ Form에서 파일 다루기 
						ㄴ Form에 FileField, ImageField와 같이 파일 필드가 포함되어 있는 경우, 
							파일 데이터를 Form 인스턴스에 bind하려면 Form 생성자에 'files' 인자로 파일 데이터를 따로 넘겨주어야 한다.  
							나머지 다른 데이터들은 'data'인자에 똑같이 넘기고. 
							ㄴ ex ) 
								data = {'subject': 'hello',
								         'message': 'Hi there',
											~~~ 
								  		} 
								file_data = {'file1': SimpleUploadedFile('face.jpg', ~~~)}
								f = TestForm(data=data, files=file_data)  # data와 마찬가지로 dict형태로 파일 데이터를 files인자에 넘김. 
						ㄴ 일반적으로, django view에서 기본적으로 받는 request인자의 FILES 속성에 파일 데이터가 dict형태로 들어있으므로 
							이를 그대로 넘김. 
							ㄴ ex ) TestForm(data=request.POST, files=request.FILES) 
						ㄴ Form.is_multipart() 
							ㄴ Form 인스턴스가 form 태그의 enctype를 "multipart/form-data"로 설정해야하는지 여부를 bool로 반환. 
								즉, multipart형식의 form태그를 필요로하는 form인지를 알려주는 메소드. 
							ㄴ template에서 form렌더링시, 이 메소드 반환값을 기준으로 enctype속성을 설정하는식으로 사용. 
					ㄴ Form 상속 
						ㄴ Form class도 상속가능. 
							상속시 상위 Form class의 모든 필드를 하위 클래스가 포함하고, 그 다음 하위 클래스의 필드들을 포함하게됨. 
						ㄴ 다중상속도 가능. 
						ㄴ 하위 클래스 정의에서, 상위 클래스로 상속받은 필드를 명시하고 None을 할당함으로서 해당필드를 상속받지 않을 수 있다. 
							ㄴ ex ) 
								class TestForm(forms.Form):
									name = forms.CharField()
									
								class ChildTestForm(TestForm):
									additional_field = forms.CharField() 
									name = None  # TestForm으로부터 상속받은 name 필드를 상속받지 않음. 
					ㄴ Form.prefix 
						ㄴ Form 인스턴스에 prefix를 설정하면 해당 인스턴스의 필드들이 html상에 렌더링될 때 추가적인 prefix가 붙어서 렌더링. 
							ㄴ ??? 구체적으로 어떤식으로 prefix가 붙는지는 ? 
								ㄴ 일단 input의 name속성에 prefix가 붙음. 
						ㄴ 이를 이용해, 하나의 html form태그 안에 여러 Form 인스턴스를 렌더링할 때, 필드명이 겹쳐도 prefix로 구분 가능. 

					ㄴ widget 
						ㄴ form으로 만들어지는 html form 요소를 의미. 
						ㄴ form의 필드들이 가질 수 있는 타입별로 여러 종류의 widget 존재. 
						ㄴ ex ) form.CharField() 필드에는 < input type="text"> 이 생성.  
						ㄴ form의 필드들이 input등의 html 요소 하나하나로 나타내짐. 
						ㄴ input들의 label
							ㄴ 디폴트로 각 input들의 label은 필드명이 변환되어 출력. 
								ㄴ unserscore는 uppercasing으로 변환. 
							ㄴ Form class 필드 정의시, label 속성 설정시 이 값으로 출력. 
					ㄴ Form 의 Field 
						ㄴ Form class를 구성하는 필드에 ㅐㄷ한 내용. 
						ㄴ django.forms.Field class
							ㄴ clean( (*value*) )
								ㄴ (*value*)로 해당 필드에 대해 유효성 검증하는 메소드. 실패시 에러. 성공시 clean value 반환. 
						ㄴ Field 공통 인자 
							ㄴ Field 인스턴스 생성시 사용되는 공통 인자. 
								field 클래스에 따라 추가적인 인자는 있어도 최소한 아래 인자들은 공통적으로 가짐. 
							ㄴ 목록 ) 
								ㄴ required 
									ㄴ 필드가 필수인지 여부. 
									ㄴ True인데 해당 필드값이 None이거나 빈문자열인 경우 유효성 검증 실패. 
									ㄴ False인 경우, clean()은 필드 클래스에 따라 적절한 값 반환. 
										이를 'normalized empty value'라함. 대략 필드에 대한 디폴트 값이라 생각해면 될듯. 
										ㄴ CharField인 경우 빈 문자열, 나머지는 대부분 None.
								ㄴ label 
									ㄴ input에 명시될 label 이름 명시. 사용자 친화적인 이름을 따로 명시가 가능하다는 점에서 유용. 
								ㄴ initial 
									ㄴ ex ) 
										class TestForm(forms.Form):
											name = forms.CharField(initial='hello')
										
									ㄴ unbound Form을 html에 렌더링할 때, 해당 필드에 미리 들어가 있을 값 설정. 
									ㄴ 이를 이용하지 않고 그냥 Form인스턴스에 값을 넣어버리면 bound Form이 되고 따라서 
										html에 렌더링 될때 validate가 실행되어 에러메세지 등이 같이 렌더링 될수있음. 
									ㄴ validate시, 필드에 값이 없다고 해서 이 inital값으로 대체되지 않는다. 
									ㄴ callable 도 설정 가능. 
										ㄴ ex ) 
											class TestForm(Form):
												name = forms.CharField(initial=datetime.date.today)
									ㄴ Form.initial 속성을 설정하여 같은 기능 가능. 
								ㄴ ~~~ 나머지 ref참고 
									ㄴ https://docs.djangoproject.com/en/5.1/ref/forms/fields/ 
						ㄴ Built-in Field class 목록 
							ㄴ 기본적으로 forms 라이브러리에 있는 Field class 목록 
							ㄴ 각 필드 클래스 항목에서 설명하는 
								'디폴트 위젯'이란, 'widget'을 따로 설정하지 않은 경우 사용되는 위젯을 의미. 
								'empty value'란, 필드가 required=False이고, 값이 비었을 경우 사용되는 디폴트값 의미. 
								'normalizes to'란, 필드값이 어떤 데이터 타입으로 변환되는지를 의미. 
							ㄴ BooleanField 
								ㄴ 디폴트 위젯 : CheckboxInput 
								ㄴ empty value : False 
								ㄴ Normalizes to : True 또는 False 
								ㄴ 
							ㄴ CharField 
								ㄴ 디폴트 위젯 : TextInput 
								ㄴ empty value : CharField의 'empty value'속성에 설정한 값. 
								ㄴ Normalizes to : string 
								ㄴ max_length, min_length 속성 설정시, MaxLengthValidator, MinLengthValidator으로 유효성 검증. 
									설정 안한 경우, 모두 유효한것으로 취급. 
								ㄴ 추자적 속성 
									ㄴ max_length 
										ㄴ 옵션 
										ㄴ 문자열 최대 길이 제한. 
									ㄴ min_length 
										ㄴ 옵션 
										ㄴ 문자열 최소 길이 제한. 
									ㄴ strip 
										ㄴ 옵션
										ㄴ True인 경우, 앞뒤 공백 제거. 
										ㄴ 디폴트 True. 
									ㄴ empty_value 
										ㄴ 'empty'를 나타내는 값. 디폴트는 빈문자열 "". 
							ㄴ ~~~
							ㄴ ComboField 
								ㄴ 필드 정의시, 'fields'라는 속성으로 Field 인스턴스로된 배열을 넘겨 정의하고, 
									이 ComboField의 데이터를 clean()할 때, 이 데이터를 위에서 넘긴 Field인스턴스들로 모두 유효성검증을 진행. 
									ㄴ ex ) 
										class TestForm(forms.Form):
											name = forms.CharField()
											age = forms.IntegerField()
											comb = forms.ComboField(fields=[forms.CharField(max_length=5), forms.IntegerField()])

										form = TestForm({
											"name": "hello", 
											"comb": "1234567"
										})
										form.is_valid()  # 여기서 comb의 값이 max_length=5를 초과했다는 ValidationError발생. 
										ㄴ form.is_valid()시, "comb"의 값 "1234567"에 대해, forms.ComboField()정의시 넘긴 fields들 
											(forms.CharField(), forms.IntegerField())로 유효성검증을 진행. 
											max_length=5였으므로 길이초과로 오류 발생. 
								ㄴ 디폴트 위젯 : TextInput 
								ㄴ empty value : ""
								ㄴ normalizes to : string 
							ㄴ MultiValueField 
								ㄴ ??? 대략, ComboField와 비슷하게 필드 인스턴스 생성자에 fields란 매개변수로 Field 인스턴스로 이루어진 튜플을 넘기고, 
									필드 데이터를 여러개 받고 이 각각을 정의햇던 필드들로 각각 검증히고 compress() 에서 이 값들을 하나로 취힙하는 필드? 
								ㄴ 상속해서 사용해야하며 compress() 구현 필요. 
							ㄴ SplitDateTimeField
								ㄴ ~~~ ??? 
									
							ㄴ ~~~ 나머진 ref 참고 
								ㄴ https://docs.djangoproject.com/en/5.1/ref/forms/fields/
						ㄴ custom field 
							ㄴ 방법 
								ㄴ django.forms.Field를 상속하는 클래스 정의. 
								ㄴ clean() 오버라이딩 
								ㄴ __init__()이 다음 필수 인자를 받도록 오버라이딩 
									ㄴ required, label, initial, widget, help_text 
									ㄴ 당연히 커스텀 필드에서 필요한 별도의 추가 인자를 받아 사용할 수 있음. 
							ㄴ ex )  
								
								class ListField(forms.Field):

									def __init__(self, *, field_obj: forms.Field, min_length: int, max_lengths: int, **kwargs):
										"""
										Args: 
											field_obj (forms.Field): 리스트 원소가 어떤 Field일지. 
										"""
										# widget은 원소의 필드와 동일하도록. Form의 _clean_fields()에서 widget을 통하여 input으로부터 필드의 값을 가져오는데 
										# widget이 적절하지 않은 경우, 값 제대로 못가져옴. 원소가 FileField인데 widget은 TextInput인 경우 등. 
										super().__init__(widget=field_obj.widget, **kwargs, )
										self.field_obj = field_obj 
										self.min_length = min_length
										self.max_length = max_lengths

									def clean(self, data, ): 
										"""리스트 각 원소에 대해 field_obj.clean()을 수행. """
										result = [] 
										if not isinstance(data, list):
											raise forms.ValidationError("list형이어야 합니다. ")
										elif len(data) < self.min_length:
											raise forms.ValidationError(f"최소 {self.min_length}개 이상이어야 합니다. ")
										elif len(data) > self.max_length:
											raise forms.ValidationError(f"최대 {self.max_length}개 이하이어야 합니다. ")
										
										for item in data:
											result.append(self.field_obj.clean(item)) 

										return result

								~~~ 
								class UserPromptForm(forms.Form):
									prompt = forms.CharField() 
									file1 = forms.FileField()  
									file_list = ListField(field_obj=forms.FileField(),  ) 
									name_list = ListField(field_obj=forms.CharField()) 

						
					ㄴ Form의 데이터가 is_valid()로 유효성검증을 하고 이게 통과됐을 경우, form.cleaned_data 속성 안에 dict형태로 
						form의 데이터가 존재. 이 안의 데이터는 python타입. 
				</pre>

				ㄴ file <button>more</button>
				<pre>
					ㄴ 유저가 업로드한 파일 등을 다루는 방법. 
					ㄴ settings.py의 MEDIA_ROOT
						ㄴ 
					ㄴ settings.py의 MEDIA_URL
						ㄴ 
					ㄴ ??? 디폴트로 settings.py의 MEDIA_ROOT 값에 파일 저장. 
					ㄴ model의 필드 
						ㄴ django.db.models.FileField, 
							ㄴ 파일을 나타내는 model의 필드타입. 
								당연히 왠만한 파일관련 기능들 내장. 
							ㄴ 속성 
								ㄴ upload_to :
								ㄴ storage 
									ㄴ ~~~
									ㄴ callable으로 설정하여 런타임시에 동적으로 결정되도록 가능. 
						ㄴ django.db.models.ImageField 
							ㄴ 
					ㄴ django의 File 객체 
						ㄴ django.core.files.File 
							ㄴ 장고에서 파일을 나타내고 다룰 때 사용하는 클래스. 
							ㄴ python built-in 'file' object의 wrapper. 약간의 기능만 더한 것. 
							ㄴ python built-in 'file' object를 통해 쉽게 생성 가능. 
								ㄴ ex )
									f = open("/path~~~", "w")
									myfile = django.core.files.File(f)

								ㄴ ??? 이런식으로 생성한 경우, python built-in file은 명시적으로 close해야함. 자동으로 안 닫힘. 
							ㄴ 속성 
								ㄴ name : MEDIA_ROOT부터 시작하는 상대경로. 
								ㄴ size : 파일 크기.
								ㄴ file : 내부적으로 가지고있는 python built-in 'file' object.
									ㄴ 서브클래스들에 의해 오버라이드되는 경우 있음. 유의 필요. 
								ㄴ mode : file에 대한 read/write 모드. 
								ㄴ open(mode=None) 
									ㄴ ??? 파일을 열거나 다시열음. 
									ㄴ mode값은 python built-in open()의 mode인자와 동일. 
								ㄴ close() : 파일 닫음. 
								ㄴ ~~~ 
								ㄴ ??? model의 object와 연관된 경우의 추가 속성
									ㄴ save(name, content, save=True) 
										ㄴ??? File 객체의 파일명과 내용으로 새 파일 생성 & model의 object가 이 파일을 가리키도록 수정. 
										ㄴ save=True일시, 파일 저장 후, 연관된 model객체에 대해 save()호출. 
									ㄴ delete(save=True)
						ㄴ django.core.files.images.ImageFile 
							ㄴ 이미지 파일을 위한 장고 파일 객체. 
							ㄴ django.core.files.File을 상속. 
							ㄴ 추가된 속성 
								ㄴ width: 이미지 픽셀 넓이ㅣ. 
								ㄴ height: 이미지 픽셀 높이.
					ㄴ file storage system
						ㄴ ??? 파일이 어디에 어떻게 저장될지를 결정하는데 장고가 내부적으로 사용하는 시스템. 
						ㄴ DEFAULT_FILE_STORAGE
							ㄴ 어떤 storage systme을 사용할지 결정하는 설정값.
							ㄴ 디폴트는 django.core.files.storage.FileSystemStorage
						ㄴ django.core.files.storage.FileSystemStorage 
							ㄴ 디폴트 file storage. 
							ㄴ ??? local filesystem에 대한 스토리지 생성? 
							ㄴ django.core.files.storage.Storage 클래스를 상속. 
							ㄴ class FileSystemStorage(location=None, base_url=None, file_permissions_mode=None, directory_permissions_mode=None)
								ㄴ location : 파일을 저장할 폴더에 대한 절대경로. 디폴트값은 MEDIA_ROOT 설정값. 
								ㄴ base_url : 저장된 파일을 참조할때 사용할 URL. 디폴트값은 MEDIA_URL 설정값.
								ㄴ file_permissions_mode 
									ㄴ 저장될 파일이 가질 permission mode값.(600, 644 등) 디폴트는 FILE_UPLOAD_PERMISSIONS 설정값. 
									ㄴ ```
								ㄴ directory_permissions_mode : 파일저장할 디렉토리에 대한 권한.
							ㄴ Storage에서 상속한 delete() 호출시, 해당 파일이 없어도 예외발생하지 않음. 
							ㄴ 메소드 
								ㄴ get_created_time(name) 
									ㄴ ``` 
						ㄴ django.core.files.storage.Storage 
							ㄴ 다론 모든 storage system들의 상위 클래스. 
							ㄴ 다른 모든 storage system들이 상속해서 사용할 기본적인 동작을 위한 기능들을 제공. 
							ㄴ 메소드 
								ㄴ delete(name)
									ㄴ name에 해당하는 파일삭제. 
									ㄴ 해당 storage system이 이 메소드를 지원하지 않으면 에러 발생. 
								ㄴ exists(name)
									ㄴ name에 해당하는 파일이 존재하는지 확인.
								ㄴ get_accessed_time(name)
								ㄴ get_alternative_time(file_root, file_ext)
								ㄴ ~~~
								ㄴ listdir
								ㄴ open 
								ㄴ path
								ㄴ save  
								ㄴ size
								ㄴ url 
						
						ㄴ settings.py의 STORAGES 
							ㄴ 

				</pre>
				
				ㄴ static file 세팅 <button>more</button>
				<pre>
					ㄴ django.contrib.staticfiles 모듈이 관련 기능 제공. (settings.py 의 INSTALLED_APPS에 포함되야함)
					ㄴ 관련 설정값
						ㄴ STATIC_URL
							ㄴ ex ) STATIC_URL = "static/"
							ㄴ django template에서 'static' tag 사용시 이 STATIC_URL값을 참고하여 장고가 URL을 생성.
								ㄴ ex ) < img src="{% static 'img/test.jsp' %}" />  // '/static/img/test.jpg' 와 같은식으로 자동생성.
						ㄴ STATICFILES_DIRS
							ㄴ static file finder가 static file을 찾을때 탐색할 위치를 명시하는 설정값.
							ㄴ full path 문자열의 리스트 형태
							ㄴ ex )
								STATICFILES_DIRS = [
									"/home/polls.com/polls/static",
									"/opt/webfiles/common",
								]
							ㄴ unix-style forward slashe 형태로 경로입력해야함. (윈도우더라도)
							ㄴ prefix
								ㄴ 리스트 값으로 tuple을 ( (*prefix*), (*static file 경로*) ) 와 같이 입력시,
									이때의 경로를 django template에서 (*prefix*)값으로 나타낼 수 있다.
								ㄴ ex )
									STATICFILES_DIRS = [
										("testPrefix", "/opt/static/img"),
									]

									... in template
									< img src="{% static 'testPrefix/test.png' %}" />
									ㄴ testPrefix란 경로를 튜플의 /opt/static/img로 자동 인식하여 알맞은 static file을 반환해준다.
								ㄴ 특정 경로에 접두어, 이름같은걸 붙일 수 있는셈.
						ㄴ STATICFILES_FINDERS
							ㄴ static file들을 찾는데 사용될 'finder'들을 정하는 설정값.
							ㄴ 디폴트는
								django.contrib.staticfiles.finders.FileSystemFinder와
								django.contrib.staticfiles.finders.AppDirectoriesFinder
								각각 'STATICFILES_DIRS' 설정값의 위치와 app의 'static' subdirectory 위치에서 static file을
								찾는 finder.
							ㄴ 같은 이름의 파일 존재시, 먼저 찾은 파일을 취한다.
							ㄴ ??? Static file finders are currently considered a private interface, and this interface is thus undocumented.
							ㄴ finder 목록
								ㄴ django.contrib.staticfiles.finders.DefaultStorageFinder
									ㄴ 'STORAGES' 설정값의 'default' 키값에 정의된 위치에서 파일을 찾는다.
								ㄴ AppDirectoriesFinder

					ㄴ django 프로젝트에서 사용되는 static file들의 위치를 설정
					ㄴ ~~~
					ㄴ production 환경에서
						ㄴ 동일 서버 안에 장고와 static file을 지원하는 웹서버가 같이 있는 경우
							ㄴ 일반적으로 보안상의 이유로 웹서버가 직접 장고의 루트폴더에 접근 가능하게 하지 않는다함.
								장고에서 사용하는 static file들을 웹서버가 문제없이 접근가능한 위치에 세팅한 뒤 여기서 static file을
								접근하도록 설정하는게 일반적이라함.
							ㄴ ~~~
							ㄴ python manage.py collectstatic 명령어 실행
								ㄴ STATICFILES_DIRS 리스트에서 static file들을 규칙에 따라 추려내어
									STATIC_ROOT 위치에 복사.
								ㄴ 장고 앱 실행 전에 실행하여 static file들을 깔끔하게 정리하는데 사용.
								ㄴ 규칙
									ㄴ ~~~
									ㄴ STATIC_ROOT에 해당 파일 없으면 복사.
									ㄴ STATIC_ROOT에 동일파일 존재시, 파일의 업데이트 일자를 비교하여 STATIC_ROOT에 있는 파일이 더 이전값이면
										덮어씌움.
									ㄴ ~~~
							ㄴ 위와 같이 STATIC_ROOT에 static file들을 복사한 뒤, webserver를 적절히 설정하여
								django의 STATIC_URL 로 들어오는 요청을 STATIC_ROOT에서 자원을 찾도록 세팅하면됨.
						ㄴ whitenoise 이용 

				</pre>

				ㄴ MEDIA 파일
					ㄴ django는

				ㄴ 설정 <button>more</button>
				<pre>
					ㄴ ~~~
					ㄴ DATABASES 설정
						ㄴ ex )
							DATABASES = {
								'default': {
									'ENGINE': 'django.db.backends.postgresql',
									'NAME': 'openmetric',
									'USER': 'openmetric',
									'PASSWORD': ')!metricAdmin01',
									'HOST': '112.220.72.179',
									'PORT': '2345', 

									# django의 'USE_TZ'=True일시, db로부터 datetime패치해올 때, UTC 대신 이 timezone인 aware datetime으로 
									# 패치해옴. 'USE_TZ'=False일때 이 설정 설정시, 에러뜬다함. 
									# timezone이 pytz.DstTzInfo 를 사용하는 듯하한데, pytz에서 일반적으로 생각하는 시간단위 offset이 아닌 
									# 더 세밀한 offset 사용하는 듯하다. ex ) +0900이 아닌 +0825 등. 
									# 또한, db의 datetime값을 여기서 설정한 timezone으로 계산하여 반환하는게 아닌, 그냥 timezone만 변경해서 
									# 반환하는 듯함. db에 +0900으로 되어있고 timezone을 'Asia/Taipei' 등으로 설정해도 아무 계산없이 
									# timezone만 붙어 반환됨. 
									# 또한  db상에서 naive인 datetime값은 timezone안붙이고 그냥 naive형태로 반환. 
									'TIME_ZONE': "Asia/Seoul", 

									# request 단위로 트랜잭션을 묶을지 여부. True설정시 당연히 view에 @transaction.atomic() 설정 필요 없다.
									"ATOMIC_REQUESTS": True,
								}
							}
						ㄴ 
					ㄴ timezone )
						ㄴ ~~~
						ㄴ USE_TZ 
							ㄴ django상에서 timezone 기능을 사용할지 여부. 
							ㄴ True일시, 장고 내부적으로 여러곳에서 naive datetime 대신 timezone aware datetime을 사용. 
								ㄴ template상에ㅓ naive datetime 렌더링할때 aware datetime으로 변환하거나 
									db에 naive datetime insert하려하면 aware datetime으로 벼노한하거나 등. 
								ㄴ 하여, datetime.now() 대신 django.utils.timezone.now()를 사용하여 
									aware datetime인 현재시간을 사용하는것이 좋음. 
									ㄴ aware datetime, native datetime간 비교 연산 등이 불가하고 
									ㄴ ??? DST 관련 이슈 때문에? 
							ㄴ??? db model로부터 데이터를 패치해올 땐, datetime을 디폴트 timezone으로 자동으로 안바꿔줌? 
								ㄴ django 3.2, postgresql 13 사용시, 
									django TIME_ZONE이 서울이고, postgresql상에 timestamptz & 서울타임존으로 데이터 있어도 
									model instance로 받아보면 UTC datetime으로만 나옴. 
								ㄴ django DATABASES 설정 중, TIME_ZONE 이용하면 특정 타임존으로 패치해옴. 
					ㄴ Session
						ㄴ ~~~
						ㄴ SessionMiddleware ~~~
						ㄴ 설정값들 )
							ㄴ SESSION_SAVE_EVERY_REQUEST
								ㄴ ??? 매 요청마다 session값을 업데이트
								ㄴ 업데이트하며, expire time을 SESSION_COOKIE_AGE에 맞게 업데이트함.
							ㄴ SESSION_COOKIE_AGE
								ㄴ 세션 지속 시간 설정. 세션을 설정한 값 시간동안 유지시킴. 초단위 정수. 디폴트 2주.
							ㄴ SESSION_COOKIE_NAME
								ㄴ 브라우저 쿠키에 세션키값이 저장될 때, 쿠키 키값 설정.
								ㄴ 디폴트 'sessionid'
								ㄴ 브라우저에서 도메인별로 쿠키값 목록을 구분하여 저장하기 때문에 일반적으론 쓸일 없으나,
									도메인이 같고 포트만 다른데 다른 장고 플젝인 경우 등에는 쿠키값을 구분하는데 사용할 수 있다.
									(브라우저는 도메인에 따라서만 쿠키값을 나누고 포트는 고려하지 않으므로?)

				</pre>

				ㄴ File handling
					ㄴ ~~~
					ㄴ request로 파일 받을시, request.FILES 속성에 파일 저장.
						dict 형태이며, key는 ???, 값에 파일이 저장.
					ㄴ request로 파일 받으려면, request method가 'POST' 필수.
						form 태그에 'enctype' 속성이 'multipart/form-data' 필수.
						아닐 경우, request.FILES 값은 빈 dict.

				ㄴ Serializing 
					ㄴ 

				ㄴ django test
					ㄴ ~~~
				
				ㄴ Asynchronous support
					ㄴ ??? view를 async로 만들어서 사용하는 방법. 
					ㄴ ??? ASGI 위에서 동작. WSGI 위에서 동작시, 성능이슈 및 오래 실행되는 요청에 대한 효율 이슈 존재. 
					ㄴ ~~~ 
					ㄴ 참고 
						ㄴ https://docs.djangoproject.com/en/3.2/topics/async/
				
				ㄴ django Cache framework <button>more</button>
				<pre>
					ㄴ 장고에서 제공하는 캐시 관련 시스템. 
						캐싱에 사용할 저장소를 선정하고 이와 상호작용 할 수 있는 인터페이스, 여러 세분화된 설정 등 제공.  
					ㄴ django CACHES 설정 <button>more</button>
					<pre>
						ㄴ settings.py 등에 'CACHES'란 이름으로ㄴㄴ 설정. 
						ㄴ 디폴트 
							ㄴ ??? local memory 캐시가 설정되어있음. ? 설정 없어도 기본적으로 사용할 수 있는건가? 
							ㄴ ex ) 
								{
									"default": {  
										"BACKEND": "django.core.cache.backends.locmem.LocMemCache",
									}
								}
						ㄴ ex ) 
							{
								"default": {  # 캐시 alias. 'default'란 이름의 캐시 필수. 값으로 캐시 option들 설정.  
									"BACKEND": "django.core.cache.backends.locmem.LocMemCache",
									~~~ 옵션들. 
								}
							}
						ㄴ 캐시 옵션 
							ㄴ BACKEND 
								ㄴ 캐시 backend 설정. 
								ㄴ 가능한 buit-in 목록 
									ㄴ 'django.core.cache.backends.db.DatabaseCache' 
									ㄴ 'django.core.cache.backends.dummy.DummyCache' 
									ㄴ 'django.core.cache.backends.filebased.FileBasedCache' 
									ㄴ 'django.core.cache.backends.locmem.LocMemCache' 
									ㄴ 'django.core.cache.backends.memcached.PyMemcacheCache' 
									ㄴ 'django.core.cache.backends.memcached.PyLibMCCache' 
									ㄴ 'django.core.cache.backends.redis.RedisCache'
								ㄴ 그 외 backend 
									ㄴ backend class의 fully-qualified path를 명시하여 설정 가능. ex ) mypackage.backends.whatever.WhateverCache 
							ㄴ KEY_FUNCTION 
								ㄴ django cache framework에선, 유저가 입력한 캐시 키를 곧이곧대로 사용하지 않고 key_prefix, version과 조합하여 캐시 키를 생성. 
									가령, 키가 'noname'이고, prefix가 'test'이고 version이 '2'인 경우, 키가 'test:2:noname' 이런식으로 결정됨. 
									이때, prefix, version, key를 가지고 최종 캐시 키를 반환하는 함수를 이 설정값으로 명시가능.  
								ㄴ 디폴트로 사용되는 함수 로직 
									ㄴ 디폴트로 사용되는 함수가 있으며, 다음과 같이 구현되어 있다함. ':'를 기준으로 prefix, version, key를 concat하여 형성하는 방식. 
										def make_key(key, key_prefix, version):
											return ":".join([key_prefix, str(version), key])
							ㄴ KEY_PREFIX 
								ㄴ 캐시 키 앞에 추가되는 문자열인 'prefix' 설정. 
									해당 캐시를 통해 저장시 자동으로 추가됨. 
								ㄴ 하나의 캐시 인스턴스를 여러 서버 등에서 공유하는 경우, 같은 이름의 키를 구분해야 하는 경우 유용. 
								ㄴ ex ) 키가 'noname'이고, prefix가 'test'인 경우, 키가 'test:1:noname' 이런식으로 자동생성되어 저장됨. 
								ㄴ 디폴트 "" 빈문자열. 
							ㄴ LOCATION 
								ㄴ 캐시의 위치. 캐시 종류가 뭔지(database cache인지, 메모리캐시인지, filesystem캐시인지)에 따라 다름. 
								ㄴ ex ) 
							ㄴ OPTIONS 
								ㄴ cache backend에 넘겨질 추가적 파라미터들. 당연히 backend에 따라 다름. 
								ㄴ 주로 사용되는 설정값 
									ㄴ MAX_ENTRIES 
										ㄴ backend의 culling 전략에 쓰이는 설정값. 
										ㄴ 오래된 캐시 데이터가 제거되기 전까지 허용되는 최대 캐시 데이터 수. 
									ㄴ CULL_FREQUENCY 
										ㄴ??? MAX_ENTRIES에 도달했을 때, culling할 캐시 데이터의 비율 설정. 
											1 / CULL_FREQUENCY 만큼의 캐시데이터를 제거.  
										ㄴ 디폴트 3. 
										ㄴ 0일시, 모든 데이터 제거. 
							ㄴ TIMEOUT 
								ㄴ 캐시에 저장된 데이터가 '오래된 것으로 간주'되기까지 걸리는 시간. 대략 만료시간이라 생각하면 될듯. 
								ㄴ 초단위 
								ㄴ None설정시 만료 없음, 0 설정시 즉시만료. 
								ㄴ 디폴트 300 
							ㄴ VERSION 
								ㄴ 캐시 키의 디폴트 버전. 
									KEY_PREFIX와 비슷하게, django cache framework에선 캐시 키별로 version을 가지고 있어 이 버전값으로도 키가 구별됨. 
									'test:1:noname'과 'test:2:noname'이 구분되는식. 
									이 캐시 키 version의 디폴트 버전을 명시하는 설정. 
								ㄴ ex ) 키가 'noname'이고, prefix가 'test'이고 version이 2인 경우, 키가 'test:2:noname' 이런식으로 자동생성되어 저장됨. 
								ㄴ 디폴트 1. 
					</pre>
					ㄴ 가능한 저장소 <button>more</button>
					<pre>
						ㄴ Memcached 
							ㄴ 'Memcached'항목 참고 
							ㄴ Memcached를 파이선에서 사용할 수 있게 해주는 모듈 필요. 
								ㄴ django에선 'pylibmc', 'pymemcache'를 지원한다함. 
							ㄴ 설정 
								ㄴ django setting에서, 'CACHES' 하위의 'BACKEND'에 
									'django.core.cache.backends.memcached.PyMemcacheCache' 또는 
									'django.core.cache.backends.memcached.PyLibMCCache' 추가. 
								ㄴ 'LOCATION' 설정값에 Memcached 데몬이 listen하고 있는 ip:port 설정. 
									??? 소켓파일 사용시, unix:path 설정. 
								ㄴ ex ) 
									CACHES = {
										'default': {
											'BACKEND': 'django.core.cache.backends.memcached.PyMemcacheCache',
											# 3개의 엔드포인트에 대해 설정. memcached는 여러 머신에 걸쳐 캐싱데이터 저장 가능하므로. 
											'LOCATION': [
												'172.19.26.240:11211',
												'172.19.26.242:11212',
												'172.19.26.244:11213',
											]
										}
									}
								ㄴ memcache 사용시 디폴트로 넘어가는 OPTIONS 값. 
									"OPTIONS": {
										"allow_unicode_keys": True,
										"default_noreply": False,
										"serde": pymemcache.serde.pickle_serde,
									}
						ㄴ Redis 
							ㄴ redis를 파이선에서 사용하게 해주는 모듈 필요. 
								ㄴ django에서 권장하는건 redis-py, hiredis-py . 
							ㄴ 설정 
								ㄴ BACKEND 
									ㄴ django.core.cache.backends.redis.RedisCache 추가 
								ㄴ LOCATION 
									ㄴ Redis instance를 가리키는 URL 설정. 
								ㄴ ex ) 
									CACHES = {
										"default": {
											"BACKEND": "django.core.cache.backends.redis.RedisCache",
											"LOCATION": "redis://username:password@127.0.0.1:6379",
										}
									}
								ㄴ ???redis replication mode로 여러개의 redis server instance를 실행중인 경우, 
									LOCATION에 배열로 여러 URL설정 가능. 
									첫번째 서버가 'leader' server가 되고 write작업이 전달되고, 
									그 아래 서버들이 'replicas' server가 되고 read 작업이 전달됨. 
						ㄴ database 
							ㄴ 데이터베이스도 캐싱 저장소로 사용 가능. 
							ㄴ ~~~
						ㄴ Filesystem 
							ㄴ ~~~ 
						ㄴ local memory 
							ㄴ 디폴트 캐시. Memcached 등의 다른 대안이 없을 때 사ㅛㅇㅇ. 
							ㄴ 프로세스별 할당. 
								ㄴ 즉 같은 데이터여도 프로세스 다르면 각각 저장하고 있어야 하며 
									이는 메모리 효율적이지 않음. 
							ㄴ thread-safe 
							ㄴ 설정 
								ㄴ CACHES 설정에서 BACKEND를 'django.core.cache.backends.locmem.LocMemCache'로 설정.
								ㄴ LOCATION에 캐시 저장소를 유일하게 식별할 문자열. 
								ㄴ ex ) 
									CACHES = {
										'default': {
											'BACKEND': 'django.core.cache.backends.locmem.LocMemCache',
											'LOCATION': 'unique-snowflake',
										}
									}
							ㄴ LRU 전략 사용. 
								ㄴ 가장 오래 사용 안된 데이터부터 제거하는 방식. 
						ㄴ ??? dummy cache 
							ㄴ ??? 실제 캐싱기능을 수행하지 않으면서 인터페이스만 존재하는 backend? 
							ㄴ ??? This is useful if you have a production site that uses heavy-duty caching in various places but a development/test environment where you don’t want to cache and don’t want to have to change your code to special-case the latter. 
							ㄴ BACKEND에 'django.core.cache.backends.dummy.DummyCache' 설정. 
						ㄴ 커스텀 cache backend 
							ㄴ 커스텀 backend class의 fully-qualified path를 명시하여 설정 가능. 
					</pre>
					ㄴ 사용법 
						ㄴ request별 캐싱 <button>more</button>
						<pre> 
							ㄴ 사이트 전체에 대해 request별로 response가 캐싱됨. 
							ㄴ django.middleware.cache.UpdateCacheMiddleware, django.middleware.cache.FetchFromCacheMiddleware 설정. 
								ㄴ 각각 middleware의 가장 첫번째와 가장 마지막에 위치해야함. 
									미들웨어들이 request, response의 header를 기반으로 동작해서 response를 캐시에 저장할 때 가장 마지막에, 
									request를 보고 이에 맞는 캐시된 데이터를 가져오기 위해 request단계 가장 마지막에 수행되어야한다함. 
									다른 미들웨어들이 header를 모두 수정하고 난 다음에. 
							ㄴ settings.py에 다음 설정 추가 
								ㄴ CACHE_MIDDLEWARE_ALIAS 
									ㄴ ??? per-site 캐싱에 사용될 캐시alias를 지정? 
								ㄴ CACHE_MIDDLEWARE_SECONDS
									ㄴ ??? CACHES 설정의 'TIMEOUT'과 뭐가 다른지? 어떤거 우선적용하는지? 
								ㄴ CACHE_MIDDLEWARE_KEY_PREFIX 
								
							ㄴ FetchFromCacheMiddleware 
								ㄴ ???FetchFromCacheMiddleware caches GET and HEAD responses with status 200, where the request and response headers allow. 
								ㄴ request 단계에서 사용되는 미들웨어로, request에 대해 캐싱된 데이터가 있으면 캐시된 response를 반환. 
								ㄴ 동일한 url이면서 파라미터가 다른 경우도 별도의 키로 캐싱. 
								ㄴ ??? This middleware expects that a HEAD request is answered with the same response headers as the corresponding GET request; in which case it can return a cached GET response for HEAD request.
							ㄴ UpdateCacheMiddleware 
								ㄴ response 단계에서 사용되는 미들웨어로, response를 캐시에 저장. 
							ㄴ view에 대해 expire time이 설정되어 있으면, 이게 우선시됨. CACHE_MIDDLEWARE_SECONDS는 후순위. 
						</pre>
						ㄴ view 별 캐싱 <button>more</button>
						<pre>
							ㄴ django.views.decorators.cache.cache_page decorator를 이용하여 view에서 반환한 reponse를 캐시에 저장 및 캐시로부터 response를 반환.  
							ㄴ django.views.decorators.cache.cache_page(timeout, *, cache=None, key_prefix=None)
								ㄴ 매개변수 
									ㄴ timeout 
										ㄴ 캐시 timeout. 초단위 정수. 
										ㄴ Cache-Control 헤더의 max-age 지시자보다 우선순위를 가짐. 
									ㄴ cache 
										ㄴ view 캐싱에 사용할 cache alias. 
										ㄴ 디폴트는 'default'
									ㄴ key_prefex 
										ㄴ??? 'CACHE_MIDDLEWARE_KEY_PREFIX'와 같은 효과. 
								ㄴ url별로 캐싱됨. 
									ㄴ 여러 url이 하나의 view와 연결되어도, 각 url별로 캐싱됨. 
								ㄴ ex ) 
									@cache_page(60 * 15) # 15분 캐싱. 
									def my_view(request):
										~~~
										return response
								ㄴ url에 붙이기 
									ㄴ view function에 데코레이터로 붙이는것 말고도 url의 path에 이 데코레이터를 붙여서 사용도 가능. 
									ㄴ ex ) 
										from django.views.decorators.cache import cache_page

										path("~~~", cache_page(60 * 15)(my_view), name="my_view"),  # view function위에 데코레이터를 붙인것과 같은 효과. 
									ㄴ 장점 
										ㄴ 코드상, view function와 캐싱 설정을 분리. 
						</pre>
						ㄴ template fragment 캐싱 <button>more</button>	
						<pre>
							ㄴ template의 일부를 캐싱하는 기능. {% cache %} template tag로 감싼 부분을 캐싱함.
							ㄴ 사용법 
								ㄴ template 상위에 {% load cache %} 추가. 
								ㄴ 캐싱하기를 원하는 부분을 {% cache %} tag로 감싸기.
								ㄴ 태그의 positional 인자 
									ㄴ timeout 
										ㄴ 캐시 timeout. None일시 무한 저장.  
										ㄴ template 변수로 넘기기 가능. 
									ㄴ 이름 
									ㄴ 그 외 추가 인자 
										ㄴ fragement를 구분해서 저장하기 위해 쓰임. 
											인자의 값별로 fragement가 구분되어 저장 및 불러와짐. 
									ㄴ 마지막 'using' 키워드 인자 
										ㄴ ???캐싱에 사용할 캐시 alias.
										ㄴ 마지막에 와야함. 
										ㄴ ??? 디폴트 'template_fragments'
								ㄴ ex ) 
									{% load cache %}
									~~~
									< h1>{{ current_time }}< /h1>
									# 추가인자로 request.user.username을 넘겼고, 이 값별로 fragment가 구분되어 캐싱됨. 
									# username 'aaa'인 경우 캐시 데이터 하나, 'bbb'인 경우 따로 캐시 데이터 하나 이런식. 
									{% cache 10 noname request.user.username %}  
										< h1>{{ current_time }} < /h1>
									{% endcache %}
								ㄴ 감싸진 부분이 캐싱되어 다음번 template형성시 이 부분은 렌더링하지 않고 캐시에 저장된 데이터를 가져와 사용. 
								ㄴ ??? view단에서의 context 계산은 동일하게 수행. template 렌더링 단계에서 캐시를 사용하는 것. 
									cache block내부에 context의 변수가 있어도 상관없이 그냥 캐싱된 데이터 사용. 
									위 예같은 경우, 첫번째h1에선 항상 현재시간이 렌더링되는 반면, 두번째 h1에선 캐싱된 예전 시간이 출력됨. 
						</pre>
						ㄴ low-level cache API <button>more</button>
						<pre>
							ㄴ 전체 페이지단위, view단위가 아닌 더 섬세한 캐싱이 필요한 경우 사용 가능. 
								cache API를 통해 직접 pickable한 객체를 캐시에 저장 및 로드 가능. 
							ㄴ 캐시 가져오기  
								ㄴ django.core.cache.caches 를 통해 접근. 
									ㄴ dict-like 객체로, 키로 cache alias, 값으로 cache backend를 반환.
								ㄴ django.core.cache.cache 
									ㄴ default cache에 대한 shortcut. 즉, django.core.cache.caches["default"] 와 동일. 
							ㄴ cache.set(key, value, timeout=DEFAULT_TIMEOUT, version=None)
								ㄴ key는 str, value는 pickable한 객체여야함. 
								ㄴ timeout의 디폴트값은 settings.py의 CACHES의 BACKEND에 설정된 timeout값. 
							ㄴ cache.get(key, default=None, version=None)
								ㄴ default는 해당 키의 값이 없을 때 반환할 값.
									ㄴ이를 이용해, 특정 키에 None을 저장한 경우, 키의 값이 None인지, 값이 없는건지 구분 가능. 
										ㄴ default객체가 반환되면 값이 없는 것, None이 반환되면 명시적으로 None값이 들어가 있는 것. 
							ㄴ cache.add(key, value, timeout=DEFAULT_TIMEOUT, version=None) 
								ㄴ cache.set()과 동일한 인자, 동일한 동작, but 해당 키의 데이터가 이미 있으면 덮어씌우지 않음. 없는 경우에만 새로 추가. 
							ㄴ cache.get_or_set(key, default, timeout=DEFAULT_TIMEOUT, version=None) 
								ㄴ get()을 하고 없는 경우, default인자의 값으로 set()수행. 
								ㄴ default 인자에 callable 가능. 
							ㄴ cache.get_many(keys, version=None) 
								ㄴ 여러 키들을 한번에 가져옴. 키, 값 쌍의 dict형태로 반환.
								ㄴ cache를 한번한 hit
								ㄴ 만료되지 않으면서 존재하는 키들만 반환. 
							ㄴ cache.set_many(dict, timeout) 
								ㄴ 여러 키들을 한번에 set. 키, 값 쌍의 dict를 넘기면 그대로 캐시에 set. 
							ㄴ cache.delete(key, version=None) 
								ㄴ 키값 삭제. 
							ㄴ cache.delete_many(keys, version=None)
								ㄴ 여러 키값 한번에 삭제. 
							ㄴ cache.clear() 
								ㄴ 캐시의 모든 키 삭제. 
							ㄴ cache.touch(key, timeout=DEFAULT_TIMEOUT, version=None)
								ㄴ 키값의 만료시간 업데이트. 지금으로부터 timeout 만큼 후의 시간으로 만료시간 재설정. 
							ㄴ cache.close() 
								ㄴ cache와의 연결 끊는 메소드.  cache backend에 따라 구현되었으면 사용 가능. 
						</pre>
					ㄴ ??? downstream cache 관련 기능 
						ㄴ view에 django.views.decorators.vary.vary_on_headers() decorator를 통해 response의 Vary 헤더의 값 추가 가능. 
							ㄴ ex ) 
								# response의 Vary 헤더에 'User-Agent', 'Accept-Encoding'가 추가됨.
								@vary_on_headers("User-Agent", "Accept-Encoding")
								def my_view(request):
									~~~
							ㄴ 이를 통해 downstream cache들의 동작을 제어 가능? 
								ㄴ django cache framework의 request별 캐싱, view별 캐싱에서 이를 반영하여 별도 캐싱. 
									즉, Vary에 'User-Agent'가 있으면, User-Agent의 값이 다르면 별도로 캐싱해놓음. 
						ㄴ django.views.decorators.views.cache.cache_control decorator를 통해 Cache-Control header 설정. 
							ㄴ 이 데코레이터를 이용해 response header에 캐시관련 설정을 하는 'Cache-Control' 헤더를 추가 가능. 
							ㄴ 가능한 인자는 Cache-Control에서 가능한 지시자 및 django문서 참고. 
								ㄴ 몇가지 
									ㄴ private 
									ㄴ public 
									ㄴ max_age
							ㄴ ex ) 
								@cache_control(private=True, max_age=60 * 15)
								def my_view(request):
									~~~ 
							ㄴ ??? 구현 코드를 봐도 그냥 헤더 추가만 함. 걍 헤더만 추가하고 다운스트림단에서 알아서 캐싱에 참조하라는식으로 동작하는 것? 
								django cache framework 관련해선 뭐가 다르단건지? 
							ㄴ ???django cache framework의 request별 캐싱, view별 캐싱에서 자동으로 설정하는 헤더값과 겹치는 것들 있어 확인 필요? 
					ㄴ 캐시 키 경고 
						ㄴ memcached를 사용하는는 경우, 키로 쓰이는 문자열에 대한 제약 존재하고 (250자 이하여야하고, 공백안되고 등) 위반시 오류 발생. 
							코드가 cache-porable하는데 도움을 주기 위해, memcached를 사용하지 않더라도 캐시 키가 memcached의 이런 제약을 위반하면 경고를 띄운다함. 
							뜨는 경고는 django.core.cache.CacheKeyWarning 
					ㄴ 비동기 지원 
						ㄴ django 4.2기준, 아직 미지원. 
				</pre>
				ㄴ 보안 <button>more</button>
				<pre>
					ㄴ ~~~ 
					ㄴ 유저 업로드 파일 관련 
						ㄴ ??? 프레임워크 레벨에서 유저 업로드 파일에 대한 보안 장치는 없다? 
					ㄴ clickjacking 
						ㄴ django에서 clickjacking 방지 기능 제공. 
						ㄴ 방법 
							ㄴ 'django.middleware.clickjacking.XFrameOptionsMiddleware' middleware 
								ㄴ django middleware 추가하여 response에 X-Frame-Options 헤더 추가 가능. 
								ㄴ 디폴트로 헤더값 'DENY' 
								ㄴ django settings.py에 'X_FRAME_OPTIONS' 값으로 헤더값 설정 가능. 
							ㄴ django.views.decorators.clickjacking 데코레이터들 이용 
								ㄴ decorator들을 view에 추가하여 X-Frame-Options 관련 설정 가능. 
								ㄴ xframe_options_exempt decorator 
									ㄴ 해당 view만 X-Frame-Options 설정 제거. 
								ㄴ xframe_options_deny, xframe_options_sameorigin 
									ㄴ 해당 view에 X-Frame-Options 설정. 각각 헤더값을 'DENY', 'SAMEORIGIN'으로 설정. 
									ㄴ 미들웨어도 설정되어 있으면 데코레이터 우선. 
						ㄴ 한계 
							ㄴ 헤더값만 설정할뿐, 실제 방지는 브라우저에서 하는것이므로 당연히 브라우저에 따라 안될수도. 
				</pre>
				ㄴ DJANGO 버전업 <button>more</button>
				<pre>
					ㄴ 필요성 
						ㄴ 새 기능 및 기존 기능 개선
						ㄴ 버그 픽스 
						ㄴ 보안 업데이트 
						ㄴ 안하면 한번할때 점점 버전업 비용 커짐. 
					ㄴ 현재 버전 이후, 업그레이드할 버전까지의 각 final release들의 'release note' 확인. 
					ㄴ deprecation될 기능들 확인. 
					ㄴ 'feature version'을 여러 버전을 건너뛰어 업그레이드하는 경우, 한번에 건너뛰기보단 하나씩 업그레이드하는게 수월하다함. 
					ㄴ 관련 의존성 이슈 
						ㄴ??? 프로그램에서 사용하는 의존성이, 새 장고 버전을 아직 지원하지 않는 경우, 기다려야 한다? 
					ㄴ deprecation warning 처리 
						ㄴ 업그레이드 하기 전, 현재 버전에서 deprecation warning들을 미리 처리하면 수월. 
						ㄴ 파이선에서 warning은 디폴트로 꺼져있어 활성화 필요. 
							ㄴ python -Wa manager.py ~~~ 
					ㄴ django 새 버전 설치 
						ㄴ??? 가상환경을 사용중이고, major 업그레이드를 하는 경우, 새 가상환경을 세팅하는게 좋다함. 
					ㄴ test suit 실행 및 수정. 
					ㄴ 배포 
						ㄴ 테스트 완료되면 배포. 
						ㄴ 배포 전, django cache를 사용중이면, 한번 clear하는것 권장한다함. 
							이미 캐싱된 데이터와 새 장고 버전의 데이터가 호환될지 미지수이므로. 
				</pre>
				ㄴ 실무 팁
					ㄴ service layer? manager?, model instance method? repository? 
						ㄴ 한 모델 인스턴스 내에서의 로직은 model instance method사용하는게 맞는듯하고
						ㄴ 여러의 모델이 관여된 쿼리는 리포지토리? 
						ㄴ 하나의 모델 관련 쿼리는 manager에서? 
						ㄴ 하나의 모델 관련 로직은 service layer? manager? 
						ㄴ 쿼리용 메소드는 java repository처럼 필요한 사용 케이스별로 각각 만들도록. 
							범용으로 사용한다고 모든 인자 다 넣고 쿼리하는 메소드 만드지 말고. 
							ㄴ 일단 공통적으로 사용되는 쿼리를 사용처마다 model query하지 않고, 메소드 하나로 묶는다는 점에서 관리에 용이해지지만 
								너무 범용적으로 만들면 불필요? 

				ㄴ Django styleGuide 
					ㄴ 개요 
						ㄴ https://github.com/HackSoftware/Django-Styleguide?tab=readme-ov-fileㄴ
						ㄴ 그냥 django를 어떤 스타일로 개발해야할지에 대해 몇사람들이 제안하는 방식에 대한 문서. 
						ㄴ 제안일 뿐, 케이스에 맞게 적절히 선택적으로 취해도 된다함. 
					ㄴ 주요 내용 
						ㄴ django에서 비즈니스 로직은 
							'Service', 'Selector', Model property, Model 'clean' method 안에 위치해야함. 
						ㄴ django에서 비즈니스 로직은 
							APIs, View, Serializer, Forms, Form tag, Model 'save' method, Custom manager, queryset, Signal에 위치해서는 안됨. 
							ㄴ APIs, View, Serializer, Forms에 두면 안되는 이유 
								ㄴ 비즈니스 로직을 여러 곳으로 파편화하여 로직 파악 어렵. 
								ㄴ ??? 로직이 추상화되어 가려짐. 뭘 하는지 잘 파악되지 않아 내부를 일일이 확인해야함. 
								ㄴ ??? 단순한 CRUD 에 잇어서는 유요할 수 있으나, 
									이렇게까지 단순한 CRUD는 실무에서 매우 드물고, 이런 형태로 사용시, 이런 단순한 CURD를 벗어나게 되면 많이 지저분해진다함. 
							ㄴ custom manager, queryset에 두면 안되는 이유
								ㄴ 아예 안되는건 아님. 모든 로직을 여기에 두는게 적절치 않다는 것.
								ㄴ 러직이 하나의 모델과 먀핑되ㅈ 않는 경우 어느 모델의 매니저나 쿼리셋에 위치할지 쉽게 파악하기 힘듦. 헷갈림. 
									모델이 특정 모델에 대한 것이 아니라 도메인에 댜한 것인 등
								ㄴ 모델과 관계없는 서드파티를 사용하는 경유 위치시키기 야매하다.
								ㄴ 이런 경유거 어니라면 커스텀매니저나 쿠ㅏ리셋에 로직울 적절히 위치시키는건 매우 유용.
							ㄴ signal에 위치시키면 안되는 이유
								ㄴ ??? !!! signal 먼저 학습 필요. 
						ㄴ Model 
							ㄴ 모델에 대한것은 책임져야 하나, 그 외의 범위로 벗어나면 책임지는게 적절치 않다? 
						ㄴ ??? model 유효성 검증?
							ㄴ 유효성 검증이 한 모델 인스턴스내의 관계형이 아닌 필드들로만 가능하거나 매우 단순한 경우, 
								유효성 검증 로직은 model의 'clean' 메소드 안에 있는게 좋다. 
							ㄴ 유효성 검증 로직이 복잡하거나, 여러 테이블에 걸쳐있거나 데이터를 fetching해오는게 필요하다면, 
								service 로 빼는게 좋다. 
							ㄴ 모델의 clean method, service 계층 둘 다 가능하면 왠만하면 서비스 계층 권장한다함. 
							ㄴ Django 'constraint'를 사용하여 어플단이 아닌 db단에서의 제약조건으로 유효성을 검증할 수도 있다. 
								ㄴ 이런 경우, db단에서 발생한 에러가 throw됨. 
									django단에서 유효성 검증 에러를 의미하는 ValidationError가 아닌 IntegrityError 같은게 뜨기 때문에 
									이를 추가적으로 처리해주어야함. 
								ㄴ django 4.1부터는 full_clean()에서 db의 제약조건도 체크하여 실패시 ValidationError를 던진다고함. 
									하여 위의 단점은 없어짐. 
						ㄴ Property 
							ㄴ 관계형이 아닌 필드들로부터 단순하게 도출이 가능하거나, 도출로직이 매우 단순하면 model의 property로 정의.
							ㄴ 도출이 여러 테이블에 걸쳐져야 가능하거나 추가적인 데이터를 패치해와야 하거나 도출로직이 복잡하다면 서비스 계층으로 빼냄. 
						ㄴ 메소드
							ㄴ 관계형 필드가 아닌 필드와 인자값으로 계산이 가능하거나, 매우 단순하거나, 한 필드값의 수정이 다른 필드값의 수정을 반드시 수반해야 한다면 
								모델 메소드 안에 의치시킨다.
							ㄴ 관계형 필드를 필요로 하거나 여러 테이블에 걸쳐 계산이 진향되거나 추가적인 데이터를 패치해와야 하거나 계산이 복잡하다면 서비스 계층으로 뺀다.
						ㄴ 서베스 계층
							ㄴ view와 db 사이에 위치
							ㄴ 함수, 클래스, 모듈 등 무엇이든 서비스가 될 수 있다.
							ㄴ 일반적으로 [service.py](http://service.py) 내에 엤는 함수들이며, 이 안에서 비즈니스 로직들 수향. db에 얀결하고 모델 생성 등 뭐든.
							ㄴ 클랴스 형태로 만들어 사용도 가능.
						ㄴ 소비스 계층의 네이밍 컨벤션
							ㄴ 알아서 하면되지만 가이드에선 ‘(*엔터티명*)_(*액션명*)’ 형식의ㅜ메소드명을 선호한다함.
								ㄴ (*엔터티*) 부분이 같은 것들끼리 묶어놓기 편하고 검색도 편한 이점이 있다함.
						ㄴ 서비스 계층 모듈로 분리
							ㄴ 간단한 얍인 경우 하나의 service.py에 모든 로직이 들어갈테지만 좀 큰 경유 로직을 분리하는게 좋을 수도 있다. 
								services란 모듈을 두고 그 하위에 ~~~.py 같은식으로 관련잇는 로직끼리 묶어듀는식.
						ㄴ Selector
							ㄴ 서비스계층이 데이터 업데이트릉 맡는다면 selector는 데이터 패치를 맡음. 
								서비스 계층의 일부라고 할수도 있음. 그냥 selectir 따로 듀는것없이 데이터 퍄치도 서비스 계층 언에 둘 수조 있음.
							ㄴ 리포지토리 같다?
						ㄴ test
						ㄴ api, serializer
							ㄴ api는 view를 말함. 
							ㄴ ??? !!! Serializer 공부 선행 필요. 
							ㄴ api naming convention 
								ㄴ (*엔터티*)(*액션명*) 형식 추천한다함. 
								ㄴ ex ) UserCreateApi
							ㄴ class based api vs function based api 
								ㄴ ??? !!! 관련 내용 학습 선행 필요. 
								ㄴ 딱히 큰 차이는 없다함. 
							ㄴ filter & pagination 
								ㄴ ??? !!! 관련 내용 학습 선행 필요. 
						ㄴ ??? !!! 하위 내용들도 django, DRF에 대한 선행 학습 필요. 

				ㄴ 관련 모듈 <button>more</button>
				<pre> 
					ㄴ DRF, Django Rest Framework<button>more</button>
					<pre>
						ㄴ ~~~
						ㄴ exception handler )
						ㄴ Throttling <button>more</button>
						<pre>
							ㄴ 서비스 정책상, 요청 빈도, 요청 횟수를 제한하려는 경우, 이런 제한 기능을 제공함. 
							ㄴ application level에서의 동작이고, 보안적인 목적으로 사용되기에는 부적절. 
							ㄴ ??? class list 형태로 정의? 
							ㄴ ??? view의 body가 실행되기 전에 list내의 throttle들이 체크되는 방식? 
								하나라도 실패시 exceptions.Throttled 예외 발생? & view의 body 실행 안됨? 
							ㄴ settings.py에서 글로벌하게 또는 class view별로 또는 함수형 view별로 설정 가능. 
								ㄴ settings.py에서 글로벌 설정 
									ㄴ REST_FRAMEWORK.DEFAULT_THROTTLE_CLASSES 를 통해 설정 가능. 
									ㄴ ex ) 
										REST_FRAMEWORK = {
											'DEFAULT_THROTTLE_CLASSES': [
												'rest_framework.throttling.AnonRateThrottle',
												'rest_framework.throttling.UserRateThrottle'
											], 
										}
									ㄴ 장고 플젝 전체 요청에 대해 적용됨. 
										즉, 어떤 endpoint에 대한 요청이건, 하루 100건 이런식. 
								ㄴ class view 
									ㄴ view class의 클래스변수로 'throttle_classes'에 list형태로 정의. 
										list 안의 throttle class들이 적용됨. 
									ㄴ ex ) 
										class NoNameView(APIView): 
											throttle_classes = [UserRateThrottle, AnonRateThrottle] 
											~~~
								ㄴ 함수형 view 
									ㄴ @api_view 가 있는 함수형view에 '@throttle_classes' decorator 추가.
										list 안의 throttle class들이 적용됨. 
									ㄴ ex ) 
										@api_view(['GET'])
										@throttle_classes([UserRateThrottle, AnonRateThrottle])
										def no_name_view(request): 
											~~~
							ㄴ rate 판단 방식 
								ㄴ 내부 구현이, cache key 기준으로 req cnt값을 가져와 초과 여부를 판단함. 
								ㄴ AnonRateThrottle은 class의 'scope'값과 req header값의 조합으로 cache key 결정. 
								ㄴ UserRateThrottle은 class의 'scope'값과 user id값의 조합으로 cache key 결정. 
								ㄴ 이 캐시 키로 값 가져와서 초과 여부 판단. 
									따라서, throttle class가 달라도 키가 같으면 req cnt값이 공유됨. 
								ㄴ 기본 클래스인 AnonRateThrottle, UserRateThrottle의 scope값은 각각 'anon', 'user'. 
								ㄴ 이 기본 클래스를 상속하여 custom throttle 클래스를 만들어도 scope따로 지정하지 않으면 당연히 기본 클래스와 동일. 
									ㄴ 하여, 커스텀 클래스를 만들어도 scope설정 않으면 기본클래스와 req cnt값을 공유. 
								ㄴ 당연히 서로 다른 커스텀 클래스더라도 scope값 같으면 req cnt값 공유. 
								ㄴ 서로 다른 여러 view들에 적용했어도 클래스 scope 같다면 req cnt값 공유.  
 
							ㄴ rate 설정 
								ㄴ AnonRateThrottle, UserRateThrottle 이나 이들을 상속하는 커스텀 throttle 클래스들에 적용될 req rate 설정에 대한 내용. 
								ㄴ 방법 
									ㄴ throttle class의 'rate' 클래스변수값으로 설정. 
										ㄴ ex ) 
											from rest_framework.throttling import UserRateThrottle 

											class CustomThrottle(UserRateThrottle): 
												rate = "1/minute" 

											~~~

											@api_view(["GET"])
											@throttle_classes([CustomThrottle])
											def aaa(request): 
												~~~ 
											ㄴ 이렇게하면 aaa view에 대한 요청이 들오면 CustomThrottle로 throttle체크를 하게되고 
												CustomThrottle의 rate 속성이 '1/minute'이므로 요청이 분당 1회로 제한됨. 

									ㄴ settings.py의 REST_FRAMEWORK.DEFAULT_THROTTLE_RATES 에 값을 추가하여 설정. 
										ㄴ ex ) 
											class CustomThrottle(UserRateThrottle): 
												scope = "noname"

											REST_FRAMEWORK = {
												'DEFAULT_THROTTLE_RATES': {
													'anon': '1000/day',
													'user': '1000/day',
													"noname": '1000/day',
												}
											}
										ㄴ Throttle class에 'scope' 속성을 부여하고, 이값을 키값으로 하는 값을 DEFAULT_THROTTLE_RATES에 추가하여 
											그 scope값을 가지는 throttle class들의 rate값을 설정할 수 있다. 
											
									ㄴ 결정 방식 우선순위 
										ㄴ 첫번째 방식으로 우선 결정. 없으면 두번째 방법으로. 
							ㄴ 내부적으로 django cache framework를 사용. 
								ㄴ throttling사용하려면 적절한 django cache 설정 필요. 
							ㄴ ~~~ 

						</pre>

					</pre>

					ㄴ django-apscheduler <button>more</button>
					<pre>
						ㄴ https://pypi.org/project/django-apscheduler/
						ㄴ 개요 
							ㄴ python의 apscheduler 모듈을 기반으로 django에서 쉽게 사용할 수 있는 스케줄러 모듈. 
							ㄴ 내부적으로 apscheduelr 모듈을 그대로 사용하고, 
								apscheduler의 jobstore django migrate를 이용해 생성한 model db로 대체한게 주요 기능. 
						ㄴ 한계 
							ㄴ ??? 한 db에 대해 여러개의 django-apscheduler가 실행될 경우, 
								이들사이의 동기화 기능은 현재 없어 job관리 로직이 꼬임. 
								ㄴ 당연히, gunicorn 등으로 여러개의 worker process로 실행하는 것도 안됨.  
								ㄴ 공식문서에선, 별도의 django manage.py custom command를 생성하고 
									이를 따로 하나만 호출하는식으로 사용하라함. 
								ㄴ ex ) <button>more</button>
								<pre>
									from apscheduler.schedulers.blocking import BlockingScheduler
									from django.core.management.base import BaseCommand 
									from django_apscheduler.jobstores import DjangoJobExecution, DjangoJobStore

									class Command(BaseCommand):  
										def handle(self, *args, **options):    
											scheduler = BlockingScheduler(timezone=settings.TIME_ZONE)
											scheduler.add_jobstore(DjangoJobStore(), "default")

											# scheduler.add_job(
											#     tasks.test_func, #실행할 임의 callable. 
											#     trigger=CronTrigger(second="*/10"), 
											#     id="test_func",
											#     max_instances=1,
											#     replace_existing=True,
											# )  

											try:
												scheduler.start()

											except Exception as e: 
												logger.error(traceback.format_exc()) 
												scheduler.shutdown()
								</pre>
					</pre>

					ㄴ WhiteNoise <button>more</button>
					<pre> 
						ㄴ 개요 
							ㄴ 파이선 코드상으로 웹서버가 static file을 서빙할 수 있게 해주는 모듈. 
								이를 통해 nginx, Amazon S3등의 별도 컴포넌트가 필요치 않음. 
							ㄴ ??? CDN과도 잘 동작한다? 
							ㄴ 파일을 압축하여 캐싱해놓는 기능 제공. 
								ㄴ 내부적으로 django cache framework를 사용하는듯? 
						ㄴ 기본 사용법 
							ㄴ pip install whitenoise
							ㄴ 미들웨어 추가 
								ㄴ "whitenoise.middleware.WhiteNoiseMiddleware" 
								ㄴ django SecurityMiddleware 아래, 다른 미들웨어보다 위에 위치시켜야함. 
							ㄴ ~~~
						ㄴ nginx 등의 웹서버 vs whitenoise 
							ㄴ 웹서버로 static file을 서빙하려면 필요한 여러 자잘한 설정등을 알아서 처리해준다는 장점이 있다함. 
					</pre>

				</pre>

				ㄴ 무제 <button>more</button>
				<pre>
					ㅡ 장고 db 테이블 생성
						ㄴ 장고 설치
							ㄴ pip install Django
							ㄴ pip3 install djangorestframework
							ㄴ pip install psycopg2
						ㄴ 프로젝트 폴더 안의 setting.py
							ㄴ 장고 설정 파일.
							ㄴ DATABASES name에서 db관련 설정.
							ㄴ TIME_ZONE name에서 시간 설정.
							ㄴ INSTALLED_APPS
								ㄴ ????? 현재 장고 인스턴스에서 활성화된 모든 장고 어플리케이션의 이름 목록 포함.
								ㄴ 기본적으로 몇 가지 앱들을 포함.
									ㄴ 'django.contrib.admin',
									'django.contrib.auth',
									'django.contrib.contenttypes',
									'django.contrib.sessions',
									'django.contrib.messages',
									'django.contrib.staticfiles',
						ㄴ python manage.py migrate
							ㄴ migrate명령어는 setting.py의 INSTALLED_APPS를 보고 필요한 db 테이블들을 생성해 준다.
							ㄴ 아직 적용되지 않은 migration들을 수집하여 적용시켜줌.
						ㄴ 모델 생성
							ㄴ ~~~~~
						ㄴ 모델 활성화
							ㄴ 모델 정의 후, INSTALLED_APPS 목록에 정의가 들어있는 앱을 추가.
							ㄴ python manage.py makemigrations polls
								ㄴ 모델의 변경 사항에 대한 migration을 만드는 명령어.
							ㄴ 적용 내용들은 해당 앱의 migrations 폴더 안에 0001_initial.py 등과 같은 형태로 저장된다.
						ㄴ migrate시 실행되는 sql문 확인
							ㄴ python manage.py sqlmigrate polls (*mirgrations번호??*)
							ㄴ 해당 migration실행시 실행되는 sql을 보여준다.
					ㅡ 장고 프로젝트
						ㄴ 원하는 폴더 생성 후, 그 안에서 'startproject'옵션으로 장고 프로젝트 생성.
							ㄴ 이 폴더가 플젝의 리포지토리 폴더가 된다.
							ㄴ 리포지토리 폴더 안에 conf폴더 (또는 플젝 이름 폴더)를 만들고
						ㄴ 스프링 프레임워크와 같은 웹 프레임워크 중 하나.
							ㄴ 스프링처럼 MVC패턴을 따른다.
								ㄴ python을 이용해 db부분을 orm으로 다룰 수 있고(M)
								ㄴ 스프링의 컨트롤러처럼 url을 받아서 특정 함수 등으로 매핑시켜 처리할 수 있고(C)
									ㄴ 장고에서는 이를 'view'라고 부른다. (내가 생각하던 mvc의 view와 헷갈린다)
								ㄴ '템플릿'이라는 구성요소를 이용해 보여줄 페이지를 처리한다(V)
					ㅡ 장고 설치 및 실행
						ㄴ 파이썬 설치 후 django패키지를 설치.
						ㄴ 장고 프로젝트를 만들 폴더로 이동 후,
							django-admin startproject (*플젝이름*)
							실행.
						ㄴ 구조 )<button>more</button>
						<pre>
							ㄴ (*임의의 폴더명*)/
									manage.py
									(*플젝명*)/
										__init__.py
										settings.py
										urls.py
										asgi.py
										wsgi.py
							ㄴ 맨 위 폴더는 그냥 플젝이 들어있는 단순 폴더. 이름 변경해도 상관없음.
							ㄴ manage.py
								* django-admin, manage.py
									ㅡ 장고에서 제공하는 커맨드라인 명령어. 이ㅣ 명령어를 통해 장고 프로젝트의 여러 기능들을 사용할 수 있다.
									ㅡ 다음과 같은 형태로 사용된다.
											django-admin < command> [options]
											manage.py < command> [options]
											python -m django < command> [options]
									ㅡ 명령어 목록 )<button>more</button>
									<pre>
										ㄴ django-admin runserver [ (*주소와 포트*) ] )
											ㄴ '경량 개발 서버'를 실행시킨다.
										ㄴ manage.py startapp (*앱 이름*)
											ㄴ 어플 하나 생성.

									</pre>
								
							ㄴ (*플젝명*)폴더
								ㄴ 프로젝트의 실제 파이썬 패키지들이 위치.
							ㄴ (*플젝명*)/__init__.py : 단순히 파이썬에서 패키지를 나타낼때 사용되는 그 __init__.py파일.
							ㄴ (*플젝명*)/settings.py : 장고 플젝의 설정 파일
							ㄴ (*플젝명*)/urls.py : 장고 플젝의 url 선언 및 저장
							ㄴ (*플젝명*)/asgi.py : ?????ASGI 호환 웹서버의 시작 파일??
							ㄴ (*플젝명*)/wsgi.py : ?????WSGI 호환 웹서버의 시작 파일??
						</pre>
					ㅡ ~~~~~
					ㅡ django shell
						ㄴ python manage.py shell
							ㄴ 파이선 shell을 열어준다.
							ㄴ manage.py가 'DJANGO_SETTINGS_MODULE' 환경 변수를 설정하여 프로젝트의 setting.py파일 등의 정보들을
								import할 수 있게 해주기 때문.
					ㅡ django model에 대해 filter메소드를 호출함으로서 db쿼리를 이용한 조회와 같은 기능을 사용할 수 있다.
						ㄴ fk와 같이 연결된 데이터도 가져올 수 있다. ( 더블언더바 '__'를 이용)
					ㅡ django.urls
						ㄴ path(route, view, kwargs=None, name=None)
							ㄴ route는 string타입의 url 패턴값.
								ㄴ 매개변수나 도메인 이름을 제외한 부분만을 대상으로 한다.
								ㄴ 패턴이 일치할 경우, HttpRequest객체를 첫번째 인수로 하고
								ㄴ <, >를 이용해 해당 부분의 url의 값을 view의 인자로 넘길 수 있다. 'bio/< username>/'
									ㄴ < > 안의 이름 앞에 타입을 넣어 값을 변환할 수도 있다. 'bio/< int:num>/'
							ㄴ view 인자
								ㄴ view함수 또는 view명칭.
								ㄴ django.urls.include()함수를 사용할 수도 있다.
							ㄴ kwargs 인자 : view에 추가적인 인자를 넘길 수 있다.
						ㄴ include
							ㄴ ????? 다른 URLconf의 파이선 full import path를 받아서 이를 URLconf에 추가시켜 준다.
							ㄴ ex) 'path('summernote/', include('django_summernote.urls'))'
								ㄴ 'summernote/'패턴과 일치하게 되면 'summernote/'부분을 제거하고 나머지 부분을 'django_summernote.urls'의
									URLconf로 보낸다.
					ㅡ setting.py의 'TEMPLATES'으로 탬플릿 설정 가능.
						ㄴ 어느 폴더로부터 탬플릿 파일을 찾을지 등.
					ㅡ ex)
						def index(request):
						latest_question_list = Question.objects.order_by('-pub_date')[:5]
						template = loader.get_template('polls/index.html')
						context = {
							'latest_question_list': latest_question_list,
						}
						return HttpResponse(template.render(context, request))
						ㄴ 'polls/index.html'탬플릿을 가져와 context 데이터와 함께 전달하며 호출.
						ㄴ 이를 render(request, 'polls/index.html', context)로 간단하게 쓸 수 있다. render()는 위 과정의
							shortcut 메소드.
					ㅡ 'Http404'예외를 발생시켜 404를 반환할 수도 있다.
						ㄴ shortcut
							ㄴ get_object_or_404( (*객체*), (*조건*) ) : 객체가 없을 경우 404예외 발생.
					ㅡ 모델 )
						ㄴ django.db.models.Model
						ㄴ 파이썬 클래스로서, db의 테이블에 해당한다고 보면 된다.
							ㄴ 속성 하나는 테이블의 필드 하나로 보면 되고.
						ㄴ ex)
							from django.db import models

							class Person(models.Model):
								first_name = models.CharField(max_length=30)
								last_name = models.CharField(max_length=30)
						ㄴ 위와 같이 모델 정의 후, 해당 모델을 이용할 것이라고 장고에 명시해야 한다.
							ㄴ setting.py의 'INSTALLED_APPS'에 해당 모델이 정의된 모듈이름을 추가하면 된다.
						ㄴ 필드 )
							ㄴ 클래스의 속성이 곧 필드.
							ㄴ 필드명이 models.Model의 이름과 겹치지 않도록 주의하라.
							ㄴ 'Field' 클래스
								ㄴ 적절한 'Field' 클래스의 인스턴스이어야 한다.
									ㄴ 어떤 'Field' 인스턴스인지에 따라 다음을 결정
										ㄴ db의 자료형
										ㄴ 템플릿에서 form 렌더링에 사용될 디폴트 html 위젯
										ㄴ 장고 어드민과 자동 생성 폼에서 사용될 최소한의 유효성 검증.
									ㄴ 'Field' 인스턴스 리스트 : https://docs.djangoproject.com/ko/3.2/ref/models/fields/#model-field-types
							ㄴ 'Field' 클래스의 옵션
								ㄴ 각 'Field' 인스턴스들에 인자로서 옵션을 줄 수 있다.
								ㄴ 인스턴스마다 다를 수 있고 필수인 것도, 아닌 것들도 있다.
								ㄴ 대표 예
									ㄴ null : 필드에 null 가능 여부. 디폴트는 false.
									ㄴ blank : 필드에 blank 가능 여부. 디폴트는 false.
									ㄴ choices : 필드에 대한 값이 선택형이 된다. 2개의 tuple로 된 파이썬 'sequence'를 인자로 받는다.
													form 위젯의 디폴트가 'select'가 된다.
										ㄴ 튜플의 첫 번째는 db에 저장될 값, 두번째는 form 위젯에 표시된다.
										ㄴ 두 번째 값은 모델의 get_(*필드명*)_display()를 통해 얻을 수 있다.
									ㄴ default : 필드의 디폴트 값. 값이나 callable object가 올 수 있다. 후자인 경우, 새 객체 생성시마다
													호출된다.
									ㄴ help_text : form 위젯에 표시될 도움말 텍스트. 주석으로서도 도움이 된다.
									ㄴ primary_key : True이면, 해당 필드가 모델의 pk가 된다.
													모델에 이게 True인 필드가 없으면 자동으로 pk인 IntegerField가 추가된다.
													자동 할당시, setting의 'DEFAULT_AUTO_FIELD'를 이용한다.
													pk는 read-only이며, 수정 후 저장하게 되면 수정이 아닌 그 pk값으로 새 객체 생성.
									ㄴ unique : True일시, 유니크 제약 추가.
								ㄴ 상세 필드 옵션 리스트 : https://docs.djangoproject.com/ko/3.2/ref/models/fields/#common-model-field-options
								ㄴ verbose name
									ㄴ ForeignKey, ManyToManyField, OneToOneField를 제외한 필드들은 optional first positional 인자로
										verbose name을 받는다.
									ㄴ ~~~~~
							ㄴ 관계
								ㄴ 장고는 다대일, 다대다, 일대일 관계를 제공.
								ㄴ 다대일 )
									ㄴ 모델의 필드 정의에 ForeignKey를 사용함으로서 정의.
									ㄴ ex)
										class Car(models.Model):
											manufacturer = models.ForeignKey(Manufacturer, on_delete=models.CASCADE)
									ㄴ class ForeignKey(to, on_delete, **options)
										ㄴ 인자 )
											ㄴ to : 연결될 모델 클래스
											ㄴ on_delete : 참조하는 객체 삭제시, 어떻게 처리할지를 설정.
												ㄴ db에 대하여 sql 제약을 생성하지는 않는다.
												ㄴ 가능한 값들 )
													ㄴ CASCADE : 참조되는 객체 삭제.
													ㄴ PROTECT : 삭제하지 않음.
													ㄴ RESTRICT : ?????
													ㄴ ~~~~~

								ㄴ 다대다 )
									ㄴ ManyToManyField 사용함으로서 정의.
									ㄴ ex)
										class Pizza(models.Model):
											# ...
											toppings = models.ManyToManyField(Topping)
									ㄴ 양방향인 두 모델 중 하나에만 정의하면 된다.
									ㄴ 다대다로 정의시 중간 매핑 테이블이 자동으로 생성되지만, ManyToManyField에
										'through' 인자를 추가하여 임의로 만들 수 있다. 이를 '중개 모델'이라고 한다.
										ㄴ 자동으로 생성되는 중개 모델은 필드로 id값만 가지고 있기 때문에 추가적인 데이터가 필요하면
											이를 사용한다.
										ㄴ ????? 개인적으로 임의로 중간 매핑 테이블을 생성하여 사용하는 것과 뭐가 다른지 잘 모르겠다.

						ㄴ 메소드 )
							ㄴ get_next_by_(*필드명*) (), get_previout_by_(*필드명*) ()
								ㄴ DateField, DateTimeField의 필드의 경우, 필드 옵션의 null=False인 경우 이 메소드를 통해 바로
									이전, 이후의 모델 객체를 반환받을 수 있다.
								ㄴ DoesNotExist 예외를 발생시킨다.


					ㅡ 마이그레이션 )
						ㄴ 개요 )
							ㄴ '모델'에 생긴 변화를 버전 관리 시스템처럼 관리하는 장고의 기능.
							ㄴ makemigrations 명령어로 모델에 생긴 변화를 '마이그레이션' 파일에 기록하고, migrate명령어로 이 변경점을
								db에 반영한다.
							ㄴ '마이그레이션 파일'은 각 앱의 'migrations' 폴더 안에 있다.
						ㄴ 명령어 )
							ㄴ migrate
							ㄴ makemigrations
								ㄴ --name 옵션으로 마이그레이션 파일에 이름을 부여할 수 있다.
									ㄴ python manage.py makemigrations --name (*이름*) (*앱*)
							ㄴ sqlmigrate
							ㄴ showmigrations
						ㄴ ????? db 별
							ㄴ ~~~~~
						ㄴ 과정 )
							ㄴ 모델 파일 수정 후, makemigrations 명령어 수행시, '마이그레이션 파일'들에서 최신 버전과 비교하여
								모델 파일을 스캔.
								ㄴ 장고가 인식한 마이그레이션 변경 사항이 정확한지 확인할 수 있다.
						ㄴ vc 관련 이슈
							ㄴ 두 개발자가 같은 이름의 마이그레이션 파일을 동시에 커밋 할 수도 있다.
							ㄴ 마이그레이션 파일 번호는 개발자의 편의를 위해서 있을 뿐이고, 장고는 각 마이그레이션에 대한 다른 이름을
								부여하고 있고, 각 마이그레이션들은 각각이 의존하고 있는 다른 마이그레이션들을 참조하고 있다.
						ㄴ 트랜젝션 이슈
							ㄴ DDL 트랜젝션을 지원하는 db의 경우(SQLite, PosgreSQL)는 모든 마이그레이션 작업이 한 트랜젝션 안에서 일어나지만,
								지원하지 않는 경우(Mysql, Oracle)는 트랜젝션 없이 일어난다.
					ㅡ Authentication system
						ㄴ ~~~~~
						ㄴ User
							ㄴ 기본 장고 User
								ㄴ ~~~~~
							ㄴ 커스텀 User 사용
								ㄴ django.contrib.auth.models.AbstractUser를 상속하는 모델을 커스텀으로 정의하여 사용.
								ㄴ 정의후, settings.py에 'AUTH_USER_MODEL = "(*커스텀 User모델*)"입력 필요.
								ㄴ ex )
									in models.py... )
									class DeepQUser(AbstractUser):
										~~~

									in settings.py... )
									~~~
									AUTH_USER_MODEL = "member.DeepQUser"
								ㄴ 장고 기본 User와 동일한 기능을 하는 auth_user가 생성되며, 커스텀 model에서 table에 대해 커스텀이 가능하다.
								ㄴ 기존에 User를 사용하다 커스텀 User로 변경하려는 경우 )
									ㄴ
				</pre>

			</pre>

		</pre>

		스크래핑<button>더보기</button>
		<pre>
			ㄴ 웹 크롤링 vs 웹 스크래핑
				ㄴ 크롤링이란, 특정 '시드'?를 기준으로 관련된 데이터들을 탐색해가며 모두 가져오는 것. 중복이 당연히 없어야하고, 스케일이 크다.
					ㄴ 이를 수행하는걸 crawl agent, crawl bot, spider 이라고 불린다.
				ㄴ 스크래핑이란, 단순히 웹이나 기타 소스를 통해 필요한 데이터를 뽑아내는 것. 중복이 상관없고 소스로부터 데이터를 뽑아낼 수 있는 파서가 필요하다.
				ㄴ 두 단어가 혼동되어 사용되는 경우가 잦으며, 보통 단순한 웹 스크래핑을 웹 크롤링이라 잘 못 부르는 경우가 많다고 한다.
			ㄴ 여기서 다룰 내용은 웹 스크래핑이다.

			* 데이터 전처리<button>more</button>
			<pre>
				ㅡ 수집한 데이터를 분석에 사용하기 위해 가공하는 것을 말한다.
				ㅡ
				ㅡ 분석에 부적합한 구조, 누락 항목, 결측값 등을 처리
				ㅡ 노이즈 제거, 중복값 제거, 결측값 보정, 데이터 구조 변경 등
				ㅡ 그냥 분석에 안 맞는 데이터들을 수정해 주는 것.
				ㅡ 무제 )
					ㄴ 딱히 일반적인 기술이나 이론같은게 없는 것 같다. 그냥 수집한 데이터에 따라서 데이터를 잘 가공하면 되는 듯 하다.
			</pre>

			* Beautiful Soup 라이브러리.<button>더보기</button>
			<pre>
				ㅡ https://www.crummy.com/software/BeautifulSoup/bs4/doc/# 참고.
				ㅡ html, xml 문서를 받아서 이것으로부터 데이터를 뽑아 올 수 있게 해주는 파이썬 라이브러리.
					ㄴ ????? 파서들을 이용하여 요소들의 데이터를 뽑아오는식인듯 하다.
				ㅡ 내부적으로 파이선 표준 라이브러리의 HTML parser를 지원해주며, 추가적으로 third-party 파이선 parser인 'lxml parser'등도 지원해 준다.
					* lxml이란?
						ㅡ ????? C언어의 'libxml2'와 'libxslt'를 묶어서 파이썬에서 사용할 수 있게 해주는 xml도구?
				ㅡ find(), find_all()?등의 여러 함수 제공
				ㅡ ~~~~~
				ㅡ 파서의 종류가 다르면 반환되는 문서의 형태가 다를 수 있다.
					ㄴ ex)
						BeautifulSoup("< a>< /p>", "lxml")
						// < html>< body>< a>< /a>< /body>< /html>

						BeautifulSoup("< a>< /p>", "html5lib")
						// < html>< head>< /head>< body>< a>< p>< /p>< /a>< /body>< /html>

						BeautifulSoup("< a>< /p>", "html.parser")
						// < a>< /a>
					ㄴ 따라서 BeautifulSoup 객체 생성시 파서를 명시해주는것이 좋다.
				ㅡ 인코딩 )
					ㄴ ~~~~~
				ㅡ 무제 )
					ㅡ html, xml등의 문서를 파싱해주는 라이브러리???
					ㅡ 문서에서 특정 요소들을 추출해주는 기능을 해준다.
						ㄴ ex)
							from bs4 import BeautifulSoup

							soup = BeautifulSoup( (*html문서*) )
							soup.find('title') #html문서에서 title태그를 찾아 반환해준다.
					ㅡ 요소를 찾기위해 인자로 넘어가는 문자열은 css 셀렉터와 거의 동일한 듯하다.

			</pre>

			* selenium<button>더보기</button>
			<pre>
				ㅡ 참조 ) 공홈 https://www.selenium.dev/, https://selenium-python.readthedocs.io/, https://www.selenium.dev/selenium/docs/api/py/index.html
				ㅡ 웹페이지 테스트 자동화용 모듈.
				ㅡ 지원하는 브라우저들의 'WebDriver'와 자체적인 'WebDriver'를 사용하여 동작.
				ㅡ 각 브라우저의 'Web Driver'가 있어야 사용가능하다. ex) 크롬의 크롬드라이버, 파이어폭스의 geckodriver 등
					ㄴ 드라이버의 경로 또한 정확하게 있어야한다.
				ㅡ Navigating )
					ㄴ ?????
					ㄴ driver.get( (*url*) )
						ㄴ url에 해당하는 페이지를 드라이버가 받아온다.
						ㄴ 드라이버는 해당 페이지가 완전히 로드 될때까지('onload'이벤트 호출) 기다렸다가 그 이후에 완료된다.
						ㄴ 해당 페이지에 대해서만 완전히 로드되는걸 기다리는 것이고, ajax등으로 데이터를 로드하거나 문서구조가 바뀌는 것은
							드라이버가 이게 언제 완료되는지 알 수 없기때문에, get()에서 이런것들까지 기다리지는 않는듯하다.
							ㄴ 이런건 아래에 나오는 'Wait'기능으로 해결한다.
					ㄴ ~~~~~
				ㅡ ~~~~~
				ㅡ WebDriver<button>more</button>
				<pre>
					ㄴ ~~~~~
					ㄴ selenium.webdriver.remote.webdriver.WebDriver 클래스<button>more</button>
					<pre>
						ㄴ ~~~~~
						ㄴ 이름들<button>more</button>
						<pre>
							ㄴ ~~~~~
							ㄴ page_source : 현재 페이지의 소스가 'str'형태로 들어있다.
							ㄴ current_url : 현재 window의 url을 출력
							ㄴ current_window_handle : 현재 window handle의 이름이 'str'형태로 들어있다.
							ㄴ window_handles : 모든 window handle들의 이름 목록이 'list'형태로 들어있다.
							ㄴ ~~~~~
							ㄴ switch_to )
								ㄴ ~~~~~
								ㄴ window handle을 전환할 수 있다.
									ㄴ ex) driver.switch_to.window( (*window handle*) )
						</pre>
					</pre>

					ㄴ webdriver Chrome <button>more</button>
					<pre>
						ㄴ ~~~
						ㄴ Option<button>more</button>
						<pre>
							ㄴ chrome webdriver를 실행할 때, 여러가지 옵션을 주어 실행시킬 수 있다.
							ㄴ 목록 )<button>more</button>
							<pre>
								ㄴ ~~~
								ㄴ --headless
									ㄴ 창 없이
								ㄴ user-agent
									ㄴ request headers의 user-agent라는 속성값을 설정하는 옵션.
									ㄴ user-agent가 무엇이느냐에 따라 웹페이지의 동작 방식이나 구성이 달라지는 듯 하다.
										ㄴ ex ) user-agent가 HeadlessChrome인 경우 페이지의 특정 요소가 렌더링이 안 되는 등.
									ㄴ headless 사용시 user-agent가 headless 관련된 값으로 자동 설정되고 이로인해 페이지 구성이 다른 경우가 많은 듯 하다.
										headless 사용시 꼭 user-agent를 설정하도록.
							</pre>
						</pre>
					</pre>
				</pre>

				ㅡ Wait )
					ㄴ ajax등을 통해 페이지의 요소들이나 데이터들이 각기 다른 시점에 로드되는 경우, 드라이버를 통해 요소를 찾는 것이 어려워진다.
						이런 경우들을 위해, 잠깐 '대기'를 하는 기능을 제공한다.
					ㄴ 대기의 종류에는 '암시적 대기'와 '명시적 대기'가 있다.
					ㄴ Explicit Waits )
						ㄴ 특정 조건을 만족할 때까지 대기한다. ex) 특정 요소가 존재할때까지 대기, 특정 text가 있을때까지 대기 등
						ㄴ ~~~~~
					ㄴ Implicit Waits )
						ㄴ 요소를 찾는데 그 요소가 현재 없거나 하여 이용가능하지 않을 경우, 몇초동안 찾고있을지를 설정한다.
						ㄴ ex)
							chrome_driver = 'C:/Users/kai/Desktop/chromedriver_win32/chromedriver.exe'
							driver = webdriver.Chrome(chrome_driver)
							driver.get('https://deepsearch.com/analytics/economic-indicator?pageView=1&symbol=BOK%3A036Y001.0000001&chartEditSetting=JTdCJTIyc2VyaWVzTGlzdCUyMiUzQSU1QiU3QiUyMnN5bWJvbCUyMiUzQSUyMkJPSyUzQTAzNlkwMDEuMDAwMDAwMSUyMiUyQyUyMmF4aXMlMjIlM0EwJTdEJTVEJTJDJTIybGVnZW5kUG9zaXRpb24lMjIlM0EyJTJDJTIybGVnZW5kT3JpZW50YXRpb24lMjIlM0ElMjJoJTIyJTdE')
							driver.implicitly_wait(1) //implicit wait를 1초로 설정. 요소를 찾을때 요소가 없으면 1초동안 계속 찾도록 설정된다.
							data = driver.find_element_by_css_selector('div.rt-resizable-header-content')
							print(data.text)
						ㄴ 설정하지 않으면 디폴트값은 당연히 0이다.
						ㄴ 설정한 시간동안 못찾으면 못찾았다는 예외 발생.

				ㅡ 무제 )
					ㄴ WebElement의 click()는 해당 요소의 좌표를 클릭하는 식으로 동작하는 듯함.
						ㄴ 해당 요소가 화면에서 안 보이거나, 가려져 있으면 영어로 '해당 좌표에서 해당 요소르 ㄹ클릭할 수 없다는 오류'발생.
						ㄴ 해서, 'driver.execute_script("arguments[0].click();", button)' 등의 방법으로 클릭 실행.
						ㄴ click()사용시, clickInterrcept오류 발생시, 화면 안에 요소가 없어서 다른 요소가 클릭을 받았다는 오류.
							바로 위의 execute_script()를 쓰거나 안 되면, selenium의 Actions을 사용하여 해당 요소로 위치 이동 후,
							click()을 수행해 보자.
							ㄴ ex ) 	from selenium.webdriver import ActionChains
										ActionChains(self.driver).send_keys(Keys.PAGE_UP).move_to_element(button).click(button).perform()
								ㄴ 중간의 send_keys(Keys.PAGE_UP)은 해당 요소가 애매하게 현제 스크롤 위치 근처에 있으면 move_to_element()로
									스크롤이 이동하지도 않고 click()은 여전히 clickInterrcept되는 경우가 있어서, 스크롤 위치를 한번
									옮겨주고 클릭하려는 요소 위치로 이동하는 것.

			</pre>

			* Scrapy <button>더보기</button>
			<pre>
				ㅡ 공식문서 참조 https://docs.scrapy.org/en/latest/
				ㅡ Scrapy 2.5
				ㅡ 웹 크롤링, 웹 스크래핑에 사용되는 프레임워크.
				ㅡ 설치 )
					ㄴ 윈도우면 아나콘다 또는 미니콘다를 이용하여 설치하는걸 권장.
						ㄴ conda install -c conda-forge scrapy
				ㅡ Command line tool <button>더보기</button>
				<pre>
					ㄴ ?????
					ㄴ scrapy.cfg 파일로부터 설정정보를 읽어들인다.
						ㄴ scrapy.cfg파일은 시스템전체용, 유저전체용, 각 플젝용 세 종류가 있으며,
						ㄴ 이 세파일의 정보가 병합된다. 병합시 우선순위는 플젝용 > 유저전체용 > 시스템전체용 이다.
						ㄴ 시스템 전체용 : c:\scrapy\scrapy.cfg
						ㄴ 유저 전체용 위치 : ~/.scrapy.cfg
						ㄴ 플젝용 위치 : 각 scrapy플젝 루트폴더에 scrapy.cfg
					ㄴ 스크래피 플젝의 디렉토리 구조 )<button>더보기</button>
					<pre>
						ㄴ 디폴트 구조는 다음과 같다.
							scrapy.cfg
							myproject/
								__init__.py
								items.py
								middlewares.py
								pipelines.py
								settings.py
								spiders/
									__init__.py
									spider1.py
									spider2.py
									...
							ㄴ scrapy.cfg가 있는 위치가 '프로젝트 루트 디렉토리'이다.
						ㄴ scrapy.cfg
							ㄴ 플젝의 설정을 정의하는 파이선 모듈이름을 포함하고있다.
								ㄴ ex)
									[settings]
									default = myproject.settings
							ㄴ 여러 스크래피 플젝 사이에서 공유될 수 있다.
								ㄴ 이런 경우, 각 플젝마다 설정 모듈에 별칭을 부여해야한다.
									ㄴ ex)
										[settings]
										default = myproject1.settings
										project1 = myproject1.settings
										project2 = myproject2.settings
								ㄴ ?????scrapy command line은 디폴트로 'default'설정을 사용한다.
									ㄴ 'SCRAPY_PROJECT'환경변수를 변경하여 이를 변경할 수 있다.
										ㄴ ex) export SCRAPY_PROJECT=project2
											ㄴ 별칭 project2에 해당하는 myproject2.settings의 설정정보를 scrapy command line이 사용하게된다.
					</pre>
					ㄴ 사용법 )<button>더보기</button>
					<pre>
						ㄴ 명령어를 인자없이 입력하면 해당 명령어에 관한 도움말이 출력된다.
							ㄴ ex) scrapy 입력, scrapy crawl입력 등
							ㄴ 또는 '-h'옵션을 붙이면 더 자세한 도움말을 얻을 수 있다.
						ㄴ 스크래피 프로젝트 생성
							ㄴ scrapy startproject (*플젝이름*) [(*디렉토리*)]
							ㄴ 이후 해당 폴더로 이동하면, 해당 플젝에 대해 scrapy command를 사용할 수 있다.
						ㄴ 그 외 명령어들 )<button>더보기</button>
						<pre>
							ㄴ 명령어는 두가지로 구분할 수 있다. 플젝 안에서 실행시켜야하는 명령어('Project-only commands')와 그렇지 않아도 되는 명령어('Global command').
								ㄴ 후자의 경우, 플젝안에서 실행시키게되면 플젝의 설정이 override되기때문에 동작이 조금 다를 수 있다.
							ㄴ Global command)
								ㄴ startproject
								ㄴ genspider
								ㄴ settings
								ㄴ runspider
								ㄴ shell
								ㄴ fetch
								ㄴ view
								ㄴ version
							ㄴ Project-only commands)
								ㄴ crawl
								ㄴ check
								ㄴ list
								ㄴ edit
								ㄴ parse
								ㄴ bench
						</pre>
					</pre>
				</pre>
				ㅡ Spiders<button>더보기</button>
				<pre>
					ㄴ 어떻게 특정 사이트가 스크랩될지, 어떻게 크롤링을 수행할지, 어떻게 데이터를 추출할지를 정의하는 파이썬 클래스.
					ㄴ 동작과정 )
						ㄴ 초기 요청을 발생시키고, 해당 요청의 응답에 대한 콜백함수 지정.
							ㄴ 초기 요청은 'scrapy.http.Request'를 반환하는 'start_requests()'의 호출을 통해 얻어지고
							ㄴ 콜백함수는 parse()메소드가 된다. (디폴트로)
						ㄴ 콜백함수는 응답을 파싱하고 'item object' 또는 'scrapy.http.Request', 또는 이들의 iterable을 반환한다.
							ㄴ 반환하는 'Request'또한 각각의 콜백함수를 가지며, 응답에 대해 콜백함수가 호출된다.
							ㄴ scrapy의 'Selectors' 또는 BeautifulSoup, lxml등을 사용하여 응답을 파싱하고 scrapy의 'item'을 반환한다.
						ㄴ 반환된 scrapy의 'item'들은 db에저장되거나 파일로 씌여진다.
					ㄴ 목적에 따라 다양한 종류의 'Spider'가 존재한다.
					ㄴ scrapy.Spider <button>더보기</button>
					<pre>
						ㄴ scrapy.spiders.Spider 클래스<button>more</button>
						<pre>
							ㄴ 가장 기본형태의 스파이더이자, 다른 종류 또는 커스텀으로 정의한 모든 스파이더들이 상속해야하는 클래스.
							ㄴ ?????
							ㄴ 요소들 <button>more</button>
							<pre>
								ㄴ name )
									ㄴ 스파이더의 이름을 정의. 유일해야한다.
									ㄴ 필수값.
									ㄴ ?????
								ㄴ allowed_domains
								ㄴ start_urls
								ㄴ custom_settings
								ㄴ crawler
								ㄴ settings
								ㄴ logger
								ㄴ from_crawler()
								ㄴ start_requests()
									ㄴ 스파이더가 열리면, scrapy에 의해 처음 단 한번만 호출되는 메소드.
									ㄴ Request의 iterable을 반환해야한다.
									ㄴ override하지 않을시, 디폴트 구현체는 'start_urls'의 각 url에 대해 Request( (*url*), dont_filter=True)를 발생시킨다.
								ㄴ parse( (*response*) )
									ㄴ scrapy가 각 응답에 대해 디폴트 콜백으로 사용하는 메소드. 요청에 대해 콜백을 명시하지 않으면 이 디폴트 콜백이 사용된다.
									ㄴ 각 응답을 처리하거나 데이터를 추출하여 반환하거나 follow할 추가적인 url을 반환하는 역할이다.
									ㄴ 'scrapy.http.Request'의 iterable 또는 scrapy의 'item objects'를 반환해야한다. 둘다 반환할 수도 있다.
										ㄴ 이는 parse()뿐만 아니라, request에 대한 콜백함수 모두에 해당한다.
								ㄴ log()
								ㄴ closed()
							</pre>

						</pre>

					</pre>
					ㄴ Spider argument<button>more</button>
					<pre>
						ㄴ 스파이더는 호출시 인자를 받을 수 있다.
							인자는 스파이더 정의 안에서 자유롭게 사용할 수 있다.
							일반적으로 url을 설정하거나 크롤링할 url에 대한 조건을 설정하는데 사용된다.
						ㄴ 사용법 )
							ㄴ crawl명령어에 '-a'옵션을 주고 인자를 넘겨주면된다.
								ㄴ ex) scrapy crawl myspider -a category=electronics
							ㄴ 스파이더 클래스에서 __init__()을 통해 인자를 받을 수 있다
								* __init__() : 파이선에서 '인스턴스'생성시 호출되는 메소드.
								ㄴ ex)
									import scrapy

									class MySpider(scrapy.Spider):
										name = 'myspider'

										def __init__(self, category=None, *args, **kwargs):
											super(MySpider, self).__init__(*args, **kwargs)
											self.start_urls = [f'http://www.example.com/categories/{category}']
											# ...
								ㄴ __init__()을 정의하지 않으면 디폴트 __init__()은 인자들을 스파이더 인스턴스의 attribute로 만들어준다.
							ㄴ 인자는 'string'형태로만 들어온다. 필요하다면 직접 파싱해야한다.
					</pre>
					ㄴ Generic Spiders<button>more</button>
					<pre>
						ㄴ 자주사용될법한 스파이더 형태를 미리 정의해 둔것.
						ㄴ CrawlSpider<button>more</button>
						<pre>
							ㄴ scrapy.spiders.CrawlSpider 클래스
							ㄴ
						</pre>
						ㄴ XMLFeedSpider
						ㄴ CSVFeedSpider
						ㄴ SitemapSpider
					</pre>

				</pre>
				ㅡ Selectors<button>more</button>
				<pre>
					ㄴ BeautifulSoup, lxml 등과 같이 문서로부터 데이터를 추출해주는 기능을 하는 scrapy의 기능.
						ㄴ XPath나 css 표현식으로 문서의 특정 부분을 추출한다.
						ㄴ scrapy의 Selector들은 python의 'parsel'라이브러리의 wrapper이다.
							ㄴ 'parsel' 라이브러리란, XPath, Css선택자, 정규표현식을 이용해 html, xml문서로부터 데이터를 추출하고 제거하는 라이브러리.
								ㄴ 내부적으로 'lxml'을 사용한다고 한다.
							ㄴ 따라서 lxml과 매우 유사하다.
					ㄴ 사용법<button>more</button>
					<pre>
						ㄴ response객체의 'selector'속성을 통하여 'scrapy.selector.selector'에 접근할 수 있다.
							ㄴ 이 'selector'객체의 xpath(), css()를 통해 데이터를 추출한다.
								ㄴ ex) response.selector.xpath('//span/text()').get()
								ㄴ 이렇게 selector.xpath(), selector.css()와 같이 사용하는 경우가 아주많아서 shortcut을 제공한다.
									ㄴ ex) response.css(), response.xpath()
						ㄴ scrapy.http.Selector
							ㄴ response의 컨텐츠의 '선택된 부분'을 담고있는 wrapper이다.
								ㄴ xpath(), css()등으로 어느부분을 선택했느냐에 따라 내용물이 바뀐다.
								ㄴ 여기서 response란, 'HtmlResponse' 또는 'XmlResponse'객체이다.
							ㄴ selector객체는 'scrapy.http.TextResponse'객체나 문자열로된 마크업을 text 매개변수로 받아 생성된다.
								ㄴ ex)
									body = '< html>< body>< span>good< /span>< /body>< /html>'
									Selector(text=body).xpath('//span/text()').get()	//Selector객체를 body를 인자로 넘기며 생성하고있다.
								ㄴ ex)
									response = HtmlResponse(url='http://example.com', body=body)
									Selector(response=response).xpath('//span/text()').get()	//HtmlResponse객체를 넘기며 Selector객체를 생성하고있다.
																								//HtmlResponse는 TextResponse의 subclass이다.
								ㄴ Selector객체는 입력받은 데이터의 타입에따라 가장 적절한 파싱규칙을 선택한다(HTML인지 XML인지)
							ㄴ 요소들<button>more</button>
							<pre>
								ㄴ xpath( (*query*), (*namespaces=None*), )
									ㄴ XPath문법에 따라 (*query*)에 매칭되는 노드들을 찾고 'SelectorList'로 반환.
									ㄴ ~~~~~
								ㄴ css( (*query*) )
									ㄴ css selector를 나타내는 문자열을 인자로 받아 매칭되는 노드들을 찾고 'SelectorList'로 반환.
									ㄴ 내부적으로 입력받은 css selector를 xpath 쿼리로 변역하여('cssselect'라이브러리 이용) xpath()을 호출하여 동작한다.
								ㄴ get()
									ㄴ Selector가 담고있는 내용을 직렬화하여 unicode 문자열로 반환한다.
									ㄴ get()은 단 하나의 결과만 반환, getall()은 'SelectorList'의 메소드로, 배열형태로 내용을 모두 반환.
									ㄴ 매칭되는게 없으면 'None'반환. 메소드에 'default'란 키값으로 인자 넘길시 'None'대신 해당 인자값이 디폴트로 반환.
								ㄴ attrib 속성 : 요소에 대한 속성 'dict'를 반환.
								ㄴ re( (*정규표현식*), (*replace_entities=True*) )
									ㄴ
							</pre>
						ㄴ Selector 사용법
							ㄴ get(), getall()
								ㄴ Selector가 담고있는 내용을 직렬화하여 unicode 문자열로 반환한다.
								ㄴ get()은 단 하나의 결과만 반환, getall()은 'SelectorList'의 메소드로, 배열형태로 내용을 모두 반환.
								ㄴ 매칭되는게 없으면 'None'반환. 메소드에 'default'란 키값으로 인자 넘길시 'None'대신 해당 인자값이 디폴트로 반환.

							ㄴ css()
								ㄴ
								ㄴ 'SelectorList'객체를 반환.
							ㄴ attrib 속성
								ㄴ Selector에 해당하는 요소의 속성을 선택할 수 있다.
						ㄴ css 선택자의 확장
							ㄴ 요소의 text node를 선택하려면, '::text'를 사용하면된다.
								ㄴ ex) response.css('title::text').get()
							ㄴ 요소의 속성값을 선택하려면, '::attr( (*name*) )'을 사용하면된다.
								ㄴ ex) response.css('a::attr(href)'.getall()
						ㄴ css(), xpath()가 SelectorList를 반환하므로, 이 반환 Selector들에 대해 css(),xpath()를 체인형태로 계속 호출할 수 있다.
						ㄴ 속성 선택
							ㄴ xpath문법을 통해 선택
								ㄴ ex) response.xpath("//a/@href").getall()
						ㄴ 정규표현식을 통한 선택
							ㄴ re()
						ㄴ extract(), extract_first()
						ㄴ ~~~~~
					</pre>

				</pre>
				ㅡ Items<button>more</button>
				<pre>
					ㄴ 스크래핑을 통해 추출한 데이터를 반환하는 형태.
						ㄴ key-value쌍을 정의하는 파이선 객체이다.
						ㄴ 데이터 타입이 여러개이어도 상관없다.
						ㄴ 지극히 개인적인 비유를 하자면, scrapy에서 스크랩한 데이터를 저장하는 용도로 쓰이는 클래스. scrapy에서 지원하는
							여러 기능들을 사용할 수 있다.
						ㄴ ????? item type? item클래스가 있는건 알겠는데, item type중에 하나로 item 클래스? 그럼 item이 정확히 뭔가?
					ㄴ ????? 이후 Item Loaders, Item Pipeline, Item exporter 등에서 어떻게 쓰이는지를 봐야 정확하게 이해가 될 듯 하다.
					ㄴ scrapy.item.Item 클래스
						ㄴ ????? 파이썬의 'dict'와 유사한 메소드들과 여기에 scrapy에서 사용될 추가적인 기능들을 제공하는 scrapy의 내장 클래스..???
							ㄴ 'dict'와 유사하게 데이터 입력, 추출, 객체 생성 등이 가능
								ㄴ ex) product['last_updated'] = 'today'
										product['last_updated'] //'today'출력
						ㄴ 파이썬의 'dict'의 메소드들을 동일하게 가지고 있다. (__init__()을 포함하여)
						ㄴ 'Item exporter'는 디폴트로 모든 필드를 export한다
						ㄴ ????? 필드 메타데이터를 정의할 수 있다
						ㄴ ?????
						ㄴ 추가적인 메소드
							ㄴ copy()
							ㄴ deepcopy()
							ㄴ fields : 선언된 모든 'field'들을 담고있는 'dict'. 키값은 필드명이고, 값은 'Field'객체이다.
					ㄴ 사용법 )
						ㄴ Item객체의 subclass를 정의하여 사용한다.
							ㄴ ex)
								import scrapy

								class Product(scrapy.Item):
									name = scrapy.Field()
									price = scrapy.Field()
									stock = scrapy.Field()
									tags = scrapy.Field()
									last_updated = scrapy.Field(serializer=str)
						ㄴ Field 선언
							ㄴ scrapy.item.Field 클래스
								ㄴ 파이썬 dict클래스에 별칭만 달리한 것. 즉, 그냥 dict이다.
							ㄴ Field객체는 각 필드에 대한 메타데이터를 명시하는데 사용된다.
								ㄴ 위의 예에서 'last_updated'에 Field()를 생성하면서 넘겨준 인자들이 메타데이터로 쓰이는식.
							ㄴ 사용된 Field객체들은 Item클래스의 attribute로 존재하는게 아닌, Item클래스의 'fields' attribute안에 들어있다.
						ㄴ Item객체 생성
							ㄴ ex) product = Product(name='aaa', price=1000)
						ㄴ ex) product['name']
						ㄴ 복사 )
							ㄴ 파이썬 객체의 복사와 동일하다. copy(), deepcopy()
						ㄴ Item으로부터 dict생성 : dict(product)
						ㄴ dict로부터 item생성 : Product({'name': 'Laptop PC', 'price': 1500})
						ㄴ Item subclass 확장 )
							ㄴ 기존 subclass를 상속하는 또 다른 클래스를 정의하여 Item의확장이 가능하다
							ㄴ ?????
						ㄴ 'item pipeline'이나 'spider middleware'와 같이 Item을 받는 부분에서, item이 어떤 type이어도 item을
							받을 수 있게 하기 위해 'itemadapter.ItemAdapter'클래스나 'itemadapter.is_item()'을 사용하는것이 권장된다.
				</pre>
				ㅡ Item Loaders<button>more</button>
				<pre>
					ㄴ 스크랩된 'items'을 저장하는 편리한 기능들을 제공해주는 기능.
						ㄴ 그냥 item을 직접 저장할 수도 있지만 추출된 데이터의 파싱을 자동화 하는 등의 기능 제공.
						ㄴ 즉, item이 스크랩된 데이터의 '컨테이너'라 하면, 'item loader'는 이 '컨테이너'들을 잘 쌓아올리는 메커니즘을 제공.
					ㄴ ~~~~~
				</pre>
				ㅡ Scrapy Shell<button>more</button>
				<pre>
					ㄴ scrapy에서 사용할 몇가지 기능들이 추가된 파이썬 cnosole.
						ㄴ 파이썬 대화형 쉘처럼 scrapy를 shell로 빠르게 사용할 수 있는 기능.
						ㄴ 실제로 파이썬 대화형 인터프리터에서 동작한다.
						ㄴ 디버그, 테스트에 많이 사용된다.
					ㄴ ~~~~~
				</pre>
				ㅡ Item Pipeline<button>more</button>
				<pre>
					ㄴ item이 스크랩된 뒤, 이 item들이 어떤 컴포넌트들에 의해 연속적으로 처리되기 위해 보내지는 곳.
						ㄴ 각 컴포넌트를 'item pipeline component'라 부르고, 이는 몇몇 메소드들을 구현하는 일반 파이선 클래스이다.
							ㄴ 몇몇 메소드란 다음과 같다.
								ㄴ process_item(self, (*item*), (*spider*))
									ㄴ 모든 컴포넌트들에서 호출되는 메소드.
									ㄴ Item객체 또는 'Deferred'객체?????를 반환하거나ㅓ 'DropItem'예외를 raise해야한다.
									ㄴ DropItem발생시 해당 Item은 더이상 파이프라인에서 진행되지 않는다.
								ㄴ ~~~~~
						ㄴ item을 받아 특정 로직을 실행하고, pipeline을 계속 진행해야할지 말지 등을 결정한다.
					ㄴ 일반적인 쓰임새
						ㄴ ????? html데이터 cleaning
						ㄴ 스크랩트된 데이터의 유효성 검증
						ㄴ 중복검사
						ㄴ 스크랩트된 item의 db저장
					ㄴ ~~~~~
					ㄴ 예제 <button>more</button>
					<pre>
						ㄴ ~~~~~
						ㄴ MongoDB에 item 쓰기<button>more</button>
						<pre>
							ㄴ 'pymongo'를 이용하여 'item'을 MongoDB에 입력하는 예제이다.
							ㄴ MongoDB의 주소, db이름 등의 설정정보는 scrapy설정에서 설정한다.
							ㄴ pipeline의 item처리 부분에서 'pymongo'에서 얻은 MongoDB 객체의 메소드를 사용하여 db에 넣어주면 된다.
							ㄴ ex)<button>more</button>
							<pre>
								import pymongo
								from itemadapter import ItemAdapter

								class MongoPipeline:

									collection_name = 'scrapy_items'

									def __init__(self, mongo_uri, mongo_db):
										self.mongo_uri = mongo_uri
										self.mongo_db = mongo_db

									@classmethod
									def from_crawler(cls, crawler):
										return cls(
											mongo_uri=crawler.settings.get('MONGO_URI'),
											mongo_db=crawler.settings.get('MONGO_DATABASE', 'items')
										)

									def open_spider(self, spider):
										self.client = pymongo.MongoClient(self.mongo_uri)
										self.db = self.client[self.mongo_db]

									def close_spider(self, spider):
										self.client.close()

									def process_item(self, item, spider):
										self.db[self.collection_name].insert_one(ItemAdapter(item).asdict())
										return item
							</pre>
						</pre>
					</pre>
				</pre>
				ㅡ Feed exports<button>more</button>
				<pre>
					ㄴ scrapy에서 스크랩한 item을 export하는 기능을 말함.
						ㄴ 여러 직렬화 형태를 이용하여 데이터를 저장할 수 있게 해준다
					ㄴ 직렬화 format
						ㄴ 데이터 직렬화를 위해 'item exporter'를 사용한다.
					ㄴ ~~~~~
				</pre>
				ㅡ ~~~~~
				ㅡ 아키텍쳐<button>more</button>
				<pre>
					<img src="image/scrapy_architecture_02.png" height="940"/>
					ㄴ 흐름 )
						ㄴ '엔진'에 의해 전체적인 흐름이 제어된다.
						ㄴ 'spider'로부터 엔진이 초기 request를 받아온다.
							ㄴ 엔진과 'spider'의 데이터 교환은 'spider middleware'를 통해 이루어 진다.
						ㄴ '스케줄러'?????
						ㄴ 엔진이 요청을 'downloader'엑 주면 'downloader'는 요청을 보내고 응답을 받아와 엔진에게 넘겨준다.
							ㄴ 'downloader middleware'를 통하여 엔진과 데이터를 주고 받는다.
						ㄴ 엔진은 이 응답을 'spider'에게 넘겨준다.
						ㄴ 스파이더는 원하는 로직을 처리하고 'Item'또는 또 다른 요청을 반환하고 엔진이 이를 받는다.
						ㄴ 엔진이 'Item'은 'item pipeline'으로 넘기고 또 다른 요청은 다시 '스케줄러'에게 넘겨준다.
						ㄴ '스케줄러'?????
						ㄴ 이를 반복.
					ㄴ ~~~~~
				</pre>
				ㅡ 스케줄러<button>more</button>
				<pre>
					ㄴ
				</pre>
				ㅡ 스크래핑을 위한 브라우저 개발자 도구 사용에 관해<button>more</button>
				<pre>
					ㄴ 개발자 도구는 실시간 DOM을 보여준다.
						ㄴ 즉, 처음 받아온 html이 아닌, 어떤 js코드가 실행되어 수정되었을 수도 있는 페이지를 보여준다.
					ㄴ Scrapy는 이런 수정된 페이지가 아닌, 처음 받아온 html을 사용한다.
					ㄴ 하여, 다음과 같은 것들을 유의해야 한다
						ㄴ 스크래피를 사용하여 DOM에 접근할 때는 js기능을 꺼두는 게 좋다.
						ㄴ ????? full XPath path를 사용하지 마라??
						ㄴ ????? XPath 표현식 안에 'tbody' 태그를 포함시키지 마라.
					ㄴ ~~~~~
				</pre>
				ㅡ 동적 웹 페이지 스크래핑<button>more</button>
				<pre>
					ㄴ 웹 브라우저 상에서는 보이는 데이터들이 스크래피를 이용해 받으면 없는 경우들을 다루는 부분.
						ㄴ 간단하게 js ajax 등을 사용하여 데이터 받아와 dom업데이트로 보여주거나 하는 경우를 말한다.
							이런 경우, 스크래피를 사용하여 받아온 응답 html 안에는 ajax으로 요청해서 받아오게되는 데이터들은 당연히 없다.
					ㄴ 방법은 크게 두 가지를 소개하고 있다.
						ㄴ 해당 데이터가 어디서 오는지를 확인하고 거기서 데이터를 추출하는 방법. (우선적으로 사용하기를 추천한다함)
						ㄴ 'pre-rendering js'를 이용.
					ㄴ 데이터가 어디서 오는지 찾기 )<button>more</button>
					<pre>
						ㄴ 찾으려는 데이터가 text형태가 아니면, 브라우저의 네트워크 탭을 열어 해당 데이터를 받아오는 요청을 찾고 '요청을 복제'하라.
						ㄴ 찾으려는 데이터가 text형태인 경우, 해당 데이터가 js코드 안에 있거나 다른 리소스로부터 온 것일 수 있다.
							ㄴ 이런 경우, 'wgrep'등을 이용하여 해당 데이터가 오는 리소스를 찾고,
								ㄴ 해당 데이터가 처음 ?????
									ㄴ '페이지의 소스 코드를 조사'하여라.
								ㄴ 해당 데이터가 다른 url에서 오는 경우, '요청을 복제'하라.
					</pre>
					ㄴ 'Pre-rending js'
						ㄴ

					ㄴ 페이지의 소스코드 조사하기 )
						ㄴ 데이터가 js 코드 안에 있는 경우,
							ㄴ js code 파싱 )
								ㄴ 찾으려는 데이터가 js 코드로 하드 코딩되어 있다면, js코드를 읽어서 데이터를 추출해야 한다.
								ㄴ js code를 가져오기 위해선..
									ㄴ js파일이 따로 존재할 경우 해당 파일을 요청하여 response.text로 가져오면 된다.
									ㄴ html파일의 < script>태그 안에 들어있다면, scrapy의 'selector'로 < script>태그의 text정보를 가져올 수 있다.
								ㄴ js 코드에서 데이터 추출하기
									ㄴ 정규식 검색 이용
									ㄴ chompjs 이용
									ㄴ js2xml을 이용하여 js 코드를 xml문서로 변환후, 'selector'를 이용해 추출.
						ㄴ 아닌경우
							ㄴ curl, wget 등의 HTTP client를 이용하여 요청을 보내보고, 응답에 데이터가 있는지 확인 해 본다.
								있다면, 이 HTTP client의 요청과 유사하도록 scrapy.http.Request를 만들어 다시 요청한다.
						ㄴ ~~~~~
					ㄴ request 복사 )
						ㄴ 스크래핑 도중에 특정한 요청을 똑같이 복사하여 보내야 하는 경우가 있다.
						ㄴ 웹 브라우저의 네트워크 탭을 이용하여 해당 요청을 보고 스크래피를 이용하여 똑같이 만들면 된다.
						ㄴ 일반적으로는 요청의 메소드와 url을 동일하게하여 'scrapy.http.Request'를 yield하는 것으로 충분하지만,
							헤더나 body, parameter정보가 필요한 경우도 있다.
							ㄴ 이런 경우, scrapy.http.Request의 from_curl()을 사용하면 된다.
							ㄴ 인자로 curl command형식의 문자열을 받아 이 정보와 일치하는 Request를 반환해 주는 메소드이다.
							ㄴ 해당 요청에 대한 curl command는 대부분의 브라우저 네트워크 탭에서 해당 요청을 curl로 변환해주는 기능을 제공하니
								이를 이용하면 된다.
								ㄴ 크롬의 경우, 네트워크 탭에서 요청을 우클릭하면 'curl로 변환하여 복사'기능이 있다.
					ㄴ response 형태가 다른 경우 데이터 추출하기 )
						ㄴ html, xml이면 'selector'를 이용하면 된다.
						ㄴ json이면, 파이썬 표준 라이브러리인 'json'의 json.loads()를 이용하여 추출하라.
							ㄴ ex) data = json.loads(response.text)
						ㄴ js이면 위의 'js code 파싱' 부분처럼 하면 된다.
						ㄴ css이면, 정규식을 이용하여 추출.
						ㄴ ????? 이미지, pdf 등이면, 'response'의 'body'속성으로 바이트 코드로 읽어들인 다음, 'OCR 솔루션'?????을 이용하라.
						ㄴ sbg나 sbg를 포함한 html이면 'selector'로 추출이 가능하다. svg가 xml기반이라서 이라 한다.
					ㄴ 페이지가 추가적인 요청으로 데이터를 가져온다면 그 요청을 복사하여 원하는 데이터를 추출하는게 우선.
						근데 요청을 복사하기가 어렵거나 요청으로부터 얻을 수 없는 데이터인 경우 'Splash'를 사용하면 된다.
						ㄴ 요청에 대한 페이지를 로드하고 이를
						ㄴ js-rendering service이고 'scrapy-splash'를 통하여 사용할 수 있다.
						ㄴ 페이지의 dom을 html으로 반환한다고함.
					ㄴ headless browser 사용하기
						ㄴ 이미 작성된 스크립트가 아닌 파이선코드로 직접 dom과 상호작용하고자 한다면 'headles browser'를 이용하라함.
						* headless browser
							ㅡ 그래픽으로 된 유저 인터페이스가 없는 웹 브라우저.
							ㅡ 웹 브라우저와 비슷한 환경에서????? command-line 인터페이스를 통해 웹페이지 자동화 컨트롤 기능을 제공.
							ㅡ ?????
						ㄴ scrapy에서 headless browser를 사용하는 가장 쉬운 방법은 'selenium'을 이용한느 것이라 한다.

					ㄴ 무제 )

				</pre>
				ㅡ
				ㅡ 무제 )<button>more</button>
				<pre>
					ㄴ 웹 크롤링용 프레임워크
					ㄴ XPath 사용가능? (Beautiful Soup와 다르게)
					ㄴ spider를 정의한 파이선파일을 만들고, scrapy runspider (*파일명*) 식으로 scrapy프레임워크를 실행시키면
						scrapy가 spider정의를 찾아서 크롤러엔진을 통해 이 정의한 spider를 실행시킨다??
					ㄴ 크롤러는 url을 호출하는 것으로 시작, 응답을 parse메소드로 전달하며 parse()호출
					ㄴ 요청이 스케줄되고 비동기적으로 처리될 수 있다.
					ㄴ 그 외에 많은 기능들 존재
						ㄴ css selector, XPath표현식, 정규식을 통한 html, xml로부터 데이터 추출
						ㄴ 상호작용 shell 기능. css,xpath표현식이나 스파이더 테스트에 용이
						ㄴ json,csv,xml등의 파일 export 등등. ('Feed exports')
						ㄴ 인코딩 관련 기능
						ㄴ 확장기능?????
						ㄴ ?????
					ㄴ beatifulSoup처럼 단순히 html문서만을 가지고 동작하여 비동기요청으로 인한 데이터와 요소에 접근 못하는 문제는
						selenium을 사용하거나 scrapy안에 관련 기능이 있을 수 있는지 확인해봐야한다. scrapy동작 원리도 확인해 보면
						답이 나올 수도 있겠다.
						ㄴ https://stackoverflow.com/questions/8550114/can-scrapy-be-used-to-scrape-dynamic-content-from-websites-that-are-using-ajax?rq=1
						ㄴ api에 대고 호출하여 데이터를 가져오거나 selenium을 이용하란 답변들이 보인다.
					ㄴ scrapy 프로젝트 생성 )
						ㄴ 원하는 디렉토리로 이동하여 다음 명령어 입력
							scrapy startproject (*플젝이름*)
						ㄴ 대략 다음과 같은 구성으로 프로젝트폴더가 생성된다
							ㄴ scrapy.cfg 파일
							ㄴ (*플젝이름*) 폴더
								ㄴ 안에 다음과 같은 파일들
								ㄴ __init__.py
								ㄴ items.py
								ㄴ middlewares.py
								ㄴ pipelines.py
								ㄴ settings.py
								ㄴ spiders폴더
									ㄴ 하위에 __init__.py파일과 정의한 '스파이더'파일들이 저장됨.
					ㄴ scarpy에서 'spider'란 용어는 파이썬 클래스를 말하며, Scrapy가 웹사이트로부터 정보를 스크랩하는데 사용하는 클래스이고 개발자가 직접 정의하는 클래스이다.
						ㄴ 'Spider'라는 클래스를 상속하여 만든다.
						ㄴ 정해진 초기 조건을 만족시켜서 정의해야하며, 어떻게 링크를 타고갈건지, 다운받은 데이터들은 어떻게 파싱할건지 등도 설정가능하다.
							ㄴ 초기조건? 그냥 클래스에 정의해야할 속성이나 메소드를 말한다.
								ㄴ name : 정의해야하는 속성. 스파이더의 식별이름으로, 프로젝트에서 유일해야한다.
								ㄴ start_requests() : 정의해야하는 메소드. 'Requests'의 'iterable'을 반환해야한다. (리스트를 반환하든, generator를 만들든)
														스파이더가 크롤링을 시작할 요청목록을 반환하는것이다. 이 초기 요청들로부터 서브 요청들이 지속적으로
														생성되며 크롤링을 하게된다.
								ㄴ parse() : 정의해야하는 메소드. 각 요청이 반환하는 데이터들을 다루는데 쓰이려고 호출되는 메소드.
												'TextResponse'클래스의 인스턴스를 인자로받으며, 이는 응답페이지의 내용과 여러 유용한 메소드들을 포함하고있다.
												일반적으로 응답으로부터 데이터를 dict형태로 추출하고 새로운 url을 찾아 이에대한 새 request를 만드는 일을 한다.
						ㄴ ex)<buttoN>더보기</buttoN>
						<pre>
							import scrapy

							class QuotesSpider(scrapy.Spider):
								name = "quotes"

								def start_requests(self):
									urls = [
										'http://quotes.toscrape.com/page/1/',
										'http://quotes.toscrape.com/page/2/',
									]
									for url in urls:
										yield scrapy.Request(url=url, callback=self.parse)

								def parse(self, response):
									page = response.url.split("/")[-2]
									filename = f'quotes-{page}.html'
									with open(filename, 'wb') as f:
										f.write(response.body)
									self.log(f'Saved file {filename}')
						</pre>
						ㄴ start_requests()대신 클래스에 'start_urls'속성을 정의하여도 된다.
							ㄴ ex)
								start_urls = [
									'http://quotes.toscrape.com/page/1/',
									'http://quotes.toscrape.com/page/2/',
								]
							ㄴ 디폴트로 start_requests()가 생성되고 각 요청에 대해 parse()가 호출된다.
					ㄴ 스파이더 실행방법
						ㄴ 프로젝트의 최상위 폴더로이동하여 다음 명령어 실행
							scrapy crawl (*스파이더이름*)
					ㄴ 실행 과정 )
						ㄴ Scrapy가 start_requests()로부터 'scrapy.Request'객체를 받아 이를 스케줄링.
						ㄴ 각 요청에 대해 응답을 받고 이를 'Response'객체로 객체화.
						ㄴ 각 요청에 맞는 콜백함수를 호출( 디폴트 콜백함수는 parse()이다. )
					ㄴ 데이터 추출 )
						ㄴ Scrapy shell )
							ㄴ 파이썬 대화형 쉘처럼 scrapy를 shell로 빠르게 사용할 수 있는 기능.
							ㄴ 실제로 파이썬 대화형 인터프리터에서 동작한다.
							ㄴ ex) scrapy shell (*url*)
								ㄴ url에 해당하는 요청을 보내고 response를 받은 상태로 파이썬 대화형 인터프리터를 실행시키는듯.
								ㄴ 켜진다음 response 이름을 입력하면 'scrapy.http.response.Response'객체가 들어있는걸 확인할 수 있다.
						ㄴ (*response*).css()
							ㄴ 인자로 css selector와 같은 문자열을 받아 이 selector와 매칭되는 'scrapy.selector.Selector'의 리스트형인 'scrapy.selector.SelectorList'를 반환한다.
							ㄴ 'Selector'로부터 html요소를 나타내는 파이선문자열을 얻을 수 있다. get()이나 'SelectorList'의 getall() 등
						ㄴ re()메소드를 통해 정규표현식으로 데이터 추출이 가능하다.
					ㄴ XPath )
						ㄴ css를 통한 데이터 추출 말고, scrapy는 'XPath 표현식'을 통한 selector도 지원한다.
						ㄴ ????? 나중에 필요하면 공부. 일단은 css selector로도 할수 있으니까.
					ㄴ 스크랩한 데이터 저장 )
						ㄴ scrapy의 'Feed exports'사용
						ㄴ ex) scrapy crawl quotes -O quotes.json
							ㄴ 스파이더를 실행시켜 요청에 대한 콜백함수에서 반환하는 데이터를 json형태로 저장.
							ㄴ -O 옵션은 파일이 이미존재하면 덮어씌움. -o옵션은 끝에 이어붙임.
								ㄴ 근데 json파일에 -o옵션으로 json파일을이어붙이면, json파일 내용물이 json으로서 유효하지않게됨.
								ㄴ json파일을 이어붙이려면, 'JSON Lines'파일형식을 이용하면된다.
									ㄴ ex) scrapy crawl quotes -o quotes.jl
								ㄴ 데이터량이 많을때는 JSON Lines만으로는 안되고 'Item Pipeline'을 이용하라고함.
									ㄴ
					ㄴ follwing link
						ㄴ ~~~~~
					ㄴ ~~~~~

					ㄴ 오류 기록 )
						ㄴ conda install -c conda-forge scrpay 설치시 파이선 버전이 맞지 않는다고 오류발생.
							ㄴ 해결) 가상환경을 낮은버전으로 새로만들어 설치.
				</pre>
			</pre>

			ㅡ 스크래핑 차단 방지<button>more</button>
			<pre>
				ㄴ (*대상 사이트 url*)/robots.txt 로 접속하면 해당 사이트에서 어느 부분이 크롤링이 허용되고 안되는지 명시되어 있다.
					ㄴ 강제력은 없지만 불법과 합법의 기준?이 된다고 한다???
					ㄴ 형식 )
						ㄴ ex)
							User-agent: *
							Allow: /
							Disallow: /search.php
						ㄴ User-agent는 대상 크롤러, 즉, 봇이름을 말하는 듯하다.
						ㄴ 그 봇에 대해 Allow는 크롤링 허용 url을 말하고, Disallow는 금지하는 url.
				ㄴ 요청시 헤더의 'User-Agent'를 브라우저로 만들어서 보내야 한다.
					ㄴ 'python-urllib'같은 걸로 보내면 바로 알아차린다.
				ㄴ 데이터 긁는 속도 조절
					ㄴ 사람이 사용하는 것보다 너무 빠른 속도로 요청을 하면 봇으로 인식하고 차단당함.
					ㄴ 중간중간에 랜덤한 텀을 두어서 방지.
				ㄴ IP 로테이션
					ㄴ 동일한 ip로 계속 접속하면 걸릴 위험이 있다.
					ㄴ ????? 'Tor'라는 암호화 네트워크???를 이용하여 ip확인을 못하도록.
					ㄴ 또는 aws ec2를 여러개 두어서 스크래핑 하는 방법도 ㅣㅇㅆ다함.
			</pre>
			ㅡ 스크래핑 실무<button>more</button>
			<pre>
				ㄴ html구조에서 클래스 명이 랜덤으로 바뀌는 경우가 있음.
			</pre>

			ㅇ 모니터링
				ㅡ 방법 목록 )
					ㄴ (scrapy 사용시) scrapy의 logs, stat 이용
					ㄴ (scrapy 사용시) 'ScrapeOps' 이용
						ㄴ 스크래핑 모니터링 솔루션? 전용 대시보드에서 모니터링 화면을 보여주고, 여러 기능 제공
						ㄴ 유료?
					ㄴ (scarpy 사용시) 'Spidermon' 이용
						ㄴ scrapy 전용 오픈소스 모니터링 모듈
						ㄴ 대시보드가 따로 없음.
						ㄴ 여러 기능들을 제공하며, 직접 구현 필요.
					ㄴ 일반적인 모니터링 및 로깅 툴 사용
						ㄴ 시중에 나와 있는 일반적인 로깅, 모니터링 툴로 직접 구현.

		</pre>

		결제???<button>more</button>
		<pre>
			ㅡ PG사 (payment gateway)
				ㄴ ??? 카드 단말기에서 여러 카드사들과 연결해서 결제를 해주듯이,
					온라인 상에서 여러 카드사들과 연결하여 결제를 할 수 있게 해주는 중간 매개 서비스?
				ㄴ ex ) KG이니시스, 케이에스넷, lg u+, KCP, 나이스정보통신, KICC, ...
					온라인에서 결제할 때 뜨는 창들.
				ㄴ 간편결제도 지원해주는 추세.
			ㅡ VAN사

			ㅡ <img src="image/결제_서비스_프로세스.png"/>
				ㄴ 중간단계로 카드 정보를 전달하지 않기 위해, 카드사와 고객사이에서 먼저 카드 유효성 검증을 진행,
					완료 후, 이 카드 인증 정보를 가지고 결제를 진행하는 방식.
				ㄴ 카드 유효성 검증을 하면 카드사에서 1회성 결제 인증 정보를 준다함.
				ㄴ 카드사와 고객 사이에 직접적인 통신을 통해 카드 유효성 검증을 하기 위해 카드사에선 특정한 프로그램 설치를
					요구한다함. (결제할때 깔으라하는 여러 프로그램들)
				ㄴ ???모바일에 한하여, 카드사들이 이러한 카드 인증 정보를 저장하고 있는 앱을 만들어 매번 유효성 검증이 필요 없이
					결제를 할 수 있도록함?

			ㅡ app to app 결제
				ㄴ
		</pre>

		ㄴ PWA, Progressive Web App <button>more</button>
		<pre>
			ㄴ 개요 
				ㄴ 웹어플의 한 유형. 
				ㄴ 웹 기술로 만들어지지만, standalone 어플처럼 디바이스에 설치 가능. 
				ㄴ 배경 
					ㄴ cross-platform상에서, 각 플랫폼별로 native앱을 개발, 빌드 등의 작업 필요 없이, 
						웹기반 어플 하나만으로 cross-platfor앱을 만들 수 있도록 하기 위함. 
				ㄴ 특징 
					ㄴ 웹 기반 기술로 만들어지기 때문에 하나의 codebase로도 os, device에 국한되지 않고 실행 가능. 
					ㄴ 웹을 통해 바로 접근 가능. 
					ㄴ 플랫폼의 app store 또는 웹을 통해 설치 가능. 
					ㄴ 다른 플랫폼 전용 앱들과 같이, 장치에 앱 아이콘을 가지고 하나의 앱처럼 설치됨. 
					ㄴ 웹 브라우저 없이도 standalone 앱으로서 실행 가능. 
					ㄴ 네트워크가 없어도 실행 가능. 
					ㄴ 백그라운드에서 동작 가능. 
					ㄴ push 알림에 반응 가능. 
					ㄴ 장치, os와 통합 가능. 장치의 기능에 접근하거나, 다른 앱들과 공유하기 기능을 사용하거나 등. 
				ㄴ 한계 
					ㄴ 
				ㄴ 지원 현황 (2025-01-14)
					ㄴ Chromium-based 브라우저 ) 
						ㄴ window, macOs, linux, android 지원. 
						ㄴ google chromem, edge, brave, opera, vivaldi 등. 
					ㄴ firefox, safari ) 
						ㄴ 지원 안함 또는 부분 지원. 
						
			ㄴ 동작 원리 
				ㄴ platform-spec 앱이 동작할 때, os가 이 앱의 실행을 관리하듯, 
					PWA는 ???브라우저 engine?가 PWA의 실행을 관리한다함. 
					즉, 다른 일반 웹사이트처럼 브라우저 안에서 돌아가지는 않지만, 브라우저의 기능을 이용해 돌아가는 것? 
					<img src="image/PWA_architecture.png"/> 

			ㄴ 설치 방법 
				ㄴ PWA를 디바이스에 설치하는 방법은 os마다, 플랫폼마다, 접속하는 브라우저마다 다름. 
				ㄴ 크롬 등의 경우, 상단 url에 설치 마크가 뜨고 클릭시 설치되는식. 
				ㄴ 지원 않는 플랫폼, os, 브라우저의 경우 당연 설치 안됨. 

			ㄴ install을 위한 앱의 필요조건 <button>more</button>
			<pre>
				ㄴ PWA가 앱처럼 설치되기 위해서는 몇가지 조건 충족 필요. 
				ㄴ 조건 충족시, 브라우저가 이를 판단하고 웹앱이 앱으로서 설치될 수 있도록 기능 제공. 
					ㄴ 크롬으로 해보니, 조건만 충족되면 크롬상에서 자동으로 설치 버튼 생김. 
				ㄴ web_app manifest file 포함. 
					ㄴ web_app manifest file 
						ㄴ 브라우저에게 PWA가 어떻게 보여아하고, 디바이스와 어떻게 동작해야하는지를 명시한 Json파일. 
						ㄴ PWA를 설치할 때 필요한 정보들을 포함하고 있는 파일. 앱 이름, 아이콘 등. 
							그 외, 테마 색, 공유 대상으로서의 동작 등 여러 설정 포함.  
						ㄴ ex ) 
							{  // 하나의 json 객체로 구성. 
								"name": "My PWA",
								"icons": [
									{
										"src": "icons/512.png",
										"type": "image/png",
										"sizes": "512x512"
									}
								]
							}
						ㄴ 필수 json항목 
							ㄴ chromium-based 브라우저들(크롬, 엣지, 삼성인터넷 등)의 경우, 다음 항목 필수 
								ㄴ name 또는 short_name 
								ㄴ icons 
									ㄴ 192px, 512px 사이즈짜리 이미지 필요. 
									ㄴ 둘 중 하나만 있음 되는듯? 
								ㄴ start_url 
								ㄴ display, display_override 
								ㄴ prefer_related_applications 
									ㄴ false거나 항목이 없어야함. 
							ㄴ ??? 다른 것들은?
						  
					ㄴ html상에서 < link>태그를 통해 포함됨. 
						ㄴ ex )  
							< html lang="en">
							< head>
								< link rel="manifest" href="manifest.json" /> 
							< /head>
							< body>< /body>
							< /html>
					ㄴ 모든 페이지에 포함되어야함. 
						따라서, 모든 페이지에 < link>태그로 포함시켜야함. 
				ㄴ HTTPS 지원 
					ㄴ사이트가 https를 지원해야함. 
					ㄴ 또는 localhost, 127.0.0.1이어야함. 
			</pre>

			ㄴ 앱스토어를 통한 설치 
				ㄴ PWA가 되기 위한 필요조건 충족시, 앱을 앱스토어도 배포 가능. 
				ㄴ 참고 
					ㄴ https://chromeos.dev/en/publish/pwa-in-play
					ㄴ https://developers.meta.com/horizon/documentation/web/pwa-overview/
					ㄴ https://learn.microsoft.com/en-us/microsoft-edge/progressive-web-apps-chromium/how-to/microsoft-store
				ㄴ 또는 PWABuilder 이용. 

			ㄴ??? PWA가 되기 위한 조건 충족 안해도 일부 플랫폼, 브라우저에선 웹사이트를 앱으로 다운 가능? 

			ㄴ ??? 설치창 커스텀 ? 
				ㄴ 실험적 기능이라함. 패스. 

			ㄴ ??? service worker 
				ㄴ PWA에서 오프라인상태에서의 동작, 백그라운드에서의 동작 기능에 사용되는 컴포넌트. 
				ㄴ service worker 란 
					ㄴ 'web worker'의 일종. 
				ㄴ ??? service worker를 이용해서 PWA웹페이지가 동작하는것 외에 여러가지 가능한 기능들에 대해 다루는듯? 
					알림이나, 백그라운드 동작 등등.
			
			ㄴ ??? caching 
				ㄴ PWA에서, 웹 어플에 필요한 데이터들을 디바이스상에 저장해 놓을 수 있다. 
					ㄴ html, css, image, request를 통해 받아온 데이터 등등. 
				ㄴ 이점 
					ㄴ 온라인 상태가 아니어도 동작 가능. 
					ㄴ 앱의 반응성 증가. 
				ㄴ??? PWA 상에서 뭔가 특별한 기능을 제공한다기보다, Wep API 들을 이용하여 캐싱기능을 구현하는듯. 
			
			ㄴ ~~~

			ㄴ 참고 
				ㄴ https://developer.mozilla.org/en-US/docs/Web/Progressive_web_apps
				ㄴ https://en.wikipedia.org/wiki/Progressive_web_app

		</pre>

	</pre>

	<br>기타 지식<button>더보기</button>
	<pre>
		XPath<button>more</button>
		<pre>
			ㅡ XML Path Language
			ㅡ XML문서의 '노드'들에 대한 쿼리 언어이다.
			ㅡ 파일 경로 같은 '경로식'을 이용하여 노드들을 찾는다.
			ㅡ 축약형 문법과 확장형 문법이 있다.
			ㅡ 문법 )
				ㄴ ex) child::A/descendant-or-self::node()/child::B/child::node()[position()=1]
				ㄴ 축(axis), node test, predicate 로 구성된다.
				ㄴ 축)
					ㄴ 탐색을 어느 방향으로 갈지 결정하는 부분.
					ㄴ 위 예에서 'child', 'descendant-or-self'드으이 부분이 이에 해당.
					<img src="image/XPath_axis.png" height="472"/>
					ㄴ 종류 )
						self :	현재 노드를 선택함.
						attribute : 	현재 노드의 속성 노드를 모두 선택함.
						namespace :	현재 노드의 네임스페이스 노드를 모두 선택함.
						child :	현재 노드의 자식 노드를 모두 선택함.
						descendant :	현재 노드의 자손 노드를 모두 선택함.
						descendant-or-self :	현재 노드와 현재 노드의 자손 노드를 모두 선택함.
						following :	XML 문서에서 현재 노드의 종료 태그 이후에 등장하는 모든 노드를 선택함.
						following-sibling :	현재 노드 이후에 위치하는 형제 노드를 모두 선택함.
						parent :	현재 노드의 부모 노드를 선택함.
						ancestor :	현재 노드의 조상 노드를 모두 선택함.
						ancestor-or-self :	현재 노드와 현재 노드의 조상 노드를 모두 선택함.
						preceding : XML 문서에서 현재 노드 이전에 등장하는 모든 노드를 선택함.
									(조상 노드, 속성 노드, 네임스페이스 노드는 제외함)
						preceding-sibling :	현재 노드 이전에 위치하는 형제 노드를 모두 선택함.
				ㄴ node test )
					ㄴ 표현식에서 특정 노드를 선택하는 부분.
					ㄴ 위의 예에서 '::A', '::node()'등의 부분에 해당.
				ㄴ predicate )
					ㄴ 선택된 노드들을 특정 조건으로 필터링하는데 쓰이는 부분
					ㄴ 위의 예에서 '[position()=1]'에 해당한다.
					ㄴ []안에 조건들이 들어감.
		</pre>

		xml<button>더보기</button>
		<pre>
			* 마크업 언어  : 태그 등을 이용해 문서나 데이터 구조를 명기하는 언어의 일종 (ex) html, xml)
			* 메타 언어 : 대상을 직접 서술하는 언어 그 자체를 언급하는 언어
			* SGML : 문서용 마크업 언어를 정의하기 위한 메타언어. html등을 만들었다.
			* DTD(Document Type Definition) : 해당 문서가 어떤 규칙을 따르는지 나타내는것, 따르는 규칙. '유효성 검사'란것에 쓰임.
			* xml(Extensible Markup Language) : SGML의 확장형으로 다른 언어를 만드는데 쓰려고 만든 다목적 마크업 언어이자 메타언어.

			ㅇ xml이란?
				ㅡ 데이터를 저장하고 전달하기 위한목적으로 만들어졌다. 근데 현재 아주 다양하게 쓰이고 있어 그 목적을 특정하기는 의미가 없는듯하다.
				ㅡ 특징)
					ㄴ 다른 마크업 언어를 만드는데 사용되는 다목적 마크업언어(메타언어)
					ㄴ 다른 시스템끼리의 데이터 교환을 쉽게
					ㄴ 사용자 저으이 태그가 가능하여 확장성이 좋다
					ㄴ 데이터를 보여주는 거이 아닌 전달하는ㄷ데에 쓰인다
					ㄴ 텍스트 데이터 형식의 파일로, 모든내용은 유니코드로 이루어져잇다

			ㅇ 문법)
				<img src="image/xml구조.png" style="height:400px; width:auto;">
				ㄴ 그림과같은 전체적 구조를 가진다.
				ㄴ 문서 맨처음에 < xml>을 통해 xml문서임을 선언해주어야한다.
					ㄴ속성)
						version : xml문서의 버전을말함
						encoding : 문서의 문자셋을 명시
						standalone : 문서가 외부 DTD와 같은 외부 소스데이터에 의존하고있는지 xml파서에게 알려주는 부분. (기본값은 no)
				ㄴ 모든 태그에는 종료태그가 포함되어야 한다.(홀로쓰이는 태그면 끝에 '/'를
						붙여주면 된다.
				ㄴ 대소문자를 구분한다.
				ㄴ 태그를 여닫는 순서가 반드시 지켜져야한다
				ㄴ 띄어쓰기를 인식하므로 주의한다
				ㄴ '<', '>'등등 문서에서특별한 기능으로 사용하는 기호를 예약되어있는 기호라고하며, 이들을 문서상에서 표현하기위해 따로 정해둔 문자셋이있고 이를 '엔터티'라고함
					ㄴ < :  & l t ;
					ㄴ > :  & g t ;
					ㄴ & :  & a m p ;
					ㄴ " :  & q u o t ;
					ㄴ ' :  & a p o s ;
				ㄴ  주석은 < !--- ---- >으로 표현하며, 하이픈(-)의 개수는 상관없다. 단, 주석 내용부분에 두개의 연속한 하이픈은 오류가생긴다.
				ㄴ 문서 선언부다음에 맨처음나오는 태그를 루트요소라고하며 루트요소는 단하나이며, 모든 요소는 이 루트요소안에 포함되어야한다.
				ㄴ 요소의 이름은 영문자,숫자,하이픈(-), 언서스코어(_),점(.)으로만이루어져야하며, 영문자나 언더스코어로 시작하여야한다. 예약어인 xml,XML,Xml은 사용x.
				ㄴ 속성은  <-태그이름- -속성이름-="-속성값-" ...> 형태로 온다.
				ㄴ 네임스페이스)
					ㄴ <(*요소이름*) xmlns="-URI-"> 또는 <(*요소이름*) xmlns:(*ns이름*)="-URI-">.
					ㄴ ns이름을 넣지않는경우 해당요소의 자식요소들은 모두 해당 ns에 속하게 된다. ns이름을 넣을경우
						<(*ns이름*):(*요소이름*)>이런식으로 요소이름앞에 ns이름을써주고 :을 써준다.
					ㄴ URI는 그냥 URL처럼 웹자원을 나타내는 식별자. 여기선 ns를 구분하기위한 용도로 사용한다.

			ㅇ xml 문서의 구분
				ㅡ위 문법을 모두 만족하는 XML문서를  well-formed XML문서 라고한다.
				ㅡwell-formed xml이면서 DTD를 만족하는 xml문서를 valid XML문서 라고 한다.

			ㅇ xml 파서
				ㅡ응용 프로그램이 xml문서를 읽을수 있도록도와주는것.
				ㅡxml문서의 문법을 검토하기도함.
				ㅡhttp://tcpschool.com/lectures/img_xml_parser.png : 파서의 역할

		</pre>

		Database <button>더보기</button>
		<pre>
			ㄴ ~~~~~
			ㄴ db일반<button>더보기</button>
			<pre>
				ㄴ db의 데이터 저장
					ㄴ 다른 메모장, 한글 등의 파일과 마찬가지로 db역시 파일 형태로 보조기억장치(HDD, SSD 등)에 저장된다.
					ㄴ
				ㄴ 인덱스<button>more</button>
				<pre>
					ㄴ 개요 )
						ㄴ 간단히 말해 db에서 검색 성능을 올려주는 어떤 자료구조라고 보면된다.
					ㄴ 종류 )
						ㄴ 단일단계 인덱스 )
							ㄴ 테이블에서 임의의 하나의 컬럼의 값과 그 행의 데이터가 저장되어있는 물리적 주소를 연결해서 테이블로 만든다.
							ㄴ 그 컬럼값을 기준으로 정렬이 되어있어서, 이 컬럼값으로 테이블에서 데이터를 찾고 거기의 물리적 주소를 읽어와 데이터를 찾는식.
							ㄴ 그냥 쌩으로 테이블을 다 뒤지는것보다 빨리 찾을 수 있다.
							ㄴ 그걸 또 이진탐색 등을 이용하여 서치하기때문에 빠르다.
						ㄴ primary index )
							ㄴ primary key를 가지고 인덱스를 만들면 primayr index라고한다.
							ㄴ 희소인덱스
								ㄴ 반대말은 '밀집 인덱스'
							ㄴ primary index는 희소인덱스를 유지할수있다.
						ㄴ 클러스터링 인덱스
							ㄴ db record 순서와 일치되는 인덱스.
								ㄴ 테이블에 record가 저장되는 순서를 결정하는 인덱스.
							ㄴ primary index라고도 한다.
							ㄴ 테이블 당 단 하나만 존재.
							ㄴ 보통 pk지정시, pk가 자동으로 clustered index가 된다.
								ㄴ pk가 아닌 다른 컬럼일 수도 있다.
						ㄴ non-clustered index
							ㄴ clustered가 아닌, 그냥 일반적인 인덱스를 의미.
							ㄴ secondary index라고도 한다.
						ㄴ multi-column index 
							ㄴ composite index
							ㄴ 여러 컬럼으로 구성된 인덱스. 
							ㄴ ~~~
							ㄴ 인덱스의 컬럼 순서
								ㄴ 인덱스 정의시 설정한 컬럼의 순서대로 인덱스 structure의 컬럼이 구성되고, 
									이 컬럼순대로 정렬되어 있다. 
									가령, 컬럼 a,b,c 로 multi index 구성했다면, 인덱스 구조가 
									|a    |b    |c 
									 11    32    113
									 11    35    89
									 11    35    92
									 13    3     23 
									이런식이기 때문에, 이 인덱스를 유의미하게 사용하려면 맨 앞의 컬럼에 대해 인덱스를 적용할 수 있어야함. 
									즉, where 조건 등에 a컬럼이 포함되어야 이 인덱스를 사용하여 a컬럼값으로 먼저 필터링하고 b,c값을 필터링하든말든하는것이지
									b,c값은 특정 a값에 대해서만 정렬이 되어있는거고 b,c값 자체만으로 정렬되어있는게 아니라 
									a값 없이 b,c값만으로는 이 인덱스를 사용하는 의미가 없다. 
							ㄴ 성능
								ㄴ 하나의 컬럼에 대해 쿼리하는 경우면 당연히 single-column index가 더 빠름. 
									multi-column index도 없는것보단 빠르긴하나 single이 더 빠름. 
								ㄴ 여러 컬럼에 대한 쿼리의 경우, '일반적으로' multi-column index가 더 빠름. 
									상황에 따라 다르겠지만, multi-column index없으면, query planner가 
									single-column index를 하나만 적용한 뒤, sequential scan으로 조건체크하거나 
									single index 두개 적용하여 합치는 등의 방식을 사용하는데 multi-column사용하는것보단 느려보임. 
							ㄴ 인덱스 설계
								ㄴ multi-column index를 사용한다면, 
									ㄴ 인덱스를 구성하는 첫번째 컬럼이 쿼리에 없으면 인덱스가 사용되지조차 않으므로 
										첫번째 컬럼을 가장 많이 사용되는 컬럼으로, 
										안쓰이는 경우가 많은 컬럼일 수록 뒤쪽에 배치하는 것이 좋다. 
									ㄴ 추가로, 인덱스 성능을 최대한 끌어올리기 위해 첫번째 컬럼은 되도록 데이터 분배와 cadinarity를 고려하여 선정. 
							ㄴ 참조 
								ㄴ https://stackoverflow.com/questions/179085/multiple-indexes-vs-multi-column-indexes
								ㄴ https://stackoverflow.com/questions/2349817/two-single-column-indexes-vs-one-two-column-index-in-mysql
								ㄴ https://use-the-index-luke.com/sql/where-clause/the-equals-operator/concatenated-keys

					ㄴ 테이블에 대해, 특정 컬럼의 값과 record의 위치를 나타내는 포인터값으로 데이터 묶음을 만드는 것.
						이 데이터 묶음을 컬럼 값에 대해 정렬을 하여, 이 컬럼 값으로 record를 찾을 때 이진 탐색이 가능하게 하여
						탐색 속도를 올려준다.
					ㄴ 위에 말했듯이, 컬럼 값과 record의 포인터 값 저장을 위해 추가적인 저장 공간 사용.
					ㄴ range query condition에서의 인덱스 사용 
						ㄴ where조건에 column1 > 100 and column2 < 200 등과 같은 range 조건이 들어간 경우, 
							db에 따라 약간씩 상이하겠으나, 
							index는 정렬되어 있으므로 range조건에도 인덱스 사용 가능. 
							인덱스에서 column1의 값이 100인곳을 찾아 그 다음부분부터 추출하는 식. 
						ㄴ range조건과 equal조건이 섞여있는 경우, (column1=100 and colum2< 200 등)
							multicolumn index가 있으면 더 쉽게 찾을 수 있다. 
							가령, multicolumn index (column1, column2) 가 있으면 인덱스에서 column1부분에서 100값 찾고 
							column2부분에서 200인 부분부터 추출하는식.  
					ㄴ 인덱스 설계 
						ㄴ 고정된 정답이 없음. 
							위의 인덱스 일반에 대한 내용, 사용하는 database의 인덱스에 대한 내용과 
							프로그램의 로직, 사용하게될 쿼리 등을 고려하여 가장 적절해보이는걸 선택하는 것. 
						ㄴ 인덱스가 많을수록 추가적인 insert, delete비용이 들어감 유의. 
							row 추가, 삭제가 많은 테이블의 경우 유의해야함. 
						ㄴ cardinality? 
							ㄴ 전체 row들 중에서 값이 얼마나 유니크한지를 나타내는 특성? 
								즉 익 ㅔ높으면 전체 row들 중 각 값들이 몇개 안되는거고 낮으면 동일한 값들이 많은 것. 
								전자는 주민번호, 후자는 성별이 예. 
							ㄴ cadinality가 높을수록 좋은 인덱스 후보. 
								서치해야할 대상row의 수가 많이 줄어듦으로. 
						ㄴ 단순히 일반적으로 쿼리에 많이 사용하는 조건을 생각하고 이에 맞게 인덱스를 정의할 수도 있지만, 
							복잡한 쿼리의 경우, query planner가 최적화를 위해 어떤 데이터를 먼저, 어떤식으로 가져올지 정확히 예측하기 어려우므로 
							실제로 사용되는 인덱스는 생각과 다를 수 있다. 
							하여, 성능이 중요하거나 성능이슈가 생기는 테이블의 경우, 키가 되는 컬럼에 대한 인덱스는 모두 있는게 좋다? 
				</pre>

				ㄴ 트랜잭션<button>more</button>
				<pre>
					ㄴ 다음 조건을 따르는 일련의 연산들 묶음을 한 단위로서 지칭하는 개념적인 단어.
						ㄴ ACID 조건 )
							ㄴ atomic (원자성)
								ㄴ 트랜잭션을 구성하는 연산들을 한 묶음으로 보고, 이 연산들 중 하나라도 실패할 경우, 묶음 전체가
									모두 실패처리되고. 이 연산들 모두가 성공해야 묶음 전체가 성공처리 되는 것.
								ㄴ 트랜잭션이 부분적으로 적용되는 것을 방지.
									ㄴ ex ) 송금 트랜잭션에서, 돈 빠져나가는 부분만 적용되고 받는 부분은 적용 안 되는 경우.
							ㄴ consistency(correctness) (일관성)
								ㄴ 다른 트랜잭션에게 영향을 받은 게 아니라면, 한 트랜잭션의 완료 후에도 db가 일관된 상태를 유지해야 한다.
								ㄴ 일관된 상태란, db스키마의 제약 조건들이나 db의 다른 조건들을 만족시키고 있는 상태..???
							ㄴ isolation
								ㄴ 여러 트랜잭션이 들어왔다면, 한번에 한 트랜잭션만 수행될 수 있다. 즉, 나머지 트랜잭션은
					ㄴ 무제 ) <button>more</button>
					<pre>
						ㄴ DBMS는 동시에 시스템을 사용할 수 있는 유저의 숫자를 기준으로 분류될 수 있다.
							ㄴ 한번에 한 명의 유저만 사용할 수 있으면 single-user, 여러명이면 multiuser.
							ㄴ 물론, 대부분의 시스템은 multiuser.
						ㄴ
							ㄴ Interleaved processing에서는 한 프로세스가 돌다가 잠깐 멈추고 다른 프로세스가 돌다가 또 잠깐 멈추는 식으로
								여러 프로세스를 처리할 수 있다.
							ㄴ paralled processing에서는 여러개의 cpu가 있어 여러 프로세스를 동시에 돌릴 수 있다.
							ㄴ db에서 병렬처리에 대한 대부분의 이론들은 interleaved 방식에 관점에서 만들어졌다.
						ㄴ 이런 조건을 갖추게 트랜잭션을 구현을 한다고?

					</pre>
				</pre>

				ㄴ 정규화<button>more</button>
				<pre>
					ㄴ 데이터의 중복을 없애고 무결성을 보장하기 위해, 소위 '정규화 형태'라고 불리는 형식에 따라 관계형 데이터 베이스의 구조를
						결정하는 방식을 말한다.
					ㄴ 다음의 문제를 개선 )
						ㄴ 업데이트 오류 )
							ㄴ 같은 데이터가 여러 곳에 존재할 시, 일부만 업데이트 되어 데이터의 논리적 일치성이 훼손될 수 있음.
						ㄴ 삽입 오류 )
							ㄴ 특정 데이터를 새로 삽입하고자 할때, 이 데이터를 적절히 나타내는 테이블이 없을 시, 데이터를 삽입할 수 없는 이슈
							ㄴ ex )
								???
						ㄴ 삭제 오류 )
							ㄴ 특정 데이터의 삭제가 필연적으로 다른 데이터의 삭제를 동반해야 하는 경우
							ㄴ ex )
								???
					ㄴ 정규화 목록 )<button>more</button>
					<pre>
						ㄴ 제 1정규화 )
							ㄴ 컬럼의 값들이 '원자성'을 가져야 함.
								ㄴ 원자성이란 더 이상 나누어지지 않는 성질.
								ㄴ 즉, 한 컬럼에 여러 가지 데이터가 들어가선 안됨.
							ㄴ ex )
						ㄴ 제 2정규화 )
							ㄴ 후보키가 아닌 컬럼들은 후보키인 컬럼 일부가 아닌 전체에 의존적이어야 한다.
							ㄴ ex )
								'Book' 이란 테이블에서,
								'title', 'format', 'author', 'author_nation', 'price' 컬럼으로 이루어져있고,
								title, format이 후보키라했을 때,
								후보키가 아닌 author, author_nation, price 중 author는 title에는 의존적이지만 foramt에는
								의존적이지 않다. 따라서 제 2정규화를 만족하지 않는다.
						ㄴ 제 3정규화 )
							ㄴ 후보키가 아닌 컬럼들은 다른 후보키가 아닌 컬럼들에 대해 의존성을 가져서는 안된다.
						ㄴ BCNF 정규화 )
							ㄴ 제 3정규화를 강화한 것으로 3.5정규화라고도함.
							ㄴ ~~~
						ㄴ 제 4정규화 )
							ㄴ ~~~
						ㄴ 제 5정규화 )
							ㄴ ~~~

					</pre>
					ㄴ 성능과 반정규화 )
						ㄴ 정규화를 통하여 db에서의 무결성과 중복을 개선할 수 있음.
							허나, 많은 조인으로 인해 성능상의 trade off를 가지는 경향 있음.
						ㄴ 이러한 성능상의 이슈 해결을 위해 정규화된 db 구조를 다시 합치는 것을 '반정규화'라고함.
				</pre>

				ㄴ db 설계<button>more</button>
				<pre>
					ㄴ ~~~~~
					ㄴ 설계 프로세스<button>more</button>
					<pre>
						ㄴ 설계 프로세스의 중요성
							ㄴ ????? db의 규모와 유형에 상관없이 설계 프로세스는 처음부터 끝까지 모두 수행되어야 한다고 한다.
							ㄴ 그렇지 못 할수록 구조의 복잡성, 데이터 무결성 문제 등 db에서 문제가 발생할 확률이 높아진다고 한다.
						ㄴ 임무 명세 및 임무 목표 정의
							ㄴ 인터뷰 진행
							ㄴ 임무 명세 정의
								ㄴ ??? 간결하고 명확하게 DB의 목적을 정의?

							ㄴ 임무 목표 정의
								ㄴ ??? 데이터로 하게될 각각의 기능, 작업을 표현하는 문장?
									ㄴ 느낌상, 프로그램 설계에서 구현해야 할 요구사항과 유사하다.
								ㄴ 이를 어떻게 달성할지는 어플리케이션 단에서 다룰 내용이고,
									이 단계에선 이런 목표들을 참고하여 db를 더 잘 설계하는 것에 관심을 둔다.
								ㄴ 여러 내용이 중복되면 나눌 필요가 있다.
								ㄴ ~~~
						ㄴ 기존 db 분석 )
							ㄴ 기존 db가 존재시, 이에 대한 분석 필요. (db든 종이로된 문서db든)
							ㄴ ~~~
						ㄴ 데이터 구조 생성 )
							ㄴ 테이블, 필드, 키, 필드 명세 정의.
							ㄴ
						ㄴ 테이블 관계 연결 및 결정 )
							ㄴ
						ㄴ 업무 규칙 정의 및 결정 )
							ㄴ ???
						ㄴ 뷰의 정의 및 결정 )
							ㄴ 사용자, 관리자와 인터뷰를 다시 진행하여 그들이 데이터로 작업을 수행하는 방식을 확인하고 이를 토대로 필요한
								뷰를 정의.
						ㄴ 데이터 무결성 재확인 )
							ㄴ

						ㄴ 무제 )
							ㄴ 설계 단계 )
								ㄴ 1. db의 목표와 명세 작성
									ㄴ 임무 명세 )
										ㄴ 일반 언어로 db의 목적을 정의.
										ㄴ ????? 간결하게 목적을 표현해야 한다
									ㄴ 임무 목표 )
										ㄴ db의 데이터가 지원하는 작업들을 표현하는 문장.
								ㄴ 2. 기존의 db가 있는 경우, 이의 분석.
								ㄴ 3. 테이블 구조 생성.
									ㄴ 테이블, 필드 정의, 키 설정, 필드 명세 작성.
									ㄴ
									ㄴ 유형
										ㄴ 데이터 테이블
										ㄴ 연결 테이블
										ㄴ 부분 집합 테이블
										ㄴ 검증 테이블
									ㄴ 테이블 명세서
										ㄴ 정확하게 테이블을 정의하는 문장 포함.
										ㄴ 테이블이 필요한 이유를 설명
										ㄴ 명확하고 간결하게.
										ㄴ db구현과 관련된 내용을 담지 않는다.
										ㄴ 다른 테이블 명세서에 의존적인 명세서를 작성하지 않는다.
											ㄴ '테이블 A의 명세서 참고' 등.
										ㄴ 예제를 넣지 말아라.
									ㄴ 테이블 명
										ㄴ 중복되어서는 안된다.
										ㄴ 테이블이 나타내는 대상을 정확하고 명확하게 나타내는 이름을 만든다.
										ㄴ 가능한 최소 개의의 단어를 사용하라
										ㄴ 물리적 특성을 표현하는 단어는 포함시키지 마라.
											ㄴ file, table등
										ㄴ 머리글자, 약어를 사용하지 마라.
											ㄴ 의미 전달이 어렵다.
										ㄴ 테이블에 들어갈 데이터를 모두 포함할 수 있는 이름이어야 한다.
										ㄴ 둘 이상의 의미를 가지는 이름을 사용하지 마라.
										ㄴ 복수형 이름을 사용한다.
									ㄴ 필드 명
										ㄴ 서술적인 고유한 이름
										ㄴ 필드의 특성을 정확,명확하게 나타내는 이름
										ㄴ 최소 단어 개수 사용
										ㄴ 약어 사용 신중
										ㄴ 불분명한 의미 자제.
										ㄴ 여러 의미를 나타내는 이름 사용 않기
										ㄴ 단수형 사용

					</pre>
					ㄴ json형태 데이터 저장? 
						ㄴ 데이터를 table로서 구조화하여 저장하지 않고 json형태로 통째로 저장하는 방식. 
						ㄴ 고려 요소 
							ㄴ 해당 데이터 수정 여부
								ㄴ json으로 표현하는 데이터를 빈번하게 수정해야하면, json보다는 테이블로 구조화하는게 낫다. 
							ㄴ 데이터 무결성 필요 여부
								ㄴ json으로 표현하는 데이터에 무결성 제약이 필요하다면, 테이블로 구조화하는게 낫다. 
									(json형태에선 무결성 제약이 가능하지도 않을듯)
							ㄴ 데이터 조회 
								ㄴ json으로 표현하는 데이터를 json데이터 내부에 대해 복잡한 방식으로 쿼리할일이 많은 경우, 
									테이블로 구조화하는게 낫다. 
							ㄴ ??? 데이터에 대한 분석 여부? 
								ㄴ json으로 표현하는 데이터에 대한 분석이 필요하다면, 
									복잡한 쿼리가 빈번해지므로 테이블로 구조화하는게 낫다? 
						ㄴ 대안 
							ㄴ json형태로 표현할 데이터 중에서, 중요하다 판단되는 일부 데이터를 컬럼화하여 저장하는 방식. 

					ㄴ 무제 )
						ㄴ 정규화 )
							ㄴ 제 1정규화
							ㄴ 제 2정규화
								ㄴ 조건 ) '키'가 아닌 컬럼들은 모든 '키'인 컬럼들 조합에 의해 결정되어야 함.
								ㄴ 모든 '키' 중 일부에 의해 결정된다면 조건을 만족하지 않은 것.
									키를 변경하거나, 일부에 의해 결정되는 컬럼을 분리해야함.
								ㄴ 키 중 일부만에 의해 결정되는 컬럼이 중복이 되므로.
									불필요하게 같은 내용이 여러번 들어가고, 이 중 일부만 업데이트되는 오류 발생.
							ㄴ 제 3정규화
								ㄴ 후보키가 아닌 컬럼들이 후보키가 아닌 컬럼들에 대해 의존성을 가지는 경우,
									즉, 후보키에 대해서만 의존성을 가져야함.
							ㄴ BCNF (3.5 정규화)
								ㄴ ???
						ㄴ 테이블 개수는 중요한게 아닌가? 구조가 오류가 없고 잘 정규화 되어있어야?

				</pre>

				ㄴ Partition 
					ㄴ ~~~ 
					ㄴ 방법 
						ㄴ Horizontal partitioning (Shard)
							ㄴ 테이블을 row단위로 나누는 방식. 
								가령, column1의 값이 1000이상인 row들은 table_A에, 1000미만인 row들은 table_B에 저장하는 식. 
							ㄴ 장점 
								ㄴ 각 테이블당 row수가 줄어듦으로 당연히 서치 속도 향상. 
									ㄴ 여러 머신에 걸쳐 분산된 경우, 큰 성능 향상. 
							ㄴ ??? 엄밀히 shard와 horizontal partitioning은 다르다? 
						ㄴ Vertical partitioning 
							ㄴ 테이블을 column단위로 나누는 방식. 
								가령, column1, column2, ..., column10이 있다면, column1, column2, column3은 table_A에, 
								column4, column5, column6, ...은 table_B에 저장하는 식.
							ㄴ '정규화'라고도 불리나, vertical partitioning이 더 큰 범위. 
							ㄴ 'row splitting'이라고도 불림. row를 쪼갠다 하여. 

				ㄴ 성능 튜닝(최적화)<button>more</button>
				<pre>
					ㄴ 성능 측정 기준 )
						ㄴ ??? 실질적으로 block I/O를 줄이는 정도가 판가름?
					ㄴ ~~~
					ㄴ 방법 ) <button>more</button>
					<pre>
						ㄴ db 설계 )
							ㄴ ??? 파티션
							ㄴ ??? 클러스터링
							ㄴ 정규화/반정규화
							ㄴ 인덱스
							ㄴ 적절한 데이터 타입 설정

						ㄴ DBMS 관련 )
							ㄴ ??? DBMS의 설정값 변경을 통한 성능 최적화.

						ㄴ SQL 관련 )
							ㄴ 적절한 조인 방식 사용
							ㄴ 인덱스를 활용한 쿼리
							ㄴ sql hint 사용


					</pre>
					ㄴ 성능에 영향을 주는 요인들 
						ㄴ db 설정값 수정.
						ㄴ 인덱스
						ㄴ 반환 데이터 크기 조정 
						ㄴ 시스템 리소스 
						ㄴ 동시에 실행되는 연산들. 동시에 실행되는 다른 유저의 쿼리 등. 
						ㄴ 캐싱. 
						ㄴ 네트워크 지연
						ㄴ wait event 
						ㄴ 파티션
							ㄴ 크기가 큰 테이블에 대해, 이 테이블에 접근시 전체를 다 훑는게 아니라,
								특정 기준으로 데이터를 나누어 저장하여 그 기준값에 따라 해당 파티션에 접근시켜 속도를 개선하는 방식.
						ㄴ 데이터 구조 변경
							ㄴ 실행중인 프로그램에 대해 데이터 모델을 변경하는 것은 많은 수정을 필요로 하지만, 필요한 경우 어쩔 수 없다.
						ㄴ 쿼리 튜닝
						ㄴ hint 사용 : 쿼리 옵티마이저가 항상 최적의 튜닝을 하는것은 아니므로 hint를 사용하여 임의 설정이 필요한 경우가 있음.
						ㄴ sql 재작성
							ㄴ 절차적으로 작성된 쿼리는 집합적으로 재작성 필요.
				</pre>

				ㄴ 백업
					ㄴ ~~~
					ㄴ ??? 백업 전략
						ㄴ 백업 방법 분류
							ㄴ online backup / offline backup
								ㄴ online backup
									ㄴ db실행 중에 백업을 진행하는 방식.
									ㄴ cold backup 이라고도함.
									ㄴ 백업 과정에서의 db변경사항도 가져가고자 한다면 archive log를 백업하고 있어야함.
										ㄴ archive log란 db변경사항에 대한 로그.
							ㄴ 전체 백업
								ㄴ ??? 물리적 백업?
								ㄴ ??? 모든 데이터를 백업 & 백업이 진행되는 중에 생긴 트랜잭션 로그 백업.
								ㄴ ??? db가 offline 상태에서 백업하는 경우 로그 필요 없고 online 상태에서 백업하는 경우 필요?
							ㄴ 차등 백업
								ㄴ ??? 가장 마지막 전체 백업 이후에 변경된 데이터만 백업.
							ㄴ 트랜잭션 로그 백업
								ㄴ ??? 트랜잭션 로그 파일 백업
						ㄴ 일반적으로 백업 방법들을 조합하여 백업 전략 설정.
							ex ) 전체 백업(주 1회, 2주분 보관) + 차등 백업(일 1회, 7일분 보관) + 트랜잭션 백업(시간당 1회, 3일분 보관)

				ㄴ Row-oriented db vs column-oriented db
					ㄴ
					ㄴ ex )
						번호 	이름 	나이
						11		john 	19
						13		steve 	23
						19 		kate 	21
					ㄴ row-oriented db
						ㄴ row 하나를 직렬화하여 저장하는 방식.
							즉, 위 예에서, (11, john, 19)를 한줄로 저장, (19, kate, 21)을 한 줄로 저장하는 식.
							간단히말해, row하나를 한줄로 저장하는 방식.
						ㄴ row 전체 데이터를 적은 비용으로 가져올 수 있도록 설계된것.
						ㄴ 많은 경우에 적합한 방식. 쇼핑몰의 상품에 대한 정보를 가져오거나, 회원에 대한 정보를 가져오거나 등.
					ㄴ column-oriented db
						ㄴ 컬럼 하나를 직렬화하여 저장하는 방식.
							즉, 위 예에서, 번호인 (11, 13, 19)를 한줄로 저장, (john, steve, kate)를 한 줄로 저장하는 식.

				ㄴ OLTP (=Online Transaction Processing)
					ㄴ

				ㄴ database Page
					ㄴ

			</pre>

			ㄴ NoSQL<button>more</button>
			<pre>
				ㄴ ~~~~~
				ㄴ 분류 <button>more</button>
				<pre>
					ㄴ 모호하기는 하지만 대략 다음과 같이 분류하고 있다고 한다.
					ㄴ wide column store
					ㄴ document-oriented db<button>more</button>
					<pre>
						ㄴ document 형태의 데이터를 저장하고 관리하는 프로그램.
						ㄴ XML db도 이것의 일종
						ㄴ key-value db의 서브클래스와 같다고 볼 수 있다.
							ㄴ key-value db는 실제 들은 데이터가 db에게는 보이지 않는 반면, document-oriented db에서는 document의 내부 구조에
								의존한다.
						ㄴ RDB와 완전히 대칭점에 있다.
							ㄴ ????? RDB는 개발자가 정의한 테이블에 데이터들을 분리하여 저장하고 하나의 객체는 여러 테이블에 분산되어 있을 수 있지만
							ㄴ ????? document db는 주어진 객체의 모든 정보를 하나의 db인스턴스???에 저장하고 모든 저장된 객체는 다른 모든 객체와 다를 수 있다.
								ㄴ 때문에 ORM이 필요 없다 한다.
						ㄴ 각 document-oriented db에 따라 구체적인 내용은 조금씩 달라도, 공통적으로
							document가 XML, YAML, JSON등과 같은 형식으로 데이터를 인코딩하고 캡슐화 하고 있다고 가정한다.
						ㄴ document-oriented db에서 'document'는 프로그래밍에서 '객체'의 개념과 거의 유사하다.
							ㄴ 각 'document'들은 특정 형식을 준수할 필요가 없다.
							ㄴ 한 store안에 'document'들의 타입이 같은 필요가 없고 내부의 필드들이 있어도 되고 없어도 된다. 서로 다른 형식으로 인코딩 되어 있을 수도 있다.
						ㄴ db 종류<button>more</button>
						<pre>
							ㄴ MongoDB<button>more</button>
							<pre>
								ㄴ
									ㄴ 각 record를 'document'라 부른다.
									ㄴ 'document'는 필드와 그 값 쌍으로 구성되어있는 data structure이다. json 객체와 유사하다고 보면 된다.
									ㄴ 키-값 쌍에서 값은 다른 'document'나 배열 등을 포함할 수 있다.
									ㄴ 장점 )
										ㄴ 'document'의 구성은 프로그래밍 언어의 '객체'와 매우 유사하다.
										ㄴ 값으로 'document'나 다른 배열을 담을 수 있는 것은 join작업의 필요성을 줄여준다.
										ㄴ record의 형태가 자유롭다.

								ㄴ Driver<button>more</button>
								<pre>
									ㄴ ~~~~
									ㄴ Python Driver<button>more</button>
									<pre>
										ㄴ 참조 ) https://docs.mongodb.com/drivers/pymongo/
										ㄴ ex)
											import pymongo

											client = pymongo.MongoClient('localhost', 27017)
											db = client.(*db명*)
											collection = db.(*컬렉션명*)

											collection.insert_one( (*파이션 dict형 데이터*) ) #db에 데이터가 삽입됨.
									</pre>
								</pre>

								ㄴ 무제 )<button>more</button>
								<pre>
									ㄴ 데이터를 JSON형태와 같이 저장한다.
										ㄴ 해서, 안의 필드들의 데이터 타입에 구애받지 않고, 어떤 필드들이 있는지 없는지에 관해서도 규약이 없다.
									ㄴ 데이터들에 대해 인덱싱, 집계, 쿼리가 가능하다.
									ㄴ db의 record를 'document'라 부른다.
									ㄴ 'document'를 'collection'안에 저장한다. 'collection'은 RDB의 테이블과 유사하다고 생각하면 된다.
									ㄴ 읽기만 가능한 'View'와 'On-Demand Materialized View'?????를 제공한다.
									ㄴ 장점 )
										ㄴ 성능
											ㄴ embedded data model 기능이 db시스템의 I/O작업을 줄여준다?????
											ㄴ 인덱스가 쿼리를 빠르게하고, embedded document나 배열의 키를 포함할 수 있다?????
										ㄴ 풍부한 쿼리언어
											ㄴ CRUD작업을 위한 쿼리언어 지원
											ㄴ 집계기능, 문자 검색, 'Geospatial query'?????
										ㄴ ????? High availability
										ㄴ ????? 수평 확장성
										ㄴ ????? multiple storage engine
									ㄴ mongodb shell에서..
										ㄴ 명령어 )
											ㄴ db : 현재 참조하고 있는 db이름 출력
											ㄴ use (*db명*) : 참조할 db변경
												ㄴ 없는 db명이면, 해당 db에 데이터를 처음 집어넣을 때 새로 생성.
										ㄴ collection
											ㄴ 컬렉션이 존재하지 않으면 처음 데이터 넣을 때, 자동으로 생성해 준다.
									ㄴ db는 하나 이상의 'collection'을 저장한다.
									ㄴ insertOne(), insertMany() 'collection'에 'document'를 넣는 메소드.
									ㄴ db와 'collection'이름에는 지켜야 하는 규칙이 있다.
									ㄴ db.createCollection()을 통해 명시적으로 'collection'을 생성할 수 있다.
										ㄴ 다양한 옵션들로 'collection'의 설정 정보를 정할 수 있다.
										ㄴ 이러한 'collection'의 설정정보들을 수정하려면 'collMod'를 이용하라.
									ㄴ 'collection'내의 'document'들은 내부의 데이터 타입이나 필드들이 같을 필요가 없다.
										ㄴ 같게 하고 싶다면 'document validation'을 사용하라.
									ㄴ 'document'의 구조를 바꿀 수도 있다. (필드 수정이나 타입변경 등)
									ㄴ 'collection'은 불변인 'UUID'를 할당받는다.
										ㄴ ????? 이 UUID는 replica와 shard들 간에 공유된다.
										ㄴ UUID확인하려면 listCollections명령어나 db.getCollectionInfos()메소드 호출.
									ㄴ 'View'
										ㄴ 다른 'collection'이나 'View'의 'aggregation pipeline'에 의해 내용물들이 결정되는
											쿼리 가능한 객체.
										ㄴ disk상에 저장되지 않으며, 클라이언트에서 view를 대상으로 쿼리할 때만 계산된다.
										ㄴ 'view'에대해 클라이언트가 쿼리하는 것에 대한 권한 설정이 가능하다
										ㄴ 'view에 대한 쓰기 작업은 불가하다. 읽기만 가능하다.
										ㄴ ????? 클ㄹ라이언트가 'view'에 대해 쿼리하면, mongodb는 'pipeline'??에 그 쿼리를 이어붙여 이를 반환한다.
										ㄴ ????? db.createCollection(), create명령어나 db.createView()를 통하여 'view'생성 가능.
										ㄴ source가 되는 'collection'과 같은 db에서 생성하여야 한다.
										ㄴ 다음 메소드 사용 가능
											ㄴ db.collections.find(), db.collections.findOne(), db.collections.aggregate(),
												db.collections.countDocuments(), db.collections.estimatedDocumentCount(),
												db.collections.count(), db.collections.distinct()
										ㄴ index, sort
											ㄴ 소스 'collection'의 인덱스를 사용한다.
											ㄴ ?????
										ㄴ projection 규약?????
										ㄴ 'view'이름을 수정할 수 없다.
										ㄴ view 생성?????
											ㄴ ?????
										ㄴ ????? sharded view
										ㄴ ????? collation
										ㄴ ????? public view definition
										ㄴ db.collection.drop()을 통해 뷰 제거 가능.
										ㄴ 사용가능한 메소드들
											ㄴ ~~~~~
									ㄴ ????? 'On-Demand Materialized View'
										ㄴ aggergate pipeline으로 부터 나온 'stage'???들을 'collection'에 쌓아오리ㅓㅣ
									ㄴ Document
										ㄴ mongodb는 record를 'BSON'으로 저장한다.
										ㄴ 키값 쌍의 데이터이고
										ㄴ 값으로는 BSON의 어떤 데이터 타입도 올 수 있다.
									ㄴ ~~~~~
									ㄴ 데이터 모델링
										ㄴ 다른 db들에 비해 유연하다. 정해진 스키마가 고정되지 않아도 된다.
											ㄴ 이를 통해 '객체'나 '엔터티'를 매핑하는게 수월하다.
										ㄴ embedded 'document'
										ㄴ reference
											ㄴ document는 필드로 또 다른 document를 참조 할 수 있다.
										ㄴ mongodb에서, 쓰기 작업은 하나의 document에 대해서 원자성을 보장한다.
											ㄴ embedded document를 수정할 때에도.
											ㄴ embedded 형태의 'denormalized data'는 쓰기작업에서 원자성을 보장하기 수월하게 해준다.
											ㄴ 쓰기 작업이 여러 document들을 수정할 때는, 각 document들에 대해서는 원자성을 보장하지만, 전체에 대해서는 아니다.
												ㄴ 이 경우에도 원자성을 보장하는 방법이 있다함. (문서의 'transactions'항목)
										ㄴ 디자인
											ㄴ embedded 모델
												ㄴ embedded되는 'document'를 포함하는 경우 사용
												ㄴ document는 최대 BSON 데이터 크기 제한을 가지고 있다.
											ㄴ reference 이용
												ㄴ embedded document의 이용이 데이터의 중복을 발생시키면서, embedded를 이점인 읽기 작업의 성능이
													충분히 발휘되지 않을 때
												ㄴ 다대다 관계 연결이 필요한 경우
												ㄴ ????? 규모가 큰 계층형 데이터를 모델링할때???
											ㄴ ~~~~~
										ㄴ 예시, 패턴 )
											ㄴ 일대일 )
												ㄴ 포함하고 있는 데이터일 경우, embedded 형태를 사용한다. ex) 사람 컬렉션 안에 embedded document로 포함된 주소 컬렉션
												ㄴ 너무 포함된 데이터가 많은 경우, reference로 빼낸다. 이를 'subset pattern'이라 함.
													ㄴ 너무 embedded된 데이터가 많은 경우, 불필요한 load를 가져오게 되므로.
													ㄴ 당연히 이렇게 나누게 되면 나뉘어진 데이터를 가져올 때 비용이 더 들고, 이런 데이터들을 추적하기 어려워지므로
														적절하게 사용하여야 한다.
											ㄴ embedded를 이용한 일대다 관계
												ㄴ '사람'엔터티와 매핑되는 여러개의 '주소'엔터티가 있는 경우, reference를 이용하려면
													'주소'에서 '사람'에 대한 참조를 가지고 있어야 한다. 이런 경우, '사람'의 이름으로 '주소'를 찾으려면
													여러개의 쿼리가 나가야 '주소'를 찾을 수 있다.
												ㄴ 이런 경우는, 'reference'보다는 embedded를 이용하여 '사람'엔터티가 여러개의 '주소'엔터티를
													포함하고 있는 게 적절하다.
												ㄴ 이러한 경우에 embedded를 사용하는 경우에도 'subset pattern'을 사용하여 너무 embedded되는 데이터가
													많을 경우 적절하게 나눌 수 있다.
											ㄴ reference를 이용한 일대다 관계 )
												ㄴ embedded와 유사. '퍼블리셔', '책'의 예를 들면, '퍼블리셔'당 '책'의 수가 적고 제한적이면
													'퍼블리셔'안에 '책'에 대한 참조를 넣으면 되고, '퍼블리셔'당 '책'의 수가 많고 제한 없이 증가하면
													'책'에서'퍼블리셔'에 대한 참조를 가지고 있는 것이 적절할 수도 있다.
												ㄴ 컬렉션의 필드로 다른 컬렉션의 키값을 가지는 배열을 가지고 있으면
											ㄴ 트리 구조 )
												ㄴ
									ㄴ ~~~~~
									ㄴ Sharding )
										ㄴ mongodb에서 여러 기계에 db를 분배하는 방법을 말함.
										ㄴ 쉬운 수평적 확장과 큰 규모의 데이터 set과 높은 연산 성능의 이점이 있다.

								</pre>
							</pre>
						</pre>
					</pre>
					ㄴ key-value db<button>more</button>
					<pre>
						ㄴ Map, dictionary, hash 등과 같은 '연관 배열'의 저장, 검색, 관리를 위한 db 패러다임.
						ㄴ ~~~~~
					</pre>
					ㄴ graph db
				</pre>

			</pre>

			MySQL<button>더보기</button>
			<pre>
				ㅇ MYSQL
					ㅡ 참조 : https://dev.mysql.com/doc/refman/8.0/en/preface.html
					ㅡ 디비란 그냥 정보를 저장한 것?
					ㅡ dbms ( database management system)이란 말그대로 사용자가 db를 관리하게 해주는 소프트웨어.
						ㄴ 디비를 defining, constructing, manipulating, sharing을 쉽게 하게해줌.
							ㄴ defining : 디비의 데이터 타입, 구조, 제약조건 등을 명시하는것
							ㄴ constructing : 디비에 데이터를 저장하는것.
							ㄴ manipulating : 특정 데이터 추출을 위한 쿼리나 업데이트, 기록 출력 등의 함수를 실행하는것.
							ㄴ sharing : 여러 사용자가 디비에 동시에 접근하게 해주는것.
						ㄴ 추가적으로 디비 protecting, maintaining의 기능도 한다.
							ㄴ protecting : 보안상의 공격이나 기능상의 문제로부터 디비를 보호하는것
							ㄴ maintain : 디비시스템을 업데이트해주는것
					ㅡ 어플리케이션 프로그램은 '쿼리'를 보냄으로서 디비에 접근한다.

					ㅡ 결국 디비프로그램은 그냥 파일에 데이터 저장하는 것을 좀더 체계적으로 저장하고 이를 편리하게 조작할 수 있게 해주는 등의 기능을 제공하는 프로그램의 일종?
						ㄴ image폴더의 dbms 구조 예.png
					ㅡ 기타 알아두어야 할것 )
						ㄴ 디비명과 테이블명은 case-sensitive이다. (unix에서만. window는 해당안된다함. 그래도 헷갈리니까 걍 다이렇게알고잇자)

					ㅡ 더 알아봐야하나?
						ㄴ 파일에 데이터를 저장하고, 읽어오고 이런게 기반기술??이고 이건 내가 아는 부분과 맞닿아있기때문인가?
						ㄴ 그 외에 나머지부분들(내부적으로 이를 기반으로 돌아가는 알고리즘? 같은거)은 정확하게 모르긴해도 굳이 지금 공부할 이유는 없는 부분이라 안궁금한건가? 일단 전체적인 윤곽은 잡았으니 나중에 필요하면 그때 와서 공부하면 되니까.
							ㄴ 늘 말하듯이 모든걸 다 공부할 수 는 없으니 윤곽만이라도 파악해두고 나중에 필요할 때 와서 공부하는 방식이 괜찮다고 생각하기때문?

				ㅇ db 권한
					ㅡ 모든 디비접근은 해당 디비에 대한 권한이 있어야 가능.
						ㄴ GRANT ALL ON menagerie.* TO 'your_mysql_name'@'your_client_host'; 와 같은 명령문을 관리자계정에서 실행하는것을 통해
							권한 부여가 가능하다.

				ㅇ 디비 명령어
					ㅡ 처음 연결 )
						ㄴ 'mysql' 명령어를 사용한다.
						ㄴ mysql -h (*host명*) -u (*유저명*) -p 입력후, 나오는 비번입력해주면 접속.
					ㅡ 데이터 베이스 조회 )
						ㄴ show databases : 존재하는 db목록을 보여준다.
							ㄴ 권한이 없는 db는 보여주지 않는다.
					ㅡ db 선택 )
						ㄴ use (*db명*) : 해당 디비로 접근한다.
					ㅡ db 생성 )
						ㄴ create database (*디비명*) : 디비생성
					ㅡ 테이블 목록 조회 )
						ㄴ show tables : 디비의 모든 테이블 출력.
					ㅡ 테이블 생성 )
						ㄴ CREATE TABLE (*테이블명*) (name VARCHAR(20), owner VARCHAR(20),
							species VARCHAR(20), sex CHAR(1), birth DATE, death DATE);
					ㅡ 특정 테이블 조회 )
						ㄴ describe (*테이블명*) : 해당 테이블 구조 출력.
					ㅡ 테이블 입력 )
						ㄴ 텍스트 파일을 이용한 입력 )
							ㄴ LOAD DATA LOCAL INFILE '/path/pet.txt' INTO TABLE pet; : 텍스트파일을 통해 테이블에 값입력.
							ㄴ 텍스트 파일 예
								Whistler        Gwen    bird    \N      1997-12-09      \N
								ㄴ 한줄에 테이블의 한 row를 입력하며 tab키로 컬럼을 구분, 비워둘 컬럼은 \N(null)을 이용해 채움.
								ㄴ local data에대한 사용가능 문제로 안될 수 도 있다.
						ㄴ 명령어를 통한 입력 )
							ㄴINSERT INTO pet VALUES ('Puffball','Diane','hamster','f','1999-03-30',NULL);
							ㄴ 테이블의 칼럼순으로 데이터를 입력한다.
					ㅡ 데이터 검색 )
						ㄴ SELECT (*컬럼들 또는 * *) FROM (*테이블*) WHERE (*조건*) ;
						ㄴ 조건 목록 )
							ㄴ order by )
								ㄴ 데이터들을 정렬하여 받을 수 있다.
								ㄴ ex) select * from aaa order by (*컬럼명*) =>컬럼명을 기준으로 오름차순 순서로 정렬하여 검색한다.
								ㄴ 디폴트는 오름차순이며 내림차순으로 정렬하려면 (*컬럼명*)뒤에 DESC 키워드를 붙여주면된다.
								ㄴ 여러 컬럼을 기준으로 정렬도 가능하다.
									ㄴ ex) select (*컬럼*) from (*테이블*) order by (*컬럼1*), (*컬럼2*) DESC ; 	=>컬럼 1을 기준으로 오름차순 정렬후, 컬럼2를 기준으로 내림차순 정렬하여 검색.
						ㄴ 쿼리문에 date calculation 함수를 사용 할 수 있다.
							ㄴ ex) 	SELECT name, birth, MONTH(birth) FROM pet;
								SELECT name, birth, CURDATE(), TIMESTAMPDIFF(YEAR,birth,CURDATE()) AS age FROM pet ORDER BY age;
						ㄴ ??? NULL
						ㄴ pattern matching 기능 )
							ㄴ 검색문에서 특정 패턴을 조건으로 검색할 수 있다.
							ㄴ 'LIKE', 'NOT LIKE' 키워드 뒤에 원하는 패턴을 주어 검색하며, 패턴에는 '%'와 '_'을 사용한다.
								ㄴ % : 임의의 수의 문자들을 나타냄. (임의의 수에는 0도 포함이다)
								ㄴ _ : 단 하나의 문자를 나타냄.
							ㄴ ex)	SELECT * FROM pet WHERE name LIKE 'b%';	=>name의 값으로 'b' 이후에 임의의 문자들이 오는 경우를 검색. buffy, bower 등이 검색된다.
								SELECT * FROM pet WHERE name LIKE '%w%';	=> 임의의 문자들 다음 'w'가 오고 다시 임의의 문자들이 오는 패턴 검색. claws, bower, whistler 등이 검색된다.
								SELECT * FROM pet WHERE name LIKE '_____';	=> _가 다섯개가 있으므로 name의 값이 정확히 다섯개가 되는 패턴이 검색. claws, buffy 등이 검색된다.
							ㄴ 그 이외의 패턴을 사용하고자 한다면, mysql에선 extended regular expressions을 제공한다.
								ㄴ regexp_like()함수를 사용하여 추가적인 패턴 검색을 할 수 있다.
								ㄴ 참조 https://dev.mysql.com/doc/refman/8.0/en/pattern-matching.html
						ㄴ counting row 기능 )
							ㄴ 검색 결과에 대해 합계, 평균, 카운팅 등의 작업을 수행할 수는 기능이 있다.
							ㄴ 참조 https://dev.mysql.com/doc/refman/8.0/en/group-by-functions.html
						ㄴ 여러 테이블 묶어서 검색하기 )
							ㄴ inner join과 on 키워드를 통하여 여러 테이블로부터 검색을 수행 할 수 있다.
							ㄴ ex)	SELECT pet.name,
								TIMESTAMPDIFF(YEAR,birth,date) AS age,
								remark
								FROM pet INNER JOIN event		=>pet 테이블과 event 테이블을 묶었다.
								ON pet.name = event.name		=>on 키워드를 통하여 pet테이블의 name과 event테이블의 name을 검색쿼리상에서 같은것으로 취급하고 있다.
								WHERE event.type = 'litter';		=>두 테이블을 묶었기 때문에 컬럼을 사용할때 어떤 테이블의 컬럼인지를 도트(.)를 이용해 명시해주어야한ㄴ다.
						ㄴ 예시들 )
							ㄴ SELECT MAX(article) AS article FROM shop;
							ㄴ SELECT * FROM pet WHERE birth >= '1998-1-1';
							ㄴ SELECT * FROM pet WHERE species = 'dog' AND sex = 'f';
							ㄴ SELECT * FROM pet WHERE (species = 'cat' AND sex = 'm')
									OR (species = 'dog' AND sex = 'f');
							ㄴ SELECT name, birth FROM pet;
							ㄴ SELECT name, species, birth FROM pet ORDER BY species, birth DESC;
					ㅡ??? batch mode에서 사용하기 )
						ㄴ 참조 https://dev.mysql.com/doc/refman/8.0/en/batch-mode.html


					ㅡ 테이블 변경 )
						ㄴ alter 명령어 )
							ㄴ alter table (*table이름*) add column (*컬럼이름*) (*컬럼형식*) (*옵션*) : 테이블에 컬럼추가
							ㄴ alter table (*table명*) modify column (*컬럼이름*) (*컬럼형식*) (*옵션*) : 테이블의 컬럼 변경
						ㄴ UPDATE pet SET birth = '1989-08-31' WHERE name = 'Bowser'; : 업데이트 명령어.
					ㅡ auto_increment )
						ㄴ 컬럼 설정할때 뒤에 옵션에 'auto_increment'라고 설정하면된다
						ㄴ aaa int auto_increment
					ㅡ primary key )
						ㄴ 컬럼 설정할때 뒤에 옵션에 'primary key'라고 설정하면된다.
						ㄴ 보통 not null옵션과 같이쓰는듯하다.
					ㅡ 컬럼 디폴트값 설정 )
						ㄴ 컬럼 설정할때 뒤에 옵션에 'default'키워드를 쓰고 다음에 디폴트로 설정할 값을 써주면된다
						ㄴ ex) aaa int default 1
					ㅡ 시간 컬럼 설정하기 )
						ㄴ 컬럼 설정할때 컬럼 형식으로 datetime을 사용하고 디폴트값으로 'current_timestamp'를 설정하면 데이터가 삽이되는 시간이 디폴트값으로 설정된다.
						ㄴ aaa int default current_timestamp
					ㅡ 삭제 )
						ㄴ delete from (*테이블명*) where ~~
					ㅡ null값 검색 )
						ㄴ where (*컬럼명*) = null 이런식으로하면 안되고, where (*컬럼명*) is null 으로 해야 된다.

				ㅡ 일단 아주 기초적인것들은 알았으니 여기까지만하고, 더 필요하면 reference참고해서 공부하도록하자.
					ㄴ 데이터 타입, mysql 프로그램, 서버쪽 클라이언트쪽, statement가 어떻게돌아가는지, 함수들... 공부할게 너무 많다. 일단 다른것부터 하자.

				ㅇ java에서 mysql사용하기
					ㅡ jdbc라는 툴을 사용하여 커뮤니케이션한다.

				ㅡ ResultSet 관련)
					ㄴ 쓸만한 메소드들)
						ㄴ https://docs.oracle.com/javase/8/docs/api/java/sql/ResultSet.html  오라클 jdbc api참조
						ㄴ boolean absolut ( int row ) : 해당 row번호로 커서를 이동.
						ㄴ boolean first() : 커서를 맨처음으로 이동. 1번의미.
						ㄴ (*데이터형*) get(*데이터형*) () : 데이터 받는 메소드. 데이터형태 무수히 많음.
						ㄴ ResultSetMetaData getMetaData() : resultset의 컬럼에 대한 정보를 알려주는 객체 반환. 컬럼의 개수 타입 속성등을 알수있다.
						ㄴ int getRow() : 현재 row의 번호를 반환.
						ㄴ boolean isLast() : 커서가 현재 마지막row인지 판별.
						ㄴ boolean last() : 커서를 마지막위치로 이동.
						ㄴ boolean next() : 커서를 다음row로 이동
						ㄴ boolean previous() : 커서를 한줄 위로 이동.
						ㄴ boolean relative ( int row ) : 커서를 상대위치로 이동. row의 값이 양수면 다음으로 음수면 이전으로 이동.
						ㄴ void beforeFrist() : 커서를 첫번째 바로 이전 위치로 이동시킨다. 0번의미.
						ㄴ 등등..
					ㄴ ResultSet 객체받고 맨처음 next()하기 전에는 커서가 0을 가리키고잇으며 이는 row를 가리키는게 아니다. 쿼리결과의 첫번째 row는 1번부터이다.

			</pre>

			ㄴ Postgresql<button>more</button>
			<pre> 
				ㄴ 기본 설치 및 세팅 
					ㄴ ~~~ 
					ㄴ 

				ㄴ SQL 문법 <button>more</button>
				<pre>
					ㄴ 구문 구조 <button>more</button>
					<pre>
						ㄴ 명령어는 여러개의 'token'으로 구성.
						ㄴ 'token'은 'key word', 'identifier', 'quoted identifier', 'literal', 'constant', 등이 될 수 있음.
						ㄴ 토큰들은 일반적으로 space, tab, newline 등으로 구분.
						ㄴ sql 구문 문법은 토큰이 무엇인지에 따라 달라짐.
						ㄴ keyword
							ㄴ sql 구문 문법상에서 이미 의미가 정해져 고정된 단어들.
							ㄴ ex ) insert, select, values, on 등.
							ㄴ 전체 목록은 문서 부록에 존재.
						ㄴ identifier
							ㄴ postgresql의 object? 등을 식별하는 단어.
							ㄴ ex ) 테이블명, 컬럼명, 다른 postgresql object명 등.
						ㄴ keyword, identifier는 소문자문자나 underscore로 시작해야함.
							구성은 소문자, 숫자, underscore, $ 사용 가능.
							ㄴ underscore와 $는 sql standard에선 사용못함.
							ㄴ 길이는 최대 'NAMEDATALEN'라는 설정값 -1 만큼까지 가능. 그 이상 입력시 잘려서 적용.
								ㄴ NAMEDATALEN의 디폴트는 64.
								ㄴ src/include/pg_config_manual.h에서 변경 간으.
						ㄴ keyword, unquoted identifier는 case insensitive.
						ㄴ quoted identifier (=delimited identifier)
							ㄴ sql에서 문자열을 쌍따옴표로 감싼것을 말하며, 항상 'identifier'로 취급된다.
								하여 "select"라고 사용시 키워드 SELECT가 아닌 'select'라는 identifer로 취급한다. (일반적으로 미리 정의된 keyword는 identifier로 사용 못하므로)
							ㄴ 이를 사용시 identifier로 어떤 문자도 표현 가능하다.
								ㄴ 단, ??? code zero인 문자만 제외?
							ㄴ 안의 문자열이 case sensitive해진다.
							ㄴ 쌍따옴표 사용하려면 쌍따옴표 두개 입력으로 가능.
							ㄴ quoted identifier의 변형형태를 사용함으로써 escape된 unicode character를 포함시킬 수 있다.
								ㄴ ex ) U&"d\0061t\+000061"
									ㄴ U&" ~~~ " 형식으로 quoted identifier의 변형형태를 표현.
									ㄴ 쌍따옴표 안에 백슬래쉬 뒤에 4비트 16진수 또는 백슬래쉬 & '+' 기호 뒤에 6비트 16진수를 작성하여
										escape된 문자를 표현 가능.
						ㄴ constant <button>more</button>
						<pre>
							ㄴ 암시적으로 결정되는 세가지 constant type 존재. string, bit string, number.
								??? 그 외에는 명시적으로 표현하여 타입결정가능?
							ㄴ 종류
								ㄴ string constant
									ㄴ 작은따옴표로 문자열을 감싸면 string constant.
									ㄴ 작은따옴표를 문자열 내용으로 사용하려면 작은따옴표 두개 입력. ex ) 'toby''s dog'
									ㄴ 두 string constant사이가 줄바꿈이 포함된 공백으로 떨어져 있으면 붙여진 것으로 취급.
										ㄴ ex )
											select 'hello'
												'world';  -- 결과 문자열은 'helloworld'
									ㄴ escape string constant
										ㄴ string constant 바로 앞에 e 또는 E를 붙이면 escape string constant가 되며,
											이 안에서 백슬래쉬(\)를 사용하면 그 다음문자는 그 문자가 그대로 사용된다( \‘ 라고쓰면 그냥 작은따옴표가 문자열내용이됨. ).
											또는 백슬래쉬 다음에 특정 문자 조합이 오면 특정한 값으로 취급된다. 가령 \n은 줄넘김으로, \x1A 는 16진수바이트값으로 취급되거나 등.
										ㄴ ~~~
									ㄴ string constant로 unicode 표현
										ㄴ ~~~ string constant안에서 unicode 코드 포인트값 사용하는 방법.
											ex ) U&'d\0061t\+000061'
										ㄴ ~~~
									ㄴ dollar-quoted string constant
										ㄴ 작은따옴표가 아닌 달러($)기호를 이용해 문자열constant를 표현하는 방법.
										ㄴ ~~~
								ㄴ bit string constant
									ㄴ B 또는 b로 시작하는 작은따옴표로 둘러싼 문자열로 표현 가능.
										ex ) select B'1010101000';
									ㄴ 내용으로 0 또는 1만 가능.
									ㄴ 16진수형식으로도 가능. 앞에 X로 시작하여 표현 가능.
										ex ) select X'10FAE';
										ㄴ 이 경우, 16진수 문자 하나가 4자리 bit string과 동일하게 취급.
											ㄴ ex ) select X'F';  -- 1111
								ㄴ number constant
									ㄴ 형식
										digits
										digits.[digits][e[+-]digits]
										[digits].digits[e[+-]digits]
										digitse[+-]digits
										ㄴ 'digits'은 0~9
										ㄴ 소수점이 존재한다면 그 앞 또는 뒤에 숫자가 반드시 하나 와야함.
										ㄴ 지수e를 사용했다면 그 뒤에 숫자가 반드시 하나 와야함.
										ㄴ 그 외 다른 문자나 공백은 있으면 안됨.
										ㄴ digits 앞에 있는 +, - 기호는 부호로 적용되는게 아닌 constant에 대한 연산자로 취급됨.
										ㄴ ex )
											42
											3.5
											4.
											.001
											5e2
											1.925e-3
									ㄴ number constant의 타입 결정.
										ㄴ 소수점, 지수 e가 포함되지 않은 number constant는 일단 'integer'로 취급.
											값이 여기에 맞지 않으면 'bigint'. 여기에도 안맞으면 'numeric' 타입으로 취급.
										ㄴ 소수점, 지수 e가 포함된 number constant는 'numeric'으로 취급.
										ㄴ 이는 초기 결정된 타입이고, 문맥에 따라 자동으로 바뀔 수 있다.
										ㄴ 물론, 명시적으로 타입 지정도 가능.
								ㄴ 그 외 타입
									ㄴ 다음 형식으로 그 이외의 타입들을 명시하여 해당타입의 constant 사용 가능.
										type 'string'
										'string'::type
										CAST ( 'string' AS type )
									ㄴ string constant가 해당 타입으로 cast됨.
									ㄴ constant의 값의 타입이 뭐가 될지 확실하게 명확한 경우, 명시적 type cast는 생략될 수 있다.
										가령, 특정 타입인 컬럼에 넣을 값인 경우 등.
									ㄴ typename( 'string' )
										ㄴ 위에 나온형식들 말고 이 형식으로도 cast 가능.
										ㄴ 단, 일부 타입들에 한함.
									ㄴ ~~~
						</pre>
						ㄴ operator
							ㄴ postgresql의 사용자 정의 operator를 의미하는 듯.
							ㄴ 이름으로 postgresql의 기본 연산자들(+, -, < 등) 문자로 이루어진 문자열이 쓰임.
							ㄴ ~~~
						ㄴ 그 외 special characters
							ㄴ 케이스에 따라 영문,숫자가 아닌 문자들이 특별한 의미로 사용된다. 함수 정의시, 함수 바디에 ' $(*숫자*)'는 positional parameter로 취급되는 등.
							ㄴ 여기서 다루진 않고, 각 부분 설명에서 다룸.
						ㄴ 주석
							ㄴ '--' 와 '/* ~~~ */'
						ㄴ 연산자 적용 순서
							ㄴ https://www.postgresql.org/docs/13/sql-syntax-lexical.html#SQL-PRECEDENCE-TABLE 참고.
							ㄴ 순서를 명시하고 싶으면 당연히 괄호 사용하면됨.
							ㄴ 사용자 정의 operator라도, 위 기본 연산자와 이름이 같다면, 위와 같은 연산자 적용순서를 가진다.

					</pre>

					ㄴ 값 표현식, value expression
						ㄴ 다양한 곳에서 사용. select문의 대상 리스트,
						ㄴ table expression(table 의미)과의 구분을 위해 'scalar', 'scalar expression' 라고도 부름.
						ㄴ 목록 )<button>more</button>
						<pre>
							ㄴ constant, literal value
								ㄴ string constant, numeric constant 등. 일반적으로 아는 문자, 숫자 상수값.
								ㄴ ex ) select 'hello', 123;
							ㄴ 컬럼 참조
								ㄴ (*테이블명*).(*컬럼명*)
								ㄴ ex ) basic_info.code
							ㄴ positional parameter, 위치 파라미터
								ㄴ ex ) select * from basic_info where code= $1
								ㄴ sql에 파라미터 형태로 인자를 외부로부터 받을 때, '$(*숫자*)' 형태로 파라미터 위치를 지정하는 표현.
							ㄴ subscripts,
								ㄴ ex) basic_info.arraycolumn[3], basic_info.arraycolumn[2:5], basic_info.multidimensionarray[12][32]
										$1[21], (somefunction(a))[23]
								ㄴ 값이 array타입인 경우,  (*array타입 값 표현식*)[(*정수*)] 등과 같이 사용 가능.
								ㄴ 배열 슬라이스표현 ([2:5]), 다차원 배열인 경우, 위치 파라미터에 대해, 함수 결과값에 대해서도 사용 가능.
							ㄴ field selection, 필드 선택???
								ㄴ ex ) (*표현식*).(*필드명*)
								ㄴ 표현식이 복합타입인 경우?(row형태 등처럼 여러값들을 가지고 있는 경우), 그 중 특정 필드를 추출하는 표현식.
								ㄴ 일반적으로 (*표현식*) 부분은 소괄호로 감싸며,
									(*표현식*)이 일반 테이블인 경우, 생략 가능.
									(*표현식*)이 일반 테이블인 경우, 위에서 나온 표현식 중 하나인 '컬럼 참조'이며, 이는 'field selection'의
									일부라고 할수 있다.
								ㄴ 컬럼 자체가 복합 타입인 경우 자주 쓰인다.
									ㄴ ex ) (myTable.compositeCol).somefield
										ㄴ myTable 테이블의 compositeCol이 복합타입 컬럼인 경우.
							ㄴ operator 호출
								ㄴ postgresql의 operator의미.
								ㄴ ~~~
							ㄴ 함수 호출
								ㄴ ex ) sqrt(2)
								ㄴ (*함수명*) ( (*인자1*), (*인자2*), ... )
									ㄴ 그냥 함수 호출형태.
							ㄴ 집계 표현식
								ㄴ (*집계 명*) ( (*표현식*), ... )
								ㄴ (*집계 명*) ( all (*표현식*), ... ) : 모든 input row들에 대해 집계.
								ㄴ (*집계 명*) ( distinct (*표현식*), ... ) : input row 중 중복 제외한 것들에 대해 집계.
								ㄴ ~~~???
								ㄴ 대부분의 집계시, null은 배제하고 계산.
								ㄴ 대부분의 집계시, input row들의 정렬 여부가 상관 없지만, 일부의 경우, 정렬에 따라 결과 다를 수 있다(array_agg, string_agg)
									이런 경우, (*표현식*) 뒤에 order by를 붙여 집계시 정렬기준을 설정할 수 있다.
									ㄴ array_agg input으로 들어온 값들을 배열로 만들어 반환.
									ㄴ 'order by'는 집계함수의 모든 인자 다음에 와야 한다. ex ) string_agg(a, ',' order by a)
									ㄴ 'distinct'와 같이 사용시, distinct에 명시된 목록만 order by에 사용할 수 있다.
								ㄴ ??? ordered-set aggregate
									ㄴ order by 구문이 필수인 일부 집계함수들? rank, percentile 계산 등.
									ㄴ 'WITHIN GROUP ()' 구문 안에 order by 구문이 작성된다?
									ㄴ ~~~ ???
								ㄴ 결과 리스트, 'HAVING'절에만 집계 표현식 사용 가능.
									집계표현식 처리 순서 때문???
							ㄴ window 함수 호출
								ㄴ ~~~???
							ㄴ type cast
								ㄴ 형식
									ㄴ CAST ( (*expression*) AS (*type명*) )
										ㄴ ex ) select CAST('202301' AS integer);  -- 정수값 202301
									ㄴ (*표현식*)::(*type명*)
										ㄴ ex ) select '202302'::integer;  -- 위와 동일.
								ㄴ ~~~???
							ㄴ Collation 표현식
								ㄴ ~~~
							ㄴ ~~~
						</pre>

					ㄴ 함수 호출
						ㄴ ~~~
				</pre>

				ㄴ 데이터 정의<button>more</button>
				<pre>
					ㄴ table <button>more</button>
					<pre>
						ㄴ 컬럼별로 타입을 명시. 해당 컬럼엔 정해진 타입 외의 값 저장 불가.
						ㄴ CREATE TABLE command
							ㄴ ~~~
							ㄴ like 
						ㄴ 가질 수 있는 컬럼 개수는, 컬럼들의 타입에 따라 다르지만, 약 250 ~ 1600 개라함.
						ㄴ DROP TABLE command

					</pre>
					ㄴ 디폴트 값
						ㄴ 표현식 가능. 디폴트값 insert 순간 처리.
						ㄴ 디폴트값 지정을 안 하는건, 사실상 디폴트값을 null로 지정하는 것과 동일.
							명시적 디폴트값이 지정되지 않으면 암시적으로 null이 들어가기 때문.
							(당연히 not null조건이 있으면 다른이야기)
					ㄴ generated column <button>more</button>
					<pre>
						ㄴ 다른 컬럼들로부터 계산되는 컬럼.
						ㄴ 분류 )
							ㄴ stored generated column : insert/update시 계산되어 저장소에 저장.
							ㄴ virtual generated column : read시 계산.
						ㄴ postgresql은 'stored generated column'만 지원.
							ㄴ 'create table' 구문 안에 'GENERATED ALWAYS AS' 구문 사용.
							ㄴ ex )
								CREATE TABLE people (
									...,
									height_cm numeric,
									height_in numeric GENERATED ALWAYS AS (height_cm / 2.54) STORED
								);
							ㄴ 뒤에 잇는 'STORED'가 stored generated column임을 명시.
						ㄴ insert, update 등에서 직접적으로 write 불가. 알아서 업데이트 될 수만 있음.
						ㄴ column의 default설정과의 비교
							ㄴ default값은 명시적으로 입력받은 값이 없을 때 들어가는 값. generated column은 직접 넣을 수 없으니
								항상 알아서 업데이트됨.
							ㄴ ??? default값에는 ?휘발성 함수? (random()이나 현재 시간을 반환하는 함수 등)를 사용 할 수 있지만
								generated column은 안됨.
						ㄴ 한계, 제약조건
							ㄴ??? generated column 정의시 사용되는 표현식에는 'immutable function'만 사용 가능.
							ㄴ generated column 정의시 사용되는 표현식에는 서브쿼리 사용불가.
							ㄴ??? generated column 정의시 사용되는 표현식에는 해당 row 이외의 다른 것들을 참조할 수 없음.
							ㄴ generated column 정의시 사용되는 표현식에는 다른 generated column을 참조할 수 없음.
							ㄴ generated column 정의시 사용되는 표현식에는 'tableoid'를 제외한 system column을 참조할 수 없음.
							ㄴ generated column은 디폴트 설정 불가.
							ㄴ??? generated column은 identity definition을 가질 수 없음?
							ㄴ??? generated column은 partition key가 될 수 없음
							ㄴ??? 'FOREIGN TABLE'은 generated column을 가질 수 있음?
							ㄴ ??? 상속의 경우, ~~~
						ㄴ generated column은 값 생성에 사용되는 기반 컬럼들과 별도의 접근권한을 가짐.
							따라서, 기반 컬럼들엔 접근 못하면서 generated column만 접근 가능하게 설정 가능.
						ㄴ generated column의 값은 'BEFORE' trigger가 실행된 이후에 업데이트됨.
							따라서, 'BEFORE' trigger에서 기반 컬럼들이 업데이트되면 이게 generated column값에 반영됨.
							단, 'BEFORE' trigger 안에서 generated column에 접근할 수 없음.
					</pre>

					ㄴ constraint<button>more</button>
					<pre>
						ㄴ 테이블, 컬럼에 다양한 제약조건 설정 가능.
						ㄴ 컬럼 정의에 정의된 제약조건을 '컬럼 제약조건'
							컬럼 정의와 나란히 정의된 제약조건을 '테이블 제약조건'이라함.
							ㄴ ex )
								CREATE TABLE products (
									product_no integer,
									name text,
									price numeric CONSTRAINT positive_price CHECK (price > 0)
									discounted_price numeric CHECK (discounted_price > 0),  -- 컬럼제약조건
									CHECK (price > discounted_price)  -- 테이블 제약조건
								);
						ㄴ Check constraint
							ㄴ 가장 기본적 제약조건.
							ㄴ constraint (*제약조건명*) check (*표현식*)
								ㄴ 'constraint (*제약조건명*)' 생략가능
								ㄴ 컬럼 제약조건, 테이블 제약조건 둘다 가능.
							ㄴ ex )
								CREATE TABLE products (
									product_no integer,
									name text,
									price numeric CONSTRAINT positive_price CHECK (price > 0)
									discounted_price numeric CHECK (discounted_price > 0),
									CHECK (price > discounted_price)
								);
								ㄴ 맨 아래줄같이 컬럼 정의 자리에 제약조건을 정의 가능.
							ㄴ 확인할 (*표현식*)부분이 true, null으로 평가되면 조건 충족으로 취급. 유의 필요.
							ㄴ ~~~
						ㄴ Not-Null constraint
							ㄴ '컬럼 제약조건'으로만 정의 가능.
							ㄴ 해당 컬럼값으로 null이 오지 않도록 하는 조건.
							ㄴ ex )
								CREATE TABLE products (
									product_no integer NOT NULL,
									name text NOT NULL,
									price numeric NOT NULL CHECK (price > 0)
								);
						ㄴ Null constraint
							ㄴ 형식은 Not-Null과 동일.
							ㄴ 기능은 단지 해당 컬럼이 null일 수 있음을 명시.
						ㄴ Unique constraint
							ㄴ 테이블 row 전체에서, 특정 컬럼/컬럼 조합이 유일함을 제약.
							ㄴ CONSTRAINT (*제약조건명*) UNIQUE
								또는 CONSTRAINT (*제약조건명*) UNIQUE( (*컬럼1*), (*컬럼2*), ... )
								ㄴ 'CONSTRAINT (*제약조건명*)' 생략가능.
							ㄴ ex )
								CREATE TABLE products (
									product_no integer UNIQUE,
									name text,
									price numeric,
									UNIQUE(product_no, name)
								);
							ㄴ 컬럼 제약조건, 테이블 제약조건 둘다 가능.
							ㄴ 컬럼 목록에 대해 B-tree index가 자동 생성.
							ㄴ 조건 평가시 null 값.
								ㄴ 디폴트로, null은 같은 값 취급 안함.
									즉, 컬럼값 중 null이있으면 다른값취급.
								ㄴ UNIQUE 뒤에 'NULLS NOT DISTICT' 키워드 붙여 반대 동작 가능.
								ㄴ 디폴트 동작은 'NULLS DISTICT'
								ㄴ ex ) UNIQUE NULLS NOT DISTICT (product_no, name)
						ㄴ Primary key
							ㄴ 특정 컬럼/컬럼 조합이 테이블 내 row들 중에서 유일한 식별자임을 제약.
							ㄴ UNIQUE이고 'NOT NULL'이어야 함.
							ㄴ ex )
								CREATE TABLE products (
									product_no integer PRIMARY KEY,
									name text,
									price numeric
								);

								CREATE TABLE example (
									a integer,
									b integer,
									c integer,
									PRIMARY KEY (a, c)
								);
							ㄴ UNIQUE와 마찬가지로 B-tree index 생성.
								그리고 자동 'NOT NULL' 설정.
							ㄴ 테이블에 최대 1개의 primary key 제약조건 설정 가능.
						ㄴ Foreign Key
							ㄴ 특정 컬럼의 값이 다른 테이블의 값과 일치해야함을 제약. ('두 테이블간의 참조 무결성을 유지함'이라 표현)
							ㄴ 외래키 제약조건은 primary이거나 unique조건이 걸려있는 컬럼(들)을 참조해야 한다.
							ㄴ 어떤 컬럼을 외래키로 참조할지 설정하지 않으면, '참조되는 테이블'의 primary key가 참조되는 컬럼이 된다.
							ㄴ ??? 외래키 제약조건의 추가는 'SHARE ROW EXCLUSIVE' lock을 필요로한다?
							ㄴ 임시테이블과 영구테이블 사이에 외래키제약조건을 설정할 수 없다.
							ㄴ 데이터 삽입시, 참조하는 컬럼(또는 컬럼들)의 값과 참조되는 컬럼(또는 컬럼들)의 값을 '매칭'시킴.
								'매칭'시 3가지 타입 존재.
								ㄴ match type
									ㄴ match full
										ㄴ 외래키 컬럼(들)이 모두 null이면 match 하지 않고 제약조건 패스.
										ㄴ 외래키 컬럼(들) 중 일부가 null이면 match 실패. 제약조건 오류 발생.
											ㄴ 여러 컬럼으로 외래키가 구성된 경우를 생각해 볼 수 있음.
										ㄴ 즉, 외래키 구성 컬럼들의 값이 모두 존재해야 match를 시도.
									ㄴ match simple
										ㄴ 외래키 컬럼(들) 중 일부 또는 모두 null이면 match하지 않고 제약조건 패스.
									ㄴ match partial
										ㄴ 구현안됐다함.
								ㄴ match type에 따라 match를 시도할지 패스하여 외래키 제약조건을 패스할지 결정하는 식인 듯 하고,
									match을 시도했을 때, 참조테이블에 매칭되는 값이 없으면 당연히 외래키 제약조건 실패.
								ㄴ match type에 따라 외래키 구성 컬럼이 null이면 매칭을 안하고 넘어가는 것과 'not null constraint' 등과는 별개이다.
									not null 있는데 match type이 simple이라고 insert되고 그런건 없다. not null에 막혀 오류뜬다.
							ㄴ 컬럼 그룹을 외래키 제약으로 설정 할 수 있다.
								ㄴ ex )
									CREATE TABLE noname (
										a integer PRIMARY KEY,
										b integer,
										c integer,
										FOREIGN KEY (b, c) REFERENCES other_table (c1, c2)
									);
								ㄴ 당연히, 참조하는 외래키 컬럼과 참조되는 외래키 컬럼의 수가 같아야 한다.
							ㄴ many-to-many 관계 형식으로 테이블을 구성할 수 있다.
								ㄴ A, B 테이블 간에 many-to-many 관계를 구성하고 싶으면,
									중간 테이블 C를 두고, C에서 A,B를 외래키로 참조하고 이 외래키 조합을 C의 primary key로 설정하면 됨.
								ㄴ ex )
									CREATE TABLE products (
										product_no integer PRIMARY KEY,
										name text,
										price numeric
									);

									CREATE TABLE orders (
										order_id integer PRIMARY KEY,
										shipping_address text,
										...
									);

									CREATE TABLE order_items (
										product_no integer REFERENCES products,
										order_id integer REFERENCES orders,
										quantity integer,
										PRIMARY KEY (product_no, order_id)
									);
							ㄴ 자기 자신 테이블에 대한 외래키를 설정하는 것을 'self-referential 외래키'라함.
							ㄴ cascade
								ㄴ 외래키가 참조하고 있는 테이블 row가 삭제되려할때, 어떤 동작을 취할지 설정 가능.
								ㄴ ex )
									CREATE TABLE order_items (
										-- 'ON DELETE (*옵션*)'으로 CASCADE 동작 설정.
										product_no integer REFERENCES products ON DELETE RESTRICT,
										order_id integer REFERENCES orders ON DELETE CASCADE,
										quantity integer,
										PRIMARY KEY (product_no, order_id)
									);
								ㄴ 옵션 목록 )
									ㄴ NO ACTION
										ㄴ 외래키로 참조되고 있는 row의 삭제를 제한함. 에러를 발생시킴.
											??? 단, contraint check가 연기되었을시, 기다렸다가 체크타임에 체크.
										ㄴ 디폴트 값.
									ㄴ RESTRICT
										ㄴ 외래키로 참조되고 있는 row의 삭제를 제한함.
										ㄴ NO ACTION과 다르게 constraint check가 연기되지 않음.
									ㄴ CASCADE
										ㄴ 외래키로 참고되고 있는 row를 삭제하고, 참조하고 있는 table의 row도 같이 삭제.
									ㄴ SET NULL ( (*컬럼1*), (*컬럼2*), ... )
										SET DEFAULT ( (*컬럼1*), (*컬럼2*), ... )
										ㄴ 외래키로 참조되고 있는 row 삭제시, 이를 참조하고 있는 row의 컬럼을 NULL 또는 DEFAULT값으로 설정.
										ㄴ NULL이나 DEFAULT로 설정할 컬럼 지정 가능.
										ㄴ DEFAULT 설정시, 디폴트값은 매칭되는 fk값이어야함. 아닌 경우 동작 실패.
								ㄴ 어플리케이션에 따라 적절한 옵션선택 필요.
									ㄴ 두 데이터가 완전히 종속적이고 독립적으로 존재하기 어려우면 CASCADE가 적절.
									ㄴ 그게 아니라면 나머지 옵션 중 적절히 선택.
								ㄴ ON UPDATE
									ㄴ ON DELETE 와 유사하게, 외래키로 참조되는 컬럼값이 변경되는 경우,
										이를 참조하고 있는 외래키 컬럼값을 어떻게 처리할지 설정 가능.
									ㄴ CASCADE인 경우, 동일하게 값 update.
									ㄴ ON NULL, ON DEFAULT의 경우, 컬럼 설정 불가.
						ㄴ Exclusino constraint
							ㄴ ~~~ ???

					</pre>

					ㄴ system column <button>more</button>
					<pre>
						ㄴ 모든 테이블엔 기본적으로 'system column'들이 존재.
							시스템이 암시적으로 정의하는 컬럼들.
							당연히 이 컬럼들의 이름은 유저 정의 컬럼 이름으로 사용 불가.
							쓸일도, 개발 과정에서 고려할 경우도 없으나 그냥 있다는 것만 알고있으라함.
						ㄴ 목록 )
							ㄴ tableoid
								ㄴ 해당 row가 속한 table의 oid. (테이블의 oid는 테이블의 식별값 같은 것)
							ㄴ xmin
								ㄴ 해당 row의 version을 삽입한 transaction의 id.
								ㄴ postgresql에선 개념적으로 row가 삽입되거나 update되면 새로운 row의 version이 생기는 것.
							ㄴ cmin
								ㄴ xmin의 트랜잭션 안에서 row version을 삽입한 command의 식별자값. (시작을 0으로 명령어의 위치를 나타내는 듯)
							ㄴ xmax
								ㄴ 해당 row를 삭제한 transaction의 id. 디폴트 0.
								ㄴ 삭제했으나 아직 적용이 안되었거나, 삭제했다가 rollback된 경우 등에만 0이 아닌 값이 있는걸 볼 수 있다.
							ㄴ cmax
								ㄴ 삭제의 경우에 cmin과 동일.
							ㄴ ctid
								ㄴ 테이블 안에서 해당 row version의 물리적 위치.
								ㄴ ??? 'VACUUM FULL'에 의해 업데이트되고 이동될 때마다 값이 변하므로 장기적으로 유의미하지 않은 값이다?
					</pre>

					ㄴ modifying table<button>more</button>
					<pre>
						ㄴ 이미 정의된 테이블의 구조, 정의를 변경하는 기능.
						ㄴ 'ALTER TABLE' 명령어를 통하여
							컬럼 추가/제거, 제약조건 추가/제거, 컬럼의 디폴트값 변경, 컬럼 데이터 타입 변경, 컬럼 rename, table rename 등의 기능 가능.
						ㄴ 컬럼 추가
							ㄴ ex )
								alter table noname add column (*컬럼명*) (*데이터타입*) (*그외 옵션*)
							ㄴ default 정의가 있으면 그값으로 아니면 null 값을 가지는 새 컬럼이 추가됨.
							ㄴ postgresql 11 이전엔, default 값과 함께 alter table로 add column시,
								statement 실행시에 테이블의 모든 row에 대해 추가한 컬럼을 디폴트값으로 update 연산을 실행.
								테이블이 큰 경우, 느리게됨.
								??? 11부터는 이렇게동작하지 않고, update안하고 있다가, 나중에 row 접근시 디폴트값을 가져와서 테이블 write시
								디폴트값을 적용한다함. 이전에 비해 상대적으로 동작이 빠름.
								근데, 디폴트값이 clock_timestamp() 등과 같이 당장 적용해야 하는 경우, 이전처럼 모든 row를 업데이트침.
								??? 이런 경우, 성능 이슈를 방지하기 위해, 디폴트값 없이 컬럼을 추가하고, update문으로 원하는 값을 채우고
								컬럼에 디폴트 설정을 하라함? (???뭔차인지?)
							ㄴ 컬럼 정의 부분은 'create'문에서 컬럼 정보 정의하는 부분(컬럼 정의 한줄에 하는거)에서 할 수 있는건 다 할 수 있다.
								당연히, 제약조건 등도 설정 가능.
							ㄴ 디폴트값과 제약조건 같이 설정시, 디폴트값이 제약조건을 위배하지 않는지 유의 필요. 위배시 add column 연산 실패.
								ㄴ tip) 제약조건 없이 디폴트값으로 컬럼 추가 후, 나중에 제약조건만 추가할 수도 있다.
						ㄴ 컬럼 제거
							ㄴ ALTER TABLE (*테이블명*) DROP column (*컬럼명*);
							ㄴ 해당 테이블 내에서 해당 컬럼과 관련된 제약조건, 인덱스들은 자동으로 제거.
							ㄴ 다른 테이블에서 해당컬럼을 foreign키 등으로 참조하고 있으면 컬럼 제거 불가.
								명령어 맨 뒤에 'CASCADE' 키워드를 붙임으로서, 다른 테이블에서 참조하고 있는 fk 제약조건도 같이 삭제시킬 수 있음.
								ㄴ ex ) alter table noname1_tables drop column name cascade;
						ㄴ 제약조건 추가
							ㄴ ex )
								ALTER TABLE products ADD CHECK (name <> '');
								ALTER TABLE products ADD CONSTRAINT some_name UNIQUE (product_no);
								ALTER TABLE products ADD FOREIGN KEY (product_group_id) REFERENCES product_groups;
								ALTER TABLE products ALTER COLUMN product_no SET NOT NULL;
							ㄴ 조약조건 추가시, 바로 조건체크 실행됨.
						ㄴ 제약조건 제거
							ㄴ ex )
								alter table (*table명*) drop constraint (*제약조건명*);
							ㄴ 제거하려면 제약조건명을 알아야함.
								ㄴ 제약조건 생성시 명시적으로 이름을 설정했다면 그냥 그 이름 사용하면됨.
								ㄴ 명시적으로 이름설정하지 않았다면, 시스템이 자동으로 생성하여 할당했을 것이고, 이 이름을 확인해서 사용해야함.
							ㄴ 'NOT NULL'조건을 제거하는 경우 형식이 다름.
								alter table (*table명*) alter column (*컬럼명*) drop  not null;
						ㄴ 컬럼 디폴트값 변경
							ㄴ alter table (*table명*) alter column (*컬럼명*) set default (*디폴트값*);
							ㄴ alter table (*table명*) alter column (*컬럼명*) drop default;
							ㄴ 당연히 현재 컬럼값들에 영향 없음. 앞으로 insert될 row에만 영향.
						ㄴ 컬럼명 변경
							ㄴ alter table (*테이블명*) rename column (*이전 컬럼명*) to (*새 컬럼명*);
						ㄴ 테이블명 변경
							ㄴ alter table (*이전 테이블명*) rename to (*새 테이블명*);
						ㄴ ALTER TABLE command
							ㄴ ~~~
					</pre>

					ㄴ privileges, 권한 <button>more</button>
					<pre>
						ㄴ postgresql object에 대해 어떤 작업을 할 수 있는 권한을 말함.
						ㄴ 어느 role이 postgresql object에 대해 create statement으로 object를 생성시, 해당 object의 owner는
							그 role이 된다.
						ㄴ 대부분의 object에 대해, object의 owner와 superuser만이 그 object를 사용할 수 있다.
							그 이외의 role들이 해당 object를 사용하려면 'privilege'가 grant 되어야 한다.
							ㄴ ex ) 가령, role A로 table A를 만들고, role B로 table A를 select하려하면 권한이 없다면서 불가함.
						ㄴ 권한의 종류
							ㄴ SELECT, INSERT, UPDATE, DELETE, TRUNCATE, REFERENCES, TRIGGER, CREATE, CONNECT, TEMPORARY, EXECUTE, USAGE, SET, ALTER SYSTEM
							ㄴ object의 타입별로 적용되는 권한의 종류가 다르다.
							ㄴ object를 수정하거나 제거하는 권한은 owner에게만 주어진 권한.
								grant되거나 해당 권한들이 revoke될 수 없다.
								ㄴ table의 경우, alter table, drop table 등의 명령을 하는 권한은 grant될 수 없는 것.
									ㄴ table에 grant되는 delete, insert 등의 권한은 row에 대한것이고 테이블 object 자체에 대한 수정, 제거 권한이 아님.
								ㄴ role membership을 통한 상속은 가능.
						ㄴ alter table (*테이블명*) owner to (*role명*) 을 통하여 owner를 변경할 수 있다.
							ㄴ 명령어를 실행하는 유저는 다음 조건 충족 필요.
								ㄴ owner를 변경하려는 object의 owner이어야함.
								ㄴ 소유권을 넘기려는 role을 'SET ROLE' 명령이 가능해야함.
							ㄴ superuser는 당연히 모든 권한 조건을 패스하므로 조건 충족 필요 없음.
						ㄴ 'GRANT' 명령어를 통한 권한 할당
							ㄴ grant (*권한명*) on (*object명*) to (*role명*)
								ㄴ 상세한 형식은 docs참고. (https://www.postgresql.org/docs/13/sql-grant.html)
							ㄴ 특정 테이블에 대한 특정 권한을 특정 role에게 부여.
							ㄴ (*권한명*)에 'ALL' 키워드입력시, 해당 object와 관련된 모든 권한을 부여.
							ㄴ GRANT command
								ㄴ ~~~
								ㄴ 기본적으로 2개의 인자 필요.
									postgresql object에 대해 부여할 '권한'과 권한을 받을 'role'. 나머진 약간씩 다름.
								ㄴ 대상이 되는 object의 종류는
									테이블, 컬럼, 뷰, foreign table, 시퀸스, database, foreign-data wrapper, foreign server,
									function, procedure, procedural language, large object, configuration parameter, schema,
									tablespace, type.
								ㄴ role 부분 인자에 'PUBLIC' 키워드
									ㄴ '모든' role을 의미. ex ) grant insert on noname_table to PUBLIC;  # 모든 role에게 noname_table에 대한 insert권한부여.
								ㄴ 'WITH GRANT OPTION' 명시시, 권한을 받은 사람이 해당 권한들을 또 다른 role에게 부여 가능.
									명시되지 않았으면 불가.
									ㄴ PUBLIC에게는 사용 불가.
								ㄴ grant (*role명*) to (*role명*)
									ㄴ role의 membership을 설정하는데 사용되는 형식.
									ㄴ 자세한 내용은 'Database Role'부분 참고.
						ㄴ 'REVOKE' 명령어를 통한 권한 부여 취소
							ㄴ revoke (*권한명*) on (*table명*) from (*role명*)
						ㄴ 일반적으로, object의 owner 또는 superuser 또는 'with grant option' 키워드를 포함하여 grant받은 경우 만이 권한을 grant 또는 revoke 가능.
						ㄴ object의 owner는 스스로 object에 대한 특정 권한을 revoke할 수 있다. read-only table을 만들때 등에 쓰인다???
							단지, owner는 항상 모든 권한을 가진것으로 취급되기 때문에, 언제든 revoke했던 권한을 스스로에게 다시 grant할 수 있다.
						ㄴ 권한 목록 <button>more</button>
						<pre>
							ㄴ SELECT
								ㄴ 테이블의 모든 컬럼에 대해, 또는 특정 컬럼에 대해, 또는 특정 컬럼 집합에 대해,
									또는 view, materialized view에 대해, 또는 table-like object에 대해 select 할 수 있는 권한.
								ㄴ update, delete, merge 연산을 수행할 때도 where 조건 등이 있으면 데이터 조회가 필요하므로
									이런 경우 select 권한 필요. 즉, UPDATE, DELETE 등의 권한이 있어도 where조건 등이 있을 때
									select권한 없으면 수행 못함. update noname_table set name='default'; 등처럼 where조건 없이하면 되긴됨.
								ㄴ 'COPY TO' 연산도 허용하게됨. 이게 데이터를 조회해서 복사해가는 기능이므로.
								ㄴ 시퀀스에 대해선, currval() 함수를 사용 가능하게 해줌.
								ㄴ ??? 'large object'에 대해선, 해당 오브젝트를 읽을 수 있게해줌.
							ㄴ INSERT
								ㄴ table, view 등에 새 row를 삽입할 수 있게해주는 권한.
								ㄴ 특정 컬럼 또는 컬림 집합에 대해서도 설정 가능.
									이 특정 컬럼들에 대해 insert문에서 값을 넣고 나머지는 디폴트처리하는식으로 사용됨.
								ㄴ 'COPY FROM' 연산도 허용하게됨.
							ㄴ UPDATE
								ㄴ 테이블이나 view 등의 모든 커럶 또는 특정 컬럼 또는 특정 컬럼 집합을 업데이트할 수 잇게해줌.
								ㄴ 대부분의 update 연산에선 어떤 row를 업데이트할지 결정하기 위해 where조건 등에서 데이터 조회가 필요하므로
									select권한도 함께 필요하다.
								ㄴ 시퀀스에 대해선, nextval(), setval() 함수를 사용 가능하게 해줌.
								ㄴ ??? 'large object'에 대해선, 해당 object를 write하거나 truncate 가능하게 해줌.
							ㄴ DELETE
								ㄴ 테이블, view 등에서 row를 삭제할 수 있게 해줌.
								ㄴ UPDATE와 마찬가지로 보통 where조건 때문에 select권한과 함께쓰임.
							ㄴ TRUNCATE
								ㄴ 테이블을 truncate 할 수 있게해줌.
							ㄴ REFERENCES
								ㄴ ???
							ㄴ TRIGGER
								ㄴ 테이블, 뷰 등에 대해 trigger를 생성할 수 있는 권한.
							ㄴ CREATE
								ㄴ database에 대한 create권한의 경우, 테이블의 스키마와 publication을 생성할 수 있게 해줌.
									??? 또한, 'trusted extension'이 db에 설치될 수 있게 해줌.
								ㄴ ??? 스키마에 대한 경우, ~~~???
								ㄴ ??? tablespace에 대한 경우, ~~~???
								ㄴ ??? ~~~
							ㄴ CONNECT
							ㄴ TEMPORARY
							ㄴ EXECUTE
							ㄴ USAGE
							ㄴ SET
							ㄴ ALTER SYSTEM
							ㄴ 그 외
								ㄴ 특정 명령어별 추가적으로 필요한 권한들이 있을 수 있음. 각 명령어 reference에 명시.

						</pre>
						ㄴ 자동으로 object에 대해 부여되는 권한
							ㄴ postgresql은 특정 타입의 object에 대해, object생성시 자동으로 특정 권한들을 'PUBLIC'에게 부여함.
								즉, 어떤 타입의 object들은 생성되자마자 모든 role이 그 object에 대한 특정 권한을 가지도록 설정되는 것.
							ㄴ 해당되는 object유형과 그 권한
								ㄴ database에 대해 CONNECT, TEMPORARY
								ㄴ function, procedure에 대해 EXECUTE
								ㄴ language, data type에 대해 USAGE
							ㄴ 물론, 이것들에 대한 revoke 가능.
							ㄴ ALTER DEFAULT PRIVILEGES 명령어를 통해 변경가능.
						ㄴ 권한별 적용되는 object 종류 및 권한 축약어
							ㄴ https://www.postgresql.org/docs/16/ddl-priv.html#PRIVILEGE-ABBREVS-TABLE 참조.
							ㄴ https://www.postgresql.org/docs/16/ddl-priv.html#PRIVILEGES-SUMMARY-TABLE 참조.
						ㄴ 부여된 권한 확인
							ㄴ object에 대한 role들의 권한 정보 조회 방법
							ㄴ information_schema.role_table_grants view.
							ㄴ psql에서 object 정보 조회 관련 'meta-command' (\dp, \l 등)
								ㄴ 출력 결과의 'aclitem'(access privilege?)이란 목록에서 누가 어떤 권한을 누구에게 부여받았는지 알 수 있음.
								ㄴ 형식
									ㄴ (*권한받은role*)=(*권한약어*)[*].../(*권한부여한role*)
									ㄴ ex )
										calvin=r*w/hobbes  # calvin role이 hobbes role에게서 read권한(r), update권한(w)를 받음.
									ㄴ (*권한부여한role*)이 다르면 구분된 row에 작성됨.
									ㄴ???  (*권한받은role*)이 비어있으면 PUBLIC을 위한 경우라함.
									ㄴ 아예 비어있는 경우, 해당 object가 디폴트 privilege를 가지고 있음 의미.
									ㄴ ~~~
						ㄴ 기타 유의사항
							ㄴ table에 대한 권한부여가 자동으로 그 테이블에서 사용하는 sequence에 대한 권한부여도 진행하지 않는다.
								별도로 grant해야함.
						ㄴ 실무 
							ㄴ django web application 사용시 user 권한 설정. 
								ㄴ web app이 db의 owner user를 사용하게하는건 상대적으로 risky. 
									딱 필요한만큼의 제한된 권한을 가진 유저를 따로 생성하여 사용하게하는게 권장. 
								ㄴ django에선 migration 사용시, 테이블 생성, drop, 구조변경 등과 같은 권한 필요하므로 
									위에서 말한 제한된 유저 외에 이런 권한들을 가진 유저 필요. 
								ㄴ djang의 test 사용시, db생성 권한 필요. 
					</pre>

					ㄴ Row Security Policy<button>more</button>
					<pre>
						ㄴ 위 'privileges'에서 다룬 grant 등을 통한 테이블에 대한 권한 부여 말고,
							테이블의 row-level에서, row에 대한 조회, 수정, 삽입, 삭제 권한을 유저별 설정할 수도 있다.
						ㄴ alter table 명령어로 on 설정.
						ㄴ 설정시, row에 대한 select, update는 row security policy를 통과해야함.
							ㄴ table owner는 패스.
						ㄴ row security policy를 on했는데, 아무 정책이 없으면, 디폴트 정책이 사용되며,
							이는 모든 row가 select되거나 수정될 수 없도록 한다.
						ㄴ 테이블 전체에 대한 작업(truncate, reference 등)은 row security policy에 영향받지 않음.
						ㄴ 디폴트로는 아무 관련 정책이 없음.
						ㄴ ~~~ 딱히 크게 쓸일 없어보임. 패스.
					</pre>

					ㄴ Schema <button>more</button>
					<pre>
						ㄴ 하나의 db안에서, db의 데이터 구조를 정의하는 테이블, operator, function, sequence 등을 포함하고 있는 그룹같은 것.
							namespace같은 것이라 생각하면 된다.
							스키마가 다르면 테이블, function 등 object들의 이름이 겹쳐도 된다.
						ㄴ 유저는 권한만 있다면, 하나의 db에 접속해서 그 db 내에 있는 모든 스키마들에 접근할 수 있다.
						ㄴ 사용 이유
							ㄴ 여러 유저가 서로 방해받는 것 없이 하나의 db를 사용하려고
							ㄴ db object들을 관리 용이를 위해 분리하고자 할 때.
							ㄴ third party 어플이 의해 사용되는 경우.
						ㄴ 스키마 사용
							ㄴ 테이블을 표기할 때, 원래는 스키마명까지 같이 명시하여 테이블을 나타낸다. 
								ㄴ ex ) myschema.mytable 
								ㄴ 일반적으로 스키마 명시부분이 생략되는 것. (public으로)
						ㄴ CREATE SCHEMA command
							ㄴ
						ㄴ DROP SCHEMA 
						ㄴ PUBLIC schema
							ㄴ 데이터베이스 생성시 디폴트로 존재하는 스키마. 
							ㄴ 별다른 스키마 명시가 없으면 이 PUBLIC 스키마가 사용된다. 
								ㄴ 테이블 생성 등에서 별다른 스키마 명시 없으면 PUBLIC 스키마에 테이블 생성하는 식.
						ㄴ schema Search path 
							ㄴ 테이블 등이 스키마명과 함께 full qualified name으로 명시되지 않고 단순히 테이블명 등으로만
								명시될 때, 'schema search path'를 통해서 이 이름이 가리키는 대상을 특정함. 
							ㄴ 첫번째로 매칭되는 대상이 타겟으로 결정. 
							ㄴ 매칭되는 대상이 없으면 에러. 
							ㄴ ??? ~~~
						ㄴ schema 권한
							ㄴ 디폴트로, own하지 않은 스키마에 대한 접근권한 없음. 
							ㄴ 스키마 사용하려면 스키마에 대한 'USAGE' 권한 필요. 
								(스키마 내의 object들에 대한 권한은 별개)
							ㄴ 스키마 내에서 object생성 위해서는 스키마에 대한 'CREATE' 권한 필요. 
							ㄴ PUBLIC 스키마에 대한 권한
								ㄴ 디폴트로 모든 유저가 public 스키마에 대해 'USAGE', 'CREATE' 권한 가짐. 
						ㄴ pg_catalog schema
							ㄴ 데이터베이스별 기본으로 가지는 스키마로, 
								시스템 테이블, 내장 데이터 타입, 내장 함수, 내장 operator 등이 들어있다. 
							ㄴ search path에 명시적 입력하지 않는 경우, search path로 스키마를 서치하기 전에 
								암시적으로 pg_catalog 스키마에서 먼저 서치를함. 
								ㄴ pg_catalog보다 다른 스키마에서 먼저 서칭하고자 한다면
									search path에 pg_catalog를 먼저 서칭하고자 하는 스키마 뒤에 추가하면됨.
							ㄴ 시스템 테이블들은 앞에 'pg_'가 붙은 이름이므로 이런 형식의 이름을 가진 유저 정의 테이블을 
								만들지 않는게 좋다. 
						ㄴ ??? secure schema usage pattern ? 
					</pre>

					ㄴ Inheritance <button>more</button>
					<pre>
						ㄴ postgresql은 테이블 상속 지원.
						ㄴ 상속관계에 있는 테이블의 경우, query시, 
							디폴트로, 해당 테이블의 자손 테이블의 row들까지 자동으로 결과에 포함. 
							'from' 대신 'from only' 사용시, 자손테이블의 row들 포함되지 않음. 
							ㄴ ex ) 
								create table parent(
									id serial primary key,
									name varchar(50) not null 
								);
								create table child (
									name2 varchar(50) 
								) inherits (parent); 

								select * from parent;  -- child테이블의 row들까지 검색됨. 
								select * from only parent;  -- child테이블의 row들 포함 안되고 parent 테이블의 row들만 포함. 
							ㄴ row가 어느 테이블로부터 유래한건지는 테이블의 시스템 컬럼인 tableoid을 확인하여 가능. 
								ㄴ ex ) 
									select *, tableoid from parent; 
						ㄴ insert는 상속관계에 잇는 테이블과 관련 없이, insert하는 테이블에 대해서만 동작. 
						ㄴ 부모 테이블에 대한 스키마 변경은 자식 테이블에 전파. 
						ㄴ 컬럼 중복 처리  
							ㄴ 여러 테이블을 상속하는 경우, 
								부모 테이블 중 중복되는 복수의 컬럼명 존재시, 그 두 컬럼의 데이터 타입이 동일하지 않으면 오류. 
								동일하다면, 새로 만드는 그 자식 테이블에서는 이 중복되는 컬럼이 하나의 컬럼으로 merge됨. 
								ㄴ merge되는 것이란, 하나의 컬럼으로 합쳐짐을 의미. 
							ㄴ 부모 테이블에서 중복되는 컬럼을 이들을 복수 상속하는 자식테이블에서 동일한 컬럼명으로 정의하는 경우, 
								마찬가지로 타입이 같아야함. 아니면 오류. 
								타입이 같으면 컬럼 정의들이 merge됨.  
							ㄴ 부모테이블들과 자식테이블이 동일한 컬럼명을 가지는 경우, 자식테이블 정의에서 해당컬럼에 디폴트값을 설정한다면, 
								부모테이블에서 정의한 디폴트값을 덮어씀. 
								자식테이블에서 해당 컬럼에 디폴트값을 설정하지 않고, 부모테이블에서 해당 컬럼에 디폴트값을 가진다면 이 부모테이블들의 디폴트값이 모두 
								같지 않으면 오류. (merge되기 어려워서인듯)
						ㄴ 제약조건 중복 처리
							ㄴ 부모테이블들, 자식테이블에서 동일한 이름의 check 제약조건이 있다면, 그 표현식이 반드시 같아야함. 
								동일한 제약조건명, 동일한 표현식인 경우 자식테이블에서 하나로 merge됨. 
								ㄴ 이름이 없는 제약조건은 항상 유일한 이름이 할당되기 때문에, 위 조거때문에 충돌날일도 없고 merge될 일도 없이 항상 상속됨. 
							ㄴ 부모테이블에서 'NO INHERIT' 키워드가 붙은 제약조건은 논외.  
						ㄴ ??? Column STORAGE settings are also copied from parent tables.
						ㄴ ??? If a column in the parent table is an identity column, that property is not inherited. A column in the child table can be declared identity column if desired.
						ㄴ not-null, check 제약조건은 명시적으로 'NO INHERIT'이 없는한 자동상속. 
							그 외 제약조건(unique, pk, fk)는 상속 안됨. 
						ㄴ alter table의 inherit 키워드를 통한 상속관계 생성/제거.
							ㄴ alter table의 inherit 키워드로 이미 정의된 테이블이 다른 테이블을 상속하게 할 수 있다.  
								ㄴ 이 방식으로 상속관계 형성시, 자식테이블은 부모테이블의 모든 컬럼(컬럼명과 타입 동일해야함)과 check 제약조건(조건명과 표현식 동일해야함)을 
									가지고 있어야함. 
							ㄴ alter table의 no inherit 키워드로 이미 존재하는 상속관계를 제거할 수 있다. 
							ㄴ create table의 like 키워드를 이용하여, 이런식으로 나중에 상속관계를 이룰 테이블을 쉽게 만들 수 있다. 
						ㄴ 테이블이 다른 테이블에 의해 상속되고 있으면 drop 불가. 
							ㄴ ??? cascade 옵션으로 자식테이블까지 같이 drop 가능. 
						ㄴ 자식테이블에선 상속받은 컬럼, 제약조건 제거 또는 수정 불가. 
						ㄴ alter table 에서의 컬럼 정의, check 제약조건의 변경은 이 테이블을 상속하는 자손 테이블들에게 전파되며, 
							create table을 통한 상속관계 형성시에 적용되는 컬럼 중복 등의 규칙들이 동일하게 적용받고 위배시 오류 발생. 
							ㄴ ex ) 부모가 2개이고 동일한 컬럼명을 가지고 있는 경우, 두 부모 중 한 부모의 해당 컬럼의 타입을 변경하려 한다던가. 
									(컬럼명 중복시 타입 같지 않으면 오류이므로) 
						ㄴ 상속 관계 테이블에 대한 쿼리에서의 권한 
							ㄴ 부모테이블에 대한 쿼리시, 자손테이블의 row들도 결과에 포함된다 했었음. 
							ㄴ 부모테이블에 대한 select, update 등의 권한이 있다면, 이 부모테이블을 통해 자손테이블의 row들에 대한 작업 수행 가능. 
								ㄴ 가령, 부모테이블에 대한 update권한이 있으면, 부모테이블 쿼리시 자손테이블의 row들도 포함이 되므로 이 row들에 대한 update가 가능. 
							ㄴ 그러나ㅏ 직접적으로 자손테이블에 대한 작업을 하려면 부모테이블에 대한 권한만으로는 안되고, 직접적으로 자손테이블에 대한 권한 필요. 
								ㄴ 가령, 부모테이블에 대한 update권한이 있어, 이 부모테이블을 통해 자손테이블의 row들을 업데이트할 수는 있지만, 
									직접적으로 자손테이블에 대한 update를 할 수는 없다. 자손테이블에 대한 update권한이 따로 있어야함. 
							ㄴ row security policy에 대해 ~~~ 
								ㄴ ~~~ 
						ㄴ ??? Foreign table의 경우, ~~~ 
						ㄴ 유의사항 
							ㄴ 모든 sql command가 상속관계 관련 동작이 가능하지는 않음. 각 명령어별로 상속관계 관련 동작이 조금씩 상이하므로 확인 필요. 
								ㄴ select, update, delete, alter table 등에는 동작하나 insert 등에는 동작하지 않음. 
								ㄴ 상속관계 동작하는 경우, only 키워드로 상속관계 동작 없이 해당 테이블에만 연산 적용 가능.  
							ㄴ index와 fk 제약조건이 테이블 단위로만 적용이 가능. 상속관계라고 통합되어 적용되지 않음. 
								ㄴ unique 제약조건은 테이블 단위로 적용. 상속관계에 있다고 함께 고려되어 unique하도록 적용되지 않는 것. 
									ㄴ 가령, 부모테이블 정의에서 컬럼 a에 unique 제약조건이 있다하면, 자식테이블에선 이 a컬럼에 대해 unique제약조건이 적용되지 않음. 
										하여 자식테이블에 a컬럼값이 중복되게 insert하여도 오류가 나지 않으며, 부모테이블 쿼리시 자식테이블의 이 중복된(unique가적용되지 않은)
										row들도 포함되므로, 중복된 컬럼a 결과들이 잡히게됨. 
										ㄴ ex ) 
											create table parent (
												a int unique 
											); 
											create table child (
												b int 
											) inherits (parent); 
											insert into parent values (1); 
											insert into child(a, b) values (1, 10); 
											insert into child(a, b) values (1, 11);  -- 컬럼 a값이 동일하게 1이어도 unique제약조건 적용이 안되기때문에 그냥 insert됨. 

											select * from child;  하면,  
											|a|b |
											|-|--|
											|1|10|
											|1|11|
											
											select * from parent; 하면,
											|a|
											|-|
											|1|
											|1|
											|1|
											이런식으로 unique가 적용안된 자식테이블의 row들이 그대로 결과로 나오게됨. 
								ㄴ fk 설정도 테이블 단위로 적용. 자식테이블이 fk 컬럼을 상속하더라도 이 컬럼은 fk제약조건이 설정된 컬럼이 아님. 
									자식테이블에서 명시적으로 fk조건을 설정해야함. 
								ㄴ 다른 테이블에서 fk를 참조받는 경우에도, 테이블 단위로 적용. 
									즉, 다른 C 테이블이 부모테이블을 참조하더라도 상속관계라고 자식테이블을 참조할수는 없음. 

					</pre>

					ㄴ table partitioning<button>more</button>
					<pre>
						ㄴ 논리적 단위인 하나의 테이블을 여러개의 물리적 공간에 나누어 저장하는 것. 
							정의한 특정 기준에 따라 partition이 나뉘어짐. 
							파티션이 사용된 테이블을 'partitioned table'이라함. 
							partitioned table에 insert된 데이터들은 파티션 기준에 따라 적절한 파티션에 저장됨. 
							row의 파티션 키값을 변경하는 update는 해당 row의 파티션을 적절히 이동시킴. 
						ㄴ 이점
							ㄴ ??? 접근하려는 row들이 하나 또는 소수의 파티션 안에 위치해 있다면 쿼리 성능이 많이 향상된다.
								ㄴ ??? Partitioning effectively substitutes for the upper tree levels of indexes, making it more likely that the heavily-used parts of the indexes fit in memory.
							ㄴ ??? 하나의 파티션의 많은 비중에 대한 쿼리 또는 업데이트시, 
								테이블 전체에 대한 random-access를 사용하는 index scan 대신 해당 파티션에 대한 sequence scan을 사용하여 성능이 향상. 
							ㄴ ??? bulk load 또는 bulk delete시, 파티션을 제거하거나 추가하는식으로 동작하여 성능향상? 
								DROP TABLE이나 ALTER TABLE DETACH PARTITION을 이용. 
								ㄴ ???  These commands also entirely avoid the VACUUM overhead caused by a bulk DELETE. 
							ㄴ ??? Seldom-used data can be migrated to cheaper and slower storage media.
						ㄴ 위 이점들은 테이블의 크기가 커야 유효하다.
							얼마나 커야 하는지는 케바케이나, 일반적으로 db server의 메모리보다 큰 경우라함.
						ㄴ postgresql에서 제공하는 내장 파티셔닝 형식은 다음과 같다.
							ㄴ Range Partitioning
								ㄴ 테이블이 특정 컬럼(또는 컬럼들)의 값을 기준으로 range별로 파티셔닝.
								ㄴ 파티션이 다르다면 range가 겹치지 않는다. 
								ㄴ 각 파티션마다 range 시작값은 포함이고 마지막값은 포함하지 않는다. 
									ㄴ ex ) x기준으로 range를 나눈다할 때, 파티션1에 1 <= x < 10, 파티션2에 10 <= x < 20 ...  
							ㄴ List partitioning 
								ㄴ ??? 명시적으로 어떤 키값이 어떤 파티션에 들어가야하는지 list로 명시하여 파티셔닝? 
							ㄴ Hash Partitioning
								ㄴ ??? The table is partitioned by specifying a modulus and a remainder for each partition. Each partition will hold the rows for which the hash value of the partition key divided by the specified modulus will produce the specified remainder. 
						ㄴ postgresql에선 선언적 방법으로 파티션테이블 생성 가능. 
						ㄴ ??? 파티션은 각각 그 자체로 partitioned table이 될 수 있음? 
							'sub-partitioning'? 
						ㄴ ??? 파티션들은 각각 고유의 인덱스, 제약조건, 디폴트값을 가질 수 있음? 
							ㄴ ??? CREATE TABLE command을 통해 가능. 
						ㄴ ??? 일반 테이블을 파티션 테이블로 만들거나 그 반대는 불가. 
							ㄴ ??? 파티션 테이블의 파티션으로 이미 존재하는 일반테이블이나 파티션 테이블을 추가하는건 가능? 
							ㄴ ??? 파티션 테이블에서 파티션을 제거하여 일반 테이블로 만다는건 가능? 
							ㄴ ??? ALTER TABLE command를 통해 가능. 
						ㄴ ??? 파티션은 'foreign table'이 될 수 있다? 
							ㄴ ??? although considerable care is needed because it is then the user's responsibility that the contents of the foreign table satisfy the partitioning rule. There are some other restrictions as well. See CREATE FOREIGN TABLE for more information.
						ㄴ 파티션 테이블 생성 
							ㄴ 
					</pre>
				</pre>
				
				ㄴ query <button>more</button>
				<pre>
					ㄴ db로부터 데이터를 받아오는 방법. 
					ㄴ ??? The process of retrieving or the command to retrieve data from a database is called a query. 
						ㄴ ??? sql상의 'SELECT' 라는 명령어를 통하여 'query'를 명시?  
					ㄴ select 명령어 형식 
						ㄴ [WITH with_queries] SELECT (*select_list*) FROM (*table_expression*) [sort_specification]
						ㄴ ex ) 
							SELECT * FROM table1;
					ㄴ table expression 
						ㄴ query에 사용될 table을 계산하는 부분. 
						ㄴ 'From'절 및 옵션으로 where, group by, having 절으로 구성. 
						ㄴ where, group by, having 절들은 from절로부터 받은 테이블에 대해 연속적인 변환처리. 변환의 결과는 가상테이블로서 생성. 
							이를 (*select_list*)로 전달. 이후 select list에 따라 적절한 output row들이 반환되는 식.   
						ㄴ from 절
							ㄴ 형식 
								FROM (*table_reference*) [, (*table_reference*) [, ...]]
							ㄴ (*table_reference*)
								ㄴ 단순 테이블명, 서브쿼리 또는 조인 등을 이용한 테이블 표현 또는 이들의 조합을 이용항 테이블 표현이 올 수 있음. 
								ㄴ 콤마로 여러개 선언시, cross-join 처리. 
							ㄴ from 절의 결과가 가상테이블로서 생성. 
								이후 where, group by, having 절에 의한 변환 처리. 
								이후 최종적으로 table expression의 결과물이됨. 
							ㄴ (*table_reference*)에 테이블 상속계층의 부모 테이블이 올 경우, 
								후손테이블들까지 모두 포함됨. 
								ㄴ 해당 테이블명 앞에 'only' 키워드 붙여 자손테이블 제외하고 딱 그테이블만 포함가능. 
									당연히, 해당테이블의 컬럼들만 결과에 포함. 
							ㄴ joined table 
								ㄴ join type별 join규칙에 따라 두개의 테이블로부터 합쳐진 테이블. 
								ㄴ 형식 
									T1 join_type T2 [ join_condition ]
								ㄴ join은 어떤 타입이든 chainning되거나 중첩 가능. 
									ㄴ 즉, join 후 그 결과를 한번더 join할 수도 있고, 
										join을 한 테이블끼리 join할 수도 있다. 
									ㄴ ??? join 순서 명시를 위해 괄호 사용 가능? 
									ㄴ join순서 명시되지 않으면 왼쪽에서 오른쪽으로 join 진행. 
								ㄴ join type 
									ㄴ cross-join 
										ㄴ 두 테이블 row들 간의 가능한 모든 조합을 만드는 join type. Cartesian product
										ㄴ 두 테이블의 모든 컬럼들을 결과에 포함. 
										ㄴ inner join에서 on 절에 아무 조건도 없는 것과 동일. 
									ㄴ Qualified joins
										ㄴ 형식 
											T1 { [INNER] | { LEFT | RIGHT | FULL } [OUTER] } JOIN T2 ON boolean_expression
											T1 { [INNER] | { LEFT | RIGHT | FULL } [OUTER] } JOIN T2 USING ( join column list )
											T1 NATURAL { [INNER] | { LEFT | RIGHT | FULL } [OUTER] } JOIN T2
											ㄴ 'inner', 'outer'는 옵션. 명시하지 않을시 디폴트는 'inner' 
											ㄴ 'left', 'right', 'full'이 있으면 암시적으로 outer로 취급. 
											ㄴ join 조건은 'on'절, 'using'절, 'natural'절로 명시. 
											ㄴ join 조건을 통해 조인시, 두 테이블에서 어떤 row들이 'match' 취급될지를 결정. 
											
										ㄴ inner 
											ㄴ 왼쪽에 명시된 테이블의 모든 row들에 대해, 조건을 만족하는 오른쪽 테이블의 row
										ㄴ outer
									

				</pre>

				ㄴ insert 
					ㄴ ~~~
					ㄴ 'on conflict' clause 
						ㄴ insert하려는 모든 row 각각에 대해, 조건을 통과하면 insert, 
						ㄴ 형식 )
						ㄴ ex )
							insert into stock_social_content
								(created_at, updated_at, social_type, date, url, title, content, source, stock_id)
							values ('2023-04-18 16:40:43.541000', '2023-04-18 16:40:43.541000', 'news', '2023-01-01', 'url2',
								'''삼성 이름값에도''…삼성FN리츠, 상장 첫 날 공모가 밑돌아[시그널]', 'content', 'sometrend', 'A000040')
							on conflict(stock_id, url) do update set title='title2', content='content5' where stock_social_content.source='sometrend'

							insert into deepq_news_reaction
								(created_at, updated_at,  social_keyword_id, source, date, title, press, link)
							values ('2023-04-18 16:40:43.541000', '2023-04-18 16:40:43.541000', 4403, 'daum_news', '2022-08-20',
								'[재송]19일 장 마감 후 주요 종목 뉴스', '이데일리', 'https://news.v.daum.net/v/20220820060020698' )
							on conflict on constraint deepq_news_reaction_unique do update set title='[재송]19일 장 마감 후 주요 종목 뉴스3'

						ㄴ insert 연산시 unique 또는 다른 제약조건 위반 발생시 수행할 작업을 명시하는 옵션.
						ㄴ 각각의 row들에 대해 insert를 수행하거나, conflict_target에 명시된 조건 위반시, 'conflict_action'에 명시된 작업 수행.
						ㄴ 'on conflict do nothing'은 아무 것도 하지 않음.
						ㄴ 'on conflict do update'는 insert하려는 해당 row와 제약조건 충돌을 일으키는 이미 존재하는 row를 update함.
						ㄴ ??? conflict_target에는 'on constraint'를 붙여 제약조건명이나 괄호로 unique나 exclude 제약조건을 이루는 컬럼명을
							나열해야 동작하는 듯하다. 안그럼 오류.
						ㄴ do update시 where은 당연히, update대상인 row에 대해 판별하여 참인 경우에만 update하는거고.
						ㄴ 'do update' 사용시, value 목록에 conflict조건에 중복되는 row들 존재시 오류발생.
							value내에서 unique해야함?
							ㄴ ex  )
								SQL Error [21000]: 오류: ON CONFLICT DO UPDATE command cannot affect row a second time
								Hint: Ensure that no rows proposed for insertion within the same command have duplicate constrained values.

				ㄴ data type<button>more</button>
				<pre>
					ㄴ ~~~
					ㄴ Numeric type
						ㄴ ~~~
						ㄴ numeric
							ㄴ ~~~
							ㄴ Arbitrary Precision Number (임의 정확도 숫자 타입)
								ㄴ 최대 1000 자릿수의 숫자를 정확하게 표현 가능하며, 계산 역시 정확하게 수행되는 타입. 
									ㄴ decimal 타입과 동일. 
								ㄴ 다른 integer, floating-point 유형에 비해 계산속도 매우 느림. 
								ㄴ 돈 관련, 정확한 수치를 요하는 데이터에 주로 사용. 
								ㄴ 사용법 
									ㄴ 'precision', 'scale'을 정의. 
									ㄴ precision : 숫자의 전체 자릿수 의미. ex ) 12.234이면, 5. 
									ㄴ scale : 숫자에서 소수점 부분 자릿수 의미. ex ) 12.234이면, 3. 
									ㄴ NUMERIC( (*percision*), (*scale*) ) 형식으로 정의. 
										ㄴ ex ) 
											create table noname (
												~~~
												value numeric(10, 2), 
												~~~ 
											)
								ㄴ 범위 초과하는 값 insert시, 
									ㄴ 인풋값의 scale이 정의된 scale보다 큰 경우, round됨. 
									ㄴ 인풋값의 정수부분(즉, precision - scale)이 정의된 정수부분보다 큰 경우, 오류. 
								ㄴ ??? 저장 공간 차지 
									ㄴ leading zero, tailing zero가 없기 때문에, 정의한 precision, scale은 값의 최대값이지 고정값이 아님. 
									ㄴ varchar같은 느낌? 
								ㄴ NaN 값. 
									ㄴ 추가적으로 'NaN'값을 가질 수 있음. 
							ㄴ 'Infinity', '-Infinity', 'NaN'
								ㄴ 각각 양의 무한대, 음의 무한대, 'not-a-number'를 의미.
								ㄴ IEEE 754 표준부터 적용되었다함.
								ㄴ numberic 타입은 이러한 값들을 value로 입력받을 수 있음.
									ㄴ 작은따옴표로 해당 키워드를 감싸 입력 가능. ex ) update table set x='-Infinity';
									ㄴ 해당 값 insert 방지.
										ㄴ 약간 트릭 필요.
										ㄴ 컬럼 정의에 'check' 제약조건으로 (*해당 컬럼값*)=(*해당 컬럼값*) 을 하여 오류가 뜨게할 수 있음.
											ㄴ ex )
												CREATE TABLE your_table (
												your_column NUMERIC CHECK (your_column = your_column)
												);
											ㄴ 'NaN'값은 같은 'NaN'값과 = 비교를 해도 false가 나옴을 이용한 것.
										ㄴ 'BEFORE INSERT' 키워드 사용.
				</pre>

				ㄴ index, 인덱스 <button>more</button>
				<pre>
					ㄴ ~~~
					ㄴ Multicolumn index <button>more</button>
					<pre>
						ㄴ 하나 이상의 컬럼으로 구성된 인덱스. 
						ㄴ B-tree, GiST, GIN, BRIN 타입만 가능. 
						ㄴ 최대 32개 컬럼까지 가능. 
						ㄴ B-tree인 경우
							ㄴ 일반 multi-column index와 동일한듯. 'db일반' 부분의 인덱스 부분 참고. 
						ㄴ GiST 
						ㄴ GIN
						ㄴ BRIN 


					</pre>
					ㄴ ~~~
					ㄴ 여러개의 index 같이 사용 ???
						ㄴ ??? 쿼리 실행시, 한번의 index scan은 쿼리 조건에 인덱스의 컬럼들이 있거나 이들이 and로 묶여있을 때만 사용 가능?
							ㄴ 가령, index (a, b)가 있다하면, 
								'where a=2 and b=3' 에는 해당 인덱스 적용이 가능한데, 
								'where a=2 or b=3' 에는 적용 불가? ??? 무조건 안쓰는건 아니고 위의 예의 and조건처럼 바로 적용은 안되니 
									planner가 다른것들 따져보고 딱히 더 빠른 방법이 없으면 쓰는식? 
						ㄴ ??? postgresql에선 이런식으로 한번의 index scan으로 쿼리 처리가 안되는 경우 
							여러 인덱스들을 결합하여 (또는 하나의 인덱스를 여러번 사용하여) 쿼리를 처리하는 기능 제공. 
							ㄴ 가령, 'where a=1 or a=3 or b=4' 와 같은 조건이 있으면 or문 기준으로 각각의 조건들을 각각 인덱스를 사용하여 쿼리 후, 
								결과를 합치는식 등. 
								또는 a,b에 대한 single-column index가 각각 있고, 'where a=1 and b=3' 쿼리 처리한다하면, 
								a,b의 각각의 인덱스를 사용하여 a=1, b=3조건을 각각 처리하고 결과를 and로 결합하는식. 
						ㄴ ??? 인덱스를 여러개 결합하여 사용할때, 내부적으로 bitmap을 사용하여 각각의 결과를 ANDed, ORed로 병합한 뒤 최종 결과 반환. 
							ㄴ ??? bitmap 동작방식에 의거하여, 
								결과는 physical order로 반환. index의 정렬은 날라감. 
								ㄴ 따라서 쿼리에 정렬조건이 있는 경우, 이를 위한 단계 추가됨. 
						ㄴ ex ) 
							-- corp_code, account_name 각각에 대한 single-column index가 있다할때, 
							explain select * from stock_financial_statement sfs 
							where corp_code='1231' or account_name='akljl'

							Bitmap Heap Scan on stock_financial_statement sfs  (cost=292.44..31557.56 rows=28845 width=225)
							Recheck Cond: (((corp_code)::text = '1231'::text) OR ((account_name)::text = 'akljl'::text))
							->  BitmapOr  (cost=292.44..292.44 rows=28851 width=0)
									->  Bitmap Index Scan on stock_fin_corp_code_idx  (cost=0.00..142.25 rows=14638 width=0)
										Index Cond: ((corp_code)::text = '1231'::text)
									->  Bitmap Index Scan on acc_name_idx  (cost=0.00..135.76 rows=14213 width=0)
										Index Cond: ((account_name)::text = 'akljl'::text)
							ㄴ 두개의 인덱스를 사용하여 각조건에 대해 scan한 뒤 bitmap으로 결과를 합침. 

						ㄴ 물론, 당연히 항상 인덱스롤 조합하여 사용하는건 아님. 
							query planner가 적절히 비용계산하여 인덱스를 결합해 사용하는게 싸면 그렇게하는거고, 
							그냥 싱글인덱스 하나 사용하는게 싸면 하나만 사용. 
						ㄴ index 설계
							ㄴ postgresql의 이 인덱스 결합 동작을 고려하여 multi-column index를 생성할지, single-column index를 여러개 생성할지 결정. 
					ㄴ Partial Index <button>more</button>
					<pre>
						ㄴ 테이블 중 일부에 대해 생성된 인덱스. 
							어떤 일부인지는 condition expression에 의해 결정. (이 condition expression을 'predicate'라 부름)
							즉, predicate의 조건을 만족하는 row들에 대해서만 index를 생성하는 것. 
						ㄴ 생성 
							ㄴ ex ) 
								create index on market_news (date) 
								where date>'2023-05-01'; 
							ㄴ create index 명령어에 where옵션을 추가하면 일반 index가 아닌 partial index 생성. 
							ㄴ where표현식 부분에 predicate 입력. 

						ㄴ partial index에는 predicate를 만족하는 row들만 포함되며, 
							쿼리가 predicate를 만족하는 경우, 이 partial index를 사용하여 쿼리 수행. 
							아닌 경우, partial index를 사용하지 않고 일반적인 인덱스를 사용. 
							ㄴ 물론, 당연히 query planner에 의해 조건만족해도 다른 인덱스 사용할수도 있음. 
						ㄴ ex ) 
							CREATE TABLE public.market_news (
								id bigserial NOT NULL,
								"date" date NOT NULL,
								title varchar(500) NOT NULL,
								link text NOT NULL,
								"type" varchar(20) NOT NULL,
								CONSTRAINT market_news_link_type_c17554e4_uniq UNIQUE (link, type),
								CONSTRAINT market_news_pkey PRIMARY KEY (id)
							);

							-- date > '2023-05-01'인 경우에 대한 partial index 생성. 인덱스에 포함되는 컬럼은 date. 
							create index on market_news (date) 
							where date>'2023-05-01'; 

							-- partial index의 predicate인 'date>'2023-05-01'을 만족하지 않으므로, partial index사용 안함. 
							select * from market_news where date='2024-01-01';  

							-- partial index의 predicate인 'date>'2023-05-01'을 만족하므로, partial index사용.
							select * from market_news where date='2023-06-01';
						ㄴ 활용 케이스
							ㄴ 특정 컬럼에 대해 인덱싱을 해야하는데, 해당 컬럼에 큰 의미없는 동일한 데이터가 있는 row가 많아 불필요하게 인덱스가 커지고 
								이에따라 인덱스 성능이 저하될때. 
								ㄴ ex ) 네트워크 접속 로그 테이블이 있고 ip컬럼에 대해 인덱스를 해야한다할 때, 
										거의 대부분의 row의 ip컬럼값이 local이라 이들에 대한 쿼리에 큰 의미가 없고 다른 외부 ip에 대해 쿼리를 하고자 할때, 
										parital index로 ip가 local이 아닌 것들에 대해 인덱스를 생성하여 사용. 
							ㄴ 테이블의 일부에 대해 unique 제약을 걸고자 할 때
								ㄴ 테이블 일부에 대해 unique index를 추가하여 특정 조건 하의 일부 row들에만 적용되는 unique 조건 설정 가능. 
								ㄴ ex ) 
									탈퇴하지 않은 유저에 대해서만 닉네임에 unique 조건을 걸고자 할때 등. 
									create unique index on user_table(username) 
									where is_active=false ; 

						ㄴ ???~~~ Example 11.2 also illustrates that the indexed column and the column used in the predicate do not need to match. PostgreSQL supports partial indexes with arbitrary predicates, so long as only columns of the table being indexed are involved. However, keep in mind that the predicate must match the conditions used in the queries that are supposed to benefit from the index. To be precise, a partial index can be used in a query only if the system can recognize that the WHERE condition of the query mathematically implies the predicate of the index. PostgreSQL does not have a sophisticated theorem prover that can recognize mathematically equivalent expressions that are written in different forms. (Not only is such a general theorem prover extremely difficult to create, it would probably be too slow to be of any real use.) The system can recognize simple inequality implications, for example “x < 1” implies “x < 2”; otherwise the predicate condition must exactly match part of the query's WHERE condition or the index will not be recognized as usable. Matching takes place at query planning time, not at run time. As a result, parameterized query clauses do not work with a partial index. For example a prepared query with a parameter might specify “x < ?” which will never imply “x < 2” for all possible values of the parameter.
						
						ㄴ 유의사항 
							ㄴ index의 동작방식, query plan이 index를 사용하는 방식 등에 대한 이해가 선행된 후 사용하는 것이 좋다. 
							ㄴ 대부분의 경우, 쿼리 성능에 잇어서 partial index보다 일반 인덱스가 유리하다. 
							ㄴ 사용하기 안좋은 예
								ㄴ ??? ~~~ 
					</pre>
					
					ㄴ index-only scan 
						ㄴ 배경 
							ㄴ??? postgresql에서 index를 이용한 쿼리는 인덱스뿐 아니라 실제 테이블 데이터가 저장된 영역을 확인해야함? 
								하여 테이블영역상에 여러곳에 흩어져있는 row들을 참조하는데 시간이 걸림. 
							ㄴ 이를 해결하기 위해, 테이블영역에 대한 접근 없이 인덱스만으로 실행할 수 있는 기능이 index-only scan. 
						ㄴ ~~~
						ㄴ 한계
							ㄴ 사용하는 인덱스가 index-only scan을 지원해야함. 
								ㄴ ~~~
							ㄴ 쿼리가 인덱스에 존재하는 컬럼만을 참조해야함. 
								ㄴ ~~~
						ㄴ ~~~
					ㄴ 
				</pre>

				ㄴ window function <button>more</button>
				<pre>
					ㄴ 결과 row에 대해 특정 기준으로 파티션을 나누고(window처럼) 이에 대해 집계 함수 등을 적용하는 기능.
					ㄴ group by처럼 조건에 의해 묶인 그룹 row가 하나의 row로 결과가 나오는 것이 아닌,
						결과 row가 모두 그대로 있지만, window 그룹에 대한 결과만 추가되는 것.
						window function에서 해당 row가 속한 그룹의 row들에 접근 가능하여, window function 기능을 수행하고 그 결과를
						내놓는식.
					ㄴ ex )
						SELECT depname, empno, salary, avg(salary) OVER (PARTITION BY depname) FROM empsalary;
						ㄴ 'avg(salary) OVER (PARTITION BY depname)' 부분이 window function.
						ㄴ avg(salary)는 일반 group by에 의한 집계함수와 동일하게 작동하지만,
							'OVER' 문에 의해 window function이 적용되어 그 집계 대상이 일부로 제한 된다.
							ㄴ 이 예의 경우, depname이 동일한 row가 일부가 된다.
					ㄴ 'OVER' clause
						ㄴ OVER clause로 일반 함수/non-window 집계함수와 window function 구분.
						ㄴ window function에 의해 처리되기 위해 쿼리의 결과 row들이 어떻게 분리될지를 정의.
						ㄴ PARTITION BY (*표현식*)
							ㄴ row들을 (*표현식*)의 값이 동일한 것들끼리 묶어 partition을 만듦.
							ㄴ 뒤에 ORDER BY 적용 가능. (window function에 따라 필요한 경우들 있음)
						ㄴ 당연하지만, from, where, group by 절, 등등을 모두 적용한 다음 결과 row 목록에 대해 window function이 적용.
							ㄴ 따라서, 이러한 clause들에는 window function을 적용할 수 없다.
								select 리스트, order by 리스트에만 적용 가능???
					ㄴ non-window 집게함수 적용 후 window function이 적용.
						하여, window function구문에 non-window 집계함수 사용 가능.
					ㄴ window frame
						ㄴ window function에 의해 분리한 partition 내부에서 또 묶인 일부의 row 목록.
						ㄴ 특정 window function에 경우, 이러한 window frame에 대해 연산이 적용됨.
						ㄴ 가령, 'OVER'절에 'ORDER BY' 명시시,
							window frame은 partition 처음부터 현재 row + order by 기준에 대해 현재 row와 같은 row가 된다.
							즉 매 row마다 window frame이 변경되며, window frame을 사용하는 window functino들은
							이 window frame에 대해 특정 연산을 수행한다.
				</pre>

				ㄴ Transactions
					ㄴ 여러 단계들을 하나로 묶어, 모두 적용하거나 아무것도 적용하지 않는다.
						중간 단계들은 다른 병렬의 트랜잭션들에게 보이지 않고, 트랜잭션 완료 전 실패가 발생하면, 아무것도 db에 적용되지 않는다.
					ㄴ sql 앞뒤에 'BEGIN', 'COMMIT'을 붙여 트랜잭션 적용.
						ㄴ ex )
							BEGIN;
								update accounts set ~~~ ;
							COMMIT;
						ㄴ 명시하지 않으면, 각각의 sql statement에 대해 트랜잭션이 디폴트로 적용.
					ㄴ 트랜잭션 중간에 COMMIT전에 트랜잭션 내의 현재까지의 연산을 적용하지 않고 되돌리려면 'ROLLBACK'명령어 사용.
					ㄴ 트랜잭션 내의 특정 지점까지는 연산을 유지하고 그 다음부터의 연산만 되돌리려면
						특정 지점에
							SAVEPOINT (*savepoint명*);
						특정 지점 이후의 내용을 되돌리려면
							ROLLBACK TO (*savepoint명*);

				ㄴ Inheritance, 상속
					ㄴ

				ㄴ performance tip <button>more</button>
				<pre>
					ㄴ EXPLAIN <button>more</button>
					<pre>
						ㄴ postgresql의 query planner가 쿼리에 대해 생성한 query plan을 보여주는 명령어.  
							참조되는 테이블이 어떤방식으로 스캔되는지,
							join이 사용되는 경우, 어떤 join 알고리즘이 사용되는지. 
						ㄴ 결과 
							ㄴ plan node 
								ㄴ query plan은 'plan node'의 트리구조. 
								ㄴ 쿼리에 join, 집계, sort 등 다른 연산 존재시 이들을 수행하기 위한 node들이 scan node 상위에 존재. 
								ㄴ 최상위 node가 총 평가 결과. 하위 node들의 결과를 포함하고 있음. 
								ㄴ 각 node의 맨 위에 있는 summary 라인에서 아래로 들여쓰기된 부분은 해당 node의 속성들을 보여주는 부분. 
								ㄴ node 종류 
									ㄴ scan node
										ㄴ table로부터 raw data들을 가져옴. 
										ㄴ 테이블에 접근하는 방법에 따라 다른 종류의 scan node 존재. 
										ㄴ ??? 데이터 가져올 리소트 종류에 따라서도 node종류가 달라짐? 
										ㄴ 종류 
											ㄴ Seq scan 
												ㄴ sequential scan 
												ㄴ 순차적으로 row를 모두 스캔하는 것? 
											ㄴ Bitmap Heap Scan 
												ㄴ ~~~??? db개론, index 내부동작 등에 대해 먼저 알아야 할듯. 
												ㄴ 참고 
													ㄴ https://www.postgresql.org/message-id/12553.1135634231@sss.pgh.pa.us
											ㄴ ~~~
									ㄴ ~~~ 
							ㄴ estimated statement execution cost
								ㄴ 최상단에 요약된 예상 쿼리 실행 비용. 
								ㄴ ex ) (cost=0.42..345433.30 rows=1000 width=24)
								ㄴ '..'을 기준으로 cost의 앞부분 값이 'start-up cost', 뒷부분이 'total cost' 
									ㄴ start-up cost : 쿼리 실행 전, 결과를 반환받기 전 준비에 드는 비용. 
									ㄴ total cost : 결과를 모두 반환받는데 드는 비용. 
									ㄴ 상황에 따라 planner가 start-up cost를 줄일지, total cost를 줄일지 결정한다함. 
								ㄴ rows : 예상 결과 row 수. 추정치. 정확하지 않음. 
								ㄴ width : 예상 각 row의 크기. 
							ㄴ ??? bitmap heap scan
							ㄴ ??? index scan
							ㄴ ??? recheck cond? 
							ㄴ ex ) <button>more</button>
							<pre>
								ㄴ 	
									EXPLAIN SELECT * FROM tenk1;

																QUERY PLAN
									-------------------------------------------------------------
										Seq Scan on tenk1  (cost=0.00..458.00 rows=10000 width=244)
									ㄴ seq_page_cost = 1.0, cpu_tuple_cost = 0.01이라 가정하면, 
										결과에서 읽은 row개수가 10000개이고,
										(*읽은 디스크 개수*) * seq_page_cost(=1.0) + (*읽은 row 개수*)(10000개) * cpu_tuple_cost(=0.01) = 458.00 이므로, 
										디스크 페이지의 개수는 358개임을 알 수 있다. 

								ㄴ  
									EXPLAIN SELECT * FROM tenk1 WHERE unique1 < 7000;

																QUERY PLAN
									------------------------------------------------------------
										Seq Scan on tenk1  (cost=0.00..483.00 rows=7001 width=244)
										Filter: (unique1 < 7000)

									ㄴ table을 sequence span (순서대로 모두 다 scan )을 하면서, 'filter'(where조건 확인)을 하는 plan. 
									ㄴ 바로 위 예제와 비교하여, 
										where조건으로 인해 결과 row수는 줄었지만, where조건 확인을 위해 모든 row를 스캔해야하므로 비용이 감소하지는 않음. 
										모든 row에 대해 조건확인을 위한 cpu사용 비용이 추가되어 전체적으로 (*row수*) * cpu_tuple_cost 만큼 더 증가. 

									ㄴ ??? 
										ㄴ db가 디스크의 block(=page)들을 읽어들여 메모리(shared buffer)에 저장. (IO cost)
										ㄴ 이 메모리로부터 cpu가 쿼리 연산(where조건 필터링, sort 등)을 하여 결과를 
											work memory에 저장? (cpu cost)
									ㄴ ??? sequential scan 
										ㄴ 테이블의 모든 row를 읽어들이는 스캔방식. 
										ㄴ db가 데이터가 저장되어있는 디스크로부터 디스크 block(=page)를 읽을때, 
											page가 저장된 순서 그대로 순차적으로 읽어온뒤, 
											이 읽어온 데이터의 row들을 모두 스캔. 
										ㄴ 위 과정에서, 디스크로부터 하나의 page를 fetch해오는데 드는 비용을 
											'seq_page_cost' 설정값으로 설정하며, 이 값을 기준으로 plan의 비용이 계산됨. 
										ㄴ 위 과정에서, cpu가 메모리로부터 row하나를 가져오는 비용을 
											'cpu_tuple_cost' 설정값으로 설정하며, 이값을 기준으로 plan의 비용이 계산됨. 

							</pre>
						ㄴ estimate cost 계산시 사용되는 cost 기준 
							ㄴ 'seq_page_cost' 설정값 등을 기준으로 쿼리 비용이 계산. 
						ㄴ ??? The costs are measured in arbitrary units determined by the planner's cost parameters (see Section 19.7.2). Traditional practice is to measure the costs in units of disk page fetches; that is, seq_page_cost is conventionally set to 1.0 and the other cost parameters are set relative to that. The examples in this section are run with the default cost parameters.
						ㄴ planner가 고려하는 요소만이 estimated cost에 반영. 
							ㄴ 데이터 전송에 드는 시간 등은 반영되지 않음. 
						ㄴ ??? The rows value is a little tricky because it is not the number of rows processed or scanned by the plan node, but rather the number emitted by the node. This is often less than the number scanned, as a result of filtering by any WHERE-clause conditions that are being applied at the node. Ideally the top-level rows estimate will approximate the number of rows actually returned, updated, or deleted by the query.
						ㄴ planner가 고려하는 요소만이 estimated cost에 반영. 데이터 전송에 드는 시간 등은 반영되지 않음. 
						ㄴ 옵션 
							ㄴ ANALYZE 
								ㄴ plan한 결과뿐 아니라 쿼리를 실제 실행한 뒤, plan 결과뿐 아니라 실제 실행한 결과도 함께 보여줌. 
								ㄴ 결과값은 milliseconds 기준으로 표시. 단순 plan의 estimated cost의 단위는 millissecons가 아닌 설정값에 따른 임의 상대값이므로
									analyze 결과값과 비교할 수 없음 유의. 
								ㄴ 유의 사항 
									ㄴ 실제 쿼리를 실행하기 때문에, 데이터를 변경하는 쿼리 사용에 유의. 
										ㄴ BEGIN, ROLLBACK 문으로 감싸 영향이 없도록 하는 것 권장. 
							ㄴ ANALYZE, VERBOSE 옵션은 괄호 없이 사용 가능. 
								ㄴ EXPLAIN [ ANALYZE ] [ VERBOSE ] statement
								ㄴ 둘이 같이 사용하려면 이 순서 그대로 사용해야함. 
						ㄴ ??? 여러 예시들과 함께 쿼리에 따라 plan이 어떻게 구성되는지 살펴보는 내용 쭉 나옴. 
							근데 각 알고리즘들(sequential scann, index scan, merge join, beatmap heat scan 등)에 대해 먼저 알아야 이해가 될듯함. 
							이걸 먼저 확인하고 나머지 내용 마저 공부. 
					</pre>

					ㄴ ~~~
					ㄴ 대량 데이터 삽입<button>more</button>
					<pre>
						ㄴ 'COPY' 명령어 사용.
							ㄴ 여러 기능은 상대적으로 적지만, 대량 데이터 로딩에 부하가 적음.
							ㄴ ??? CREATE TABLE, TRUNCATE 명령어와 함께 사용될 때 가장 빠르다함. ~~~
							ㄴ COPY command<button>more</button>
							<pre>
								ㄴ ~~~
								ㄴ view나 상속구조 테이블에서 자식 테이블의 데이터는 copy하지 않는다.
									이를 위해선 단일 테이블명을 copy 명령어에 사용하는게 아닌 쿼리를 사용해라.
								ㄴ 삽입 중 오류 발생시 전체가 취소되므로 사전 처리 필요.
									ㄴ 가령, unique 제약 위반하는 row 존재시 이를 conflict on 같이 필터링 할 수 없음.
							</pre>
						ㄴ 'PREPARE' 명령어 사용.
							ㄴ
						ㄴ 대량의 데이터인 경우, copy가 insert보다 대부분 빠르다함.
							insert에 prepare가 사용되고, 한 트랜잭션 안에 batch로 insert하더라도.
					</pre>
					ㄴ index 제거
						ㄴ 새 테이블을 만드는 경우,
							테이블 생성, copy로 bulk insert, table에 index 추가  순서의 방식이 가장 빠르다.
							데이터를 삽입하며 점진적으로 index가 추가되는 것보다, 이미 있는 데이터들에 대해 index를 만드는게 빠르기때문.
						ㄴ 하여, 기존 데이터들이 있는 테이블에 대량의 데이터를 삽입하는 경우,
							인덱스를 삭제 후, bulk insert 후, 다시 인덱스를 만드는 것이 더 빠를 수 있다.
							물론, 인덱스가 없는 동안의 다른 연산의 성능 이슈와, ??? unique index로 인한 unique조건 체크를 고려해야한다.
					ㄴ foreign key 제거
						ㄴ index의 경우와 마찬가지로, 외래키를 제거하고 bulk insert 후 외래키를 다시 추가하는 것이 더 빠를 수 있고,
							이에 따른 외래키 조건 체크를 고려해야한다.
				</pre>

				ㄴ client Authentication<button>more</button>
				<pre>
					ㄴ postgresql 클리이언트 어플리케이션이 db server에 연결을 시도할 때, 그 유저에 대한 인증 과정에 대한 내용.
						즉, postgresql 접속시 유저 '인증' 과정에 대한 내용.
					ㄴ pg_hba.conf<button>more</button>
					<pre>
						ㄴ ex )
							# TYPE  DATABASE        USER            ADDRESS                 METHOD

							# "local" is for Unix domain socket connections only
							local   all             all                                     peer
							# IPv4 local connections:
							host    all             all             127.0.0.1/32            scram-sha-256
							# IPv6 local connections:
							host    all             all             ::1/128                 scram-sha-256
							# Allow replication connections from localhost, by a user with the
							# replication privilege.
							local   replication     all                                     peer
							host    replication     all             127.0.0.1/32            scram-sha-256
							host    replication     all             ::1/128                 scram-sha-256

							# custom
							host 	all				all				192.168.75.1/32			scram-sha-256

						ㄴ db에 대한 클라이언트 인증을 설정하는 text 파일.
							db에 대한 연결 시도에 대해,
							연결 유형, 연결하려는 db name, user name, 연결 시도하고 있느 ip주소, 인증 방법을 하나의 record로 작성하고
							이 record조합에 매칭되는 연결만 허용하며, 매칭시 인증방법은 record에 명시된 인증방법을 사용하도록 하는식으로 동작.
						ㄴ 위에 있는 record부터 차례로 탐색하며 매칭되는 record를 찾고 없으면 연결 거부.
							record중 하나에 매칭되어 인증 진행했는데 실패시 다음 record를 시도하는것 없이 그냥 실패.
						ㄴ 기타 작성 규칙
							ㄴ 빈줄 무시. 주석은 '#'로 시작하는줄.
							ㄴ 각각의 record는 줄을 넘겨 이어질 수 없다.
							ㄴ 하나의 record는 스페이스 또는 탭으로 구분되는 여러 필드들로 구성.
							ㄴ 필드값은 쌍따옴표로 감싸질 경우 스페이스를 포함할 수 있다.
							ㄴ 필드들에서 사용되는 특별한 키워드들(replication, all 등)을 쌍따옴표로 감쌀 경우, 해당 키워드로서 사용되지 않고
								문장을 그대로 사용하게됨.
						ㄴ 가능한 형식은 다음과 같음.
							local         database  user  auth-method [auth-options]
							host          database  user  address     auth-method  [auth-options]
							hostssl       database  user  address     auth-method  [auth-options]
							hostnossl     database  user  address     auth-method  [auth-options]
							hostgssenc    database  user  address     auth-method  [auth-options]
							hostnogssenc  database  user  address     auth-method  [auth-options]
							host          database  user  IP-address  IP-mask      auth-method  [auth-options]
							hostssl       database  user  IP-address  IP-mask      auth-method  [auth-options]
							hostnossl     database  user  IP-address  IP-mask      auth-method  [auth-options]
							hostgssenc    database  user  IP-address  IP-mask      auth-method  [auth-options]
							hostnogssenc  database  user  IP-address  IP-mask      auth-method  [auth-options]
						ㄴ 필드 요소 <button>more</button>
						<pre>
							ㄴ 연결 타입
								ㄴ local : ???
								ㄴ host : TCP/IP를 이용하는 연결시도와 매칭됨. SSL이건 아니건, ???GSSAPI 암호화이건 아니건 관계없음.
								ㄴ hostssl : ssl을 이용하는 TCP/IP 연결과 매칭. 사용하려면 postgresql 서버에 ssl세팅이 되어있어야함.
												아닌경우, record가 무시됨.
								ㄴ hostnossl : ssl을 사용하지 않는 TCP/IP연결과 매칭.
								ㄴ hostgssenc : GSSAPI 암호화를 사용하는 TCP/IP연결과 매칭. 사용하려면 postgresql 서버가 GSSAPI세팅이 되어있어야함.
												아닌 경우, record가 무시됨.
								ㄴ hostnogssenc : GSSAPI 암호화를 사용하지 않는 TCP/IP연결과 매칭.
							ㄴ database
								ㄴ 연결 시도하는 db를 매칭.
								ㄴ 'all' 값일시 모든 db를 매칭.
								ㄴ 'sameuser'일시, db명이 접속하려는 유저와 동일한 경우에만 매칭.
									즉, postgres유저가 postgres db에 연결은 매칭되지만 noname_db db에 연결은 매칭 안됨.
								ㄴ 'samerole'일시, 접속하려는 유저가 db명과 동일한 role의 멤버일 경우 매칭. (과거 'samegroup'과 동일하다함)
									superuser는 'grant (*타겟 role*) to (*superuser role*)' 등으로 명시적으로 해당 role의 멤버가 되는게 아니면
									role의 멤버로서 고려되지 않는다? (???role의 멤버가 아니니 당연한거 아닌가?)
								ㄴ 'replication'인 경우, physical replication 연결인 경우 매칭.
								ㄴ 그 외의 경우들은 모두 특정 db명. 여러개인 경우 콤마로 구분하여 입력. ex ) noname_db,postgres
							ㄴ user
								ㄴ 연결 시도하는 db user를 매칭.
								ㄴ 'all'인 경우, 모든 유저와 매칭.
								ㄴ 그 외의 경우들은 특정 user명. 해당 유저와 매칭됨. database 필드와 마찬가지로 콤마로 구분하여 여러개 설정 가능.
							ㄴ address
								ㄴ 연결 시도하는 클라이언트의 address를 매칭.
								ㄴ 호스트명 | address range | 정해진 키워드값이 올 수 있다.
								ㄴ 주소는 일반적으로 사용하는 CIDR mast형태로 사용. ex ) 112.220.72.179/32, 0.0.0.0/0
								ㄴ 주소는 IPv4, IPv6형태 모두 가능하며, 각 형태에 해당하는 연결과 매칭됨.
									즉, address에 IPv4형태로 주소 입력시, IPv4연결만 매칭되는식.
								ㄴ 'all' 키워드 입력시, 모든 address와 매칭.
								ㄴ 'samehost' 키워드 입력시, db서버의 ip에 해당하면 매칭.
								ㄴ 'samenet' 키워드 입력시, db서버가 직접 연결된 서브넷 내의 주소면 매칭.
								ㄴ ip address형태가 아니거나 정해진 키워드값이 아닌 경우, host명으로 취급.
								ㄴ host명인 경우 매칭여부 확인 방법
									ㄴ 클라이언트의 ip에 대해 reverse DNS Lookup 실행.
									ㄴ reverse DNS Lookup실행 결과에 명시된 host명이 있으면, host명에 대해 DNS(정방향) lookup 수행.
									ㄴ 정방향 결과에 클라이언트의 ip주소가 있으면, 양방향으로 모두 있는 것이고 이 경우 connection request가 매칭됨.
									ㄴ ??? 이렇게 하는 이유? Users sometimes wonder why host names are handled in this seemingly complicated way, with two name resolutions including a reverse lookup of the client's IP address. This complicates use of the feature in case the client's reverse DNS entry is not set up or yields some undesirable host name. It is done primarily for efficiency: this way, a connection attempt requires at most two resolver lookups, one reverse and one forward. If there is a resolver problem with some address, it becomes only that client's problem. A hypothetical alternative implementation that only did forward lookups would have to resolve every host name mentioned in pg_hba.conf during every connection attempt. That could be quite slow if many names are listed. And if there is a resolver problem with one of the host names, it becomes everyone's problem.
										Also, a reverse lookup is necessary to implement the suffix matching feature, because the actual client host name needs to be known in order to match it against the pattern.
										Note that this behavior is consistent with other popular implementations of host name-based access control, such as the Apache HTTP Server and TCP Wrappers.
								ㄴ ??? ~~~The host name that is used in pg_hba.conf should be the one that address-to-name resolution of the client's IP address returns, otherwise the line won't be matched. Some host name databases allow associating an IP address with multiple host names, but the operating system will only return one host name when asked to resolve an IP address
								ㄴ host명이 dot(.)로 시작할 경우, domain의 suffix형태로 취급하여 매칭시킨다.
									ㄴ ex ) host명이 '.example.com'인 경우, 'foo.example.com' 등과 매칭.
								ㄴ host명 사용할거면, DNS에서 name resolution이 납득할만하게 빨라야 한다함.
									???아님 'nscd'같은 local name resolution 캐시에 저장하든가.
							ㄴ IP-address, IP-mask
								ㄴ CIDR형태의 ip주소 표기방법의 대용. ???~~~
							ㄴ auth-method
								ㄴ connection request가 row와 매칭되었을 때, 사용할 인증 방법 설정.
									정해진 키워드 값들이 올수있으며, case-sensitive하다.
								ㄴ 목록 )
									ㄴ 이후 나오는 '인증 method들' 참조. 거기에 나오는 인증방법들을 여기에 명시하는 것.
									ㄴ trust
										ㄴ 인증 없음.
										ㄴ 당연히, pg_hba.conf에서 해당 row와 매칭되기 위한 database, username 컬럼에서 이미 필터링된것이긴함.
									ㄴ reject
										ㄴ 무조건 거절. 특정 연결시도들을 필터링하는데 유용하다함.
									ㄴ scram-sha-256
									ㄴ md5
									ㄴ password
									ㄴ gss : GSSAPI 인증 사용. 자세한 내용은 하위 '인증 method들' 참고.
									ㄴ sspi : SSPI 인증 사용. 자세한 내용은 하위 '인증 method들' 참고.
									ㄴ ident
									ㄴ ~~~
							ㄴ auth-options
								ㄴ auth-method에 따라, 인증에 추가적인 인자가 필요한 경우 사용.
						</pre>
						ㄴ 필드 값에 '@'를 붙여 파일형태를 입력할 경우,
						ㄴ 연결 요청에 대해 record들이 순서대로 매칭을 시도하므로, record의 순서에 대해 고려 필요.
							ㄴ 보통, 위쪽으로 갈 수록 좁은 범위의 매칭조건과 상대적으로 약한 인증메소드를 위치시키고
								아래로 갈 수록 넓은 범위의 매칭조건과 강항 인증 메소드를 설정.
						ㄴ pg_hba.conf파일은 서버 시작시와 main server process가 'SIGHUP signal'을 받을때 읽힌다.
						ㄴ postgresql의 system view인 'pg_hba_file_rules'에서 pg_hba.conf의 내용에 대한 요약을 볼 수 있다.
							error컬럼이 존재하여 해당 row에 대한 오류 확인 가능.

					</pre>
					ㄴ ??? User name map
						ㄴ ~~~

					ㄴ 인증 method들 <button>more</button>
					<pre>
						ㄴ trust 인증
							ㄴ 'trust'
							ㄴ 인증절차 없음. db에 접속 가능한 누구든, 아무 유저로나 인증을 패스할 수 있음.
							ㄴ 당연히, 사용에 주의해야함.
						ㄴ password 인증
							ㄴ 비번이 서버에 저장되는 방식, 클라이언트가 입력한 비번이 연결에서 전달되는 방식에 따라 구분되는 몇가지 존재.
							ㄴ 'scram-sha-256'
								ㄴ 'SCRAM-SHA-256' 인증 메커니즘 사용.
								ㄴ ??? https://datatracker.ietf.org/doc/html/rfc7677 에 상세내용.
								ㄴ ??? challenge-response 스키마 방식으로 'password sniffing' 공격을 방지
								ㄴ 암호화된 hash형태로 서버에 비번을 저장.
								ㄴ 가장 보안이 강함.
							ㄴ 'md5'
								ㄴ 'scram-sha-256'보다는 보안이 약한 메커니즘.
								ㄴ ~~~
							ㄴ 'password'
								ㄴ 단순 텍스트로 비번을 전달하는 방식.
								ㄴ 당연히 사용할일 거의 없으나, 연결이 ssl로 보호되는 경우 사용해도 괜찮.
							ㄴ postgresql의 비번은 os user의 비번과 별개이다.
							ㄴ postgresql의 비번은 system catalog인 'pg_authid'에 저장된다.
							ㄴ 'create role', 'alter role' 명령어 등으로 유저의 비번관리 가능.
							ㄴ 유저의 비번이 설정되지 않았다면 비번은 null이고 비번인증은 통과될 수 없다.

					</pre>
				</pre>

				ㄴ Database Role <button>more</button>
				<pre>
					ㄴ postgresql에서는 'Role'이란 개념을 기준으로 database에 대한 접근 권한을 관리한다.
						role은 특정 유저 또는 유저 그룹일 수 있으며,
						postgresql의 테이블, 함수 등 database object를 소유하거나 해당 object들에 대한 권한을 다른 role에게 부여할 수 있다.
					ㄴ postgresql version 8.1 이전에 사용되던 'user', 'group' 개념은 이 'role'안으로 포함되었다.

					ㄴ os의 유저와 별개
					ㄴ database별이 아닌 cluster 단위로 global하다.
					ㄴ CREATE ROLE
						ㄴ role 생성 sql command.
						ㄴ ex )
							create role (*role 명*);  --
						ㄴ postgresql client application 'createuser'는 이 sql command를 wrap하여 동작한다.
						ㄴ ~~~
					ㄴ DROP ROLE
						ㄴ role 제거 sql command.
						ㄴ postgresql client applicaton 'dropuser'는 이 sql command를 warp하여 동작한다.
					ㄴ postgresql system catalog 인 'pg_roles'에서 role 정보 조회 가능.
					ㄴ DBMS 처음 세팅하면, 항상 'superuser'인 role이 하나 기본적으로 존재. 이름은 db cluster를 초기화한 os의 유저와 동일.
						(일반적으로 'postgres' 유저)
					ㄴ db server에 대한 연결은 항상 특정 role로서 가능. 연결을 시도하는 클라이언트는 항상 이 role을 명시하여 접근 시도.
						이 role에 따라 권한이 있어 가능한 작업들이 결정.
					ㄴ role attribute <button>more</button>
					<pre>
						ㄴ role은 attribute들을 가진다.
						ㄴ 목록 )
							ㄴ login privilege
								ㄴ 해당 role이 db 연결시 사용될 수 있게해줌.
								ㄴ login 권한과 함께 정의된 role을 'database user'라고함.
								ㄴ create user 명령어사용시, 디폴트로 login 권한을 가진 role이 생성.
								ㄴ 옵션에 'LOGIN' 추가
							ㄴ superuser
								ㄴ 모든 권한 체크를 통과할 수 있다함.
								ㄴ 당연히 거의 사용할일이 없어야함.
								ㄴ 옵션에 'SUPERUSER' 추가
							ㄴ database creation
								ㄴ db 생성하려면 필요한 권한.
								ㄴ 옵션에 'CREATEDB' 추가
							ㄴ role creation
								ㄴ role을 추가적으로 생성하려면 필요한 권한.
								ㄴ 옵션에 'CREATEROLE' 추가.
								ㄴ role 생성뿐 아니라, 변경, 삭제, 권한 부여, 취소 등의 작업도 가능.
								ㄴ 제한
									ㄴ superuser 권한 생성 및 superuser의 권한을
									ㄴ replication user 생성 및 변경, replication 권한 부여 또는 수정 불가.
								ㄴ ??? However, it does allow ALTER ROLE ... SET and ALTER ROLE ... RENAME to be used on REPLICATION roles, as well as the use of COMMENT ON ROLE, SECURITY LABEL ON ROLE, and DROP ROLE. Finally, CREATEROLE does not confer the ability to grant or revoke the BYPASSRLS privilege.
								ㄴ ??? Because the CREATEROLE privilege allows a user to grant or revoke membership even in roles to which it does not (yet) have any access, a CREATEROLE user can obtain access to the capabilities of every predefined role in the system, including highly privileged roles such as pg_execute_server_program and pg_write_server_files.
							ㄴ initiating replication
								ㄴ 스트리밍 리플리케이션을 시작하려면 필요한 권한.
								ㄴ 옵션에 'REPLICATION'을 추가. 스트리밍 리플리케이션을 위해선 로그인이 필요하므로 'LOGIN'권한도 같이 준다.
							ㄴ password
								ㄴ db의 client authentication method가 유저에게 비밀번호를 요구하는 경우에만 유의미. ('password', 'md5' 인증메소드)
								ㄴ create role (*name*) PASSWORD '(*비번*)';
							ㄴ inheritance of privileges
								ㄴ 해당 role이 멤버로 속한 role의 권한을 상속받으려면 필요한 권한.
							ㄴ bypassing row-level security
								ㄴ row-level security (RLS)를 통과하기 위해 필요한 권한?
								ㄴ 옵션에 BYPASSRLS 추가.
							ㄴ connection limit
								ㄴ 해당 role이 만들 수 있는 연결의 개수를 제한.
								ㄴ 디폴트는 -1로 제한없음 의미.
								ㄴ create role (*name*) CONNECTION LIMIT '10';
					</pre>
					ㄴ ALTER ROLE
						ㄴ Role 변경 command.
						ㄴ ~~~
					ㄴ ??? db의 runtime 설정값들 중 많은 것들에 대해, 특정 role 전용 디폴트 값을 설정할 수 있다?
					ㄴ membership <button>more</button>
					<pre>
						ㄴ 특정 role A를 다른 role B에게 승인(grant)하여, B가 A의 member가 되게 할 수 있다.
							이를 이용해 role들을 그룹으로 묶어 권한 관리를 용이하게한다함.
							ㄴ grant (*group역할을 하는 role명*) to (*멤버가 될 role*);
								ㄴ role을 group role에 멤버쉽으로 추가.
							ㄴ revoke (*group역할을 하는 role명*) from (*멤버인 role*)
								ㄴ role을 group의 멤버쉽에서 제거
						ㄴ 일반적으로, group용 role을 하나 만들고, 이 role을 다른 role들에게 grant하여 role들을 멤버로 묶은다음
							한곳에서 관리하는 식을 많이사용한다함.
							group용 role은 로그인 권한을 안주는게 일반적이고.
							사실, group용 role, 일반유저용 role이 따로 있는게 아닌, 다 같은 role인데 이런식으로 사용하는 것.
						ㄴ circular grant는 불가. 즉, A가 B에게 grant했는데, B가 A에게 grant하지 못함.
						ㄴ ??? 'PUBLIC'에게 role을 grant하지 못함?
						ㄴ member의 권한 사용
							ㄴ 멤버는 속한 role에 대해 'SET ROLE (*role*)' 명령어를 사용하여 로그인한 원래의 role이 아니라
								일시적으로 속한 role(즉, group role)인 것이 되어 group role의 권한 사용 가능.
								원래의 role의 권한이 없고, 생성한 object들의 소유권이 group role이되고 등.
							ㄴ 멤버 role이 'INHERIT' attribute를 가지고 있는 경우, group role의 권한을 디폴트로 사용할 수 있다.
								ㄴ 즉, 'INHERIT' attribute가 있으면 group의 권한을 상속받는 것.
								ㄴ 상속받은 권한도 본인 role에 속한 멤버에게 상속이 될 수 있다(그 멤버가 'INHERIT'속성이 있다면).
									본인 role이 상속받지 않았다면 하위 멤버에게 상속되지 않는다.
									ㄴ ex )
										grand parent -> parent -> child  와 같이 멤버구성이라하면,
										child가 INHERIT속성을 가지고 있다할 때,
										grand parent의 권한은 parent가 INHERIT속성을 가져서 상속을 받았어야지만 child에게 상속된다.
										parent가 INHERIT송성이 없어 grant parent의 권한을 상속받지 않았다면 child에게 상속되지 않는다.
							ㄴ 상속 제한 attribute
								ㄴ LOGIN, SUPERUSER, CREATEDB, CREATETABLE 들은 상속되지 않는다함.
									사용하려면 SET ROLE을 통해서만 가능.
									ㄴ !!! 이 attribute들 제외하면 권한이랄게 따로 없어 실습 못함.
					</pre>
					ㄴ drop role
						ㄴ role 제거.
						ㄴ 멤버였던 role들은 자동 멤버 해제.
						ㄴ ~~~
					ㄴ ~~~
				</pre>

				ㄴ Write-Ahead Logging (WAL)<button>more</button>
				<pre>
					ㄴ ~~~

				</pre>

				ㄴ backup, restore<button>more</button>
				<pre>
					ㄴ SQL Dump<button>more</button>
					<pre>
						ㄴ db 백업 기능.
							SQL 명령어로된 파일을 생성하여 이 명령어들을 서버에 restore시 파일 생성시점의 db 상태와 동일한 db를 만듦.
							dump 실행 순간의 db 상태를 저장.( snapshot을 생성하듯)
						ㄴ postgresql에서 'pg_dump' 프로그램을 이용하여 해당 작업 수행가능.
							ㄴ postgresql의 클라이언트 프로그램 중 하나.
								ㄴ 따라서 임의의 클라이언트단(postgre로 해당 db에 접속하는 어디든)에서 dump를 실행할 수 있다.
							ㄴ pg_dump (*db명*) > (*dump파일명*)
						ㄴ dump 실행 중에도 다른 db연산들은 실행됨.
							ㄴ ??? 단 독점 lock이 필요한 연산은 예외. (alter table 등?)
						ㄴ ??? db 연결은 일반 클라이언트 인증메커니즘과 동일하다.
						ㄴ 단 하나의 db만 dump 가능.
						ㄴ 다른 백업 방법(file-level backup, continuous archiving backup)과 다르게
							dump방식은 새로운 postgre 버전에 적용할 수 있다.
							또한 32bit, 64bit 등 다른 기계 아키텍처간 db전송이 가능하다.
							ㄴ 다른 백업 방법들은 특정 버전에 제한된다.
						ㄴ output format
							ㄴ plain-text
								ㄴ 일반 텍스트 형식.
								ㄴ sql command로 이루어짐.
								ㄴ postgresql의 psql 클라이언트 프로그램을 이용해 restore 가능한 형식.
									이 외의 형식들은 pg_restore 클라리언트 프로그램 이용.
							ㄴ
						ㄴ ??? template0와 관련됨? dump로 데이터 추출하는 db에서 커스텀된 template1가 있다면
							이 내역들이 restore되는 db에도 적용되게됨?
						ㄴ pg_dump 옵션들
							ㄴ --data-only
								ㄴ
							ㄴ -n
							ㄴ -t
							ㄴ -h : 연결할 서버의 주소 명시. 디폴트는 localhost 또는 ??? 'PGHOST' 환경변수의 값.
							ㄴ -p : 연결할 서버의 포트 명시.
							ㄴ -U (*username*)
								ㄴ ??? pg_dump는 디폴트로 db연결시 현재 사용자의 username을 연결하려는 db의 username으로 입력하며
									연결시도.
								ㄴ 이 옵션으로 연결시 사용할 username 명시가능.
							ㄴ -F (*format명*)
								ㄴ output의 파일형식 설정.
								ㄴ 목록 )
									ㄴ p (=plain)
										ㄴ plain text sql script형태. 디폴트값.
									ㄴ c (=custom)
										ㄴ
									ㄴ d (=directory)
										ㄴ ~~~
										ㄴ 사용시, pg_dump에 -f 옵션 추가 필수.
									ㄴ t (=tar)

						ㄴ restoring dump
							ㄴ pg_dump의 결과물은 'psql' 프로그램이 읽을 수 있는 형태로 만들어지며,
								psql로 dump 결과물을 읽게하는 명령어는 다음과 같다.
								psql (*db명*) < (*dump파일명*)
							ㄴ restore할 db에서 ??? 객체를 소유하고 있거나 객체에 대해 권한이 승인된 모든 유저가 존재해야한다.
								아닐 경우 ownership, 권한 이슈로 객체생성을 못하여 restore 실패.
							ㄴ restore 중 오류 발생시, 디폴트 동작은 나머지를 계속 실행하는 것.
								이를 변경하려면 psql --set ON_ERROR_STOP=on ~~~ 와 같이 옵션을 주어 오류 발생시 종료하게 해야함.
							ㄴ restore가 한 트랜잭션에서 수행되어 모두 적용되거나 모두 롤백되도록 하려면
								psql에 -1 또는 --single-transaction 옵션 추가.
								ㄴ 현재까지 진행되었던 모든 restore가 모두 롤백되므로 많은 시간을 날릴 수 있어 유의필요.
							ㄴ ??? pipe를 이용해 한 서버에서 dump와 동시에 다른 서버로 restore를 할 수 있다.
								ㄴ ex ) pg_dump -h host1 dbname | psql -h host2 dbname

						ㄴ pg_dumpall
							ㄴ ??? db cluster 관련 컨텐츠 전체를 dump하는데 사용?

						ㄴ 대용량 dump output 처리.
							ㄴ pg_dump는 output을 standard output에 write 할 수 있음.
								이를 이용해 os단에서 파일 최대 크기가 제한되어 dump output file 관련 이슈가 생기는 경우 해결 가능.
							ㄴ 사용 예 )
								ㄴ output 압축
									ㄴ ex )
										pg_dump (*db명*) | gzip > (*파일명*).gz
										gunzip -c (*파일명*).gz | psql (*db명*)
										cat (*파일명*).gz | psql (*db명*)
								ㄴ split 사용
									ㄴ ~~~ ???
								ㄴ custom dump format
									ㄴ ??? ~~~
								ㄴ parallel dump 기능
									ㄴ pg_dump에는 병렬모드가 있어 여러 테이블들을 동시에 dump할 수 있다.
									ㄴ dump 속도 상승 & db서버 부하 증가.
									ㄴ pg_dump -j 3
										ㄴ
									ㄴ 이 모드 사용시, output format은 'directory' 이어야함.
										디렉토리만 멀티 프로세스가 동시에 write가능하기 때문.
									ㄴ 이 모드 사용시, 옵션으로 넘긴 값 + 1 만큼의 연결 생성.
										ㄴ db max connection 수에 유의.
									ㄴ 이 모드로 dump 중, db object에 대한 독점 lock 연산 실행시 dump 실패 가능성 존재.
										ㄴ ???~~~
									ㄴ 이 모드 사용 위해선, db server가 'synchronized snapshot' 기능을 지원해야함.
										ㄴ postgresql 9.2부터 지원.ㅓ
										ㄴ ??? synchronized snapshot이란
											db 클라이언트가 서로 다른 connection을 사용하고 있어도 같은 데이터set을 보게해주는 기능?
									ㄴ restore시 pg_restore -j 사용.

					</pre>
					ㄴ File System level backup<button>more</button>
					<pre>
						ㄴ ??? db가 데이터를 저장하는데 사용하는 파일을 직접적으로 복사하여 백업하는 방식?
							ㄴ ??? 파일의 위치?
							ㄴ ??? 해당 파일을 복사하는 방법 뭐든 사용 가능? 그냥 복사만 해서 가지고 있으면 된다?
						ㄴ 조건
							ㄴ db서버가 꺼져있어야함. restore시에도 마찬가지.
								ㄴ ??? 모든 연결을 끊어 막는 등의 방법은 안먹힘?
									tar같은 툴들이 파일시스템의 원자적 스냅샷을 찍지 않기 때문에, 그리고 서버 내의 버퍼 때문에?
							ㄴ ??? db 파일시스템에 대해 잘 아는 경우, 파일이나 폴더로부터 특정 테이블이나 db만을 백업하거나 restore하는걸
								시도할 수 있으나, 먹히지 않는다.
								??? 해당 파일에 있는 정보들은 커밋 로그 없이 사용할 수 없기 때문?
								ㄴ ??? 커밋 로그 파일이란 'pg_xact/*'에 위치하고, 모든 트랜젝션에 대한 커밋상태를 포함?
								ㄴ 전체 백업 & 전체 클러스터 복원만 가능?
						ㄴ ??? 방법 중 하나로 file system의 snapshot 기능?
						ㄴ ~~~ ???

					</pre>
					ㄴ 지속적 보관 & 특정시점복구(Point-in-Time Recovery, PITR)<button>more</button>
					<pre>
						ㄴ postgresql은 클러스터의 데이터 폴더의 'pg_wal/' 위치에 WAL파일(write ahead log)을 관리.
							wal log들은 데이터베이스에 가해지는 모든 변경사항을 기록.
							충돌방지 목적. db 시스템에 충돌 발생시, 마지막 체크포인트 이후의 wal로그들을 재실행하여 무결성을 해치지 않게 복구 가능.
							이 wal을 이용해 백업도 가능. 파일시스템 백업과 WAL을 함께 사용하는 방식.
							먼저 파일시스템을 이용해 복구한뒤, WAL 로그들을 재실행시켜 복구하는 방식.
						ㄴ 장점
							ㄴ ~~~???
							ㄴ wal file을 쌓는것만으로 지속적인 백업이 가능하다. 이는 full backup을 자주하는게 어려운 대규모 db에 좋다.
							ㄴ wal file을 처음부터 끝가지 재생시킬 필요가 없다. 원하는 시점에서 중단하여 그 시점에 해당하는 db상태를 만들 수 있다.
							ㄴ 같은 base backup을 가지고 있는 다른 기계에게 wal file을 계속 적용시킴으로서 'warm standby system'을 만들수있다.
								이는 언제든 구동시킬 수 있고, 가장 최신상태에 근접한 복사본을 가지게 된다.
						ㄴ pg_dump 등을 이용하는 dump방식 백업은 WAL을 이용한 백업과 같이 사용할만한 부분이 없다고 한다.
						ㄴ 위에서 말했듯이, file system backup과 같이 사용되며, 이 방식은 db cluster 전체에 대해서만 백업이 가능하다. 일부만은 불가.
						ㄴ 저장공간을 많이 차지하는 방식이다.
						ㄴ 이방식을 사용하기 위해선, 쌓여있는 wal file들이 필요하며, 이 wal file은 최소한 백업을 시작한 시점부터는 있어야한다.
						ㄴ WAL archiving 설정 <button>more</button>
						<pre>
							ㄴ 추성적의미에서 postgre는 끊임없이 wal record를 샹산해낸다.
								그리고 이recodr들을 ‘WAL segment file’이라는 16MB의 물리적 단위로 나눈다.
								각 세그만트는 추상적 개념상 일련의 wal 중 위치를 나타내는 숫자를 부여받는다.
								wal archiving을 사용하지 않으면 포스트그리는 몇갸의 세그먼트 파일만을 샹성하고
								이들 중 더이상 필요치 않은 시그먼트파일의 이름을 다음 시그먼트 일련번호로 변경함으로서 이 몇갸의ㅜ세그먼트파일들을 재사용한다.
								즉, 체크포인트 앞에있는 내용의 wal 파일들은 필요없다 가정하는것.
								archiving wal을 하려면, 세그먼트파일에 내용이 채워질 때, 이 내용을 캐치하여 세그만트파일이 재사용되기 잔에
								다른곳에 저장해야한다.
								이 ‘다른곳에 저장‘하는 방법은 자유롭게 정할 수 있다. NFS-mount 디렉토리에 복사하든, cd에 batch하든.
								shell command나 복사에 사용할 lib을 명시하는 것을 통하여 이 자유로운 방법을 결정할 수 있다.
								cp명령어로 단순히 복사하든 c언어 함수를 호출하든.
							ㄴ 설정방법
								ㄴ wal_level 설정을 ‘relplica’ 이상으로 설정
								ㄴ archive_mode를 ‘on’
								ㄴ postgresql.conf파일의 ahrchive_command에 shell명령어 설정 또는 archive_library에 라이브러리 명시.
								ㄴ archive_command 형식
									ㄴ %p. 쌓일 파일의 경로로 댜체. 생성될 WAL file의 경로(파일명 포함) 
									ㄴ %f. 쌓일 파일명으로 대체. 생성될 WAL file의 이름.
									ㄴ 문자 %에 대한 이스케이프는 %%
									ㄴ ex)
										archive_command = 'test ! -f /mnt/server/archivedir/%f && cp %p /mnt/server/archivedir/%f'  # Unix
										archive_command = 'copy "%p" "C:\\server\\archivedir\\%f"'  # Windows
										대체 후,
										test ! -f /mnt/server/archivedir/00000001000000A900000065 && cp pg_wal/00000001000000A900000065 /mnt/server/archivedir/00000001000000A900000065
									ㄴ archive될 새 파일들에 대해 해당명령어들이 수행된다.
									ㄴ 명령어는 postgre가 실행되는 유저의 ownership으로 실향된다.
									ㄴ archive command는 상공적으로 수행했을 때만 exit status 0값을 반환해야 한다.
										0반환하면 포스트그리가 성공적으로 wal파일의 내용이 archive되었다 판단하고 삭제하거나 재사용하기때문.
										0 반환 안하면 실패라 간주하고 주기적으로 재시도함.
								ㄴ archive_library 사용하는 방식
									ㄴ~~~
								ㄴ archive command가 signal에 의해 종료되거나(???SIGTERM signal 제외),
									shell이 125이상의 종료 상태값과 함께 에러를 던지거나,
									archive function이 'ERROR'나 'FATAL'을 내보내는 경우,
									??? archive 프로세스는 중단된뒤, postmaster에 의해 재시작된다?
								ㄴ archive command나 archive lib는 기존에 존재하는 archive 파일을 덮어쓰지 않도록 해야한다. archive파일 무결성을 위해.
								ㄴ archive command나 archive lib가 기존 존재하는 archive파일을 덮어쓰지 않는지, returnn값에 문제가 없응지 등을 반드시
									테스트해야함.
									또한 저장공간이 가득차거나, 운영자가 개입하여 처리해야 하는 이슈가 있어 archiving이 반복적으로 실패하는 케이스를 고려해야한다.
									또한, 에러 상황이나 운영자에 대한 처리 요청이 적절히 기록되도록 해야한다.
									처리되지 않고 wal파일이 끝없이 쌓이는 경우, db가 shut down될 수 있다.
									archive command나 archive lib의 수행 속도가 WAL데이터 생성 속도의 평균치를 따라잡기만 한다면
									수행 속도는 크게 문제되지 않는다.
									archiving 프로세스가 좀 뒤쳐저도 db의 다른 연산들은 상관없이 진행된다.
									이로 인해, 많이 뒤쳐지면, 문제 발생시 데이터 손실이 발생할 수 있고
									???또한, pg_wal폴더에 아카이브되지 않은 wal파일이 점점 쌓여 용량초과를 일으킬 수 있다.
									???pg_wal에는 안쌓이지 않나? 계속 재사용하느까. 아카이브가 안되면 계속 쌓이나? 실습 필요.
									따라서 arching 프로세스에 대한 모니터링이 필요하다.
								ㄴ archive되는 파일명은 최대 64글자이며, ASCII문자, 숫자, dot의 조합일 수 있다.
									ㄴ ??? 파일의 상대경로 (%p)는 변경 가능해도, 파일명(%f)는 유지도어야한다?
								ㄴ wal을 통한 restore가 데이터는 복구시켜주지만 설정파일들에 대해선 복구되지 않는다. postgresql.conf, pg_hba.conf 등.
								ㄴ archive command, lib는 '완료된 wal file'에 대해서만 동작한다.
									따라서 WAL traffic이 적은 경우, 딜레이가 있을 수 있다. 이 경우 'archive_timeout' 설정 사용 가능. (WAL 부분 참고)
									ㄴ 'pg_switch_wal'을 통하여 바로 현재 wal file을 완료처리할 수 있다.
								ㄴ wal_level을 'minimal'로 설정시, 일부 sql연산은 wal에 쓰여지지 않는다.
						</pre>
						ㄴ base backup<button>more</button>
						<pre>
							ㄴ pg_basebackup tool 사용.
								ㄴ pg_basebackup
									ㄴ db data cluster 내의 파일들의 복사본을 생성하여 백업.
									ㄴ ~~~
									ㄴ 옵션 )
										ㄴ --pgdata=(*디렉토리*)
											ㄴ 백업파일이 위치할 디렉토리 경로. 
											ㄴ 없는 부모 경로까지 자동생성. 
											ㄴ 해당 경로에 이미 파일이 있는 경우, 비어잇어야함. 
										ㄴ --wal-method=(*method값*)
											ㄴ 백업 중에 생긴 wal파일을 백업 결과에 포함시킨다.
												이를 통해 standalone 백업이 가능하다???
											ㄴ 값 목록 )
												ㄴ None : wal 파일을 포함시키지 않음.
												ㄴ
										ㄴ --dbname=(*연결db정보*)
											ㄴ 연결할 서버 정보 명시. 
											ㄴ postgresql의 'connection string' 형식의 문자열로 명시. 
										ㄴ --host=(*host*) 
											ㄴ -h (*host*) 
											ㄴ 연결할 서버의 주소 명시.
										ㄴ --port=(*port*) 
											ㄴ 연결할 포트 명시. 
										ㄴ --progress : 진행상황 출력 여부. 
									ㄴ ex ) 
										pg_basebackup --pgdata /home/postgres/standby_data --progress --host=192.168.0.186 --port=5432 --username=openmetric --wal-method=none
									ㄴ 실무 팁 
										ㄴ 당연히, pg_basebackup을 실행하는쪽 서버 정보가 백업대상 서버의 pg_hba.conf에 등록되어 있어야함.
										ㄴ 당연히, pg_basebackup에서 연결한 유자가 백업대상 서버에서 replication 권한이 있어야함. 
							ㄴ ~~~
							ㄴ 백업할 경우, 파일 시스템 백업 중간에, 그리고 그 이후에 생긴 WAL 파일을 확보해야한다.
								ㄴ 이를 위해 base backup 프로세스가 'backup history file'이란걸 생성.
									다른 WAL 파일이 archive되듯이, wal file이 archive되는 곳에 바로 저장되며,
									??? file system backup에 필요한 첫번째 wal파일명 뒤에 추가적인 문자열이 붙는식의 이름을 가진다.
									ex ) '000100~~001D'가 그 wal파일이면, '000100~~001D.023810.backup' 와 같은 형식.
									??? 이 이름보다 작은 숫자의 wal파일들은 해당 file system backup을 restore하는데 있어  더이상 필요치 않다?
									이미 base backup에 반영이 되었으므로? 하지만 보험용으로 가지고 있을수는 있다.
									??? 내용은 단순 텍스트이며, 백업 관련 여러 정보다 들어있다?
							ㄴ ??? 마지막 base backup때까지 archive된 모든 wal파일을 가지고 있어야 하므로,
								base backup 주기는 archive된 wal파일을 보관하는데 얼마만큼의 저장공간을 사용할지에 따라 결정된다?
								ㄴ ??? 왜 마지막 basbackup까지 archive된 wal파일들을 보관해야? pg_basebackup으로 백업하면 현재 데이터를 파일째 복사하고,
									기존 wal파일들을 이미 적용이 되있을 것이고, 필요없지 않나?
						</pre>
						ㄴ Continuous Archive backup을 이용하여 recovering<button>more</button>
						<pre>
							ㄴ ??? 위에서 설명한 방법들로 base backup, wal archive를 이용해 db 복구하는 방법.
							ㄴ 순서
								ㄴ 1. 우선 서버 정지
								ㄴ 2. 여유 저장공간이 충분하다면, 보험용으로 전체 cluster data directory를 따로 복사해둠.
									여의치 않으면, pg_wal 폴더라도. 마치 archive되지 못한 로그가 있을 수 있으므로.
								ㄴ 3. cluster data directory 아래의 모든 파일 삭제.
									tablespace 사용시, 이들의 root directory 삭제.
								ㄴ 4. file system backup으로부터 restore. (적절한 ownership, permission으로 restore해야함)
									??? tablespace사용하는 경우, pg_tblspc 폴더의 심볼링 링크가 정확한지 확인해야함.
								ㄴ 5. pg_wal 아래 파일들 삭제.
									이 파일들은 파일시스템백업으로부터 왔으므로, 굳이 쓸모가 없다.
									??? pg_wal에 아예 archive를 하지 않았었다면, 적절한 permission으로 생성해놓아라?
									??? 이전에 pg_wal을 심볼릭링크로 사용한 경우, 그렇게 다시 설정해두어라?
								ㄴ 6. 2번 단계에서 따로 복사해둔 '아직 archive 되지 않은 wal 파일'이 존재한다면,
									pg_wal 안으로 복사해라.
								ㄴ 7. cluster data directory에 'recovery.signal' 파일을 생성하고 postgresql.conf에
									recovery 관련 설정을 한다. ('restore_command' 등)
									recovery가 완료될때까지 다른 일반유저가 연결할 수 없도록 잠시 pg_hba.conf를 수정할 수 있다.
								ㄴ 8. 서버를 시작. 서버가 recovery 모드에 들어갈것이고, archive된 wal파일을 읽어 recovery가 진행될 것이다.
									??? 외부 오류로 인해 복구 종료시, 서버 재시작하면 알아서 복구를 계속한다함.
									recovery완료시, 서버는 recovery.signal파일을 삭제 후, 일반 db연산을 시작.
								ㄴ 9. db가 정확한 상태로 recovery되었는지 확인. 아닐시, 1번 단계로 돌아간다.
									맞다면, 7번에서 pg_hba.conf를 변경했었다면 되돌려놓는다.
							ㄴ 7번 단계에서 설정하는 restore_command 중요. postgre에게 archived된 wal file segment들을 어떻게 가져올지를 설정하는 것.
								WAL 설명부분 참고.
							ㄴ ??? wal file만 restore_command를 통해 요청받는건 아니다? '.history' suffix인 파일들도 있다?
							ㄴ ??? restore_command의 '%f'와 '%p'의 base name은 다르다? 서로 상호교환가능할거라 여겨선 안된다?
							ㄴ 찾는 wal file이 archive location에 없는 경우, 다음으로 pg_wal에서 찾는다.
							ㄴ recovery 프로세스는 마지막엔 restore_command에 설정한 명령어 실행 중 '파일을 찾을 수 없다'는 오류로 끝난다.
								또한, 프로세스 시작 시점에 '00000001.history' 파일을 찾을 수 없다는 오류가 뜰수있다.
								이들은 실제 오류가 아닌 일반적인 진행 과정이다.
							ㄴ 과거 특정한 시점으로 recovery 하고 싶으면 'recovery target' 설정을 이용.
								ㄴ 단, base backup으로 백업되는 부분 안에서는 특정 시점으로 recovery는 안됨. base backup으로 복구되는 시점 이후,
									wal file로 복구하는 지점 중에 존재하는 특정 시점으로의 복구만 가능.
							ㄴ wal file 복구중 충돌 발견시, 복구가 중단되고 서버가 자동으로 재시작하지 않음.
								??? 충돌 지점 이전으로 'recovery target'을 지정하여 복구과정을 재실행시켜 복구를 완료할 수 있다.
								ㄴ recovery target
									ㄴ 일반적으로 recovery 프로세스는 wal 파일의 마지막 부분까지 복구시키지만, recovery target을 이용하면
										그 이전지점까지만 복구를 진행할 수 있다.
										config 파일에 다음 설정값들로 설정할 수 있다.
										recovery_target, recovery_target_lsn, recovery_target_name, recovery_target_time,
										recovery_target_xid 들의 경우, 이 중 하나만 명시 가능. 아닌 경우 에러.
										설정 후 서버 재시작 필요.
									ㄴ 설정값들
										ㄴ ~~~
							ㄴ 복구 과정이 외부 요인으로 실패한 경우(시스템 충돌, wal 파일 접근권한 등), 실패지점부터 다시 시작할 수 있다.
								??? ~~~
						</pre>
						ㄴ ??? Timeline ??? 실습필요<button>more</button>
						<pre>
							ㄴ ??? 위에서 과거 특정 시점으로 recovery가 가능하다고 했는데, 이때 시간순서에 상관없이 임의의 시점으로 왔다갔다하며 복구를
								해야 하는 경우가 있다면, 이렇게 왔다갔다 하는 과정에서 wal파일이 덮어씌여져버리면 해당 지점으로 이동할 수 없게 된다.
							ㄴ 이러한 문제를 위해 postgresql에선, 복구가 완료될 때마다 그 지점부터 시작되는 'timeline'을 생성하고 해당 타임라인에 속하게 된다.
								git 의 branch와 유사? merge가 없이 특정 지점(git에선 commit, 여기선 특정 wal지점)에서
								새로운 가지로 뻗어나가기만 하는 branch라보면 된다?
								ex) 복구하면 timeline 2생성 & 그 시점부터 쌓이는 wal로그는 timeline 2에 속함.
									또 다른 위치로 복구시, timeline 3 생성...
								그 지점부터 생기는 wal은 해당 타임라인에 속하게 되며, 타임라인에 속한 wal파일끼리는 이름이 구분되어 다른 타임라인의 wal파일이
								덮어쓰지 않게된다.
								ex ) pg_wal/000000010000000000000001 =>timeline 1에 속함. pg_wal/000000020000000000000001 => timeline 2에 속함.
								타임라인이 생성될 때, 00000002.history 와 같은 형식의 history파일이 생성. 'timeline history'라 부름. archive location에 생성.
								해당 타임라인에 대한 분기지점 정보를 가지고 있음. 즉, 어느 타임라인에서 생성된 타임라인인지.
								ex) timeline1의 A시점으로 복구시, timeline2가 생기고, 이 timeline2는 timeline1의 A에서 분기한 것.
									timeline2 위의 특정 시점B으로 복구시, timeline3이 생기고,
									이 timeline3은 timeline1의 A -> timeline2 B 순으로 분기한 것. 이런 정보가 텍스트로 적혀있음.
							ㄴ 복구시 디폴트 동작은, archive location에서 찾을 수 있는 가장 최신 timeline까지 복구하는 것.
								??? 특정 timeline으로 복구하려면 ~~~???
						</pre>
						ㄴ PITR 팁 및 주의사항<button>more</button>
						<pre>
							ㄴ 쌓이는 wal 파일의 크기가 부담된다면 archive시 압축하여 저장할 수 있다.
								archive command나 archive라이브러리 사용시 압축하여 저장하고 복구시 압축해제 로직을 추가하면 된다.
							ㄴ command로 archive나 restore할 경우, config파일에 직접 명령어를 문자열로 입력하기보다
								스크립트 파일을 사용하면 깔끔하다.
								ㄴ archive_command를 스크립트로 사용시, 'logging_collector' 설정을 해야
									스크립트에서 stderr로 쓰여지는 메세지가 db 서버 로그에 쓰여진다.
							ㄴ PITR기술 자체에 한계가 존재하고 이와 관련된 주의사항들.
								ㄴ ??? ~~~
								ㄴ 'CREATE TABLESPACE' 명령은 wal 로그에 기록시 절대경로로 기록된다.
									따라서 wal을 replay하는 경우, 그 절대경로에 tablespace를 만들게된다.
									로그가 다른 기계에서 replay되거나 같은 기계에서 replay되는 경우, 고정된 절대경로에 tablespace를 만들게 되므로
									이를 원치 않을 수 있다. 해당 경로의 기존 데이터를 덮어쓸 수도 있고.
									??? 이런 문제를 방지하기 위해선 tablespace를 새로만들거나 drop할때마다 새로운 base backup을 실행하라한다?
							ㄴ 디폴트 WAL file format은 ??? 많은 디스크 페이지 스냅샷을 포함하고 있기 때문에 꽤 크기가 크다.
								~~~ ???
						</pre>
					</pre>

				</pre>

				ㄴ High Availability, Load balancing, replication<button>more</button>
				<pre>
					ㄴ 고가용성(high availability) : 여러 데이터베이스 서버가 함께 동작하다가, 메인 서버가 문제가 생겼을 때,
						서브 서버를 사용하는 것.
					ㄴ ~~~
					ㄴ 여러 db 서버가 같이 동작하도록 하려는 경우, 동기화 문제 존재.
						ㄴ 읽기 요청인 경우, 그냥 어느 서버건 데이터를 read하여 반환하면 되지만,
							write 요청인 경우, 다른 서버들에도 write내용을 전달하여 동기화시켜야하기때문.
						ㄴ 이를 간단히 해결할 수 있는 하나의 해결책은 존재하지 않는다함. 여러 해결 방법들이 있고 이를 사용하게됨.
						ㄴ
							ㄴ 하나의 서버만 데이터를 수정하도록하는 방식.
							ㄴ 데이터를 수정하는 서버를 'read/write server' / 'master server' / 'primary server' 라 부름.
								수정된 데이터를 팔로잉하기만 하는 서버를 'standby server' / 'secondary server' 라 부름.
							ㄴ primary 서버로 승격되기 전까지 실제 연결시키지 않는 서버를 'warm standby server'라 부름.
							ㄴ 실제 연결을 받고, read 요청만 받는 서버를 'hot standby server'라 부름.
					ㄴ 방법들
						ㄴ 공유디스크를 이용한 장애처리
							ㄴ
						ㄴ 파일 시스템 replication
							ㄴ db의 파일시스템 자체를 복제. 한 db의 데이터에 변경 발생시, 다른 db의 데이터에도 파일시스템 차원에서
								변경사항을 복제하여 동일하게 만듦.
							ㄴ ??? 운영서버의 변경순서와 동일한 순서로 파일시스템이 대기서버에서 복제되어야 한다?
							ㄴ ??? 솔루션 ) linux의 DRBD
						ㄴ WAL shipping <button>more</button>
						<pre>
							ㄴ warm / hot standby 서버는 primary서버의 WAL record stream을 읽어 최신 상태 유지 가능.
							ㄴ primary가 문제가 생겼을 때, primary서버 대체 가능.
							ㄴ ??? WAL shipping은 동기적 방식 또는 비동기적 방식으로 수행 가능?
							ㄴ ??? db서버 전체에 대해서만 수행가능하다
							ㄴ ??? db테이블에 대한 변경을 요하지 않아 관리 편함
							ㄴ ??? primary 서버에 상대적으로 성능부하를 일으키지 않음.
							ㄴ WAL record를 보내는 방식에 따라 'file-based log shipping', 'record-based log shipping'으로 분류.
								ㄴ file-based log shipping
									ㄴ WAL record 파일을 전송하는 방식.
									ㄴ WAL record 파일 하나에 16MB.
									ㄴ 같은 시스템상에 있건, 다른 시스템상에 있건, globe가 다르건 쉽게 전송 가능.
								ㄴ record-based log shipping
									ㄴ primary에 WAL record가 생기면 이를 바로 standby로 보내는 방식.
									ㄴ file-based에 비해 상대적으로 더 최신 상태 유지 가능.
							ㄴ WAL shipping은 비동기이다.
								ㄴ 즉, primary에서 commit 후, standby로 WAL가 전송되는 것.
								ㄴ primary서버에 치명적인 문제 발생시, 데이터가 전송되지 못하고 손실될 수 있다.
							ㄴ db server의 archive_timeout설정으로 wal file 저장 간격 조정 가능. (WAL 설명 부분 참고)
								ㄴ 이를 이용해, primary서버에 오류로 인해 데이터 손실 발생시, 그 손실되는 데이터 크기를 줄일 수 있다.
							ㄴ ??? recovery 성능은 충분히 좋다.
								standby서버가 활성화된 후 일반적으로 몇분이면 완전히 사용 가능하다.
							ㄴ standby server가 read-only 쿼리에 사용될 수 있으며, 이를 'hot standby server'라 한다. (이후 설명함)
							ㄴ ???
								ㄴ 운영 서버와 standby서버는 최대한 유사하게 구성.
									ㄴ ??? db server관점에서 특히?
									ㄴ ??? tablespace들과 관련된 경로명들은 수정없이 바로 전달되기때문에
										primary와 standby서버가 동일한 마운트포인트를 가져야한다?
										ㄴ ??? 'CREATE TABLESPACE' 명령 실행 전에, primary와 standby서버에서
											이 명령 실행을 위한 새로운 마운트포인트가 생성되어 있어야 한다.
									ㄴ 하드웨어는 완전히 동일할 필요는 없으나 유사할수록 이후에 유지보수하기 쉽다.
										하드웨어 아키텍쳐는 동일해야한다. ex) 32bit, 64bits 등.
								ㄴ 두 서버의 major release level이 같아야한다.
									ㄴ 서로 다른 minor release level이면 가능하다
									ㄴ 새로운 minor release 로 업데이트하려면, standby서버를 먼저 업데이트하는게 좋다?
										새 minor release는 이전 minor release의 WAL file을 읽을 수 있는 경우가 그 반대의 경우보다
										많으므로.
							ㄴ standby 서버 동작.
								ㄴ 서버 시작시, data directory에 'standby.signal' 파일 존재시, 서버가 standby mode가 된다.
								ㄴ standby 모드에서, 서버는 primary서버로부터 받은 WAL들을 지속적으로 적용시킨다.
								ㄴ standby는 'WAL archive' 또는 primary로부터의 TCP연결을 통해 직접 WAL을 읽을 수 있다.
								ㄴ ??? 또한 standby는 pg_wal 폴더의 WAL파일을 이용하여 restore을 한다.
									ㄴ 일반적으로 이경우는, standby가 restart하기 전에 primary로부터온 stream된 WAL파일을 재실행시키는
										경우에 해당한다.
									ㄴ 물론 수동으로도 가능하다.
								ㄴ ??? standby는 시작시,
									'resotre_command'를 이용하여 archive location에 있는 이용가능한 모든 WAL file로
									restoring을 시작.
									모든 WAL파일의 끝에 도달하고, restore_command가 실패했을 때, pg_wal 폴더의 모든 WAL파일로 restore.
									이것도 실패시, streaming replication이 설정되어있으면 primary server로 연결을 시도하여
									archive나 pg_wal에 존재하는 'last valid record' 지점부터 WAL을 stream하여 받아옴.
									streaming replication이 설정되어있지 않거나, streaming 연결이 끊기면, 가장 처음단계부터 다시시작.
									서버가 멈추거나, 'trigger file'에 의해 'failover'가 트리거되기 전까지 위 과정을 반복.
								ㄴ 'pg_ctl promote'가 실행되거나, pg_promote()가 호출되거나, trigger file(promote_triiger_file)이
									발견되면, standby mode가 종료되고 일반 연산모드로 전환된다. ??? primary로 전환된다?
									ㄴ ??? failover전에 archive나 pg_wal에 있는 이용가능한 WAL들은 restore된다.
							ㄴ primary 서저 세팅
								ㄴ WAL 설명부분을 참고하여 WAL archiving 설정을 한다./
									이때, archive location은 primary가 다운되어도 standby가 접근할 수 있는 곳,
									즉, primary 서버 내가 아닌, standby서버나 다른 안전한 위치이ㅓㅇ야한다.
								ㄴ streaming replication을 사용하려면, standby로부터의 replication 연결을 허용하기 위해
									??? role생성 후, pg_hba.conf에 적절한 entry를 생성 후, database field를 'replication'으로 설정한다?
								ㄴ ??? max_wal_senders, (replication slot 사용시) max_replication_slots 설정을 한다.
								ㄴ base backup을 하여 standby 서버를 부팅한다.(base backup에 대해선 '백업'부분 참고)
							ㄴ standby 서버 세팅
								ㄴ primary서버로부터 받은 base backup을 restore.
								ㄴ standby.signal 파일을 postgre data directory에 생성.
								ㄴ 'restore_command' 설정. war archive로부터 파일을 복사해옴.
									ㄴ
									ㄴ restore_command는 파일이 존재하지 않으면 즉시 return해야함. 서버가 명령어를 재시도하기 때문.
								ㄴ ??? 여러개의 standby서버를 두려는 경우, recovery_target_timeline을 'latest'로 설정해야함.
								ㄴ streaming replication 기능 쓰려면 primary_conninfo 설정 필요. 연결할 디비에 댜한 정보 설정.
								ㄴ standby를 고가용성 기능으로 사용하려는 경우 failover시 primary를 대체하기 위해
									archiving, 연결, 인증 등에 대한 서버를 primary와 동일하게 설정해두어야 한다.
								ㄴ archive_cleanup_command를 통해 더이상 standby에게 필요없는 wal파일을 삭제해 wal archive의
									공간을 최소화할 수 있다.
								ㄴ standby가 아닌 백업목적으로 wal을 archive하고 있다면 당연히 standby에게 더 필요가 없어도 삭제하면 안된다.
									최소한 base backup 시점 이후부터의 wal파일이 있어야 한다.

							ㄴ primary_conninfo 설정
								ㄴ standby server가 데이터를 보내는 서버에 연결할 때 사용할 연결정보를 나타내는 문자열.
								ㄴ server가 standby server인 경우에만 영향을 미침.
								ㄴ sending 서버의 호스트명 명시 필요.
									standby server와 포트 다를시, 포트번호 명시 필요.
									sending server에 대해 적절한 권한을 받은 user와 필요시 비번 명시 필요.
									db명은 명시하지 않는다?

								ㄴ 입력 형식 )
									ㄴ https://www.postgresql.org/docs/13/libpq-connect.html#LIBPQ-CONNSTRING 참고
									ㄴ ex ) 'host=192.168.1.50 port=5432 user=foo password=foopass'
								ㄴ 옵션 명시되지 않을시, 일치하는 환경변수를 참조. 이것도 없으면 디폴트 사용.
									ㄴ https://www.postgresql.org/docs/13/libpq-envars.html 참고.
								ㄴ postgresql.conf 파일 또는 server command line으로 설정 가능.
								ㄴ WAL receiver process 실행중 설정값 변경시, receiver process는 종료됨. 다시 재시작해야함.

							ㄴ streaming replication <button>more</button>
							<pre>
								ㄴ 파일 기빈 log shipping보다 더 최신상태를 유지하게 해줌. wal file이 모두 차는걸 기다리지 않고
									primary와 연결하여 wal record 생성시마다 primary로부터 받아온다.
								ㄴ 사용시 디폴트 설정은 비동기 리플리케이션이다.
									즉, p에 커밋된시점과 standby에서 변경사항이 적용되기까지 약간의 딜레이 존재. 매우 작긴하다함.
									s가 변경사항 적용에 뒤쳐지지만 않는다면 1초 미만이라함.
								ㄴ streaming replication 사용시, archive_timeout으로 데이터 손실창을 줄일필요 없다.
								ㄴ ???wal 파일 아카이빙 없이 스트리밍 리플리케이션 사용시, 서버가 오래된 wal segment파일을 재사용해서
									standby서버가 받지 못하는 경우가 있을 수 있다? (???스트리밍으로 wal record쏘는거 아닌가?
									wal파일이 사라지는게 뭔상관? 모든 wal들은 일단 pg_wal에 저장 후, 그 다음 stream으로 전송된다?
									pg_wal에 wal record를 우선 쌓고, 여기의 wal record를 walsender가 스트림으로 walreceiver에게
									전송한다함. 하여, 매우 많은 wal record가 빠르게 생기면서, wal segment의 ??? wal_keep_size가
									뭔설정인지 이해안감)
									이런경유 standby는 새 base backup으로 재초기화되어야 한다. wal_keep_size 설정 또는
									replication slot을 설정하여 예방 가능.
									wal 파일 아카이빙 사용시엔 필요없다. 아카이빙된 wal로 놓친부분을 따라잡을 수 있기땨문.
								ㄴ streaming replication 설정방법
									ㄴ standby server설정에서 추가적으로 primary_conninfo를 설정하여 primary server를 명시.
										이를 설정하기만 하면, 자동으로 walsender, walreciver 프로세스가 생기며 streaming 시작함.
										ㄴ 프라이머리의 호스트명, 포트, 프라이머리로 접속할때 사용할 유저명, 비밀번호를 명시함.
										ㄴ primary에서 listen_address 설정과 pg_hba.conf파일 설정하여 스탼바이가 프라이머리에 잡근할 수 있게한다.
									ㄴ ???keepalive socket 옵션을 지원하는 시스템에선 ~~~???
									ㄴ max_wal_senders로 스탠바이에서 프라이머리로 최대 병렬연결 가능한 연결 개수 설정.
								ㄴ ??? 설정이 모두완료되면 스탠바이는 아카이브에있는 모든 이용가능항 wal들을 재실행한 뒤 프라이머리에 연결한다.
									이후 스탠바이이선 walreceiver, 프라이머리에선 walsender 프로세스가 실행된다. (???wal archive에서도 같은 이름이던가?)
								ㄴ인증
									ㄴ 접근권한을 적절히 설정하여 특정 유저만 wal stream을 읽을 수 있게 해야한다.
									ㄴ 스탠바이는 replication 권한이 있는 유저 또는 슈퍼유저로 프라이머리에 접근해야함.
										replication, login 권한이 있는 replication용 유저를 따로 두는게 좋다.
									ㄴ replication 권한은 프라이머리에 대한 데이터 수정을 허용하지 않는다함.
									ㄴ 설정은 pg_hba.conf에서 database를 replication으로 설정하여 가능
								ㄴ모니터링
									ㄴ 스트림 복제 사용시 유의해서 봐야할 값은 파라이머리에서 생성된 뒤 아직 스탠바이에 적용되지 않은 wal record의 양이다.
									ㄴ primary의 wal write location과 standby의 마지막으로 받은 wal location을 확인하여 이 지연을 계산해볼 수 있다.
										각각, primary에서의 pg_current_wal_lsn(), standby에서의 pg_last_receive_lsn() 관리자 함수를 통하여
										또는 ps 명령어로 확인할 수 있는 walsender, walreceiver에 대한 정보를 통해 location을 확인할 수 있다.
									ㄴ db view의 일종인 'pg_stat_replication'을 통하여 primary의 walsender 프로세스에 대한 정보를 볼 수 있다.
										가령, pg_stat_replication의 'sent_lsn'(마지막으로 standby로 전송한 wal의 location값)과
										pg_curent_wal_lsn()값 사이의 차이가 커지면 primary가 과부화가 있어 write한 wal을 보내지 않고 있을 수 있거나
										'sent_lsn'과 standby의 pg_last_receive_lsn()값과의 차이가 커지면 네트워크상의 오류로 primary에서
										전송한 데이터를 standby에서 받지 못하고 있거나 standby에 과부화가 있어 받지 못하고 있을 수도 있다.
									ㄴ standby에선 'pg_stat_wal_receiver' view를 통해 walreceiver 프로세서에 대한 정보를 볼 수 있다.
							</pre>
							ㄴ replication slot <button>more</button>
							<pre>
								ㄴ ~~~
								ㄴ ??? 정확히 어떤 방식으로 내부 동작하여 이런 기능을 만드는지?
									wal파일들을 따로 다른 곳에 저장하는지? 아님 pg_wal폴더에서 삭제되지 않게만 하는지?
									pg_wal에서 삭제되지 않게만 하는거면 wal_keep_size 설정과 다른게 뭔지? standby들에서 모두 적용되었는지를
									모니터링 한다는 것이 차이?
									ㄴ ??? gpt는 replication_slot에 일종의 meta데이터를 저장하여 wal파일이 pg_wal에서 삭제되지 않도록만 한다하는데.
								ㄴ replication slot 사용 대신 wal_keep_size 설정이나 wal segment file archive를 통해 stadnby가
									필요로 하는 wal segment가 삭제되는 것을 방지할 수 있다.
									??? 하지만 이 방법들은 필요 이상의 wal segment들을 남기는 경우가 있다함.
									??? 그에 반해 replication slot은 딱 필요한 만큼의 segment만 남긴다함.
									ㄴ wal_keep_size
										ㄴ standby에서 stream replication으로 wal을 받아오는 경우에, primary에서 pg_wal에 지난 wal파일을
											얼마나 남길지 최소값 크기를 설정. standby가 primary에 대한 replication이 좀 밀려도,
											primary에서 pg_wal을 재사용하느라 덮어써버려 standby가 받아올 차례인 wal record가 없어져 버리는 것을 방지 위해.
											standby가 이 wal_keep_size 이상으로 replication이 밀리게 되면, replication 연결이 실패하며 끊긴다고함.
											단, wal을 archive하고 있으면 이 파일들로 복구 가능.
										ㄴ default값은 0. standby를 위해 추가적인 wal을 남기지 않음. 아예 안남긴다는게 아니고.
										ㄴ 단위는 default로 megabyte.
								ㄴ ??? replication slot이 pg_wal에 할당된 공간 이상으로 많은 수의 segment를 저장할 수도 있다함.
									max_slot_wal_keep_size 설정을 통해 slot에 남기는 wal file의 크기를 제한 가능.
								ㄴ ??? 내부적으로 어떻게 동작하는지? 대략 별도 파일에 데이터를 담아둔다는거 같은데 구체적인 동작 방식에 대한
									내용이 찾는데 오래 걸릴 것 같아 패스.
								ㄴ ~~~
								ㄴ cascading replication
									ㄴ ~~~
								ㄴ synchronous replication
									ㄴ ~~~
							</pre>
							ㄴ standby에서의 continuous archiving
								ㄴ standby에서 지속적으로 wal파일을 아카이빙하는 것에 대해 설명.
								ㄴ archive_mode 설정
									ㄴ wal segment를 archive하는 방식에 대한 설정.
									ㄴ enum값. 'off', 'on', 'always'
										ㄴ off : archive 안함.
										ㄴ on
											ㄴ archive 함. 서버가 archive recovery, standby 모드인 경우 안함.
											ㄴ standby인 경우, primary로 승격되면 archive함. 단, 이전에 안했던 wal파일들을 archive하지는 않음.
										ㄴ always
											ㄴ 서버가 archive recovery, standby 중이어도 archive 수행.
												이 경우, archive나 스트림 리플리케이션으로부터 restore된 파일들을 아카이빙함.
								ㄴ 스탠바이에서 지속적 아카이빙하는 경우 두가지 케이스로 나눌 수 있음.
									아카이빙 위치가 프라이머리, 스탠바이 모두에게 공유되는 경우와 스탠바이만 접근가능한 걍우.
									두 경우 모두 archive_mode를 always로 설정하여 아커이빙을 하지만 공유되는 경우에 아카이빙을 하기 전
									동일한 파일명이 있는지, 동일한 파일명의 파일이 동일한 컨텐츠를 가지고있는지 등을 archive_command,
									archive_library 에서 홛인하여 덮어쓰지 않도록 해야함. 아카이빙 위치에 대해 race condition도 발생하지 않도록 해야함.

							ㄴ ??? 고가용성용으로 standby설정시, 유저를 primary와 동일하게? 나중에 pruimary역할을 할거ㅏㄹ?


						</pre>
						ㄴ ??? logical replication <button>more</button>
						<pre>
							ㄴ 한 db서버의 데이터 수정의 stream을 다른 db서버로 보내는 기능?
							ㄴ ??? postgresql의 logical replication?
								ㄴ WAL record로부터 논리적 데이터 수정의 stream을 생성.
								ㄴ 테이블별 데이터 변경사항에 대한 복제 가능하다함.
								ㄴ 자신의 변경사항을 다른곳으로 전달하는 db서버가 다른 서버의 변경사항을 구독할 수도 있다.
									따라서 양방향으로 replication이 가능하다?
								ㄴ publisher-subscriver 구조로 동작.
									publication을 정의하면 그게 publisher가 됨. subscrition도 마찬가지.
									publisher와 subscriter는 다대다 가능.
									publication 생성시, 생성할 logical replication에 대한 정의, 필터, 틀만 정의한 것.
									이후, subscription생성시, 이에 연결된 publisher쪽에 replication slot이 생성되고 여기에
									logical replication 내용이 저장. subscription 실행시 worker가 replication 시작???
						</pre>
						ㄴ ??? 트리거 기반 primary-standby replication
							ㄴ 데이터 수정 쿼리를 primary서버에 전달 후, 데이터 변경사항을 비동기로(드물게 동기로) standby서버로 전달.
								standby서버는 primary서버가 실행 중에도 쿼리에 응답할 수 있다?
							ㄴ ??? ~~~
							ㄴ ??? 솔루션 ) Slony-I
						ㄴ SQL-based replication Middleware
							ㄴ 어떤 프로그램이 모든 sql query를 인터셉트 후, 이를 관련 db서버들로 전달하는 방식.
							ㄴ 각 db서버들은 독립적으로 실행되고, read-write 쿼리는 모든 서버로 전달되어 모두 동일한 변경사항을 반영하도록.
								read-only쿼리는 한 서버에만 전달되어 부하를 분산.
							ㄴ ~~~ ???
							ㄴ ex )  Pgpoll-2, Continuent Tungsten
						ㄴ asynchronous multimaster replication
							ㄴ primary-standby와 달리, 여러 서버들에 대해 write 연산이 가능하되(multimaster),
								그 서버들이 비동기로 데이터 동기화되는 reaplication.
								즉, 한 서버에 대한 변경사항이 바로 다른서버들에도 반영되지 않고 일정 시간 후에 한꺼번에
								서로 반영되며 동기화되는 방식.
							ㄴ 변경사항 동기화시에 발생하는 충돌은 수동으로 또는 충돌 resolution 룰을 정하여 처리한다.
							ㄴ 사용 가능한 외부 툴 ) 'Bucardo'
						ㄴ synchronous multimaster replication
							ㄴ primary-standby와 달리, 여러 서버들에 대해 write연산이 가능하며(multimaster)
								한 서버에 대한 변경사항 트랜잭션이 해당 서버에만 아니라 연결된 다른 서버들이 함께 반영되는(synchronous)
								replication 방식.
							ㄴ read 연산은 아무 서버에서 수행 가능하며 모든 서버에서 동일한 결과를 얻는다.
							ㄴ postgresql에서는 이런 형태의 replication 기능을 제공하지 않음.
								??? 'prepare transaction', 'commit prepared'를 이용해 직접 구현하거나 EDB 등 외부 툴 사용 필요.
						ㄴ ??? data partitioning
							ㄴ 테이블을 일정 set으로 나누고, 각 set이 특정 서버에 의해서만 변경이 가능하도록하는 방식.
						ㄴ ??? Multiple-Server Parallel Query Execution
							ㄴ 하나의 쿼리를 여러 서버가 병렬로 실행하는 방식.
							ㄴ ??? 서버간에 데이터를 분할하고, 각 서버가 쿼리에서 자기에 해당되는 부분?을 수행한 뒤 결과를
								중앙서버로 보내면, 중앙서버는 이 결과들을 취합하여 클라이언트에게 반환하는식으로 동작?
							ㄴ ??? PL/Proxy tool set을 이용하여 구현가능?
						ㄴ postgresql가 오픈소스라서, 위 방법들에 해당하는 기능을 제공하는 많은 close-source 솔루션들이 존재.
				</pre>

				ㄴ database activity monitoring<button>more</button>
				<pre>
					ㄴ unix tool을 이용한 방법 <button>more</button>
					<pre>
						ㄴ ps 명령어를 통한 postgre process확인.
							ㄴ unix os에서 postgresql은 'ps'명령어에 postgresql의 프로세스가 출력될 때, 그 프로세스들의 제목을 알아보기 쉽게 변경해준다.
							ㄴ ex ) ps -ef | grep postgres

								결과...

								postgres  1556     1  0  2023 ?        02:43:08 /usr/pgsql-13/bin/postmaster -D /home/postgres/postgre_data/
								postgres  2100  1556  0  2023 ?        00:01:27 postgres: logger
								postgres  2168  1556  0  2023 ?        00:23:29 postgres: checkpointer
								postgres  2169  1556  0  2023 ?        00:56:09 postgres: background writer
								postgres  2170  1556  0  2023 ?        00:24:27 postgres: walwriter
								postgres  2171  1556  0  2023 ?        00:01:30 postgres: autovacuum launcher
								postgres  2172  1556  0  2023 ?        00:01:01 postgres: archiver last was 00000001000005D2000000E4
								postgres  2173  1556  0  2023 ?        01:42:59 postgres: stats collector
								postgres  2175  1556  0  2023 ?        00:00:01 postgres: logical replication launcher
								postgres  6401  1556  0 14:43 ?        00:00:26 postgres: openmetric openmetric 192.168.0.1(51418) idle
								postgres  7119  1556  0  1월03 ?      00:00:17 postgres: openmetric openmetric 79.110.55.8(32398) idle
								postgres 13558  1556  1 15:40 ?        00:00:00 postgres: openmetric openmetric 192.168.0.1(61496) idle in transaction
								postgres 13767  1556  0 15:40 ?        00:00:00 postgres: openmetric openmetric 192.168.0.1(63805) idle in transaction
								postgres 13783  1556  0 15:40 ?        00:00:00 postgres: openmetric openmetric 192.168.0.1(63822) SELECT
								ㄴ 맨 위와 같은 형태가 보통 메인 서버 프로세스. 따라오는 인자들은 메인 postgre실행시 넘겨진 인자들.
								ㄴ 그 아래 형태가 background worker process. walwriter, logger, 등.
								ㄴ 아래 5줄 형태가 클라이언트와 연결된 서버 프로세스들.
									ㄴ postgres: (*user*) (*db*) (*host*) (*활동상태*)
										위와 같은 형태를 가짐.
									ㄴ (*활동상태*)를 제외하고는 고정.
									ㄴ (*활동상태*)는 'idle', 'idle in transaction', command타입('SELECT' 등) 값이 올 수 있음.
										ㄴ 'idle'은 클라이언트 명령 대기중, 'idle in transaction'은 트랜잭션 시작 후, 그 안에서 클라이언트 명령 대기중.
										ㄴ 뒤에 'waiting' 문자열 있을 수 있음.
											다른 세션이 lock을 잡고있어 대기중이란 의미.
							ㄴ 'update_process_title' 설정을 off하면, 프로세스 제목에서 (*활동상태*)가
								프로세스가 처음 실행될때를 제외하고 업데이트 되지 않는다.
								(일부 플랫폼에선 이 제목을 업데이트하지 않는게 부하를 유의미하게 줄여준다함)
							ㄴ ??? 'Solaris'의 경우 ~~~
					</pre>
					ㄴ postgresql의 'cumulative statistics system'을 이용한 방법<button>more</button>
					<pre>
						ㄴ ~~~ 여러가지 기능 지원.
						ㄴ 통계 수집 설정
							ㄴ 통계 수집이 쿼리 실행에 부하를 주기 때문에, 할지말지 설정 가능. (postgresql.conf에서)
							ㄴ 설정들 )
								ㄴ track_activities
									ㄴ 어느 서버에 의해서든, 현재 실행되고 있는 명령어 모니터링 여부 설정.
								ㄴ track_count
									ㄴ 테이블, 인덱스 접근에 대한 누적 통계 수집 여부 설정.
								ㄴ track_functions
									ㄴ 사용자 정의 함수에 대한 사용 추적 여부 설정.
								ㄴ track_io_timing
									ㄴ block read/write 시간 모니터링 여부 설정.
								ㄴ track_wal_io_timing
									ㄴ WAL write 시간 모니터링 여부 설정.
							ㄴ 개별 세션에서 SET 명령어로 이 설정들 변경이 가능하다.
								ㄴ superuser만 가능. 일반유저가 이 설정들을 off하여 통계에 잡히는걸 피하는 것 방지 위해.
						ㄴ ??? 누적 통계들은 'shared memory'에 수집된다. 각 postgre 프로세스들이 통계를 로컬에 저장하다, 적당한 주기로
							shared memory에 업데이트 친다.
							ㄴ 'shared memory'란? 여러 프로세스들이 공유하는 memory, 저장공간.
								여기선 여러 postgresql process들이 공유하는 memory라고 보면 된다.
							ㄴ 서버가 ???'clean'하게 종료되면, 통계 데이터가 pg_stat 서브디렉토리에 영구적으로 저장된다.
								이를 통해 서버 재시작해도 통계값들이 유지가 된다.
								서버 'unclean'하게 종료시(즉시 종료, 충돌, base backup으로부터 시작, PITR) 통계값들은 리셋된다.
						ㄴ 시스템의 현재 상태를 보여주거나, 누적 통계 데이터를 보여주는 사전정의된 postgresql view들이 존재한다.
						ㄴ 내장 누적 통계함수를 사용하여 커스텀 view를 만들 수도 있다.
						ㄴ 통계 view와 함수 사용시 유의사항.
							ㄴ view와 함수결과에서 볼 수 있는 통계값들이 즉각적으로 반영된 값들이 아닐 수 있음을 명심.
								각 프로세스들이 idle상태가 되기 직전에 공유메모리에 통계값들을 flush하므로.
								ㄴ ??? 단, 'track_activities'에 의해 수집되는 현재쿼리 데이터들은 항상 최신값이라함.
							ㄴ 통계 데이터 접근시, 통계값 고정 관련.
								ㄴ 통계 데이터를 쿼리하거나 하여 통계 데이터에 접근시,
									이 데이터들을 매번 집계하여 보여줄지,
									한 트랜잭션 내에서 처음 쿼리했을 때의 값을 매번 동일하게 보여줄지
									한 트랜잭션 내에서 특정한 하나의 snapshot 기준 통계값들을 보여줄지 설정이 가능하고
									이를 고려하여 통계데이터를 분석해야함.
								ㄴ 'stats_fetch_consistency' 설정값으로 설정 가능.
									ㄴ 'none' 으로 설정시,
										통계 데이터 접근시마다 매번 공유메모리로부터 새로 가져와 보여줌.
										ㄴ 모니터링에 적합하다함.
									ㄴ 'cache' 설정시,
										한 트랜잭션 내에서, 통계 데이터 접근시, 그 처음 접근된 데이터를 캐시에 저장하고
										트랜잭션 종료시 또는 pg_stat_clear_snapshot() 호출 전까지
										이 값을 똑같이 반환.
										ㄴ 디폴트값.
										ㄴ ??? self-join 등과 관련된 쿼리에 유용하다함?
									ㄴ 'snapshot' 설정시,
										한 트랜잭션 내에서, 통계 데이터 접근이 처음 발생시, 그 순간의 db에 대한 모든 통계값들을
										캐시에 저장하고 해당 트랜잭션 종료시 또는 pg_stat_clear_snapshot() 호출 전까지 이 값들을 반환.
										ㄴ 통계값 분석시 유용하다함. 모든 통계값들을 저장하므로 당연히 부하가 큼.
							ㄴ 트랜잭션도 각각의 통계 데이터를 가지며, 이 값들은 공유메모리에 flush하지 않았어도 볼 수 있고,
								'stats_fetch_consistency'에서 설정한 값들처럼 동작하지 않고
								트랜잭션 동안 지속적으로 업데이트된다.
								ㄴ pg_stat_xact_all_tables, pg_stat_xact_sys_tables, pg_stat_xact_user_tables, pg_stat_xact_user_functions
									위 view에서 확인할 수 있다.
							ㄴ 통계 viwe들 중 일부는 보안이 엄격하다.
								ㄴ ??? 일반 유저는 그들이 멤버로 있는 role에 속한 그들의 세션에 대한 정보들만 볼 수 있다?
									다른 세션에 대한 row들에는 많은 컬럼들이 null로 보일 것이다.
									단, 그 다른 세션의 존재와 그 세션들의 user, db같은 일반적인 데이터들은 보인다.
								ㄴ superuser와 'pg_read_all_stats' role 권한이 있는 role들은 모든세션의 데이터들을 볼 수 있다.
						ㄴ index별 통계 데이터는 어떤 인덱스가 많이 사용되고 효율적인지 확인하는데 유용하다.
						ㄴ 'pg_stat_io' view와 'pg_statio_~~~' view들은 버퍼 캐시의 효율을 확인하는데 유용.
							ㄴ ??? cache hit ratio 계산에 쓰일수있다?
						ㄴ ??? ~~~
						ㄴ 통계 View 목록 <button>more</button>
						<pre>
							ㄴ Dynamic 통계 view<button>more</button>
							<pre>
								ㄴ pg_stat_activity
									ㄴ 현재 server process들에 대한 정보 view.
										각 row가 각 프로세스를 의미.
									ㄴ 필드
										ㄴ 연결된 db의 OID, db name, pid, 유저 oid, 유저 name, 클라이언트 주소, 어플리케이션 이름.. 등등.
										ㄴ datid : oid type. 연결된 db의 OID.
										ㄴ datname : name type. db name.
										ㄴ wait_event
											ㄴ text type.
											ㄴ backend가 wait중인 경우, wait event의 이름.
										ㄴ state : text type. 이 backend의 상태.
											ㄴ 가능한 값 목록
												ㄴ active : 쿼리 실행중.
												ㄴ idle : 새 client 명령어 대기중.
												ㄴ idle in transaction : 트랜잭션 내에서 쿼리 대기 중.
												ㄴ idle in transaction (aborted) : idle in transaction과 동일한데,
													트랜잭션 내 statement 중 하나가 에러 발생한 상태.
												ㄴ fastpath function call : ??? fastpath function 실행중?
												ㄴ disabled : 'track_activities' 설정 꺼져있음 의미.
										ㄴ ~~~
							</pre>
							ㄴ collected 통계 view <button>more</button>
							<pre>
								ㄴ
							</pre>
						</pre>
					</pre>
				</pre>

				ㄴ Trigger <button>more</button>
				<pre>
					ㄴ 특정 연산 수행시, db가 자동으로 특정한 함수를 수행하도록 하는 기능.
					ㄴ trigger function
						ㄴ trigger 생성 전에 정의되어야 한다. 'CREATE TRIGGER' statement실행시에 이미 정의된 함수를 입력해야 하기때문.
						ㄴ 함수형태이어야하고, 인자를 받아선 안되고, 'trigger' type을 반환해야한다.
						ㄴ 'TriggerData' structure라는 특별한 인자를 받게된다.
						ㄴ 한 trigger function이 여러 trigger에 여러번 사용될 수 있다.
						ㄴ PL/pgSQL, PL/Tcl, PL/Perl, PL/Python, c언어 중 하나로 작성 가능.
							ㄴ 'plain SQL function language'는 불가.
					ㄴ table, view, foreign table에 attach가 가능.
					ㄴ table, foreign table의 경우,
						insert, update, delete 연산 직전, 직후에 트리거가 실행되도록 할 수 있고
						수정된 row마다 실행될지, statement마다 실행될지 설정할 수 있다.
						update의 경우, set구문에 특정 컬럼이 있을때만 실행되게 설정 가능.
					ㄴ trigger event 발생시, trigger function이 실행.
					ㄴ ???view의 경우, ~~~???
						On views, triggers can be defined to execute instead of INSERT, UPDATE, or DELETE operations. Such INSTEAD OF triggers are fired once for each row that needs to be modified in the view. It is the responsibility of the trigger's function to perform the necessary modifications to the view's underlying base table(s) and, where appropriate, return the modified row as it will appear in the view. Triggers on views can also be defined to execute once per SQL statement, before or after INSERT, UPDATE, or DELETE operations. However, such triggers are fired only if there is also an INSTEAD OF trigger on the view. Otherwise, any statement targeting the view must be rewritten into a statement affecting its underlying base table(s), and then the triggers that will be fired are the ones attached to the base table(s).
					ㄴ CREATE TRIGGER 구문을 통하여 트리거 생성.
					ㄴ per-row trigger vs per-statement trigger
						ㄴ per-row trigger
							ㄴ 트리거를 발생시킨 statement에 영향을 받은 row마다 trigger function이 실행된다.
						ㄴ per-statement trigger
							ㄴ statement 실행시 한번만 trigger function이 실행된다.
					ㄴ trigger 실행 시점
						ㄴ BEFORE trigger
							ㄴ per-statement BEFORE trigger의 경우, statement가 뭔가를 하기 전에 실행.
							ㄴ per-row BEFORE trigger의 경우, 특정 row가 연산이 되기 직전에 실행.
						ㄴ AFTER trigger
							ㄴ per-statement AFTER trigger의 경우, statement 마지막에 실행.
							ㄴ ??? per-row AFTER trigger의 경우, statement가 종료되기 전 ( & per-statement AFTER trigger가 호출되기전)에 실행.
						ㄴ INSTEAD OF trigger
							ㄴ ??? 해당 조건 동작 대신 실행? 가령, insert가 조건이면 insert 대신 실행?
					ㄴ??? 계층구조 table에서, 부모 테이블에 대한 statement실행은 자식 테이블의 statement-level trigger를 실행시키지 않음.
						부모 테이블의 statement-level trigger만 실행.
						자식 테이블에 영향을 받은 row존재시, 자식 테이블의 row-level trigger는 호출.
					ㄴ insert문에 ON CONFLICT DO UPDATE 구문이 있는 경우,
						~~~???
					ㄴ 파티션된 테이블에 대한 update문이 row의 파티션을 이동시킨다면,
						~~~???
					ㄴ per-statement trigger에 의해 호출된 trigger function은 null을 반환해야함.
					ㄴ 'create trigger' statement
						ㄴ
					ㄴ ~~~
					ㄴ trigger function 내에서 그 trigger가 발생된 테이블에 sql로 접근시, 이 sql에서 데이터 변경 관련하여
						어떻게 보여질지에 대한 규칙.
						ㄴ statement-level trigger function 내에서 sql 실행시, BEFORE trigger이면 아직 statement 실행 전이므로
							당연히 아무 변경사항이 보이지 않고, AFTER인 경우, 모든 변경사항이 보인다.
						ㄴ row-level BEFORE trigger인 경우, 이미 연산이 적용된 row들에 대한 변경사항은 보이나
							아직 연산이 되지 않은(현재 row포함. BEFORE trigger니까) row들에 대한 변경사항은 당연히 보이지 않음.
							아직 연산 자체가 수행 안되었으니까.
							이 연산적용되는 row순서를 예측할 수 없으므로 주의 필요.
						ㄴ??? row-level INSTEAD OF trigger의 경우, 이전 INSTEAD OF trigger에 의해 실행된 변경사항은 보임
						ㄴ row-level AFTER trigger의 경우, statement에 의해 변경된 모든 내용이 보임.
						ㄴ ??? ~~~

				</pre>

				ㄴ System Catalogs <button>more</button>
				<pre>
					ㄴ
				</pre>

				ㄴ View <button>more</button>
				<pre>
					ㄴ ~~~ 
					ㄴ Materialized View 
						ㄴ 개요 
							ㄴ 일반 View와 거의 유사하나, 
							ㄴ 항상 최신 상태가 아님. 
						ㄴ 사용처?  
							ㄴ 쿼리 비용이 좀 있지만 자주 사용되고 빠르게 조회되었으면 좋겠는 경우 
								(쿼리를 미리 실행하여 결과를 메모리상에 저장해두고, 매번 쿼리 실행하는것에 비해 빠르게 조회 가능하므로) 
							ㄴ 잘 변경되지 않고 (별도 명령어를 통해 refresh 필요하고 그 전엔 최신화 안되므로) 
							ㄴ 이 생성된 임시테이블(view)을 대상으로 또다른 쿼리를 실행하려는 경우 
								(단순 캐싱 시스템처럼 데이터를 빠르게 조회만 하는게 아니라, view라서 추가적인 쿼리가 가능하므로. 
								인덱스도 설정 가능하고) 
							ㄴ 볼륨이 그렇게 크지 않은 경우? 
								(table과 동일하게 저장공간을 먹음으로) 
							ㄴ 

				</pre>

                ㄴ 설정값 <button>more</button>
                <pre>
                    ㄴ 메모리 관련
                        ㄴ shared_buffers
                            ㄴ db서버가 shared momory buffer로 사용하는 메모리의 크기 설정.
							ㄴ 디폴트 128MB. 최소값 128KB. 
							ㄴ 단위 
								ㄴ GB, MB 등으로 명시 가능. 
								ㄴ ??? 명시하지 않으면 'block'단위? 'BLCKSZ' type. (일반적으로 8kb)
							ㄴ 변경시 서버 재시작 필요. 
                            ㄴ 적정값
								ㄴ db전용 서버인 경우, 전체 메모리의 25% 권장. (최대 40%까지 유효하다함)
								ㄴ ??? There are some workloads where even larger settings for shared_buffers are effective, but because PostgreSQL also relies on the operating system cache, it is unlikely that an allocation of more than 40% of RAM to shared_buffers will work better than a smaller amount.
									??? 왜 40% 이상은 효과적이지 않을까? 
								ㄴ??? Larger settings for shared_buffers usually require a corresponding increase in max_wal_size, in order to spread out the process of writing large quantities of new or changed data over a longer period of time.
						ㄴ maintenance_work_mem 
							ㄴ ??? maintenance operation(VACUUM, CREATE INDEX 등)가 사용하는 최대 메모리 크기 설정.
                    ㄴ query planning 관련 <button>more</button>
                    <pre>
                        ㄴ effective_cache_size
                            ㄴ??? 쿼리 플래너가 하나의 쿼리에 대해 이용 가능한 디스크 캐시의 크기?
                    </pre>

					ㄴ archive_timeout <button>more</button>
					<pre>
						ㄴ integer 값.
						ㄴ ??? WAL 파일들은 완료처리된? 다 쓰여진 WAL segment 파일들만 쓰인다?
						ㄴ WAL record가 매우 적을 경우, 완료된 WAL segment파일이 없어 이슈가 생길 수 있다.
						ㄴ archive_timeout값 설정시, 새 WAL 파일을 쓰기 시작한 후, 해당 시간이 지나면 db 서버가
							쓰고있던 WAL파일을 완료처리하고, 새 WAL파일에 쓰기를 시작한다.
						ㄴ ??? 단위 안적으면 디폴트로 second를 단위로 취급.
						ㄴ 이 설정으로 인해 상대적으로 더 일찍 완료처리된 WAL파일도 이 설정이 적용 안되어 다 채워진 WAL파일과
							동일한 크기를 가짐.
							따라서, 너무 짧게 설정하는것은 저장공간을 불필요하게 부하시킴.
						ㄴ 메뉴얼에선 1분이 적당하다함.
							더 짧게 하려면, streaming replication 권장한다함.
						ㄴ postgresql.conf 파일 또는 server command line으로 설정 가능.
					</pre>
					ㄴ archive recovery 관련 설정 <button>more</button>
					<pre>
						ㄴ 다음 설정들은 'recovery' 동안에만 적용되는 설정들.
							따라서, 수행하려는 recovery동작 전에 적절히 설정되어야함.
							ㄴ 'recovery' 동작이란, 서버를 standby 서버로 사용하거나,
								단순히 데이터 손실로부터 회복을 위해 지정한 recovery를 수행하는 것을 말함.
						ㄴ restore_command
							ㄴ ??? WAL file을 받아오는데 사용될 shell명령어 문자열?
							ㄴ recovery시, archive된 wal file segment를 받아오는 명령어를 설정. 문자열값.
							ㄴ 형식 )
								ㄴ '%f' : target이 되는 wal file의 이름으로 대체됨.
								ㄴ '%p' : target wal file을 복사해갈 목적지 경로명으로 대체됨. (현재 working directory에 상대경로)
								ㄴ '%r'
									ㄴ restart point. 다음 복구 재시작시, 복규를 시작하는 지점???
									ㄴ 마지막 restart point가 있는 wal파일의 이름으로 대체된다. 즉, 복구 시작시 해당 파일부터 반드시 있어야함.
										다시말하면, 해당 파일 이전 파일들은 따로 다른곳에서 사용하는게 아닌 이상 얀속적인 복구를 하는데 더이상 필요치 않음.
									ㄴ ex ) 00000001000000000000000C wal file까지 archive에서 받아와 restore를 하였다면, %r은
										파일명 00000001000000000000000C 을 가리킴.
										(근데 몇 초 안에 바로 반영되는 것 같지는 않음)
							ㄴ ex )
								// /mgt/server/archivedir 하위에 있는 archived된 wal file들을 복사해서 가져감. (recovery에 쓰려고)
								restore_command = 'cp /mnt/server/archivedir/%f "%p"'
								restore_command = 'copy "C:\\server\\archivedir\\%f" "%p"'  # Windows
							ㄴ (archive_command와 비슷하게) 해당 명령이 성공한 경우에만 0을 반환해야함.
								ㄴ archive에 없는 파일명을 요청받을 것이고, 이 경우 0이 아닌값을 반환해야함.
									ㄴ wal file을 파일명인 일련번호대로 archive location에서 계속 찾고, 아직 wal file이 쌓이지 않거나 하여
										찾는 다음 wal file이 없는 경우가 빈번하고, 이게 진짜 문제가되는 오류는 아니라서 ?
								ㄴ 예외인 경우는 마찬가지로 archive_command와 유사하게 SIGTERM signal이나 shell 에러에 의해 종료된 경우.
							ㄴ postgreslq.conf 파일 또는 server command line을 통해 설정 가능.
						ㄴ archive_cleanup_command
							ㄴ 위 'restore_command'의 %r 키워드에서 설명한 recovery 재시작 포인트가 새로 갱신?될 때마다 호출되는 명령어 설정.
							ㄴ ??? 정확한 호출 시점은 모르겠음. archive로부터 wal쌓이면 바로 restore하여 적용은 하는데
								이때마다 restart point가 갱신되는것같지는 않음. 더 주기가 길다. (%r키워드 로그찍어가며 확인해본것)
							ㄴ 'pg_archivecleanup' 명령어와 같이 쓰인다.
								ㄴ pg_archivecleanup
									ㄴ archive_cleanup_command = 'pg_archivecleanup (*archivelocation*) %r'
										ㄴ아커이브로케이션은 삭제되어야할 wal파일이 위치하는 폴더 경로.
										ㄴ %r은 위에서 설명한댜로.
										ㄴ ex ) archive_cleanup_command = 'pg_archivecleanup /var/lib/pgsql/13/archive %r'
									ㄴ 논리적으로 %r 이전에 해당하는 모든 wal파일들을 삭제.
									ㄴ 당연히 보관해야할 wal파일의 양을 줄이려 사용.
									ㄴ 장기젇으로 보관해야할지 삭제할지는 잘판단해야할 문제.
									ㄴ여러개의 standby서버가 같은 아카이브 위치에서 벅언을 하고있ㄴ 경우 주의해야한다.
									ㄴ??? archive_cleanup_command가 아닌 단독으로 사용시, ‘.partial’ , ‘.backup’ prefix를 가진 wal file을 기준으로 이전 wal파일들을 삭제한다. 이는 base backup 사용시 편리하다.
									ㄴ서버 실행자는 아카이브로케이션에 대한 읽기 쓰기 권한이 있어야한다.
					</pre>

				</pre>

				ㄴ PostgreSQL Client/Server Application <button>more</button>
				<pre>
					ㄴ Client Application 
						ㄴ pg_dump 
						ㄴ ~~~

					ㄴ Server Application 
						ㄴ initdb 
							ㄴ 새 database cluster 생성. 
							ㄴ ~~~ 
							ㄴ 옵션 
								ㄴ --pgdata=(*디렉토리*)
									ㄴ 새로 생성할 cluster의 위치 명시. 
									ㄴ 필수로 입력받거나 'PGDATA' 환경변수의 값 사용하게됨. 
						ㄴ postgres 
							ㄴ postgresql 서버 자체를 나타내는 어플리케이션. 
							ㄴ 하나의 서버는 단 하나의 cluster를 관리. 
							ㄴ 실무 팁 
								ㄴ 당연히, 한 머신 위에 여러 postgresql 서버 띄울 수 있음. 
									클러스터 여러개 만들고 서버 인스턴스 여러개 시작하며도미. 
						ㄴ pg_ctl 
							ㄴ postgresql 서버의 초기ㅗ하, 시작, 정지 등 서버 조작 기능을 편리하게 제공하는 어플. 
							ㄴ ex ) 
								ㄴ pg_ctl -D (*cluster위치*) start 
									ㄴ 해당 클러스터위치의 서버 시작. 
								ㄴ pg_ctl -D (*cluster위치*) stop 
									ㄴ 해당 클러스터위치의 서버 정지.
						ㄴ ~~~ 

				</pre>

				ㄴ 외부 툴
					ㄴ EDB, EnterpriseDB
						ㄴ postgresql관련한 소프트웨어, 서비스들을 제공하는 회사.
						ㄴ version 4
							ㄴ ~~~
							ㄴ BDR, Bi-Directional Replication
								ㄴ postgresql에서 multi-master replication 기능,
									??? data distribution with advanced conflict management,
									데이터 손실 방지, postgresql의 기본 logical replica보다 5배 빠른 처리량 등을 제공하는 확장프로그램.
								ㄴ ~~~

								ㄴ 참조
									ㄴ https://www.enterprisedb.com/docs/pgd/4/bdr/

				ㄴ 무제 )
					ㅡ ~~~
					ㅡ 외부 접속 허용
						ㄴ
					ㅡ 유저 검색
						ㄴ select * from PG_USER;
						ㄴ \du
					ㅡ 유저 생성
						ㄴ create user (*user명*) (*옵션들*)
						ㄴ ex ) create user bbdlab SUPERUSER;
						ㄴ 옵션 )
							ㄴ ~~~
					ㅡ db 생성
						ㄴ create database (*db명*) (*옵션들*);
						ㄴ ex ) create database bbdlab OWNER bbdlab;
						ㄴ 옵션 )
							ㄴ OWNER : db의 소유자 지정. 해당 db에 대해 여러 권한을 가짐.
					ㅡ db 삭제
						ㄴ drop database (*db명*);
					ㅡ talbe 목록
						ㄴ
					ㅡ table 생성
						ㄴ create table (*table명*) (
								(*컬럼명1*) (*타입*) (*설정들*),
								(*컬럼명2*) (*타입*) (*설정들*),
								~~~
							);
					
				ㄴ dump <button>more</button>
				<pre>
					ㄴ dump+
						ㄴ pg_dump -U (*db소유자*) (*db명*) > (*dump파일명*)
							ㄴ ex ) pg_dump -U test postgres > postgres_DB_NAME_bak.sql
							ㄴ 옵션 )
								ㄴ -O : ??? db owner 설정을 무시?
						ㄴ 특정 테이블 dump
							ㄴ -t (*테이블명*)  옵션 추가
							ㄴ ex ) pg_dump -U test postgres -t userTable > postgres_DB_NAME_bak.sql
						ㄴ 압축 형식 )
							ㄴ pg_dump (*db명*) | gzip > (*결과 내보낼 파일명*)
							ㄴ ex ) pg_dump openmetric | gzip > openmetric_bak.gz
							ㄴ ??? 복원시 ) ex ) gunzip -c (*dump결과 파일*) | psql (*db명*)
						ㄴ pg_dump와 postgre의 버전 다르다는 오류 발생시
							ㄴ pg_dump 파일 찾기
								find / -name pg_dump -type f 2>/dev/null
							ㄴ 결과 ex )
								/usr/pgsql-9.3/bin/pg_dump
								/usr/bin/pg_dump
							ㄴ symlink 생성
								sudo ln -s /usr/pgsql-9.3/bin/pg_dump /usr/bin/pg_dump --force
					ㄴ 복원
						ㄴ pg_restore
							ㄴ
						ㄴ psql
							ㄴ dump한 파일이 sql이면 pg_restore사용이 오류 뜸? (dump file이 text라고) psql 사용 필요.
							ㄴ psql -U (*db소유자*) (*db명*) < (*dump한 sql파일명*)
								ㄴ ex ) psql -U 소유주 DB_NAME < postgres_DB_NAME_bak.sql
								ㄴ 옵션 )
									ㄴ --set ON_ERROR_STOP=1 : sql입력시, 오류 발생하면 멈춤.
									ㄴ --single-transaction : 오류 없이 완료 되었을 때 한번에 db에 적용.
							ㄴ 특정 테이블만 복원
								ㄴ ex ) psql -U user -f db_bak.sql postgres
				</pre>

				ㄴ??? shared buffer에 저장되는건 인덱스, 테이블의 내용? 디스크에 다시 접근할 필요 없도록? 
					쿼리의 결과는 캐싱되지 않는다? 동일한 쿼리이고 관련 데이터들에 변경사항이 전혀 없어도 plan을 재실행? 

			</pre>

			ㄴ Redis
				ㄴ key-value 쌍의 데이터 저장.
					ㄴ 별다른 테이블 없음.
					ㄴ 그냥 dict 저장하듯이, key-value쌍을 끝없이 저장.
				ㄴ 인메모리 dbms
					ㄴ 디스크에 데이터를 저장하는게 아닌 메모리에 데이터를 저장하는 dbms
					ㄴ 디스크 접근 시간이 없으므로 상대적으로 빠름.
				ㄴ 컴퓨터에 설치하여 메모리를 잡고 여기에 데이터를 저장하여 요청오면 저장 또는 반환하는 식.
				ㄴ 인메모리이므로 컴퓨터 종료시 데이터 날아감.
				ㄴ ~~~

			ㄴ 비정형 데이터 (unstructured data) <button>more</button>
			<pre>
				ㄴ ~~~ 
				ㄴ Vector database  <button>more</button>
				<pre>
					ㄴ 데이터를 vector값과 함께 저장하는 데이터베이스. 
					ㄴ ??? 일반적으로 'Approximate Nearest Neighbor(ANN)'알고리즘을 구현하여 쿼리에 대해 가장 가까운 데이터를 찾아 
						반환할 수 있게한다. 
					ㄴ 벡터는 저장하는 데이터를 다차원 공간상에 수학적으로 표현한 값. 
						벡터값의 각 차원은 데이터의 한가지 특징에 해당된다. 즉, 하나의 데이터를 여러가지 특징을 기준으로 벡터값으로 표현한 것. 
					ㄴ 벡터값은 그냥 구하는게 아니라, 머신러닝의 알고리즘 등을 통해 raw 데이터로부터 계산되는 것.
					ㄴ ~~~
					ㄴ vector query
						ㄴ 비정형데이터를 벡터화 한것과 동일한 과정으로 쿼리를 벡터화. 
						ㄴ 쿼리의 벡터값으로 vector database내의 벡터값들과 유사도를 계산(유사도 계산 알고리즘 사용) 
						ㄴ 유사도에 따라 순위를 매겨 쿼리에 대한 결과 결정. 
					ㄴ 활용
						ㄴ similarity search
						ㄴ multi-modal search
						ㄴ recommendation engine
						ㄴ LLM (Large Language Model)
						ㄴ RAG (Retrieval Augmented Generation)
					ㄴ 목록 
						ㄴ Qdrant 
						ㄴ Weaviate 
						ㄴ Pinecone  
						ㄴ Milvus <button>more</button>
						<pre>
							ㄴ 개요 
								ㄴ 
								ㄴ RESTful API, python, Go, java, node, C# SDK 제공. 
								ㄴ 배포 옵션 
									ㄴ 사용 케이스에 따라 3가지 배포 옵션 제공. 
										MilvusLite, Milvus standalone, Milvus distributed 
									ㄴ 규모에 따른 적합 옵션. 
										<img src="image/Milvus_solution_for_vector_count.png"/>
									ㄴ 옵션별 제공 기능 
										ㄴ https://milvus.io/docs/ko/install-overview.md#Comparison-on-functionalities
							ㄴ 설치 
								ㄴ Milvus standalone 
									ㄴ https://milvus.io/docs/install_standalone-docker.md 참고 
									ㄴ 그냥 도커 설치하고 milvus에서 제공하는 이미지 그대로 다운받아 실행시키면 자동 세팅. 
									ㄴ 필요 사양 
										ㄴ cpu, mem, disk 등 리소스에 대한 사양 및 
											설치를 위해 어떤 소프트웨어들이 필요한지에 대해. 
											ㄴ 페이지 그냥 보면 됨. 
										ㄴ 설치시 같이 설치되는 프로그램들이 있고 이들이 요구하는 필요사양 역시 따로 존재. 
											ㄴ etcd 
												ㄴ 돌아가는데 디스크 관련 사용이 중요. 
												ㄴ NVMe SSDs 이상 강력권장. 
												ㄴ 충족 여부 테스트 
													ㄴ 'fio' 프로그램을 통해 테스트. 
													ㄴ ex ) 
														mkdir test-data
														fio --rw=write --ioengine=sync --fdatasync=1 --directory=test-data --size=2200m --bs=2300 --name=mytest
													ㄴ ??? Ideally, your disk dedicated to etcd should reach over 500 IOPS and below 10ms for the 99th percentile fsync latency. 
								ㄴ SDK 
									ㄴ python, java, go, node.js용 제공. 
									ㄴ milvus 버전에 맞는 버전 설치 권장. 
										ㄴ milvus페이지 > 버전별 릴리스 노트 페이지에 명시. 
										ㄴ https://milvus.io/docs/release_notes.md#v257
							ㄴ 기본 사용법 
								ㄴ 설치시 디폴트로 
									ㄴ milvus docker container가 port 19530에서 실행됨. 
									ㄴ 127.0.0.1:9091/webui/에서 'Milvus WebUI' 접근 가능. 
								ㄴ 정지 
									ㄴ bash standalone_embed.sh stop 
								ㄴ 삭제 
									ㄴ bash standalone_embed.sh delete 
								ㄴ 버전업 
									ㄴ bash standalone_embed.sh upgrade
							ㄴ connection 
								ㄴ pymilvus.connections, pymilvus.orm.connections 
								ㄴ 최대 연결수 ) 65536개 
								ㄴ ??? 연결을 유지하는 방식같진 않고, client의 메소드 호출시마다 연결하여 요청보내는식인듯? 
									ㄴ client객체 생성 후, milvus종료하고 메소드 호출시 오류뜨지만, milvus다시 시작하고 같은 client로 
										메소드 호출해도 정상작동한다. 
							ㄴ database 
								ㄴ ??? 
									ㄴ create_database 
										ㄴ 데이터베이스 생성 
									ㄴ list_databases 
									ㄴ describe_database 
									ㄴ alter_database_properties
									ㄴ drop_database_properties 
									ㄴ drop_database 
										ㄴ 데이터베이스 삭제
										ㄴ 조건 
											ㄴ 'default' db 삭제 불가. 
											ㄴ db삭제 전, db내의 모든 collection 삭제 필요.
								ㄴ database property 
									ㄴdatabase.replica.number 
									ㄴ ~~~ 
							ㄴ collection 
								ㄴ 개요 
									ㄴ rdb의 table 비스무리한것. 
									ㄴ fields(rdb의 column), entity(rdb의 row)로 구성. 
									ㄴ 구조를 schema라 부름. 
								ㄴ pk인 field 존재. 
								ㄴ schema 
									ㄴ field schema와 collection shema로 구성. 
										collection schema는 field schema를 포함. field schema 먼저 정의 필요. 
									ㄴ field schema 
										ㄴ 
										ㄴ ex ) 
											from pymilvus import DataType, FieldSchema 

											id_field = FieldSchema(name="id", dtype=DataType.INT64, description="id", is_primary=True, auto_id=True)
											vector_val = FieldSchema(
												name="vector_val", dtype=DataType.FLOAT_VECTOR, dim=1536, description="vector value", 
											) 
											stock_field = FieldSchema(
												name="stock_code", dtype=DataType.VARCHAR, max_length=10, description="stock code", nullable=True, 
											) 
											date_field = FieldSchema(
												name="date", dtype=DataType.VARCHAR, max_length=10, description="iso format date str", 
											)
											title_field = FieldSchema(
												name="title", dtype=DataType.VARCHAR, max_length=512, description="title", 
											)
											content_field = FieldSchema(
												name="content", dtype=DataType.VARCHAR, max_length=65535, description="content", 
											)
											receipt_no_field = FieldSchema(
												name="receipt_no", dtype=DataType.VARCHAR, max_length=100, description="공시 접수번호", 
											)
										ㄴ 속성 
											ㄴ name 
												ㄴ field의 이름. 
											ㄴ dtype 
												ㄴ field의 데이터 타입. 
											ㄴ description 
												ㄴ field에 대한 설명.	
											ㄴ is_primary
												ㄴ field가 pk인지 여부.
											ㄴ auto_id 
												ㄴ 자동 pk할당 여부. 
												ㄴ pk인 필드인 경우 필수. 
											ㄴ max_length 
											ㄴ dim 
											ㄴ is_partition_key  
											ㄴ nullable 
												ㄴ field가 null을 허용하는지 여부. 
												ㄴ True일시, insert할때 값 안넘겨도됨. 
										ㄴ data type 
											ㄴ field schema에서 'DataType'으로 정의하는 데이터 유형 의미. 
											ㄴ field의 유형?(pk field, scalar field, vector field)별로 가능한 데이터 타입 존재. 
												ㄴ pk field 
													ㄴ INT64, VARCHAR 
												ㄴ scalar field 
													ㄴ INT8, INT16, INT32, INT64, FLOAT, DOUBLE, VARCHAR, BOOL, JSON, Array 
													ㄴ VARCHAR 
														ㄴ 최대 65535
												ㄴ vector field
													ㄴ BINARY_VECTOR
													ㄴ FLOAT_VECTOR
														ㄴ 벡터값이 32bit 부동소수점으로 표현됨. 
														ㄴ 높은 정확도가 필요한 경우 많이 사ㅛㅇㅇ. 
														ㄴ 과학 연산, 머신러닝, 벡터의 유사성 검사 등에 사용. 
													ㄴ FLOAT16_VECTOR
														ㄴ 벡터값이 16bit 부동소수점으로 표현됨.
														ㄴ 정확도가 덜 중요한 경우 사용. 
													ㄴ BFLOAT16_VECTOR
														ㄴ ???벡터값이 16bit 'Brain Floating Point'로 표현됨.
														ㄴ 대용량 벡터를 빠르게 처리해야하는경우 사용된다함. 
													ㄴ SPARSE_FLOAT_VECTOR
										ㄴ field 유형 
											ㄴ 명확히 field에 유형이 있다기보단, 필드를 어떻게 정의하는지에 따라 구분되는 듯. 
												가령, FLOAT_VECTOR 타입으로 정의하면 'dense vector'로 분류되는 등. 
											ㄴ Primary Field 
											ㄴ Dense Vector 
												ㄴ 실수값이 들어있는 벡터 타입. 
												ㄴ 머신러닝, 데이터 분석, 의미 이해, semantic search, 추천시스템 등에 많이 사용. 
												ㄴ 벡터값의 각 차원들은 각각의 의미론적 특징을 나타냄. 
												ㄴ ~~~ text embedding에서 나오는 내용과 동일. 
													embedding모델로 값을 벡터화하고, 여러 차원상에 가까우면 어쩌고... 
												ㄴ 정의 
													ㄴ field의 data type을 FLOAT_VECTOR, FLOAT16_VECTOR, BFLOAT16_VECTOR 중 하나로 정의하고 
														field속성 'dim'을 설정하여 정의 가능. 
													ㄴ ex ) 
														schema.add_field(field_name="dense_vector", datatype=DataType.FLOAT_VECTOR, dim=4)
									ㄴ collection schema 
										ㄴ ex ) 
											from pymilvus import CollectionSchema

											~~~ 위 field schema 정의 코드 ~~~

											schema = CollectionSchema(
												fields=[
													id_field, vector_val, stock_field, date_field, title_field, 
													content_field, receipt_no_field, 
												], 
												enable_dynamic_field=True, description="종목공시 데이터"
											)

										ㄴ 속성 
											ㄴ field 
												ㄴ 필수 
											ㄴ description 
											ㄴ partition_key_field 
												ㄴ partition key인 필드명 
											ㄴ enable_dynamic_field 
												ㄴ dynamic field 사용 여부 
								ㄴ collection 생성 
									ㄴ ex ) 
										from pymilvus import Collection

										schema = ~~~ 위 collection schema 정의 코드 ~~~

										# 정의한 CollectionSchema 넘겨 collection 생성 
										client.create_collection(
											collection_name="noname", schema=schema, 
										)
									ㄴ Collection.construct_from_dataframe 
										ㄴ pandas DataFrame으로부터 collection schema와 collection을 생성하는 메소드. 
								ㄴ collection 수정 
									ㄴ client.rename_collection(old_name, new_name) 
										ㄴ collection 이름 변경.	
									ㄴ client.alter_collection_properties(collection_name, properties: dict) 
										ㄴ collection 속성 수정.
										ㄴ ex ) 
											client.alter_collection_properties(
												collection_name="my_collection",
												properties={"collection.ttl.seconds": 60}
											)
										ㄴ ??? 수정 가능한 속성 목록? 
											ㄴ collection.ttl.seconds 
											ㄴ mmap.enabled 
											ㄴ partitionkey.isolation 
									ㄴ client.drop_collection_properties(collection_name, property_keys: list) 
										ㄴ collection 속성 삭제. 
										ㄴ ex ) 
											client.drop_collection_properties(
												collection_name="my_collection",
												properties=["collection.ttl.seconds"]
											)
								ㄴ collection load, release 
									ㄴ load 
										ㄴ ??? 컬렉션에 대한 유사성검색, 쿼리 실행을 하게되면 milvus가 자동으로 컬렉션을 로드함.? 
											컬렉션의 index와 모든 필드의 raw 데이터가 메모리로 로드됨? 
										ㄴ ??? collection 로딩 후 삽입된 entity는 자동으로 인덱싱되고 로드된다? 
										ㄴ client.load_collection(collection_name) 
										ㄴ 특정 필드 로드 
											ㄴ 아직 실험적 기능이라함. 
									ㄴ relaese 
										ㄴ 메모리로 로드된 컬렉션을 제거하는 것. 
										ㄴ 당연히 메모리 관리 위해 안쓰면 relaese 권장.
										ㄴ client.release_collection(collection_name) 
								ㄴ collection TTL(Time-to-Live) 
									ㄴ collection에 데이터가 특정 시간동안만 존재하고 이후에는 삭제되도록하는 기능. 
									ㄴ collection에 'TTL'을 설정하여 설정 가능. 
									ㄴ ~~~ 
								ㄴ partition 
									ㄴ milvus의 collection partition이란, 
										collection 내의 부분 collection을 의미하며, 
										원래의 collection이 parent collection. partition은 parent collection과 동일 구조를 가짐. 
									ㄴ default partition 
										ㄴ collection 생성시 자동으로 생성되는 partition. 
										ㄴ '_default' 라는 이름. 
										ㄴ 별도로 추가 partition을 생성하지 않는 경우, 
											collection에 데이터 삽입시, default partition에 데이터가 삽입되며, 
											search, query도 이 partition 내에서 수행. 
									ㄴ partition 추가 
										ㄴ 특정 기준으로 파티션 생성이 가능. 
										ㄴ search, query시, 어떤 partition내에서 수행할지 결정 가능하여 성능 개선 가능. 
										ㄴ 컬렉션당 최대 1024개의 파티션 생성 가능. 
										ㄴ ex ) 
											client.create_partition(
												collection_name="quick_setup",
												partition_name="partitionA"
											)
									ㄴ partition 리스팅 
										ㄴ client.list_partition(collection_name)
									ㄴ partition load, release 
										ㄴ collection에서 특정 partition만 load / release 가능. 
										ㄴ client.load_partitions(collection_name, partition_names) 
										ㄴ client.release_partitions(collection_name, partition_names)
									ㄴ partition에 entity 삽입, upsert, delete
										ㄴ collection에 대한 insert, upsert, delete 메소드에서 
											partition_name 인자만 추가해주면됨. 
										ㄴ ex ) 
											res = client.insert(
												collection_name="quick_setup",
												# highlight-next-line
												partition_name="partitionA",  # 파티션명시. 
												data=data
											)
									ㄴ partition에 대해 search, query 
										ㄴ 마찬가지로 collection에 대한 search, query 메소드에서 
											partition에 대한 인자만 추가해주면됨. 자세한건 search, query 항목 참고. 
									ㄴ client.drop_partition(collection_name, partition_name) 
										ㄴ partition 삭제.
										ㄴ 삭제전, partition이 release되었는지 확인 필요. 
									ㄴ client.has_partition(collection_name, partition_name) 
										ㄴ 특정 collection에 partition이 존재하는지 확인하는 메소드.
								ㄴ 
							ㄴ entity insert, upsert, delete 
								ㄴ insert 
									ㄴ 삽입될 데이터는 dict형 list 여야함. 
									ㄴ dict 하나가 entity하나 의미. 
									ㄴ dict에는 schema의 모든 필드가 포함되어 있어야함. 
										ㄴ dynamic field가 collection에 정의된 경우, schema에 없는 필드가 dict에 포함될 수 있음. 
									ㄴ ex ) 
										data = [
											{~~~}, 
											{~~~}, 
										]
										client.insert( 
											collection_name="quick_setup", 
											# partition_name="partitionA",  # 특정 partition에 삽입하려는 경우. 
											data=data, 
										)
								ㄴ upsert 
									ㄴ ???
								ㄴ delete
									ㄴ metadata filtering 또는 pk를 이용하여 삭제 가능. 
									ㄴ ex ) 
										res = client.delete(
											collection_name="quick_setup",
											# highlight-next-line
											filter="color in ['red_3314', 'purple_7392']"
										)

										res = client.delete(
											collection_name="quick_setup",
											# highlight-next-line
											ids=[18, 19]
										)
							ㄴ index 
								ㄴ rdb의 index 비스무리한것. 
								ㄴ vector field에 대한 인덱스 생성 권장? 
								ㄴ ex ) 
									index_params = client.prepare_index_params()

									index_params.add_index(
										field_name="dense_vector",  # index 대상 필드. 
										index_name="dense_vector_index",
										index_type="IVF_FLAT",
										metric_type="IP",
										params={"nlist": 128}
									)
								ㄴ vector index 
									ㄴ vector field의 data type별로 가능한 index type 제한. 
										ㄴ FLOAT_VECTOR, FLOAT16_VECTOR, BFLOAT16_VECTOR : FLAT, IVF_FLAT, IVF_SQ8, IVF_PQ, 
											GPU_IVF_FLAT, GPU_IVF_PQ, HNSW, DISKANN 
										ㄴ BINARY_VECTOR : BIN_FLAT, BIN_IVF_FLAT 
										ㄴ SPARSE_FLOAT_VECTOR : SPARSE_INVERTED_INDEX 
									ㄴ 생성 
										ㄴ MilvusClient.prepare_index_params()로 index parameter를 생성하고, 
											이를 넘겨서 client.create_index()로 인덱스를 생성. 
										ㄴ ex ) 
											index_params = MilvusClient.prepare_index_params()

											index_params.add_index(
												field_name="vector",
												metric_type="COSINE",
												index_type="IVF_FLAT",
												index_name="vector_index",
												params={ "nlist": 128 }
											)
											
											client.create_index(
												collection_name="customized_setup",
												index_params=index_params,
												sync=False # Whether to wait for index creation to complete before returning. Defaults to True.
											)
								ㄴ scalar index 
									ㄴ vector field에 대한 index가 아닌, 일반 scalar field에 대한 index. 
									ㄴ index type 결정 방식 
										ㄴ auto indexing 
											ㄴ milvus scalar field의 data type에 따라 index type을 자동으로 결정하는 방식. 
											ㄴ add_index()에서 'index_type' 파라미터를 명시하지 않음으로서 사용 가능. 
										ㄴ custom indexing 
											ㄴ 사용할 index type을 명시적으로 결정하는 방식. 
											ㄴ add_index()에서 'index_type' 파라미터를 명시함으로서 사용 가능.
											ㄴ ex ) 
												index_params = MilvusClient.prepare_index_params() #  Prepare an IndexParams object

												index_params.add_index(
													field_name="scalar_2", # Name of the scalar field to be indexed
													index_type="INVERTED", # Type of index to be created
													index_name="inverted_index" # Name of the index to be created
												)
								ㄴ client.list_indexes(collection_name) 
									ㄴ collection의 index 목록 리스팅.
								ㄴ client.describe_index(collection_name, index_name) 
									ㄴ collection의 index 상세보기.
								ㄴ client.drop_index(collection_name, index_name) 
									ㄴ collection의 index 삭제.
							ㄴ search <button>more</button>
							<pre>
								ㄴ ANN (Approximate Nearest Neighbor) search algorithm 
									ㄴ kNN (k-Nearest Neighbor) search algorithm 
										ㄴ input에 대해, 데이터들 중 input과 '가장' 가까운 데이터 k개를 찾는 알고리즘. 
										ㄴ 단점 
											ㄴ ??? 모든 데이터셋에 대해 비교해봐야 하기 때문에, 데이터셋의 크기 증가시 
												계산 시간이 크게 증가. 
									ㄴ 개요 
										kNN과 비슷하나, '가장' 가까운 데이터 k개가 아닌, 
										'대략적으로 가장 가까운' 데이터 k개를 찾는 알고리즘. 
										즉, 정확도가 떨어짐. 
									ㄴ kNN 알고리즘의 단점을 해결하기 위해 정확도는 조금 떨어지지만, 모든 데이터셋에 대해 계산할 필요가 없어 
										계산이 상대적으로 빠른 방식인 ANN이 나옴. 
									ㄴ ??? 딱 구체적인 하나의 알고리즘을 지칭하는 용어는 아닌듯함. 
									ㄴ 동작 
										ㄴ 기본적으로 dimensionality reduction을 기반으로 동작. 
											ㄴ demensionality reduction? 
												ㄴ 데이터의 차원의 수를 줄이는 것. 
									ㄴ 목록 
										ㄴ ANNOY 
											ㄴ sputify에서 내놓은 ANN알고리즘. 
										ㄴ 
								ㄴ ??? 대략 동작 
									ㄴ query vector에 대해 index file을 이용하여 가장 유사도가 높은 subgroup 선택. 
										ㄴ ???index file은 vector embedding순으로 정렬되엉 있다함.
									ㄴ subgroup 내의 벡터들과 query vector를 request에 명시된 'metric type'으로 유사도 측정하여 상위 k개 선정. 
								ㄴ index file을 사용하므로, index type에 따라 성능차이 발생. 
									적절한 index type 선정 필요. 
									'AUTOINDEX'를 통해, milvus가 알아서 적절한 index type을 선정해줌. 
								ㄴ client.search() 
									ㄴ ex ) 
										res = client.search(
											collection_name="quick_setup",
											data=[query_vector],
											limit=3, # The number of results to return 
											# 검색할 partition 명시. 이 partition들 내에서 검색함. 
											# partition_names=["partitionA"], 
											search_params={
												"metric_type": "IP", 
												# 결과의 offset. 즉 건너뛸 결과의 개수. 
												# limit과 함꼐사용하여 paging 가능. limit에 한 페이지의 크기, offset에 지금까지 받아온 
												# 결과의 개수 명시하면됨. 
												"offset": 0,  
											}，
											# highlight-next-line
											output_fields=["color"]
										)
								ㄴ filterred search 
									ㄴ ANN search 전에 metadata filtering을 통해, ANN으로 검색할 범위를 줄이는 기능. 
										즉, metadata filtering과 ANN search를 같이하는 방식. 
									ㄴ 유형 
										ㄴ standard filtering 
											ㄴ 일반적인 필터링 방식. 
												entity의 metadata 에 대해 필터링을 먼저하고, 필터링된 entity들에 대해 ANN search하여 
												가장 유사항 k개를 반환하는 방식. 
											ㄴ client.search()에서 'filter'파라미터만을 추가하여 사용 가능한 방식. 
										ㄴ iterative filtering 
											ㄴ vector값에 대해 ANN search를 먼저 수행하고, 그 결과에 대해 반복하여 
												metadata filtering을 수행하는 방식. 
												즉, ANN search를 먼저하고 그 결과에 대해 filtering을 하여 k개를 찾는 방식. 
											ㄴ metadata filtering이 복잡한 경우에 유용하다함. 
											ㄴ client.search()에서 'search_params'파라미터에 "hints": "iterative_filter"를 추가하여 사용 가능. 
								ㄴ ??? range search 
									ㄴ 
									ㄴ ??? 대략 동작 방식 
										<img src="image/milvus_range-search.png"/>
										ㄴ search request에서 'radius', 'range_filter'를 인자로 받고, 
										ㄴ 우선, query vector와 가장 유사항 벡터 하나를 찾고, 이를 원의 중심으로 결정. 
										ㄴ 이 원의 중심을 기준으로하고, 인자로 받은 'radius'를 반지름으로 하는 원(outer circle)과 
											'range_filter'를 반지름으로 하는 원(inner circle)을 그린다.
										ㄴ 이 두 원 사이의 영역에 존재하는 벡터들에 대해 유사도 서칭? 
								ㄴ group search 
								ㄴ hybrid search
								ㄴ Query <button>more</button>
								<pre>
									ㄴ vector field가 아닌 scalar field에 대해 검색하는 기능. 
									ㄴ 세가지 유형 
										ㄴ Get 
											ㄴ entity pk를 기준으로 검색하는 기능. 
											ㄴ client.get() 
												ㄴ ex ) 
													res = client.get(
														collection_name="query_collection", 
														# partitionNames=["partitionA"],  # 특정 partition에서 검색하는 경우. 
														ids=[0, 1, 2],
														output_fields=["vector", "color"]
													)
										ㄴ Query 
											ㄴ custom filtering을 기준으로 검색하는 기능. 
											ㄴ client.query() 
												ㄴ ex ) 
													res = client.query(
														collection_name="query_collection", 
														# partitionNames=["partitionA"],  # 특정 partition에서 검색하는 경우. 
														filter="color like \"red%\"",
														output_fields=["vector", "color"],
														limit=3
													)
										ㄴ QUeryIterator 
											ㄴ Query와 동일한데 페이징형식으로 검색하는 기능. 
											ㄴ collection.query_iterator() 
												ㄴ query에 대한 iterator를 반환하고, iterator.next()를 호출하여 다음결과를 받아오는 방식. 
												ㄴ ex ) 
													# iterator 받아옴. 
													iterator = collection.query_iterator(
														# partition_names=["partitionA", ],  # 특정 partition에서 검색하는 경우. 
														batch_size=10,
														expr="color like \"red%\"",
														output_fields=["color"]
													)

													results = []

													while True:
														# iterator.next()로 다음 결과 받아옴. 
														result = iterator.next()
														if not result:
															iterator.close()
															break

														print(result)
														results += result 
								</pre>
								ㄴ filter expression <button>more</button>
								<pre>
									ㄴ scalar filtering시 사용되는 filter expression을 어떻게 작성하는지에 대해. 
									ㄴ 가능 연산자 
										ㄴ 비교연산
											ㄴ ==, !=, >, <, >=, <= 
											ㄴ 숫자, text, date에 대해 가능. 
										ㄴ range연산 
											ㄴ IN, LIKE 
										ㄴ 산술연산
											ㄴ +, -, *, /, % 
										ㄴ 논리연산 
											ㄴ AND, OR, NOT 
										ㄴ IS NULL, IS NOT NULL 
											ㄴ field값이 null인지 여부. 
											ㄴ JSON Field에 대해 
												ㄴ json의 모든 값이 null이거나, json값 자체가 없으면 null 취급. 
											ㄴ ARray field에 대해 
												ㄴ array의 모든 값이 null이거나, array값 자체가 없으면 null 취급.
										ㄴ ??? JSON field 특화 연산자 
											ㄴ 
										ㄴ Array field 특화 연산자 
											ㄴ 목록 
												ㄴ ARRAY_CONTAINS( (*식별자*), (*표현식*) )
													ㄴ (*식별자*) 배열 안에 (*표현식*)값이 포함되어 있는지. 
													ㄴ ex ) 
														filter = 'ARRAY_CONTAINS(history_temperatures, 23)'
												ㄴ ARRAY_CONTAINS_ALL( (*식별자*), (*표현식*) )
													ㄴ (*식별자*) 배열 안에 (*표현식*)값이 모두 포함되어 있는지. 
													ㄴ ex ) 
														filter = 'ARRAY_CONTAINS_ALL(history_temperatures, [23, 25])'
												ㄴ ARRAY_CONTAINS_ANY
													ㄴ (*식별자*) 배열 안에 (*표현식*)값이 하나라도 포함되어 있는지.
													ㄴ ex ) 
														filter = 'ARRAY_CONTAINS_ANY(history_temperatures, [23, 25])'
												ㄴ ARRAY_LENGTH ( (*식별자*) )
													ㄴ (*식별자*) 배열의 길이 반환. 
											ㄴ 유의 
												ㄴ array필드의 값이 nested 형태인 경우, 내부값은 그냥 문자열 취급. 
													따라서, nested의 깊이가 깊어질 수록 성능상의 이슈가 있을 수 있음. 
										ㄴ varchar field 특화 연산자 

									ㄴ ex ) 
										filter='color in ["red", "blue"]'

										# JSON field의 내부 값에 대해서도 filtering 가능. 
										# product가 JSON field이고, 내부에 model, price라는 키값이 있는 경우, 
										filter='product["model"] == "JSN-087" and product["price"] < 1850' 

										# Array field에 대해서도 filtering 가능.
										filter='history_temperatures[10] > 23'
									ㄴ filter templating 
										ㄴ 
								</pre>
								ㄴ search iterator 
								ㄴ full-text search 
								ㄴ text match 
								ㄴ partition key 
								ㄴ mmap
								ㄴ clustering compaction 
							</pre>
							ㄴ metric type 
								ㄴ 벡터값 사이의 유사성을 산출하는 function. 
								ㄴ 'Euclidean distance(L2)', 'Inner Product(IP)', 'Cosine Similarity(COSINE)', 
									'JACCARD', 'HAMMING', 'BM25' 등 제공. 
									ㄴ L2 
										ㄴ 값 범위 : 0 ~ 무한대 
										ㄴ 작을수록 유사도 높음. 
									ㄴ IP 
										ㄴ 값 범위 : -1 ~ 1 
										ㄴ 클수록 유사도 높음.
									ㄴ COSINE 
										ㄴ 값 범위 : -1 ~ 1
										ㄴ 클수록 유사도 높음.
									ㄴ JACCARD
										ㄴ 값 범위 : 0 ~ 1 
										ㄴ 작을수록 유사도 높음.
									ㄴ HAMMING 
										ㄴ ??? 값 범위 : 0 ~ dim(vector) 
										ㄴ 작을수록 유사도 높음.
								ㄴ vector field의 data type별로 가능한 metric type 제한. 
									ㄴ FLOAT_VECTOR : L2, IP, COSINE 
									ㄴ FLOAT16_VECTOR : L2, IP, COSINE
									ㄴ BFLOAT16_VECTOR : L2, IP, COSINE
									ㄴ SPARSE_FLOAT_VECTOR : IP, BM25 
									ㄴ BINARY_VECTOR : JACCARD, HAMMING  
							ㄴ partition 
								ㄴ 
							ㄴ Alias 
							ㄴ consistency level 
								ㄴ 분산 db시스템에서 노드간 데이터 일관성의 정도를 나타내는 레벨. 
								ㄴ 
							ㄴ 설정 
								ㄴ 설치 위치의 'user.yaml'파일을 수정하여 추가 설정 가능.
							ㄴ Milvus WebUI 
								ㄴ 
							ㄴ 참고 
								ㄴ https://milvus.io/docs/ko/overview.md
								ㄴ 
							ㄴ 실무 
								ㄴ docker standalone형태로 설치하여 사용시, milvus가 일정시간 후 혼자 종료되는 이슈 
									ㄴ 추정 원인 
										ㄴ docker container로구 확인해보면, etcd 응답이 느리다는 경고들이 쌓여있고 마지막에 
											무슨 연결이 끊겼다 찍히고 종료되는것과 
											구글링해보면 etcd속도가 느려서라는 글들이 많음. 
										ㄴ 참고 
											ㄴ https://github.com/milvus-io/milvus/issues/33757
											ㄴ https://github.com/milvus-io/milvus/discussions/35535
						</pre>
						ㄴ ChromaDB 
						ㄴ pgvector 
					ㄴ 비교 <button>more</button>
					<pre>
						ㄴ 비교 기준 
							ㄴ 오픈 소스 여부 
							ㄴ 호스트 솔루션 제공 여부 
							ㄴ 가격 
							ㄴ 가능한 vector 길이 
								ㄴ 길수록 더 복잡하고 정교한 데이터가 가능한 것. 
							ㄴ ??? 지원되는 유사성 판단 방식? 
							ㄴ ??? Nearest Neighbor search 방식? 
							ㄴ ??? clustering? 
								ㄴ ??? 비슷한 벡터들을 그룹화하는 기능? 
							ㄴ ??? filtering, aggregation 기능? 
							ㄴ Integrations 정도 
							ㄴ??? Cloud 제공 여부? 
							ㄴ 사용 난이도 
						ㄴ 비교 
							ㄴ Qdrant 
							ㄴ Weaviate 
								ㄴ 오픈소스 
							ㄴ Pinecone 
								ㄴ 오픈소스 아님.  
							ㄴ Milvus 
								ㄴ 오픈소스 
								ㄴ 무료이고 성능도 대략 무난한듯. 
							ㄴ ChromaDB 
							ㄴ pgvector 
					</pre>
					ㄴ 참고 
						ㄴ https://en.wikipedia.org/wiki/Vector_database
						ㄴ https://redis.io/blog/vector-databases-101/
				</pre>
			</pre>

			ㄴ ???etcd 
				ㄴ 

		</pre>

		캐싱 <button>more</button>
		<pre>
			ㄴ ~~~ 
			ㄴ 관련 기능 툴 목록 
				ㄴ Memcached <button>more</button>
				<pre>
					ㄴ 개요 
						ㄴ 인메모리 상에서 동작하는 단순 캐시 데이터 저장 및 조회 툴. 
						ㄴ 공식적으로 Linux, BSD 계열만 지원. 윈도우는 없음. 
						ㄴ 데몬으로 동작
						ㄴ 메모리가 할당되고, 이 메모리에 대한 데이터 삽입, 조회, 삭제 등에 대한 인터페이스 제공한다함. 
						ㄴ 메모리상에 저장하므로, 컴퓨터가 꺼지거나 충돌이 생기거나 하면 데이터 사라짐. 영구 데이터가 아님. 
							일시적 데이터 저장소로서 취급해야함. 
						ㄴ 여러 머신에 걸쳐 캐싱 데이터 저장 가능. 클라이언트쪽에선 특정 키에 대해 이들 중 하나한테 
							데이터를 조회해가는 방식이됨? 
					ㄴ ~~~
					ㄴ 설치 
						ㄴ memcached 설치 
							ㄴ dnf install memcached 
						ㄴ 클라이언트 설치 
							ㄴ memcached는 저장소 데몬이고 이와 상호작용하는 클라이언트는 따로 설치해야함. 언어에 맞는 것 적절히 선택하여 설치 필요. 
					ㄴ command 
						ㄴ 
						ㄴ 옵션 
							ㄴ --memory-limit=(*정수*) 
								ㄴ 

					ㄴ 참고 
						ㄴ https://docs.memcached.org/

				</pre>
				ㄴ Redis 
					ㄴ 'database'항목 참고. 
 
			ㄴ 툴 비교 
				ㄴ redis vs memcached 
					ㄴ memcached가 훨씬 사용하기 단순. 간단한 캐시 저장, 조회 기능만 필요하고, 규모, 사용량이 아주 크지 않다면 충분. 
						그게 아니라면 많은면에서 redis가 뛰어나다함. 성능, 확장성, 문서화, 여러 기능, 대중성 등. 단 사용하기 더 복잡. 
 
			ㄴ 웹 어플리케이션에서의 downstream? cache 
				ㄴ 백엔드 내부적으로 사용되는 캐시 이외에도, 웹 환경에서 디폴트로 사용되는 여러 캐시들 존재. 
					웹 어플리케이션 개발시 고려 필요. 
				ㄴ 목록 
					ㄴ 페이지에 대한 ISP의 캐싱 
						ㄴ ISP에서 페이지를 캐싱하고 이에 대한 요청이 왔을 때, 웹 서버가 응답을 하기도 전에 캐시된 페이지를 반환하는 경우 존재. 
					ㄴ proxy cache 
						ㄴ 웹 서버 앞단에 proxy cache 서버가 있고, 이 서버가 요청을 웹서버에 보내지도 않고 캐시된 데이터를 응답해주는 경우. 
					ㄴ 브라우저 캐시 
						ㄴ 브라우저가 일부 요청들에 대해 응답을 캐싱하고 이를 그대로 보여주느 ㄴ경우 존재. 
				ㄴ 유의사항 
					ㄴ 페이지가 유저에 따라 달라지거나 서버에서 반환할 특정 값에 따라 달라지는 경우, 
						이를 반영하지 않는 이전에 캐시된 페이지나 데이터를 그대로 반환해버리면 유효하지 않거나, 보안상의 노출이 될 수 있거나, 오류를 유발할 수 있는 동작이 일어날 수 있음.  
				ㄴ 대응 
					ㄴ downstream cache에 대한 설정을 하는 여러 http header 설정 
 
		</pre>

		backup 일반 <button>more</button>
		<pre>
			ㄴ ~~~ 
			ㄴ 기본적으로 매일 full backup 본을 가지고 있는게 이상적. 
				어느 시점에 문제가 발생해도 거의 데이터 손실 없이 복구 가능하고 
				full backup이기 때문에 단순하게 복구가 가능하기 때문. 
			ㄴ 3-2-1 backup rule 
				ㄴ backup 방법의 일종. 
				ㄴ 3개의 복사본을 2개의 다른 형태로, 1개는 다른 외부 위치에 보관하는 것. 
					즉, 기본 백업본 하나, 다른 형태의 백업본 하나, 다른 위치에 보관하는 백업본 하나. 
				ㄴ 다른 형태의 백업본은 특정 기술 관련 이슈를 대비, 
					다른 외부 위치의 백업본은 주요 컴퓨터 위치 자체에 문제가 발생햇을 때를 대비. 

		</pre>

		version control  <button>more</button>
		<pre>
			ㄴ ~~~ 
			ㄴ merge 알고리즘 
				ㄴ three-way merge
					ㄴ 2개의 버전(A, B)과 이 둘의 공통 조상 버전(C)를 찾는다.  
						이 세 버전 중, 2개의 버전에서만 동일한 부분을 찾는다. 즉, A,C는 같은데 B는 다른 부분 등. 
						이러한 경우는 해당 부분에 한해선 버전이 2가지 있다고 할 수 있다. 2개끼리 같은 버전과 나머지 하나 버전. 
						해당 부분의 이 2가지 버전 중, 공통 조상 버전(C)가 속한 버전을 버리고 나머지 하나를 merge결과로 선택한다.
						(가령, 특정 부분에 대해 A,B가 내용이 같고 C만 다르다면, A,B의 내용이 채택,
						A,C가 내용이 같고 B가 다르다면, B의 내용이 채택)
						A,B,C 모두 다르다면, '충돌'로 간주.
					ㄴ ??? 러프한 알고리즘에 속하지만, 공통 조상을 하나만 요구하기 때문에 자주 사용된다함?
					ㄴ ??? 텍스트나 구조화된 tree에 적용 가능하다?
			ㄴ 깃<button>더보기</button>
			<pre>
				ㅇ  버전관리 시스템( VCS, Version Control System )
					ㄴ 파일의 변화를 기록하고 있다가, 이후 원하는 시점의 버전을 불러올 수 있게 해주는 프로그램.
						ㄴ 아주 단순하게는, 일자별로 폴더명을 설정하고 각 폴더에 해당 일자의 파일을 저장한 뒤, 나중에 특정 일자에 저장된 파일을
							불러오는식.
					ㄴ 종류 )
						ㄴ 로컬 버전관리 : 말그대로 로컬컴퓨터 내에서 버전을 데이터베이스로서 관리하고 원하는 버전에 checkout하는 방식.
						ㄴ 중앙 집중식 버전관리(CVCS) : 중앙 서버에 버전db를 올려놓고 여러컴퓨터가 그걸받아서checkout하는 방식. 중앙서버에 문제가
														생기면 문제가 크다.
						ㄴ 분산 버전 관리시스템(DVCS) : 마지막 버전정보를 checkout하는게 아니라 지금까지의 버전정보인 히스토리와 저장소 전체를
														복제한다. 따라서 서버가 다운되더라도 클라이언트가 복제한 정보 아무거나로 복원이 가능하다.

				ㅇ 깃 개요
					ㅡ 깃은 다른 버전관리시스템과 달리 데이터를 파일시스템의 스냅샷의 연속으로 취급한다. 파일이 달라지지않으면 저장하지않고
						링크만걸어둔다.때문에 크기가 작다.
				ㅇ 특징
					ㅡ깃은 대부분의 명령과 기능이 로컬에서 이루어지기대문에 네트워크의 영향을 별로 받지 않는다.
					ㅡ 깃은 체크섬이라는 무결성체크용 기술을 사용한다고함.(뭔진 잘모름)
					ㅡ 깃에선 데이터를 삭제하거나 되돌리는건 없다. '추가'만 할뿐.

				ㄴ 체크섬
					ㄴ 깃에서 사용하는 일종의 키값으로. SHA-1이라는 해쉬데이터이다.
					ㄴ  모든 데이터를 이 체크섬값으로 식별한다.
					ㄴ  거의 온세상에서 유일한값이라하며 데이터의 고유값으로 쓰인다.
					ㄴ ex ) 8a8363d93e61185f6df18ed61321626be514c7f4 =>보통 이렇게 생긴 40자짜리 문자열값들이다.
					ㄴ  이 체크섬값을 사용할때는 앞의 7자리만 사용하여도 된다. ex) git show 8a8363d
					ㄴ ??태그를 체크아웃할수도 있으며 이럴경우 detached HEAD상태가 되어 문제가생길수도있으니 주의(detached HEAD는
						나중에알아봐)

				ㅇ 깃의 구조
					ㅡhttps://git-scm.com/book/en/v2/images/areas.png
						<img src="image/git_기본동작.png" height="300px"/>
						ㄴ working directory : 로컬에서 작업하는 해당 폴더를 의미하는 듯하다.
						ㄴ staging area : .git안에서 추상적?으로 존재하는 영역? 이폴더안에 깃의 규칙에 맞게 내용이 저장된다.
											working directory를 git init으로 설정하면 생기는 숨겨진 폴더 .git이 생성된다.
						ㄴ .git directory : 마찬가지로 .git폴더 안에서 저장되는 듯하다.
					ㅡ 깃에서 파일은 몇가지 상태로 존재한다.
						ㄴ committed : 데이터가 로컬db에 저장됨.
						ㄴ modified : 수정된파일이 아직 커밋되지않음.
						ㄴ staged : 수정된파일이 곧 커밋될것이라고 표현한 상태.
						ㄴ tracked : 스냅샷에 포함되었던 파일.
						ㄴ tracked는 unmodified, modified, staged로 나뉠수있다. 그 외에는 모두 untracked.
						ㄴ 파일의 상태확인은 git status 명령사용. -s또는 --short옵션을 붙일수 있다.
					ㅡ working directory에서 수정하면 modified상태. 이를 stage하여 staging area에 올려 커밋할 스냅샷을만들면 그게
						staged. 이를 커밋하여 영구적인 스냅샷을 git directory에 만들면 그게 commited상태.
					ㅡ git status : 폴더 안의 파일들의 상태를 나타난다.

				ㄴ 깃에서 파일의 상태
					ㄴ 종류 )
						ㄴ Untracked
							ㄴ 깃에서 관리하고 있지 않는 상태.
						ㄴ Tracked
							ㄴ 깃에서 관리 중인 상태.
							ㄴ 하위 상태
								ㄴ Unmodified
									ㄴ 변경사항이 없는 상태.
								ㄴ Modified
									ㄴ 변경사항이 있는 상태.
								ㄴ Staged
									ㄴ ???
					ㄴ 명령어 git status
						ㄴ 깃 리포지토리 내의 파일들의 상태 정보 출력.

				ㅇ 커밋
					ㅡ 어떤순간의 작업공간의 상태를 저장하는것. 작업공간 안에 있는 모든 파일과 파일의 데이터를 사진 찍듯이 복사해서 저장소에 보존합니다. 즉 커
						밋은 작	업공간의 어떤 시점의 스냅샷(버전)이라고 할 수 있습니다.
						(동사) '커밋한다'는 말은 커밋을 추가한다는 뜻입니다. 즉 현재 작업공간의 상태를 커밋으로 만들어서 저장소에 저장한다는 의미입니다.
					ㅡ커밋의 대략적 구조
						커밋이란 git commit 명령어로 저장소에 올리는 작업공간의 하나의 변경된 상태입니다. 하나의 커밋이 더해질 때는 이전 커밋에서 변경된 사항만 추가하면 될
						것입니다. 이 때문에 커밋은 서로 연결된 체인 구조를 형성합니다. 이 구조에서는 예컨대 이전 커밋이 훼손되면 그 이후 커밋도 망가집니다.
					ㄴ 커밋 메세지
						ㄴ 커밋은 이력을남기는 중요한작업이기때문에 커밋버튼을누를때는 커밋메세지를 필수로입력해야함.
						ㄴ 커밋메세지는 명료하고이해하기쉽게적어 다른이들에게도 쉽게하여야함. 권장형식이있음.
							1번째 줄 : 커밋 내의 변경 내용을 요약
							2번째 줄 : 빈 칸
							3번째 줄 : 변경한 이유
					ㅡ 커밋되는건 항상 add로 추가된 staged 파일들이라는것 명심.
					ㅡ 명령어)
						ㄴ git commit
						ㄴ 옵션
							ㄴ -a : staging area에 넣지않아도 tracked파일들이 커밋된다.
							ㄴ --amend
								ㄴ branch 맨 마지막 커밋을 수정.
								ㄴ ???

				ㄴ ??? ref
					ㄴ 'refs/~~~/~~~' 형태의 '이름'. 이 이름은 하나의 object name 또는 또다른 ref를 가리킴.
						ㄴ ex ) refs/heads/master, refs/remotes/nonameRemote
						ㄴ ??? 깃에서의 object에 대한 참조를 나타내는 이름같다?
					ㄴ 이게 git의 reference들의 풀네임이고 보통 이름을 간추려서 부름.
						ex ) 'refs/tags/v3' 을 tag 'v3',  'refs/heads/branch1'을 브랜치 'branch1' 등.
					ㄴ object name. 즉, SHA-1로 만들어진 object의 이름을 의미.
					ㄴ 실제로 working directory의 .git/refs 위치에 저장된다. 각 이름에 해당하는 파일 안에는 object name이 들어있다.
					ㄴ ??? 이름에서 refs 바로 하위의 계층은 타입에 따라 정해져 있는 듯? heads, remotes, tags 등.
						heads는 branch의 head object들이, remotes는 리포지토리의 remote들이 ..
					ㄴ 'refs/~~~' 형태가 아닌 ref
						ㄴ HEAD
							ㄴ 현재 branch.
							ㄴ working tree가 이 HEAD에 의해 결정됨.
							ㄴ 리포지토리의 'head' 중 하나.
						ㄴ ORIG_HEAD
							ㄴ merge, reset 등과 같이 현재 커밋을 check out하는 연산 수행시, 연산 수행 이전의 HEAD값을 나타냄.
								이를 통해 원래 HEAD로 쉽게 되돌아올 수 있다.
						ㄴ FETCH_HEAD
							ㄴ git fetch 명령어를 통해 가장 마지막으로 remote로부터 fetch된 브랜치를 가리킴.
						ㄴ MERGE_HEAD
						ㄴ REBASE_HEAD

				ㄴ '...' 연산자?
					ㄴ (*커밋1*)...(*커밋2*)
					ㄴ (*커밋1*) 과 (*커밋2*) 중 하나와만 연결점이 있는 커밋 목록을 모두 선택?
						둘 다 연결되면 선택 안됨?
					ㄴ 가령,
						커밋1 -> 커밋2 -> 커밋3(branch1) -> 커밋4 -> 커밋5
						일때,
						git log branch1...커밋5   를 하면,
						커밋1,2,3은 branch1과 커밋5 모두 연결되어 있으므로 결과 로그목록에 없고,
						커밋4,5는 커밋5하고만 연결되어 있으므로 결과 로그 목록에 뜬다.

				ㄴ branch<button>more</button>
				<pre>
					ㄴ
					ㄴ history상의 특정 지점에서 시작하는 '가지'를 생성.
						그 가지로 switch하면 해당 가지로 이동되고 이후 커밋 등의 동작을 하면, 가지 시작지점부터 별개의 분기로 history가 쌓여나간다.
						후에 merge 등을 통하여 가지를 합치는 등으로 사용됨.
					ㄴ remote-tracking branch
						ㄴ 초기 git clone이나 remote 추가 후 git fetch 등을 하여 원격으로 리포지토리를 받아오면,
							해당 리포지토리의 master branch뿐 아니라 그 외 branch들도 받아와지며, 추적 관리된다.(fetch, pull, push 등을 하면
							이러한 branch들을 remote-tracking branch라 하는 듯.
						ㄴ 로컬에서 임의로 수정할 수 없고 fetch 등을 할때 tracking 중인 해당 remote 상태와 맞게 업데이트됨.
					ㄴ head
						ㄴ 각 branch의 맨 끝 커밋의 ref
						ㄴ branch를 가리키는게 일반적으로 branch의 head를 가리키는 것.
					ㄴ 관련 명령어
						ㄴ git branch <button>more</button>
						<pre>
							ㄴ 명령어 형식 목록.
								ㄴ git branch<button>more</button>
								<pre>
									ㄴ git branch [--color[=< when>] | --no-color] [--show-current]
											[-v [--abbrev=< n> | --no-abbrev]]
											[--column[=< options>] | --no-column] [--sort=< key>]
											[--merged [< commit>]] [--no-merged [< commit>]]
											[--contains [< commit>]] [--no-contains [< commit>]]
											[--points-at < object>] [--format=< format>]
											[(-r | --remotes) | (-a | --all)]
											[--list] [< pattern>… ]
									ㄴ 브랜치 리스팅. 현재 브랜치는 앞에 별표.
									ㄴ 디폴트로 --list 옵션이 생략된것.
									ㄴ --remotes / -r 옵션 ) remote들의 branch가 리스팅.
									ㄴ --all / -a 옵션 ) remote와 local branch 모두 리스팅.
									ㄴ --contains (*commit*), --no-contains (*commit*)
										ㄴ (*commit*)이 포함된 브랜치만 보여줌.
										ㄴ --no-contains는 그반대.
										ㄴ (*commit*)없을시 디폴트는 HEAD.
									ㄴ --merged (*commit*), --no-merged (*commit*)
										ㄴ (*commit*)으로 merge된 브랜치 리스팅.
										ㄴ --no-merged는 그반대.
										ㄴ (*commit*) 없을시 디폴트는 HEAD.
								</pre>
								ㄴ git branch (*브랜치명*)<button>more</button>
								<pre>
									ㄴ git branch [--track[=(direct|inherit)] | --no-track] [-f]
										[--recurse-submodules] < branchname> [< start-point>]
									ㄴ (*브랜치면*)의 브랜치 추가. 이 브랜치는 현재 브랜치 head가 가리키는 지점과 동일한 지점을 가리킴.
										즉, 현재 branch의 마지막 커밋을 가리킴. 즉 현재 HEAD를 가리키는 브랜치 생성.
										이 브랜치에서 새 커밋시 별도 분기된 브랜치로 히스토리가 쌓여나가게됨.
									ㄴ < start-point> 명시시 이 지점을 가리키는 브랜치 생성. 커밋 등.
									ㄴ 새 브랜치를 생성만 할뿐, switch하지는 않음.
									ㄴ --track
										ㄴ git branch (*브랜치명*) --track (*remote*)
										ㄴ 생성하는 브랜치에 대해 'branch.(*브랜치명*).remote', 'branch.(*브랜치명*).merge' 설정값을 설정.
											ㄴ 해당 설정값 설명은 git config의 설정변수 참조.
										ㄴ ??? --track=direct? --track=inherit? branch.autoSetupMerge?
								</pre>
								ㄴ git branch --move (*기존브랜치명*) (*새브랜치명*)<button>more</button>
								<pre>
									ㄴ git branch (-m | -M) [< oldbranch>] < newbranch>
									ㄴ oldbranch에 해당하는 브랜치의 이름을 newbranch로 변경.
									ㄴ reflog에 oldbranch에 해당하는 로그가 있는 경우, 이 log의 브랜치명이 newbranch로 변경되며
										이 rename 동작에 대한 로그가 reflog에 추가된다.
										ㄴ ex )
											git branch -m branch3-1 branch3-1_new
											git reflog --all

											// 아래 로그의 'branch3-1_new'는 원래 'branch3-1'. 변경된 것.
											95f7f6c8f (branch3-1_new) refs/heads/branch3-1_new@{0}: Branch: renamed refs/heads/branch3-1 to refs/heads/branch3-1_new
											~~~
											// 왼쪽 소괄호 안의 ref명들은 rename에 따라 변경되나, 우측 내용부분은 변경되지 않는듯함.
											95f7f6c8f (branch3-1_new) HEAD@{1}: checkout: moving from branch3 to branch3-1
											~~~
									ㄴ -M 옵션은 --move --force.
								</pre>
								ㄴ git branch --copy (*기존브랜치명*) (*새브랜치명*)<button>more</button>
								<pre>
									ㄴ git branch (-c | -C) [< oldbranch>] < newbranch>
									ㄴ git branch -m ~~~ 과 거의 유사한데, rename을 하는게 아닌 복사.
										즉, oldbranch에 해당하는 브랜치를 복사하여 newbranch이름의 브랜치 생성.
										reflog도 복사하여 생성.
									ㄴ -C 옵션은 --copy --force.
								</pre>
								ㄴ git branch --delete (*브랜치명*)<button>more</button>
								<pre>
									ㄴ git branch (-d | -D) [-r] < branchname>…
									ㄴ (*브랜치명*)에 해당하는 브랜치 삭제. reflog도 같이 삭제.
									ㄴ 삭제하려는 브랜치는 upstream으로 merge되어있어야함.
									ㄴ -D 옵션은, --delete --force 와 동일.
									ㄴ -r과 함께 사용시, remote-tracking branch를 삭제.
										이 동작은 remote에 더이상 해당 branch가 없거나 fetch시 해당 브랜치를 fetch해오지 않도록 설정된 경우에만 의미가 있다.
										안그럼 fetch시 어차피 다시 로드해와 생길테니까.
								</pre>
						</pre>
						ㄴ git switch<button>more</button>
						<pre>
							ㄴ 특정 branch로 전환.
							ㄴ working tree와 index가 해당 branch에 맞게 업데이트됨.
							ㄴ 전환 후, 새롭게 추가된 commit은 해당 branch 끝에 추가되게됨.
							ㄴ 명령어 형식<button>more</button>
							<pre>
								ㄴ git switch [< options>] [--no-guess] < branch>
									ㄴ 현재 브랜치의 로컬에 커밋되지 않은 변경사항이 있는 경우, switch 실패.
										--discard-changes 옵션을 붙여 커밋되지 않은 변경사항을 버리도록 할 수 있음.
								ㄴ git switch [< options>] --detach [< start-point>]
									ㄴ (*start-point*)으로 HEAD를 이동. (*start-point*)은 tag명, commit object명 등이 가능.
									ㄴ 'HEAD'가 'detacked' 되었다라고함.
								ㄴ git switch [< options>] (-c|-C) (*새 브랜치명*) [(*start-point*)]
									ㄴ --create / -c, --force-create / -C
										ㄴ (*새브랜치명*) 이름을 가지고 ( (*start-point*)가 명시된 경우) (*start-point*)에서 시작하는
											브랜치를 만들고 해당 브랜치로 switch.
									ㄴ ex )
										// 인자로 넘긴 커밋에서부터 시작하는 'newInSwitch'란 이름의 브랜치 생성 후 switch.
										git switch --create newInSwitch dac777a10c99b30496230d8a5988a5faffe87016
								ㄴ git switch [< options>] --orphan < new-branch>
							</pre>
						</pre>
						ㄴ git reset
							ㄴ
				</pre>

				ㄴ merge
					ㄴ 명령어 형식 목록
						ㄴ git merge (*커밋*)
							ㄴ git merge [-n] [--stat] [--no-commit] [--squash] [--[no-]edit]
								[--no-verify] [-s < strategy>] [-X < strategy-option>] [-S[< keyid>]]
								[--[no-]allow-unrelated-histories]
								[--[no-]rerere-autoupdate] [-m < msg>] [-F < file>]
								[--into-name < branch>] [< commit>… ]
							ㄴ ??? 현재 브랜치가 분기된 이후 (*커밋*)의 변경사항을 현재 브랜치의 변경사항과 합치고
								현재 브랜치에 새 커밋을 추가한 뒤 그 합친 결과를 write
							ㄴ 합친 결과물이 현재 브랜치의 working tree에 덮어씌워진다.
								ㄴ 하여 수정했으나 커밋하지 않은 변경사항들이 있고, 이 파일이 merge과정에서 영향을 받는 파일인 경우,
									merge가 진행되지 않고 오류뜸.
									ㄴ ex )
										error: Your local changes to the following files would be overwritten by checkout:
												test.txt
										Please commit your changes or stash them before you switch branches.
										Aborting
							ㄴ 결합 과정에서 충돌 발생시, merge가 되다만 결과물이 되고, 없을시 완전히 merge된 결과물이 된다.
								ㄴ ex )
									충돌 발생시,
									Auto-merging test.txt
									CONFLICT (content): Merge conflict in test.txt
									Automatic merge failed; fix conflicts and then commit the result.
								ㄴ 충돌 발생시, 해당 파일 충돌지점에 표시가 되고, 수동으로 원하는대로 수정한 뒤, 해당 파일을 index에 추가 후 커밋하면
									merge 완료.
									ㄴ 충돌 수정 후, 해당 파일 커밋시, 커밋메세지는 merge 충돌에 대한 수정이라고 디폴트로 채워져 있음.
								ㄴ 충돌 발생시, 해당 충돌을 수정하여 merge를 완료할때까지 commit 불가.
							ㄴ git pull 명령어에서 자동으로 실행된다?
						ㄴ git merge --abort
							ㄴ git merge (--continue | --abort | --quit)
							ㄴ git merge (*커밋*) 의 결과가 충돌발생인 경우에만 실행가능.
							ㄴ merge 작업을 중단하고 merge 시작 전 상태로 되돌림.
							ㄴ 되돌리려는 merge 시작 전 상태에 커밋하지 않은 변경사항이 있는 경우, 해당 내용을 제대로 되돌리지 못할수도 있다함.

				ㄴ fetch<button>more</button>
				<pre>
					ㄴ 모든 remote-tracking branch를 해당 remote 리포지토리의 최신버전으로 업데이트.
						업데이트만 할 뿐, 현재 리포지토리에 아무런 변경을 하지 않음.
				</pre>

				ㄴ remote <button>more</button>
				<pre>
					ㄴ git remote add (*remote명*) (*git repo url*)
						ㄴ 현재 리포지토리에 remote를 추가. (*git repo url*)에 해당하는 외부 리포지토리를 (*remote명*)으로 등록.
							등록한 remote로 fetch, push 등 여러 동작 하게됨.
				</pre>

				ㄴ tag <button>more</button>
				<pre>
					ㄴ 'refs/tags/' 하위의 'ref'. 가리키는 object의 타입은 뭐든 상관 없다.
					ㄴ 관련 명령어
						ㄴ git tag (*tag명*) (*커밋*)
							ㄴ (*커밋*)을 가리키는 (*tag명*)의 tag 생성.
						ㄴ tag -l : tag 목록 나열.
				</pre>

				ㄴ log
					ㄴ git log
						ㄴ 리포지토리의 커밋 목록을 보여주는 명령어.

				ㄴ diff

				ㄴ 깃의 object <button>more</button>
				<pre>
					ㄴ 깃에선 모든 object의 이름은 object의 컨텐츠에 대해 SHA-1 해쉬값을 취하여 만들어진다.
						ㄴ 컨텐츠가 완전히 일치하지 않으면 해쉬값이 다를 수밖에 없고 이를 이용하여 깃은 두 객체 사이의 차이점이 존재하는지 여부를
							object의 이름만 보고 빠르게 판단 가능하다.
						ㄴ 리포지토리가 달라도 컨텐츠만 같으면 같은 이름을 가진다.
						ㄴ ??? 컨텐츠의 해시값과 이름이 일치하는지를 확인하여 오류여부를 확인한다?
							ㄴ ??? 어떤 오류? 어떻게 쓰이는지?
					ㄴ blob object
						ㄴ 바이너리 파일을 의미.
							별다른 추가적인 속성을 가지지 않고 파일 자체를 나타낸다.
						ㄴ 파일의 컨텐츠에 의해 정의됨. 따라서 내용물이 동일하면 같은blob 객체를 사용하게됨. 즉 두 파일에 대한 blob object의
							해시 키 값이 동일.
							ㄴ 디렉토리 위치와 상관 없음. 파일명과도 상관 없음.

					ㄴ tree object
						ㄴ 아주 간추려서 말하면, working directory 안에서 특정한 하나의 디렉토리와 그 컨텐츠를 나타내는 객체.
							하위에 해당 디렉토리의 구성 목록을 담고 있음.
							구성 목록의 타입은 'blob', 'tree' 중 하나.
								blob은 일반 파일을 의미, tree는 또다른 sub directory를 의미.
								즉, 하위에 또다른 tree object를 가져 계층 구조 형성.
						ㄴ 각 blob, tree는 다른 git의 object들과 마찬가지로 그 내용물의 SHA-1 hash 값이 이름이 됨.
							ㄴ 컨텐츠의 해쉬값으로 이름이 결정되므로, 내용물이 완전히 동일해야만(하위 서브디렉토리의 내용물들까지도)
								동일한 이름을 가질 수 있음.
						ㄴ git show, git ls-tree 명령어로 tree object의 상세 정보 확인 가능.

					ㄴ commit object
						ㄴ tree object의 계층 구조를 수정본들의 '비순환 방향 그래프'로 포함시킴.
						ㄴ 구성 )
							ㄴ tree
								ㄴ 특정 시점에서의 디렉토리 계층 구조를 나타내는 단 하나의 tree object의 SHA-1 이름.
							ㄴ parent
								ㄴ 부모 commit 이름. 즉, 히스토리상 바로 직전 단계의 커밋 번호의 SHA-1 이름.
								ㄴ 대부분의 경우 하나, merge commit의 경우 여러개, 최초 커밋의 경우 없으며, 이렇게 parent가 없는 커밋을
									'root commit'이라함.
							ㄴ author : ??? 해당 변경사항에 대한 책임이 있는 사람?
							ㄴ committer
								ㄴ 커밋 작성자.
								ㄴ ??? 대부분의 경우, author가 committer이다? 수정은 A가 하고 커밋만 B가 한 경우 등에서나 다름?
							ㄴ comment : 변경사항에 대한 설명.
						ㄴ git show 명령어로 상세정보 확인 가능.
							ㄴ ex ) git show -s --pretty=raw 2be7fcb476

								commit 2be7fcb4764f2dbcee52635b91fedb1b3dcf7ab4
								tree fb3a8bdd0ceddd019615af4d57a53f43d8cee2bf
								parent 257a84d9d02e90447b149af58b271c19405edb6a
								author Dave Watson < dwatson@mimvista.com> 1187576872 -0400
								committer Junio C Hamano < gitster@pobox.com> 1187591163 -0700

									Fix misspelling of 'suppress' in docs

									Signed-off-by: Junio C Hamano < gitster@pobox.com>
						ㄴ 변경점은 parent commit의 tree와 현재 commit의 tree object의 컨텐츠를 비교하여 식별된다.
					ㄴ tag object
						ㄴ 특정 object를 지칭하는 object.
						ㄴ object, object type, tag name, 태그 작성자 이름, 메지시로 구성.
						ㄴ ex ) git cat-file tag v1.5.0  // 태그 상세 정보 조회 명령어.
					ㄴ trust ???
				</pre>

				ㄴ low level git 명령어.
					ㄴ 깃 명령어들은 내부적으로 'low-level git 명령어'들을 사용하는 shell script로 구현된다함.
					ㄴ 일반적인 경우 당연히 쓸일 없지만, 예외적인 케이스나 내부 동작 이해의 관점에서 알면 좋다.

				ㄴ bisect <button>more</button>
				<pre>
					ㄴ ??? git에서 제공하는 history상 버그커밋 찾는 툴?
						ㄴ 어떤 지점이 'bad'상태이고 (버그가 존재하고), 어떤 지점이 'good'상태인지(버그가 없는지) 입력하면,
							그 사이의 히스토리 커밋들을 이등분하여 이진탐색 비슷하게 커밋을 제안하며 해당 커밋으로 detach 해준다.
					ㄴ ex )
						git bisect start  // bisect 시작함.
						git bisect good (*정상 지점*)  // 어디가 정상지점인지 명시.
						git bisect bad (*버그존재하는 지점*)  // 어디가 버그존재하는지점인지 명시.

						// 대충 다음같은 출력나오며 해당 커밋으로 detach.
						Bisecting: a merge base must be tested
						[378aa01995d7ac051248b36e47a2ca2419a34b3a] in branch3

						// 제시받은 커밋이 good인지 bad인지 명시.
						git bisect bad
						// 다시 다음 커밋 제시.

						// 이를 반복.. 마지막에 어떤커밋이 문제인지를 나타내는 문장 설명 출력. 형식 다양?
						The merge base 378aa01995d7ac051248b36e47a2ca2419a34b3a is bad.
						This means the bug has been fixed between 378aa01995d7ac051248b36e47a2ca2419a34b3a and [dac777a10c99b30496230d8a5988a5faffe87016].

						git bisect reset  // bisect 종료. bisect 시작 전에 있던 branch로 switch.

					ㄴ ~~~

				</pre>

				ㄴ 깃 명령어 <button>more</button>
				<pre>
					ㄴ git help (*명령어*)
						또는 git (*명령어*) --help  (명령어에 --help option을 붙이는 형식)
						ㄴ (*명령어*)에 대한 도움말.
					ㄴ git init<button>more</button>
					<pre>
						ㄴ 새 깃 리포지토리 생성 및 기존 리포지토리 재초기화.
							ㄴ 즉, .git 폴더와 하위 파일들 생성?
							ㄴ

					</pre>
					ㄴ git log <button>more</button>
					<pre>
						ㄴ 변경 이력 확인 명령어.
						ㄴ 옵션 )
							ㄴ ex ) git log -p
								ㄴ 어느 부분이 변경되었는지 상세하게 볼 수 있음.
							ㄴ -p 	: 각 커밋의 diff결과출력
							ㄴ -(*숫자*) : 보여줄 커밋개수를 정함.
							ㄴ --stat 	: 통계를 보여줌. 어떤파일이, 얼마나많이변경됐는지,얼마나 많은줄을 추가했는지 등. 요약정보는 맨
										아래에보여줌.
							ㄴ --pretty: 출력결과를 보여줄때 기본형식이외에 다양한 형식으로 결과를 보여주는 기능
							ㄴ -S	: 코드에서 추가되거나 제거된내용중 특정텍스트가 포함되어있는지를 검색. 옵션뒤에 그냥 검색할 텍스트를
									추가하면된다.
							ㄴ git log -- (*url*) : url에 해당하는 파일의 로그를 볼수있다.

					</pre>
					ㄴ git branch <button>more</button>
					<pre>
						ㄴ 깃 브랜치 관련 명령어.
						ㄴ ex )
							ㄴ git branch
								ㄴ 브랜치 목록 확인.
								ㄴ '*' 표시있는게 현재 브랜치.
							ㄴ git branch (*branch명*)
								ㄴ 브랜치 생성.
							ㄴ git branch -d (*브래치명*)
								ㄴ 해당 브랜치 삭제.

					</pre>
					ㄴ git diff
						ㄴ 파일의 상태별 어느 부분이 다른지 알려줌.
						ㄴ 디폴트로, 리포지토리의 working directory와 staging area의 파일 비교.
						ㄴ --staged 옵션 추가시, staging area와 커밋된 내용 비교.
					ㄴ git reflog <button>more</button>
					<pre>
						ㄴ reference log. 브랜치head 또는 다른 reference가 로컬 리포지토리에서 업데이트되면 reference log가 기록되며,
							이 명령어로 그 로그목록을 볼 수 있다.
						ㄴ ex )
							C:\Users\tony7\gitTest>git reflog --all
							6a7a9f39c (HEAD -> remoteTestBranch, branch3) HEAD@{0}: checkout: moving from branch3 to remoteTestBranch
							6a7a9f39c (HEAD -> remoteTestBranch, branch3) refs/heads/remoteTestBranch@{0}: branch: Created from branch3
							b8615b85b (nonameRemote/main) refs/remotes/nonameRemote/main@{0}: fetch nonameRemote: storing head
							6a7a9f39c (HEAD -> remoteTestBranch, branch3) refs/heads/branch3@{0}: commit (merge): Merge branch '3-2' into branch3
							6a7a9f39c (HEAD -> remoteTestBranch, branch3) HEAD@{1}: commit (merge): Merge branch '3-2' into branch307cf5c6e8 HEAD@{2}: checkout: moving from 3-2 to branch3
							0a1f155af HEAD@{3}: checkout: moving from master to 3-2
							95f7f6c8f (branch3-1_new_copy, branch3-1_new) refs/heads/branch3-1_new_copy@{0}: Branch: copied refs/heads/branch3-1_new to refs/heads/branch3-1_new_copy
							95f7f6c8f (branch3-1_new_copy, branch3-1_new) refs/heads/branch3-1_new@{0}: Branch: renamed refs/heads/branch3-1 to refs/heads/branch3-1_new
							95f7f6c8f (branch3-1_new_copy, branch3-1_new) refs/heads/branch3-1_new_copy@{1}: Branch: renamed refs/heads/branch3-1 to refs/heads/branch3-1_new
							ㄴ 'HEAD@{3}' : HEAD가 3번 업데이트되기 전에 가리키던 곳을 의미. 'HEAD@{0}'이면 당연히 현재 HEAD 위치.
					</pre>
					ㄴ git remove
					ㄴ git name-rev
					ㄴ git describe
					ㄴ git merge-base
					ㄴ git status

					ㄴ ~~~

				</pre>

				ㄴ 깃 설정하기 <button>more</button>
				<pre>
					ㄴ 세가지 파일에 의해 설정된다.
						ㄴ /etc/gitconfig
							ㄴ 깃 전체, 최상위 설정 파일. 모든 사용자, 모든 저장소에 적용.
							ㄴ 위치
								ㄴ 윈도우에선 보통 C://Program Files/Git/etc/gitconfig
							ㄴ git config 명령어에 --system 옵션으로 설정 가능.
						ㄴ .gitconfig (또는 .config/git/config)
							ㄴ 특정 사용자 적용 설정 파일.
							ㄴ 위치
								ㄴ 윈도우 ) 보통 유저 홈 디렉토리. C://Users/(*유저*)
							ㄴ git config 명령어에 --global 옵션으로 설정 가능.
						ㄴ .git/config
							ㄴ 특정 깃 디렉토리에 위치.
							ㄴ 해당 저장소에만 적용.
							ㄴ git config 명령어에 --local 옵션으로 설정 가능. (디폴트)
					ㄴ 적용 우선순위
						ㄴ .git/config > .gitconfig > /etc/gitconfig

					ㄴ 설정 변수 <button>more</button>
					<pre>
						ㄴ ~~~
						ㄴ branch.autoSetupMerge
							ㄴ ~~~ ???
						ㄴ branch.(*브랜치명*).remote
							ㄴ 해당 브랜치가 디폴트로 fetch, push할 remote를 설정.
								ㄴ 'git push' 등과 같이 따로 remote를 명시하지 않으면서 별다른 관련 설정이 없는 경우 등.
								ㄴ 즉, git push, git fetch를 하면 별다른 설정이 없는한, 여기 설정된 remote로부터 fetch, push를 수행.
							ㄴ 디폴트를 설정하는 것이지 따로 명시하면 해당 remote로도 fetch, push 가능???
							ㄴ 'remote-tracking branch'가 되는건 아님. 그냥 연결된 remote값이 설정된 것뿐.
							ㄴ push는 'remote.pushDefault' 설정에 의해 override 될 수 있음.
							ㄴ 현재 브랜치에 대해 'branch.(*브랜치명*).pushRemote' 설정에 의해 override 될 수 있음.
						ㄴ branch.(*브랜치명*).merge
							ㄴ ~~~???

					</pre>

					ㄴ git config
						ㄴ 깃 설정 명령어.
						ㅡ git config --global user.name (*이름*)
						ㅡ git config --global user.email (*이메일*)
						ㅡ 깃을 저장할대 누가 해당내용을 업데이트했는지를 나타내주는 정보이다. 컴퓨터에서 한번만 설정한다하고
							이렇게 설정하고 원격저장소에 저장하면 이 user정보로 기록이 뜨는듯하다.
						ㄴ git config --list
							ㄴ 설정된 옵션 목록 확인.
					
					ㄴ .gitignore 파일 <button>more</button>
					<pre>
						ㄴ 깃 저장소 내에서 무시할 파일에 대해 설정. Untracked조차 되지 않는다. 
						ㄴ 매칭패턴으로 타겟 파일 또는 폴더를 결정. 
						ㄴ 파일이 타겟인 경우, 해당 파일이. 폴더가 타겟인 경우, 폴더가 통째로 무시됨. 
						ㄴ 입력 형식 )
							ㄴ 상세 ) https://git-scm.com/docs/gitignore
							ㄴ 주석 : '#'으로 시작하는 라인. ex ) # 블라블라블라...
							ㄴ 확장자 )
								ㄴ ex ) *.a  // .a 확장자 무시.  
							ㄴ 패턴 앞에 '!'가 오는 경우, 
								매칭되는 패턴이 이전에 ignore에 포함되었다면 다시 제외시킴. 즉, 해당 파일이 무시되지 않게됨. 
								ㄴ ex ) 
									/noname/logs/** 
									!/noname/logs/error_log_2024-04-01.txt 
									ㄴ /noname/logs 하위 모든 내용 무시했다가, '!' 패턴으로 하위의 error_log_2024-04-01.txt는 
										다시 포함시킴. 
								ㄴ 상위 폴더 자체가 무시되었다면 유효하지 않음. 
									ㄴ ex )
										바로 위 예제와 같이 /noname/logs/** 로 logs하위 내용을 무시하는게 아니라, 
										다음과 같이 logs 폴더 자체가 무시되었다면 그 하위 내용에 대한 '!' 패턴은 유효하지 않다는 것. 

										/noname/logs 
										!/noname/logs/error_log_2024-04-01.txt
										ㄴ 여전히 error_log_2024-04-01.txt는 무시됨.  

							ㄴ 패턴이 slash (/)로 시작하거나 패턴 중간에 slash가 있으면 
								.gitignore의 위치로부터 상대경로로 해석하여 매칭파일 찾음. 
								아니라면, 경로 상관 없이 매칭되는 파일 찾음. 
								ㄴ ex ) 
									/noname/logs  # .gitignore가 위치하는 경로 바로 하위의 noname 하뉘의 logs 매칭. 
									noname/logs  # 위와 동일. 맨앞에 slash가 없어도 중간에 있으면 상대경로 취급한다. 
									/logs  # .gitignore가 위치하는 경로 바로 하위의 logs 매칭. 
									logs  # 경로 상관 없이 .gitignore가 위치하는 경로 하위에 logs란 이름의 파일(또는 폴더)가 매칭. 

									플젝루트
									ㄴ.gitignore 
									ㄴnoname
										ㄴlogs  // 패턴이 '/noname/logs' 또는 'logs'이면 매칭. 
									ㄴnoname2  
										ㄴlogs  // 패턴이 '/noname/logs'이면 매칭안됨. 'logs'이면 매칭.
									ㄴlogs  // 패턴이 '/noname/logs' 이면 매칭안됨. 'logs'이면 매칭.
							ㄴ 패턴이 slash로 끝나면, 디렉토리들만 매칭. slash로 끝나지 않으면, 디렉토리 & 파일이 모두 매칭. 
								ㄴ ex ) 
									logs/  # logs란 이름의 폴더들만 매칭.
									logs  # logs란 이름의 폴더뿐 아니라, 파일도 매칭. 

									플젝루트
									ㄴ.gitignore
									ㄴnoname
										ㄴlogs  (폴더)  // 패턴이 'logs/'이거나 'logs'이면 매칭. 
											ㄴtest1.txt
											ㄴtest2.txt
									ㄴlogs  (파일)  // 패턴이 'logs'일때만 매칭. 
							ㄴ 패턴이 '**'로 시작하면
								모든 디렉토리에 대해 해당 패턴 매칭 찾음. 
								가령, '**/logs' 이면, 모든 디렉토리 하위에 logs인 파일 또는 디렉토리 매칭. 결과적으로 패턴 'logs'과 동일. 
								또는 '**/noname/logs'이면, 모든 디렉토리 하위에 noname/logs인 파일 또는 디렉토리 매칭. 
								이 경우, 위 '**/logs'와는 약간 다르게 결과적으로 'noname/logs'와 동일하지 않다. 'noname/logs' 패턴은 
								중간에 slash가 들어가 .gitignore위치로부터 상대경로로 해석하기 때문. 
								ㄴ ex ) 
									플젝루트
									ㄴ.gitignore
									ㄴnoname
										ㄴlogs  // 패턴이 '**/noname/logs'이면 매칭.
									ㄴnoname2
										ㄴnoname
											ㄴlogs	// 패턴이 '**/noname/logs'이면 매칭. 어느곳에 있는 디렉토리건, 하위에 'noname/logs'패턴이 있으면
													매칭되는 것. 		
								ㄴ 
							ㄴ 패턴이 '/**'로 끝나면, 
								ㄴ 하위로 깊이가 몇이되든 모든 내용물들을 매칭. 시작하는 해당 폴더 또는 파일은 제외. 
									가령, 'noname/**'라 하면, noname 폴더 하위의 모든 파일 및 폴더들이 매칭됨. 
									noname폴더는 제외. 
								ㄴ 유의사항	
									ㄴ 'logs/**' 같은 형식도, 중간에 slash가 들어가기 때문에, .gitignore 위치로부터의 상대경로로 해석됨 유의. 
										모든 logs라는 폴더 하위의 내용들을 매칭하고자하면 '**/logs/**' 와 같은식으로 사용해야함. 
							ㄴ 패턴이 '/**/' 형식이면, 저 '**' 부분에 몇단계 깊이의 폴더가 있던 매칭 찾음. 
								가령, 'noname/**/spiders' 이면, .gitignore 위치로부터 시작하여 하위로 몇개의 폴더를 들어가든 상관없이 
								spiders라는 파일또는 폴더가 매칭됨. 
								ㄴ ex ) 
									플젝루트
									ㄴ.gitignore
									ㄴnoname
										ㄴlogs  // /noname/logs 임. 매칭됨. 
										ㄴnoname2
											ㄴlogs  // /noname/noname2/logs 임. 매칭됨. 
										ㄴnoname3
											ㄴnoname3_1
												ㄴlogs  // /noname/noname3/noname3_1/logs 임 매칭됨. 
									ㄴlogs  // /logs 임. 'noname/**/spiders'와는 매칭되지 않음. 
					</pre>

				</pre>

				ㄴ 깃 저장소
					ㅡ 깃저장소란
						ㄴ 말그대로 저장소인데, 파일을 변경이력별로 구분하여 저장함.
						ㄴ 로컬저장소와 원격저장소로 나뉨. 전자는 내pc에서만 저장되는 개인용, 후자는 서버에서 모두와 공유하는 저장소.
					ㅡ 로컬 저장소 만들기
						1. 기존 디렉토리를 깃 저장소로 만들기
							ㅡ 해당 폴더 위치로 이동하여 'git init'명령을 실행한다.
							ㅡ 해당폴더는 깃저장소가 되며, 이곳에서 stage, commit등을 할수 있다.
						2. 기존 저장소 clone하기
							ㅡ git clone (*url*) (*폴더이름*) 을 하게되면 url에 있는 저장소의 내용을 히스토리까지 포함해서 전부 복사해
								가져오며, 폴더이름을 쓰지않을수도있다.
					ㅡ 원격 저장소 명령어
						ㄴgit remote : 현재 프로젝트에 지정된 리모트저장소를 확인
						ㄴgit remote add (*원격저장소단축이름*) (*url*) : 현재 프로젝트에 url에 해당하느 ㄴ원격 저장소를 추가한다.
						ㄴgit remote -v : 현재프로젝트에 원격저장소의 단축이름과 url을 볼 수있다.
						ㄴgit clone을 하면 다운을받은 해당 url이 원격저장소 'origin'으로 자동등록이된다. (origin은 그냥처음에 자동으로
							기본적으로부여되는 원격저장소를 가리키는 자동지정이름)
						ㄴgit remote show (*저장소이름*) : 원격저장소 정보확인.
						ㄴgit remote reaname (*현재원격저장소이름*) (*바꿀이름*):이름바꾸기
						ㄴgit remote remove 또는 git remote rm : 삭제

				ㄴ 인덱스
					ㅡ 작업트리 : 흔히말하는 폴더를 말함.
					ㅡ 인덱스 : 작업트리에서 저장소에 저장하기 전, 사이에잇는 공간을말함.
					ㅡ 원격저장소 부분을 HEAD라고한다.
					ㅡ 저장소에 등록하기위해서는 먼저 인덱스에 등록을 해야하며, 이과정을 '스테이징(stage)'이라함. 이를통해 저장소에 올릴것들을 선택할수있음.
					ㅡ 방법) git add (*파일*)명령어로 인덱스에 추가.

				ㄴ 파일 수정 삭제
					ㅡ git diff : staged가 아닌 파일에서 수정된것이있으면 비교해볼수있다.
					ㅡ git rm : 워킹디렉토리의 파일을 삭제하고 이내용을 staging해줒는 것까지 실행하는 명령. 이후 커밋을 해야
									삭제내역이 적용되어 영구적으로 untracked, 지워진다. rm명령을쓰지않고 윈도우상에서 파일삭제만하면
									staing은 따로해야한다.
					ㅡ git mv (*파일이름*) (*바꿀 파일이름*) : 파일이름변경.

				ㄴ되돌리기
					ㅡgit commit --amend : 마지막 커밋을 현재staging area내용으로 대체한다. 가장최근의 커밋을 덮어씌우는것.
					ㅡgit reset HEAD (*파일*) : add된 파일을 staging area에서 꺼낸다.
					ㅡgit checkout -- (*파일*) : modified된파일을 되돌린다.
				ㄴ 커밋
					ㅡ 어떤순간의 작업공간의 상태를 저장하는것. 작업공간 안에 있는 모든 파일	과 파일의 데이터를 사진 찍듯이 복사해서 저장소에 보존합니다. 즉 커
						밋은 작	업공간의 어떤 시점의 스냅샷이라고 할 수 있습니다.
						(동사) '커밋한다'는 말은 커밋을 추가한다는 뜻입니다. 즉 현재 작업공간의 상태를 커밋으로 만들어서 저장소에 저장한다는 의미입니다.
					ㅡ커밋의 대략적 구조
						커밋이란 git commit 명령어로 저장소에 올리는 작업공간의 하나의 변경된 상태입니다. 하나의 커밋이 더해질 때는 이전 커밋에서 변경된 사항만 추가하면 될
						것입니다. 이 때문에 커밋은 서로 연결된 체인 구조를 형성합니다. 이 구조에서는 예컨대 이전 커밋이 훼손되면 그 이후 커밋도 망가집니다.
					ㅡ 커밋은 이력을남기는 중요한작업이기때문에 커밋버튼을누를때는 커밋메세지를 필수로입력해야함.
					ㅡ커밋메세지는 명료하고이해하기쉽게적어 다른이들에게도 쉽게하여야함. 권장형식이있음.
						1번째 줄 : 커밋 내의 변경 내용을 요약
						2번째 줄 : 빈 칸
						3번째 줄 : 변경한 이유
					ㅡ 커밋되는건 항상 add로 추가된 staged 파일들이라는것 명심.
					ㅡ 명령어)
						ㄴ git commit
						ㄴ 옵션
							ㄴ -a : staging area에 넣지않아도 tracked파일들이 커밋된다.
	 
				ㄴ 히스토리보기
					ㅡ git log 명령어를 통해 커밋 히스토리를 볼수있다.(맨위가 가장최근)
					ㅡ옵션들)
						ㄴ -p 	: 각 커밋의 diff결과출력
						ㄴ -(*숫자*) : 보여줄 커밋개수를 정함.
						ㄴ --stat 	: 통계를 보여줌. 어떤파일이, 얼마나많이변경됐는지,얼마나 많은줄을 추가했는지 등. 요약정보는 맨
									아래에보여줌.
						ㄴ --pretty: 출력결과를 보여줄때 기본형식이외에 다양한 형식으로 결과를 보여주는 기능
						ㄴ -S	: 코드에서 추가되거나 제거된내용중 특정텍스트가 포함되어있는지를 검색. 옵션뒤에 그냥 검색할 텍스트를
								추가하면된다.
						ㄴ git log -- (*url*) : url에 해당하는 파일의 로그를 볼수있다.
				ㄴ 태그
					ㅡ커밋 버전에 말그대로 태그를 붙이는것.
					ㅡ태그에는 두종류가있다. 일반태그와 주석태그. 주석태그에는 만든사람이름, 이메일, 태그만든날짜, 태그메세지를 저장.
					ㅡ 태그 등록하기
						ㄴgit tag (*태그이름*) : 현재 HEAD의 커밋에 태그를 등록.
						ㄴgit tag -a (*태그이름*) : 주석달린 태그를 현재HEAD부분의 커밋에 등록.
						ㄴgit tag나 git tag -a 명령어 끝에 현재HEAD 커밋이 아닌 과거 커밋의 체크섬값을 추가해주면 해당 커밋에 대하여
							태그를 등록할수 있다.
					ㅡgit tag : 태그목록보기
					ㅡgit push명령은 태그를 원격서버에 올리지않는다. 따로 push해주어야한다. git push (*원격이름*) (*태그이름*)을
						통해 push할수있다. git push --tags를 하면 원격서버에 없는 태그를 모두 push할수있다.

				ㄴ 복제(clone)
					ㅡ 원격저장소의 내ㅛㅇㅇ을 그대로 다운로드하여 저장

				ㄴ 푸쉬(push)
					ㅡ 로컬저장소의 변경이력을 원격저장소에 올리는것.
					ㅡ 원격저장소의내용이 로컬저장소와 같아지게됨.
					ㅡ 원격서버의 주소를 설정해주어야한다.
						git remote add origin (*원격서버주소*)
					ㅡgit push (*원격이름*) (*브랜치이름*) : push명령어
					ㅡ원격저장소에 쓰기권한이 있어야하며,
					ㅡ원격저장소에 push하였을때 충돌내용이 없어야한다. 예를들면, 내가 원격저장소를 clone을 하고 다른사람이
						그 원격에push하고 나중에  내가 push를 하려고했을때 다른사람이 이미원격에 push해놓은 내용과 내가
						push하려는 내용에서 겹치거나 달라서 충돌이생기면 push할수없다.

				ㄴ fetch
					ㅡ 원격저장소로부터 로컬저장소와 다른 변경이력들을 다운받는다.
					ㅡ로컬에 이름없는 브랜치를 만들어 이곳으로 내용을 가져오며, FETCH_HEAD라는 이름으로 checkout가능하다.
					ㅡmerge는 따로 진행하여 내용을 합쳐야한다.

				ㄴ 풀(pull)
					ㅡ 원격저장소의 내용을 내 로컬저장소에 업데이트하는것.
					ㅡ fetch와 다르게 원격으로부터 내용을 받아와 merge까지 자동으로 진행한다.
					ㅡ 하지만 충돌의 문제때문에 보통 fetch후, 수동으로 merge하는것이 권장된다고한다.

				ㄴ branch
					ㅡ 여러가지 독립된 작업을 수행하기위해 버전의 가지를 만드는것.
					ㅡ 후에 병합된다.
					ㅡ 가장 중심이되는 가지를 master가지라고 하며, 특정가시로 checkout하여 이동하지않는한, 모든작업은 이 master가지에서 진행된다.
					ㅡ 브랜치 종류)
						ㄴ 통합브랜치 : 언제든 배포가능한 상태인 버전을 말한다. 안정성이 중요하며 보통 master브랜치를 통합브랜치로서 사용한다.
						ㄴ 토픽 브랜치 : 기능추가나 버그수정같은 작업을 위한 브랜치로 작업을 완료하면 통합브랜치로 병합된다.
					ㅡ 브랜치 전환)
						ㄴ checkout 명령어를 사용하며, 전환되면 해당브랜치의 마지막 커밋내용이 출력된다.
						ㄴ stash???????????????
					*HEAD)
						ㅡ 현재 브랜치의 선두(가장 최신부분)부분을 의미하며, 기본적으로 master의 선두부분의미.
						ㅡ HEAD를 이동하면 브랜치를 변경할수있음.
						ㅡ HEAD ~3 => HEAD로부터 3세대 앞의 커밋을 가리킴

				ㄴ 병합(merge)
					ㅡ 내가 pull을 한뒤 다른사람에 의해 원격저장소가 업데이트되면, 이후 내가 하는 push는 거부된다. 원격저장소에서 다른변경점이 생겼기때문.
					이럴때 원격저장소의 내용을 내 로컬저장소에 갱신하는데 이를 병합이라함.

				ㄴ 충돌
					ㅡ 위의 병합의 경우를 예를들면, 갱신을 해줄때 같은부분에 변경점이있어 어느것으로 업데이트를해야할지 충돌이일어나는 상황을말함.
					ㅡ 이 충돌의 경우, 직접 그부분을 수정해주어야함.

				ㄴ git의 객체
					ㅡ 깃은 저장하는 데이터를 객체의 형식으로 저장하고관리한다.
					ㅡ 객체의 종류는 blob, tree, commit, tag이다.
					ㅡ blob(binary large object) 객체)
						ㄴ저장하는 파일에대한 객체로, 내용자체'만' 저장된다. 파일 이름이나 형식등은 저장되지않는다.
						ㄴ텍스트, 이미지,음악, 단순 이진파일등 다양한형식의 파일이 저장될수있다.
						ㄴ체크섬에서 앞두자리를뺀 38자리가 blob의 이름에 해당한다. 앞두자리는 blob파일이 속한 디렉토리의 이름이다.
					ㅡ tree객체)
						ㄴ 디렉토리를 담당하는 객체로, 현재디렉토리에 있는 blob객체, 하위 디렉토리의 tree객체를 담고있다.
						ㄴ
					ㅡcommit객체)
						ㄴ커밋 히스토리를 저장하는 객체이다.
						ㄴ현재 프로젝트의 최상위 tree객체, 이전 커밋객체, 누가언제 커밋하였는지에 대한 정보, 커밋메세지 등을 저장한다.
					ㅡtag 객체)
						ㄴ커밋에 태그를 달면 생성되는 태그정보에 관한 객체.
						ㄴ 일반태그는 커밋에대한 포인터로 동작하고, 주석태그는 작성자,이메일, 날짜, 메세지를 저장할수있다.

					ㅡ모든 객체는 객체 헤더와 내용으로 이루어져있다. 헤더는 객체의 종류와 크기르 나타내는 문자열, 내용은 각 객체타입별로
						담는 내용들.
					ㅡgit Alias라고 사용자정의 명령문 만들기같은게 ㅇ있다. 

				ㄴ 로그인 토큰 방식
					ㅡ 2020년부터 비밀번호를 사용한 로그인이 제한되고 토큰 방식을 이용해야 한다함.
					ㅡ 깃헙 로그인 후, settings > Developer settings > Personal access tokens 에서
						토큰을 생성해주고 git push등을 할때 원래 비번 입력하는 곳에 토큰을 입력해 주면 된다.
					ㅡ 토큰 생성시 여러 설정이 가능하고, 생성된 토큰을 따로 저장해 두어야 한다.
				ㄴ 기존 리포지토리 history 포함하여 새 리포지토리로 복사
					ㅡ git clone --mirror (*복사하려는 리포지토리 주소*)
					ㅡ 클론한 폴더에 생긴 .git파일명 변경
						mv (*생긴 리포지토리*).git .git
					ㅡ 복사하여 저장할 리포지토리 연결
						git remote set-url origin (*새 리포지토리 주소*)
					ㅡ 새 리포지토리에 push
						git push --mirror
				ㄴ fork 
					ㄴ 특정 리포지토리의 복제본을 본인의 리포지토리로 생성하는 것.
						원본 리포지토리와의 연결을 유지하여 변경사항을 받아오거나 pull request를 통해 원본 리포지토리에 업데이트 '제안' 가능. 
						복사했더라도 '내' 리포지토리이므로, 당연히 branch, 업데이트 등 모든 동작 가능. 
						ㄴ ??? 자동으로 원본 리포지토리와 연결이 되는건 아닌것같고, 
							복제한 내 리포지토리에서 remote로 원본리포지토리를 추가한 뒤 패치해오는식인듯. 
					ㄴ clone 과의 차이 
						ㄴ clone은 리포지토리를 로컬에 복사해오는 것. fork처럼 새 리포지토리를 생성하지 않음. 
						ㄴ 로컬에 복사된 리포지토리는 clone한 원본 리포지토리와 연결되어 있어 변경사항을 반영하려면 
							이 원본 리포지토리에 push 등을 해야함. 권한 없으면 당연 못하고. 
			</pre>
		</pre>

		Ajax<button>더보기</button>
		<pre>
			ㅡ 참조 : https://developer.mozilla.org/en-US/docs/Web/Guide/AJAX
			ㅡ 개요 )
				ㄴ Asynchronous JavaScript And XML
				ㄴ 간단히말해, XMLHttpRequest 객체를 사용하여 서버와 통신하는 것을 말한다.
				ㄴ 가장 두드러지는특징은 '비동기적'으로 통신하여 페이지를 refresh하는것없이 데이터를 서버와 주고받을 수 있다는점.
				ㄴ 개인적 생각 )
					ㄴ 그냥 서버하고 요청 응답 주고받는건데 form같은 일반적인 요청과 다르게 페이지 전체를 요청해서 다시 로드하는게 아닌
						일부 개발자가 원하는것만 따로 요청하는 방식인듯하다.
					ㄴ 페이지 전체를 요청해서 로드하는게 아니라는점에서 빠르고 자원낭비가 없는게 이점이라한다.
			ㅇ js의 XMLHttpRequest을 이용한 Ajax )
				ㅡ js로 Http request를 만들기 위해선 XMLHttpRequest 객체가 필요하며, 이는 원래 인터넷익스플로어의 XMLHttp라 불리는 ActiveX 객체에 의해 수행되던 기능이다. 이후 개발된게 XMLHttpRequest.
				ㅡ 기본 사용법 )
					ㅡ 우선 XMLHttpRequest객체를 생성해준다.
						ㄴ ex) httpRequest = new XMLHttpRequest();
					ㅡ request 이후에 XMLHttpRequest 객체에게 어떤 함수가 response를 받아처리할지 설정해주어야한다.
						ㄴ request객체의 onreadystatechange 프로퍼티에 함수의 참조를 할당함으로서 설정가능하다.
						ex)	httpRequest.onreadystatechange = function(){
								// Process the server response here.
							};
					ㅡ request객체의 open(), send()를 통해 실제 request를 생성할 수 있다.
						ㄴ open ( (*httpRequest의메소드*), (*url*), (*비동기인지 동기인지*) )
							ㄴ 세번째 인자는 옵션이고 디폴트값은 true로, 비동기임을 나타낸다.
								ex) httpRequest.open('GET', 'http://www.example.org/some.file', true);
									httpRequest.send();
						ㄴ send()
							ㄴ 인자에 서버에 보내고자하는 데이터를 넣으면된다.
							ㄴ 형식에 맞게 데이터를 넘겨야 한다. (name=~~~&~~~, 또는 json, xml 등)
							ㄴ ???POST형식으로 보내고자한다면 send()전에 MIME type을 설정해 주어야한다.
								ㄴex) httpRequest.setRequestHeader('Content-Type', 'application/x-www-form-urlencoded');
					ㅡ response를 처리할 함수
						ㄴ??? open()을 '비동기'로 설정했을때만 필요한 단계이다. '동기'일 경우 함수를 명시할 필요가 없다고한다.
						ㄴ 우선 request의 state를 확인해야한다.
							ㄴ request객체의 readyState 프로퍼티에 상태값이 들어있으며
							ㄴ 0(request not initialized), 1(server connection established), 2(request received), 3(processing request), 4(request is finished and response is ready)의 값을 가진다.
							ㄴ 금방 요청이 완료되긴하지만 시간이 걸리긴하므로, 바로 값을 확인하면 0~3이 뜰수도있다.
						ㄴ 이후 response의 state를 확인.
							ㄴ request객체의 status 프로퍼티에 값이들어있으며, http response의 status code와 일치한다(404, 200같은거)
						ㄴ 이후 서버로부터 받은 데이터로 원하는 작업을 할 수 있으며, 데이터를 받는 방식은 두가지이다.
							ㄴ request객체의 responseText : response를 string으로서 받는다.
							ㄴ request객체의 responseXML : response를 XMLDocument로서 받는다. js의 dom 함수로 다룰수있다.
				ㅡ 간단한 예제 <button>펼치기</button>
				<pre>
					< button id="ajaxButton" type="button">Make a request< /button>

					< script>
					(function() {
					var httpRequest;
					document.getElementById("ajaxButton").addEventListener('click', makeRequest);

					function makeRequest() {
						httpRequest = new XMLHttpRequest();

						if (!httpRequest) {
						alert('Giving up :( Cannot create an XMLHTTP instance');
						return false;
						}
						httpRequest.onreadystatechange = alertContents;
						httpRequest.open('GET', 'test.html');
						httpRequest.send();
					}

					function alertContents() {
						if (httpRequest.readyState === XMLHttpRequest.DONE) {
						if (httpRequest.status === 200) {
							alert(httpRequest.responseText);
						} else {
							alert('There was a problem with the request.');
						}
						}
					}
					})();
					< /script>
				</pre>

				ㅡ 예외 처리 ) 서버와의 통신간에 에러발생시 예외는 response를 받기로한 함수에게 전달된다. 해당함수안에 try~catch문 처리를 하는게 좋다.
				ㅡ responseXML로 받기 )
					ㄴ ex) 	var xmldoc = httpRequest.responseXML;
						var root_node = xmldoc.getElementsByTagName('root').item(0);	=>이와같이 DOM 메소드를 이용해 다룰 수있다.
						alert(root_node.firstChild.data);
				ㅡ XMLHttpRequest APIs)
					ㄴ 이 객체로 사용할 수 있는 다양한 api들에 대해 설명한다.
					ㄴ 참조 : https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest/Using_XMLHttpRequest
					ㄴ ...
			ㅡ Fetch API )
				ㄴ Ajax기술 중 하나이자 최신기술인 fetch api에 대해 배운다.
				ㄴ 참조 : https://developer.mozilla.org/en-US/docs/Web/API/Fetch_API
				ㄴ ...
		</pre>

		java<button>더보기</button>
		<pre>
			ㅇ Architecture <button>more</button>
			<pre>
				ㅡ ~~~
				ㅡ java api와 JVM의 조합을 '자바 플랫폼' 또는 '자바 runtime system'이라 부름.
				ㅡ java language
					ㄴ ??? 자바가 네트워크 특화되어 있긴 하지만 범용 언어이기도함.
					ㄴ

				ㅡ


				~~~
				ㅡ 자바 프로그램의 실행
					ㄴ 자바 프로그램은 다른 프로그램들이 os위에서 동작하는 것과 달리 JVM위에서 동작한다.
						ㄴ JVM이란 '자바 가상 머신'으로 os위에서 동작하는 소프트웨어이다. 이 위에서 자바 프로그램이 동작하는 것.
					ㄴ JVM을 사용하는 가장 큰 이유는 'os에 상관없이' 프로그램을 실행시키기 위함이다.
						ㄴ 일반적인 프로그램은 os에 따라서 구현을 달리해야 하기때문.
						ㄴ JVM을 사용하면 자바 프로그램은 똑같고 'os에 맞는 JVM'만 설치해두면 이 JVM위에서 똑같은 자바 프로그램을 실행시킬 수 있는 것.
					ㄴ 자바 컴파일러
						ㄴ 자바 소스코드를 '자바 컴파일러'가 JVM이 이해할 수 있는 '자바 바이트코드'로 변환해준다.
						ㄴ javac.exe 이란 실행파일이 자바 컴파일러이다.
					ㄴ 자바 런쳐
						ㄴ java.exe 라는 실행파일이 '자바 런쳐'이다.
						ㄴ JVM을 구동시키고, 그 위에서 자바 프로그램이 샐행되도록 돕는 프로그램이다.
					ㄴ 자바의 실행속도 )
						ㄴ JVM을 거치기때문에 속도가 느리지 않을까 생각이 되지만,
						ㄴ 오늘날 돌아가는 대부분의 프로그램에서는 이정도속도저하는 문제되지 않는다고 한다.

				ㅡ class loader
					ㄴ jvm의 subsystem
					ㄴ 두 종류 )
						ㄴ bootstrap class loader
							ㄴ jvm 구현체에 포함되는 class loader.
							ㄴ 로컬 디스크로부터 javaAPI 등의 클래스들을 디폴트로 로드해온다.
							ㄴ system class loader, default class loader라고도 불림.
						ㄴ user-defined class loader
							ㄴ 여러 방식으로(네트워크를 통해 클래스파일 다운 등) class들을 로드할 수 있는 class loader.
							ㄴ ??? 런타임시에 프로그램이 설치할 수 있다?
					ㄴ loading, linking, initialization의 기능을 한다함.
						ㄴ Loading )
							ㄴ 자바 컴파일러에 의해 생성된 .class파일을 로드한다.
								ㄴ .class 파일이란, 'java class file' 의미.
									자바 컴파일러에 의해 컴파일되어 JVM이 실행가능한 코드로 변환된 형태.
							ㄴ .class파일을 읽어 이에대한 바이너리 데이터를 만들고 JVM memory의 method area에 이를 저장한다고함.
							ㄴ 각각의 .class파일에 대해서
								ㄴ load된 class의 이름, 부모클래스
								ㄴ class나 인터페이스나 enum과 연관되엉있는지??
								ㄴ Modifier, Variables and Method information etc.
						ㄴ 로딩후, JVM은 이 클래스에 해당하는 Object 클래스를 만든다고함. (모든 클래스의 최상위 클래스라는 그 Object클래스말함)
							ㄴ JVM memory에서 heap 영역에 저장한다함.
							ㄴ 하나의 .class파일당 하나의 Object 클래스 생성.
						ㄴ Linking )
							ㄴ verification, preparation, 그리고 선택적으로 resolution을 수행하는단계
							ㄴ verification
								ㄴ .class파일이 적절하게 포메팅되었는지, 유효한 컴파일러에 의해 생긴파일인지 등을 확인
								ㄴ 문제가있을시, java.lang.VerifyError을 발생시킴.
							ㄴ Preparation : 클래스변수에 대한 메모리할당 및 초기화 과정
							ㄴ Resolution : ???
						ㄴ Initialization )
							ㄴ 스태틱 변수들  값 할당.
					ㄴ 자바에는 클래스로더라는게 잇어서 자바프로그램실행할때 모든 클래스들을 한꺼번에 로드해둘 필요가
						없다고한다. 필요할때 JRE가 클래스로더를 부르면 얘가 동적으로 JVM에 (더 정확히는 JVM메모리에) 로드해주는 방식.
					ㄴ 모든 클래스가 하나의 클래스로더에 의해 로드되는건 아니고 클래스 타입과 경로에따라 결정된다고한다.
						ㄴ getClassLoader()를 통해 해당클래스로더를 확인할 수있다.
					ㄴ 클래스 로더 종류 )
						ㄴ BootStrap ClassLoader : 가장 기본적인 클래스들을 로드하는 클래스로더. 자바 객체가 아닌
							기계어로 되어있고, 부모 클래스로더가없다.
							ㄴ /jre/lib/rt.jar에 있는 jvm실행을 위한 핵심클래스들을 로딩.
						ㄴ Extension ClassLoader : Bootstrap ClassLoader의 자식 클래스로더러, JDK extention 라이브러리
							클래스들을 로드한다.
						ㄴ System ClassLoader : Application ClassLoader라고도 한다. Extention ClassLoader의 자식 클래스
							로더이고, application class path에 있는 클래스를 로드한다.
					ㄴ Delegation - Hierarchy
						ㄴ JVM은 클래스를 로드할 때, 위임 상속 원칙을 따른다고함.
						ㄴ 맨 아래의 application 클래스로더가 로드 요청을 받으면 이를 상위에있는 extension 클래스 로더한테 요청을 전달하는 방식.
						ㄴ 이렇게 맨꼭대기의bootstrap클래스 로더까지 올라간 뒤, 요청을 처리하기 시작한다.
						ㄴ 그리고 bootstrap클래스로더에서 클래스를 찾으면 이 클래스로더가 로드를 하고
						ㄴ 못찾으면 아래로 내려가면서 찾는다.
				ㅡ JVM memory
					ㄴ method area, heap, stack, PC Register, native method stack으로 이루어져 있다.
				ㅡ 실행 엔진
					ㄴ JIT 컴파일러
				ㅡ 가비지 컬렉터
			</pre>

			ㅇ 변수<button>more</button>
			<pre>
				ㄴ '변수'를 '선언'하면 메모리에 공간이 '할당'된다.
				ㄴ 변수에 값을 '저장'하면 메모리에 그 값이 '저장'된다.
				ㄴ 원시 타입. primitive data type )
					ㄴ 자바 언어에서 사전 정의되어 잇으며, 해당하는 특별한 키워드가 예약되어 있다.
					ㄴ boolean
						ㄴ 1바이트. true 또는 false만 가짐.
						ㄴ 디폴트 false.
					ㄴ char : 2바이트. 모든 유니코드 문자.
						ㄴ 16진수로 된 유니코드가 저장된다.
						ㄴ 디폴트 "0"
					ㄴ byte
						ㄴ 1바이트(8비트). -128~127 (-2^7~2^7-1)
						ㄴ ??? 메모리의 저장이 중요한 경우, 큰 크기의 배열을 저장할 때 유용하거나,
							명시적인 값 범위의 제한을 보여줄 수 있어 int의 대용으로 사용된다.
						ㄴ 디폴트 0
					ㄴ short
						ㄴ 2바이트. -32768 ~ 32767 (-2^15 ~ 2^15-1)
						ㄴ byte와 유사한 경우에 유용하다.
						ㄴ 디폴트 0
					ㄴ int
						ㄴ 4바이트. -2^31 ~ 2^31-1
						ㄴ unsigned로 0 ~ 2^32-1 까지 표현 가능.
							ㄴ ??? 근데 이거 쓸거면 Integer class 사용하라함. ?
						ㄴ 디폴트 0
					ㄴ long
						ㄴ 8바이트. -2^63 ~ 2^63-1
						ㄴ int와 마찬가지 unsigned 사용 가능. 기능 동일.
						ㄴ 디폴트 0L
					ㄴ float
						ㄴ 4바이트.
						ㄴ 정확성을 요하는 데이터에 사용하지 마라. 이런 경우, java.math.BigDecimal을 사용하라.
						ㄴ 디폴트 0.0f
					ㄴ double
						ㄴ 8바이트.
						ㄴ 디폴트 0.0d
				ㄴ String
					ㄴ 문자열을 나타내는 기본 객체.
					ㄴ immutable.
						ㄴ 한번 초기화되면 값이 바뀌지 않음.
					ㄴ 디폴트 null.
				ㄴ 변수의 디폴트값
					ㄴ 선언만 하고 초기화하지 않을 경우, 컴파일러가 자동으로 디폴트값을 넣어주기는 한다.
					ㄴ 지역변수인 원시 타입의 경우, 컴파일러가 자동으로 초기화하지 않음.
				ㄴ 상수, literal )
					ㄴ ex ) 123, "c", true
					ㄴ 그냥 소스코드상에 표현되는 고정된 값을 의미.
					ㄴ 변수의 값과 마찬가지로 똑같이 자료형을 기반으로 메모리에 저장이 된다.
					ㄴ 단, 이름이 없으므로 이 저장된 값, 즉, '상수'에 접근할 수 없다. 따라서 변경도 불가하다.
					ㄴ 자바의 상수의 디폴트 자료형 )
						ㄴ 자바의 경우, 상수들의 디폴트 자료형이 미리 정해져있다. 상수값의 크기나 형태에 따라 자동으로 맞는 자료형을 설정해주지 않는다.
						ㄴ 따라서, 상수를 디폴트 자료형이 아닌 특정한 원하는 자료형으로 사용하고싶으면 '접미사'를 이용하여 명시적으로 선언해주어야 한다.
							ㄴ long num = 10000000000000; 	//'정수' 상수의 디폴트 자료형은 int이므로, 상수 10000000000000는 int형 자료형에
																저장된다. 근데 보다시피 int형의 범위를 넘어서므로 오류가 발생한다.
						ㄴ 상수의 디폴트 자료형 )
							ㄴ 정수 : int형
							ㄴ 실수 : double형
						ㄴ 접미사 )
							ㄴ F : float형	ex) 12.23F
							ㄴ L : long형	ex)  100000000000000L
						ㄴ 예외 )
							ㄴ byte, short형에 대해서는 상수 자료형을 명시하는 접미사가 없다. 디폴트가 int이기때문에 굳이 더 작은크기의 상수 자료형을
								사용할 일이 없기때문에. 거기다가 byte, short형에 대해서는 int형 상수를 이용한 초기화도 가능하게 해두었다.
					ㄴ 정수 상수
						ㄴ 디폴트는 int. long형 상수를 위해선 숫자 위에 'L' 또는 'l'을 붙여야함. ex ) 100000000000000L
						ㄴ 숫자체계 십진법, 16진법, 2진법을 표현 가능.
							ㄴ 16진법 : 앞에 '0x' 붙여 표현. ex ) int a = 0x1a;
							ㄴ 2진법 : 앞에 '0b' 붙여 표현. ex ) int a = 0b110;
					ㄴ floating point 상수
						ㄴ 숫자 뒤에 'F', 'f'를 붙여 float 상수, 'D', 'd'를 붙여 double 상수 사용 가능.
					ㄴ 문자, 문자열 상수
						ㄴ
					ㄴ null literal
						ㄴ 어떠한 참조 타입에 할당 가능한 상수값. 원시타입에는 안됨.
					ㄴ class literal
						ㄴ 타입명 + ".class"
						ㄴ ex ) String.class
						ㄴ
				ㄴ 배열 )
					ㄴ 자바에서 배열도 인스턴스이고 참조변수를 통해 접근된다.
					ㄴ length라는 변수를 가지고있다.
					ㄴ 생성과 초기화
						int[] arrr = new int[3];
						arr[0] = 1;
						arr[1] = 2;
						arr[2] = 3;

						int[] arr = new int[] {1,2,3};

						int[] arr = {1,2,3};
					ㄴ for-each문 )
						ㄴ for ( (*각 요소를 나타낼 변수*) : (*반복의대상*) ){ ~~~ }	//(*각 요소를 나타낼 변수*)는 (*반복대상*)안의요소와 자료형이
																				일치해야 한다.
							ㄴ ex)	for( int e : arr ){System.out.println( e );}	//arr의 모든 요소에 대해 반복, 각 반복마다 요소는 e로 접근가능.
					ㄴ 복사
						ㄴ System class의 다음 메소드 사용.
							public static void arraycopy(Object src, int srcPos, Object dest, int destPos, int length)
						ㄴ 또는 java.util.Arrays의 copyOfRange()
				* 이진수, 십진수 소수점 변환 방법
					ㅡ 십진수 -> 이진수 소수점 변환 )
						ㄴ 소수점 부분을 *2를 한다. 그리고 그 결과값의 '소수점 부분'을 다시 *2를 한다. 이를 반복한다.
						ㄴ 결과값이 1.0이 나오거나 맨 처음 *2했을때의 값이 똑같이나오면 멈추고 여태까지의 결과값들의 소수점이 아닌부분을 순서대로 써주면
							그게 이진수 소수변환된것.
						ㄴ ex)
							8.25에서 0.25를 이진수 소수점 변환한다하면,
							0.25 * 2 = 0.5	=>1.0이 아니므로 결과값의 소수점부분*2.
							0.5 * 2 = 1.0	=>1.0이므로 반복멈추고 결과값들의 소수점이 아닌부분들을 나열. '01'이고, 그러면 8.25의 이진수 변환은
												1000.01
							ㄴ *2한 결과값이 1.0이 나와도 저렇게 멈추지만 '맨처음 *2했을때의 결과값' 즉, 0.5가 다시한번 나와도 반복을 멈춘다.
					ㅡ 이진수-> 십진수 소수점 변환 )
						ㄴ 소수점 부분을 '2의 역' 즉 2^(-n)을 대입해주면된다.
						ㄴ ex)
							1000.01을 십진수 소수점 변환한다하면,
							0.01부분에서 소수점 첫번째자리는 2^(-1), 소수점 두번째자리는 2^(-2) ..... 이렇게 계산해주면된다.
							따라서, 0*2^(-1) + 1*2^(-2) = 0.25
			</pre>

			ㅇ 연산자 <button>more</button>
			<pre>
				ㅡ 우선순위
					ㄴ x++, x--
					ㄴ ++x, --x, +x, -x, ~, !
					ㄴ *, /, %
					ㄴ + -
					ㄴ << >> >>>
					ㄴ < > <= >= instanceof
					ㄴ == !=
					ㄴ &
					ㄴ ^
					ㄴ |
					ㄴ &&
					ㄴ ||
					ㄴ ? :
					ㄴ = += -= *= /= %= &= ^= |= <<= >>= >>>=
				ㅡ ~~~
				ㅡ SCE(short-circuit evaluation) 방식.
					ㄴ ex ) (1 < 0) && (1 > 0)
					ㄴ 위와 같은 표현식에 대한 참거짓 판단시 앞부분이 false이면 뒷부분 평가하지 않고 결과를 false로 결정하는 방식.
						당연히 성능 더 빠름.
				ㅡ instanceof
					ㄴ ex )
						Parent parent = new Parent();
						Child child = new Child();

						child instanceof Parent
					ㄴ 특정 객체가 어떤 클래스(타입)의 객체인지, 어떤 클래스의 하위 클래스의 객체인지, 어떤 인스턴스를 구현하는 객체인지 확인하여
						bool값 반환.
				ㅡ 형변환 연산 )
					ㄴ 값 앞에 '명시적 형 변환'을 통해 값의 자료형을 변환할 수 있다.
					ㄴ ex) int num=(int)3.14	//double형 실수상수 3.14가 '명시적 형 변환'에 의해 int로 변경되었다.
					ㄴ 실수형에서 정수형 변환시 소수점이 잘려나간다.
					ㄴ 정수형끼리 큰 자료형에서 작은 자료형으로 변환을 하면 상위 바이트가 잘려나간다.
					ㄴ '변환대상 값'을 '변경'하는게 아니라 '변환대상 값'을 형변환한 결과값을 '반환'한다.
				ㅡ Bitwise and Bit Shift 연산
					ㄴ & : 비트단위로 AND연산
					ㄴ | : 비트단위로 OR연산
					ㄴ ^ : 비트단위로 XOR연산 (두 비트값이 다르면 1, 다르면 0)
					ㄴ ~ : 모든 비트 반전.
					ㄴ << : 비트열 왼쪽으로 이동. 생기는 빈공간은 0으로 채움. 2배수 곱셈하는셈.
					ㄴ >> : 비트열 오른쪽으로 이동. 생기는 빈공간은 음수의 경우1, 양수의 경우0으로 채움. 2배수 나눗셈하는 셈.
					ㄴ >>> : 비트열 오른쪽으로 이동. 생기는 빈공간은 0으로 채움
			</pre>

			ㅇ classpath, 패키지
				ㄴ package
					ㄴ 관련있는 type(class, interface, annotaion, enumeration 등)끼리 묶은 것.
					ㄴ 이름 충돌, 탐색 및 사용의 편의, 접근 제어 등의 목적.
					ㄴ java.lang, java.io 등의 java platform의 기본적 패키지 존재.
					ㄴ 사용자가 임의로 만들 수 있음.
					ㄴ package 선언
						ㄴ ex ) package com.example.deepq
						ㄴ 한 소스파일당 단 하나의 package 선언 가능.
						ㄴ 소스파일 맨 위에 선언.
						ㄴ 한 소스 파일에는 단 하나의 public인 type만 존재할 수 있으며, 이 type은 소스파일명과 동일해야 한다.
							ㄴ ex ) NoName.java에는 public class NoName 또는 public interface Noname 등만 올 수 있음.
							ㄴ 즉, 소스파일명과 동일한 이름의 public 선언된 type이 반드시 하나 있어야함.
							ㄴ 이 public type이 외부에서 접근 가능해짐.
					ㄴ 패키지 내의 public 멤버 사용하려면 다음 중 하나 수행.
						ㄴ fully qualified name과 함께 패키지 멤버 명시
							ㄴ ex ) graphics.Rectangle r = new graphics.Rectangle();
						ㄴ 패키지 멤버 import
							ㄴ ex ) import graphics.Rectangle;
						ㄴ 패키지 전체 import
							ㄴ ex ) import graphics.*;
					ㄴ 패기지 계층
						ㄴ 상위 패키지명이 같다고 하위 패키지들이 그 상위패키지 안에 모두 포함되는게 아니다.
							패키지간 관계를 명확히하기 위해서 이름을 그렇게 붙였을 뿐.
					ㄴ 다른 패키지에 속한 같은 이름의 type을 모두 import하여 사용시, qualified name을 사용해야한다.
					ㄴ 'import static ~~~' 와 같이 static import를 하여 패키지의 static 멤버들만 import해와 클래스명 없이 사용할 수 있다.
						ㄴ ex ) import static java.lang.Math.PI;
					ㄴ .java파일을 컴파일한 .class파일들도 .java파일과 마찬가지로 패키지 구조대로 디렉토리 구조를 가져야한다.
						컴파일러나 jvm이 classpath에서 클래스파일을 찾을때 이 패키지 구조대로 찾는다.

			ㅇ 표현식(expressions), 문장(statements), 블록(blocks)
				ㅡ 표현식
					ㄴ 하나의 값을 평가하는, 문법에 따라 작성된 변수, 연산자, 메소드 호출로 구성된 구성 일부.
					ㄴ ex )
						int cadence = 0;  // cadence = 0
						anArray[0] = 100;  // anArray[0] = 100
						System.out.println("Element 1 at index 0: " + anArray[0]);  // "Element 1 at index 0: " + anArray[0]

						int result = 1 + 2; // result is now 3
						if (value1 == value2)  // value1 == value2
							System.out.println("value1 == value2");
				ㅡ 문장
					ㄴ 그냥 코드에서 한 줄의 문장을 말함.
					ㄴ
				ㅡ 블럭

			ㅇ 클래스 <button>펼치기</button>
			<pre>
				ㅡ 클래스 )
					ㄴ 클래스형 변수는 '참조변수'이다.
				ㅡ 접근 제어 지시자 )
					ㄴ 디폴트 선언 )
						ㄴ 접근제어 지시자를 선언하지 않는 경우에 해당하며, 동일 패키지 내에서의 접근을 허용한다.
				ㅡ 캡슐화 )
					ㄴ 여러 기능이 모여 '하나의 목적'을 달성하는 것. 캡슐화가 되어있다 라고 한다.
					ㄴ 관련있는 데이터나 함수를 묶어주는 것, 높은 응집도, 낮은 결합도, 모듈화.
					ㄴ 정답이 없으며 잘정의해야 한다.
				ㅡ static 변수, static 메소드 )
					ㄴ static 변수 )
						ㄴ 변수가 선언된 클래스의 '모든 인스턴스'가 공유하는 변수. '클래스 변수'라고도 한다.
						ㄴ '접근제어지시자'만 적절하다면, 인스턴스뿐만 아니라 클래스 이름을 통해서도 접근이 가능하다.
							ㄴ ex) (*클래스 이름*).(*static변수이름*)
						ㄴ JVM에 의해 클래스가 '클래스로더'에 의해 '초기화'되고 나면 인스턴스의 생성과 관계없이 사용할 수 있다.
						ㄴ 상속된 하위클래스들 사이에서도 공유된다.
					* class가 초기화 되는 시점
						ㅡ 해당 클래스의 인스턴스가 생성될때,
						ㅡ 해당 클래스의 static 메소드가 호출될때
						ㅡ 해당 클래스의 static 변수에 값이 할당될때
						ㅡ 해당클래스의 constant가 아닌 static변수가 사용될때
					ㄴ static 메소드 )
						ㄴ static변수와 마찬가지로, 인스턴스 생성없이도 static 메소드를 호출 할 수 있다. '클래스 메소드'라고도 한다.
						ㄴ 기능상 당연히 '인스턴스 변수'에 접근이 불가능하다.
					ㄴ 인스턴스 메소드처럼 런타임시에 다형성에 의해 동적으로 결정되는 것이 아니라, 컴파일시에 클래스에 기반하여 결정되기 때문에
						'static'(정적인) 이라 부른다.
				ㅡ 메소드 오버로딩 )
					ㄴ overload : 너무 많이주다, 과적하다. / 같은 이름의 메소드를 너무 많이 정의한다는 의미로 기억하자.
					ㄴ 자바에서 '동일한 이름'의 메소드를 여러개 정의할 수 있게해주는 기능.
					ㄴ 이름과 반환형을 동일하게 두고, '매개변수'의 개수, 자료형, 순서를 다르게 함으로써 이름은 같으나 매개변수에 따라 그에맞는 메소드가 호출되게 할 수 있다.
						ㄴ 반환형은 호출문으로 구분이 안되므로 오버로딩 조건에 포함안됨.
				ㅡ 생성자 )
					ㄴ ~~~
					ㄴ 기본적으론 명시적 호출 불가.
						생성자 내에선, 다른 생성자 명시적 호출 가능. (물론, 'this'키워드 사용)
				ㅡ 값에 의한 참조, 참조에 의한 참조
					ㄴ 전자는 값이 넘어오는 것.
					ㄴ 후자는 참조값이 넘어오는 것.
						ㄴ 참조값이 넘어오는 것이지 변수 자체가 넘어오는 것이 아니다. 매개변수에 참조값이 들어있을 뿐.
							매개변수에 다른 값을 할당해도 매개변수 안에 들은 참조값이 바뀔뿐이지 호출한 곳에서 참조값이 바뀌지 않는다.
				ㅡ String )
					ㄴ 자바에서 문자열을 나타내는 클래스.
					ㄴ 큰 따옴표 (" ")만으로 인스턴스의 생성이 가능하다. ex) "hello"	=>hello라는 문자열을 가진 String 인스턴스가 생성됨.
					ㄴ 한번 문자열이 저장되어 인스턴스화가 되면 문자열의 내용은 절대 변경이 불가능하다.
					ㄴ 문자열의 '내용'이 같으면 새로운 String인스턴스를 생성하지 않고 기존에 있던 인스턴스를 사용한다.
						ㄴ ex)	String str1="hello";
							String str2="hello"; 	//str1, str2는 같은 String인스턴스를 참조한다.
						ㄴ 이유는 인스턴스의 생성은 연산상 시스템에 부담이 되는 작업이기때문에 이를 최소화하기 위해서라고 한다.
						ㄴ 또한 이렇게 같은 인스턴스를 참조하게 하면, 인스턴스의 내용이 변경되었을때 같은걸 참조하는 참조변수들의 내용도 바뀌기때문에
							이를 방지하기위하여 String은 한번 정해진 문자열 내용을 변경할 수 없게 해두었다고함.
						ㄴ new String() 생성자를 통해 String인스턴스를 생성할 경우, 내용이 같더라도 새로운 인스턴스를 생성 할 수 있다.
							ㄴ ex)	String str1="hello";
								String str2="hello";
								String str3=new String("hello");	//str1, str2와는 다른 참조값을 가진다.
					ㄴ 유용한 메소드들 )
						ㄴ int length() : 문자열 길이 반환
						ㄴ String concat(String str) : str을 뒤에 이어붙여 새로운 String반환
						ㄴ int compareTo(String str) : 두 문자열 비교. 동일하면 0반환, 아니면 ~~~~~~~~~~~
						ㄴ public static String valueOf( (*다른 자료형의 값*) ) : 인자로 int, float, boolean 등의 다른 자료형이 넘어오면
							해당 값을 문자열로 변환하여 반환.
				ㅡ 배열 )
					ㄴ 자바에서 배열도 인스턴스이고 참조변수를 통해 접근된다.
					ㄴ length라는 변수를 가지고있다.
					ㄴ 생성과 초기화
						int[] arr = new int[] {1,2,3}; 또는
						int[] arr = {1,2,3};
					ㄴ for-each문 )
						ㄴ for ( (*각 요소를 나타낼 변수*) : (*반복의대상*) ){ ~~~ }	//(*각 요소를 나타낼 변수*)는 (*반복대상*)안의요소와 자료형이
																				일치해야 한다.
							ㄴ ex)	for( int e : arr ){System.out.println( e );}	//arr의 모든 요소에 대해 반복, 각 반복마다 요소는 e로 접근가능.
				ㅡ 상속 )
					ㄴ 부모 클래스의 멤버변수와 멤버메소드를 자식클래스도 가지도록하는 기능.
					ㄴ 코드의 재사용성과 다형성을 지원한다.
						* 다형성이란?
							ㅡ 하나의 형태로 여러가지 기능을 할 수 있는 것을 말한다.
								ㄴ 가령, 인터페이스 A를 구현한 클래스 B,C가 있으면, B,C는 A타입의 변수만을 이용하여 나타낼 수 있다. 이렇게 하나의 타입으로
									여러가지 객체를 나타낼 수 있거나
								ㄴ 메소드 오버로딩, 오버라이딩과 같이 하나의 함수 이름으로 여러가지 기능을 할 수 있는 것도 다형성이라 한다.
							ㅡ 자바와 같은 객체지향 언어의 특징 중 하나이다.
							ㅡ 장점 )
								ㄴ 하나의 형태로 여러가지 기능을 할수 있기때문에 유지보수에 좋다.
								ㄴ 확장성이 좋은 코드를 작성하는데 좋다.
								ㄴ 결합도를 낮춘다.
					ㄴ 'IS - A'관계가 성립되어야 상속을 사용하는것이 적절하다.
						ㄴ 'HAS - A'관계도 가능이야 하겠지만 다른방식으로 표현하는게 더 효율적이다. (멤버변수로 인스턴스를 가지게 한다든지)
					ㄴ 상위클래스의 생성자 호출 )
						ㄴ super()를 사용. 하위클래스에서 super()이 곧 상위클래스의 생성자를 호출하는 키워드이다.
						ㄴ 반드시 하위클래스의 생성자 안에서 상위클래스의 생성자를 호출해 주어야 하며, 명시적으로 호출하지 않을경우, 자동적으로 상위클래스의 디폴트 생성자
							호출을 위해 super()가 삽입된다.
					ㄴ 컴파일러의 참조변수 인식 )
						ㄴ 컴파일러는 인스턴스가 들은 참조변수를 볼때, 그 안에들은 '인스턴스'를 기준으로 보는 것이 아니라 참조변수의 '자료형'만을 기준으로 바라본다.
						ㄴ ex)
							class Parrent{

							}
							class Child extends Parrent{
								void aaa(){~~~}
							}
							일때,
							Parrent p = new Child();
							p.aaa(); 	//컴파일 오류가 발생한다. p는 Parrent형이고, 컴파일러는 참조변수에 실제 들어있는 인스턴스 Child가 아니라
								자료형Parrent를 기준으로 참조변수를 인식하고 Parrent에는 aaa()가 정의되어있지 않기때문에 없는 메소드를 호출하였다하여 오류발생.
						ㄴ 단, '오바라이딩'된 메소드를 호출하는 경우는 참조변수의 자료형에 상관없이 가장 마지막으로 '오버라이딩'된 메소드만 호출한다.
					ㄴ 메소드 오버라이딩 )
						ㄴ override : 우선하다, 기각하다 / 상위클래스의 메소드를 무시하고 하위클래스의 메소드를 우선한다는 의미로 기억하자.
						ㄴ 상위 클래스의 메소드와 이름, 반환형, 매개변수형태가 동일한 '완전히 똑같은 메소드'를 하위클래스에서 정의하면, 해당 메소드 호출시
							상위클래스 메소드가 무시되고 하위클래스의 메소드가 호출되는것을 말함. 이를 메소드 '오버라이딩'되었다고 한다.
						ㄴ 오버라이딩한 하위클래스 메소드에서 'super()'를 사용하여 상위클래스의 오버라이딩된 메소드를 호출 할 수 있다.
						ㄴ 참조변수의 자료형과 상관없이 오버라이딩된 메소드는 호출되면 항상 가장 마지막으로 오버라이딩된 메소드가 호출된다.
						ㄴ '접근 제어 지시자'의 범위를 줄이면서는 오버라이딩을 할 수 없다. (가령, protected범위였던 메소드를 오버라이딩하면서 private로 바꾸지는 못함)
						ㄴ final 키워드 )
							ㄴ 메소드앞에 'final'키워드를 붙이면 이 메소드의 오버라이딩을 허용하지 않는다는 의미.
							ㄴ ex) final void aaa(){~~~}
					ㄴ instanceof() : '상속관계'를 바탕으로 '형변환'이 가능한지 묻는 연산자. 가능하면 true, 아니면 false.
						ㄴ ex) box instanceof GoldPaperBox //참조변수 box가 GoldPaperBox형으로 형변환이 가능한지 판별. 가능하면 true,아니면false.
					ㄴ final 키워드 )
						ㄴ 클래스 선언 앞에 'final'키워드를 붙이면, 이 클래스는 상속이 불가하다 라는 의미가된다.
						ㄴ ex)	final class MyClass{~~~}
				ㅡ Object 클래스 )
					ㄴ 자바의 모든 클래스들은 직간접적으로 Object클래스를 상속하게 된다.
						ㄴ 아무런 상위클래스가 없으면 Object를 상속하게 된다.
					ㄴ toString()
						ㄴ Object클래스의 메소드.
						ㄴ 값을 문자열로 변환해 반환하는 메소드이다.
						ㄴ println()안에 인자로 전달되면 인자의 toString()이 자동적으로 호출되면서 이를 출력하게 되므로, toString()을 오버라이딩하여 원하는
							형식으로 객체가 출력되도록하는게 좋다.
					ㄴ public boolean equals( Object obj )
						ㄴ 참조값이 같은지를 확인해주는 메소드.
						ㄴ 허나, 일반적으로는 '오버라이딩'하여 사용한다.
						ㄴ String 같은 표준클래스들에서 이미 이를 오버라이딩한 경우가 있다. (String의 equals()는 문자열을 비교해 같은지 확인함)
					ㄴ protected Object clone() throws CloneNotSupportedException
						ㄴ 현재 인스턴스를 복사하고 그 참조값을 반환한다.
						ㄴ Cloneable 인터페이스를 구현한 클래스만이 사용가능한 메소드이다.
							ㄴ Cloneable 인터페이스 : 아무런 기능없이 텅 빈 인터페이스. 인스턴스의 복사는 경우에따라서 조심해야할 동작이기때문에 이를 구현함으로서
								'표시'기능을 하는것.
						ㄴ 현재 인스턴스 내부에 있는 '값'들을 복사할 뿐, 그 '값'이 참조하고있는 대상까지 복사하지는 않는다.
							ㄴ 즉, 내부에 인스턴스 변수가 있을 경우, 그 참조값을 그냥 복사할 뿐이지 참조의 대상인 인스턴스까지 복사하지는 않는다. 따라서 복사된
								인스턴스와 원래의 인스턴스가 같은 참조값을 가질 수 있다는 것. 이를 '얕은 복사'라고 한다.
							ㄴ 참조의 대상까지 복사를 하여 인스턴스를 복사하려면(이를 '깊은 복사'라고 한다) clone()을 오버라이딩하여야 한다.
				ㅡ abstract )
					ㄴ abstract 클래스 )
						ㄴ 클래스 앞에 'abstract' 키워드를 붙여서 해당 클래스가 인스턴스 생성을 못하게 설정 할 수 있다. 이를 '추상 클래스'라 한다.
						ㄴ 보통 상속을 위해 직접 인스턴스화할일이 없는 상위클래스에 부여한다.
						ㄴ 인스턴스화가 불가하다는 점을 제외하고는 일반 클래스와 모든점이 같다.
					ㄴ abstract 메소드 )
						ㄴ 메소드의 몸체를 구현하지 않고 앞에 abstract 키워드를 붙이면 '추상 메소드'가 된다.
						ㄴ 추상메소드는 호출될수 없으며, 보통 하위 클래스에서 오버라이딩을 하기위해 미리 선언해두는 용도로 사용한다.
						ㄴ 하위클래스에서는 '추상메소드'를 오버라이딩하지 않으면 여전히 추상메소드를 포함하고있는것이기때문에 추상클래스가 되거나 추상메소드를
							오버라이딩해야한다.
						ㄴ 추상메소드가 존재하는 클래스는 'abstract'키워드를 붙여 '추상 클래스'로 만들어야 한다.
				ㅡ 인터페이스, Interface )
					ㄴ 비유하자면, 모든 메소드가 abstract인 추상 클래스와 유사하다고 보면된다.
						ㄴ 인터페이스를 구현하는 클래스는 인터페이스의 추상 메소드를 구현하거나 abstract class로 선언되어야 한다.
					ㄴ 일반적으로 구조, 틀, 형식같은것을 미리 정해두고 이에따라 개발을 하고 싶을때 사용한다.
					ㄴ 특징 )
						ㄴ 인터페이스 내에 존재하는 모든 멤버변수가 무조건 public static final로 선언되며
						ㄴ 인터페이스 내에 존재하는 모든 멤버메소드가 무조건 public abstract로 선언된다.
						ㄴ 근데 보통 명시적으로 써준다함.
					ㄴ 인터페이스도 참조변수의 '자료형'으로 사용이 가능하다.
					ㄴ 인터페이스 내의 메소드 호출시, 해당 메소드의 '오버라이딩' 내용이 적용된다.
					ㄴ 일반적으로 인터페이스는 public으로 선언하여 사용한다.
				ㅡ abstract 클래스 vs interface )
					ㄴ 유사해 보이지만, 추상클래스는 클래스이므로 상속 개념 안에서 쓰이고
						인터페이스는 단순히 특정 기능의 구현을 강제하기 위하여 쓰인다.
				ㅡ Inner 클래스 )
					ㄴ 클래스 안에 정의한 클래스를 말한다.
						ㄴ ex)
								class AAA{
									~~~
									class BBB{ ~~~ }
								}
					ㄴ 바깥쪽 클래스를 'outer class', 안쪽 클래스를 'inner class'라고 부른다.
					ㄴ inner class는 outer class의 멤버이기 때문에 outer class의 멤버들에 모두 접근 가능(접근제어자가 무엇이든)
					ㄴ inner class 자체에 접근하려면 outer class의 멤버이므로 outer class 객체를 하나 만들고 이 객체를 통하여 접근해야함.
						ㄴ ex )
							Outer outer = new Outer();
							Outer.Inner inner = outer.new Inner();
					ㄴ inner class에도 접근제어자 설정 가능.
						ㄴ 위 예시처럼 inner class 직접 사용이나 inner class 객체의 멤버들에 대한 접근에 적용되는 듯.
						ㄴ ex )
							class Outer{
								private Inner{
									public String name = "inner";
								}
								public Inner inner;
								Outer(){this.inner = new Inner();}
							}
							~~~
							Outer outer = new Outer();
							Outer.Inner inner = outer.new Inner();  // 좌변 'Outer.Inner'과 우변 new Inner()부분에 컴파일 에러.
							System.out.println(outer.inner);  // outer 객체 안에 들은 inner객체 사용. inner멤버변수는 public이라 문제없음.
							// outer객체 안에 들은 inner객체의 멤버에 접근시 오류. Inner class가 private라서.
							System.out.println(outer.inner.name);
					ㄴ inner class가 static 클래스로 선언되었을 경우 이를 'Nested class'라고 부른다.
					ㄴ 이점 )
						ㄴ 클래스들을 논리적으로 묶을 수 있다.
						ㄴ 따라서 가독성이 좋아지고
						ㄴ 캡슐화에 용이하다.
					ㄴ static nested class
						ㄴ static으로 선언된 inner class를 'static nested class'라 부름.
						ㄴ static 변수처럼, static nested class는 인스턴스 멤버에 접근 불가.
				ㅡ Local 클래스 )
					ㄴ 메소드 내에서 정의가 되고, 그 메소드 내에서만 '인스턴스의 생성'과 '참조변수의 선언'이 가능하다.
					ㄴ 일반적인 쓰임 )
						ㄴ 보통 인터페이스를 하나만들고 local class가 이 인터페이스를 구현하게 하고 local class를 생성하여 메소드에서 반환함으로서
							외부에서 local class를 참조할 수 있게한다.
						ㄴ ex)
							// 반환형을 인터페이스A로 하여 local class가 메소드에서 반환되면 이를 참조할 수 있게한다.
							public (*인터페이스A*) create~~~(){
								class LocalClass extends (*인터페이스A*) {	//local class가 인터페이스A를 구현하게한다.
									~~~
								}
								return new LocalClass();
							}
					ㄴ ~~~~~~~~~~~~~~~~~~~~~~~~~
				ㅡ 익명 클래스 )
					ㄴ ~~~~~~~~~~~~~~~~~~~~~~~~~
				ㅡ 예외 처리 )
					ㄴ try~catch문을 사용한다.
					ㄴ ex)
						try{
							~~~
						}
						catch(~~~){	//우선 확인할 예외.
							~~~
						}
						catch(~~~){	//위에 catch에 해당이 안되면 다음 catch.
							~~~
						}
						...
						finally{	//예외발생 여부와 상관없이 항상 마지막에 실행되는 영역.
							~~~
						}
					ㄴ throw 명령어 : 예외를 발생시키는 명령어. 해당 예외를 던진다.
						ㄴ ex)	throw (*예외객체*);
					ㄴ throws )
						ㄴ 메소드 선언 뒤에 적는 키워드.
						ㄴ 해당 메소드에서 특정 예외가 발생하면 이를 해당 메소드를 호출한 영역으로 던질것임을 나타낸다.
						ㄴ public static int readAge() throws AgeInputException { ~~~ }
					ㄴ 예외상황이 현재 예외가 발생한 메소드 내에서 처리되지 않으면 메소드를 호출한 영역으로 예외의 처리가 넘어감.
					ㄴ main메소드까지 예외가 넘어가고 main에서도 예외를 넘기면 main()을 호출한 JVM이 예외를 넘겨받게된다.
						ㄴ JVM은 다음의 과정으로 예외를 처리한다.
							1.예외의 getMessage()를 호출하고, 2.예외상황이 발생하여 전달되는 모든 과정을 출력하고, 3.프로그램을 종료한다.
					ㄴ Throwable클래스의 pringStackTrace() )
						ㄴ JVM처럼 예외의 getMessage()를 호출하여 출력해주고 예외상황이 발생하여 전달되는 모든 과정을 출력해준다.
					ㄴ 예외 클래스들 )
						ㄴ 예외 클래스의 계층 구조 )
							Throwable
								ㄴ Exception
									ㄴ 우리가 사용하는 대부분의 예외가 여기에 속한다.
									ㄴ ex) IOException, RuntimeException 등등..
								ㄴ Error
									ㄴ 심각한 오류상황을 표현하기위해 쓰이는 클래스.
									ㄴ 개발자가 정의하는것이 아니다.
				ㅡ JVM의 메모리 )
					ㄴ JVM은 os로부터 할당받은 메인메모리를 다음과 같이 분류하여 사용한다.
						ㄴ 메소드 영역
							ㄴ 메소드의 바이트코드, static변수
							ㄴ 클래스가 메모리에 올라갈때 이것들이 메소드영역에 저장이 된다.
						ㄴ 스택 영역
							ㄴ 지역변수, 매개변수
							ㄴ 알다시피 메소드 내에서만 유효한 변수들이며, 이들이 저장되는 공간이다.
						ㄴ 힙 영역
							ㄴ 인스턴스
							ㄴ 가비지 컬렉션, Garbage Collection )
								ㄴ 참조되지 않는 인스턴스는 소멸의 대상이되며 JVM에 의해 소멸되는데 이 기능을 말한다.
								ㄴ
					ㄴ finalize() : 인스턴스가 소멸될때, 소멸 직전에 자동으로 호출되는 메소드.
				ㅡ Wrapper 클래스 )
					ㄴ 기본 원시 자료형들을 '인스턴스' 형태로 표현하고자 할때 Wrapper클래스를 사용 할 수 있다.
						ㄴ Integer intInst = new Integer(3);	//int형 데이터 3을 Wrapper클래스 Integer를 통해 인스턴스형태로 표현하였다.
					ㄴ 종류 )
						ㄴ 모든 기본 자료형에 해당하는 Wrapper 클래스들이 존재한다.
							ㄴ Boolean, Character, Byte, Short, Integer, Long, Float, Double
						ㄴ 생성자로 String형을 받을 수 있어서, String으로 해당 자료형 Wrapper클래스를 생성할 수 있다.
					ㄴ 기본 자료형을 Wrapper클래스로 만드는것을 'Boxing', 그 반대를 'Unboxing' 이라한다.
						ㄴ auto Boxing, auto Unboxing : 자바에서 Wrapper클래스와 그에맞는 자료형들을 필요에따라서 자동으로 boxing, unboxing해주는 기능.
							ㄴ Wrapper클래스에 원시자료형을 넣거나, 그반대이거나, Wrapper클래스를 대상으로 연산을 하거나와 같은 상황에서 쓰인다.
							ㄴ ex)	Integer iValue=10;
								int num1 = iValue;
								iValue++;
				ㅡ Math 클래스 )
					ㄴ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
				ㅡ Generic )
					ㄴ 클래스, 인터페이스에서 사용되는 자료형을 나중에 정의할 수 있게 해주는 기능.
						ㄴ 자료형을 파라미터처럼 설정할 수 있게해줌.
						ㄴ 하여, 같은 코드를 다른 타입에 대해 사용할 수있다.
					ㄴ ex)
						class FruitBox < T, U, ... > {	//이렇게 < T, U>로 선언해놓고 이후 인스턴스 생성시 T와 U부분을 정해주면
															클래스 내부의 T와 U부분이 그 자료형으로 정해진다.
							T item;
							public void store( T item ){~~~ }
							public U adslfkj(){~~~}
						}
						~~~
						FruitBox< Integer> box = new FruitBox< Integer>();
					ㄴ 인자로 받는 타입을 '타입 파라미터'라고 한다.
						ㄴ 그리고 엄밀히 따지면 이 '타입 파라미터'에 받아지는 타입을 '타입 argument'라 한다.
							ㄴ ex ) class FruitBox< T> 에서 T는 '타입 parameter',
									FruitBox< Integer> box 에서 Integer은 '타입 argument'
						ㄴ 명명 관례는 하나의 대문자. ex ) T, V
					ㄴ 'FruitBox< Integer>'와 같이 제네릭 타입이 지정된 것을 'parameterized type'이라 한다.
					ㄴ 당연히 T, U부분은 모든 자료형에 대해서 실행하는데 오류가 없도록 구현되어야 한다.
					ㄴ 제네릭 부분에 원시타입은 올 수 없다. class, interface, array, 또 다른 타입 변수만 가능하다.
						ㄴ 또 다른 'parameterized type'도 가능하다.
							ㄴ ex ) FruitBox< Integer, Box< Integer> > box = ~~~
					ㄴ Type Inference
						ㄴ 제네릭 클래스의 생성자 호출시 넘기는 타입 argument를 비워둠으로서 ( ex) new FruitBox<>(); )
							제네릭 타입 지정을 미룰 수 있다.
						ㄴ ~~~
					ㄴ ~~~ https://docs.oracle.com/javase/tutorial/java/generics/rawTypes.html 부터 참조.

					ㄴ 제네릭 메소드 )
						ㄴ 특정 메소드에만 제네릭을 적용할 수 잇다.
						ㄴ ex)	public < T> void showInstType( T inst ) {~~~}//이처럼 접근제어지시자 뒤에 제네릭타입을 선언하여
																				'제네릭 메소드'를 만들 수 있다.
							~~~
							< Integer>showInstType(123);
					ㄴ 제네릭 자료형에 대한 제한 )
						ㄴ T 뒤에다가 'extends (*클래스*)' 를 붙이면 해당 클래스를 상속하는 클래스만 T부분에 올수 있도록 제한하게 된다.
						ㄴ 'super'를 붙이면 해당 클래스의 조상 클래스만 올 수 있다.
						ㄴ ex)
							class Child < T extends Parent > { ~~~ }
							class Child < T super Child >{~~~ }
					ㄴ 제네릭 형태의 배열을 사용하려면 T[] 형식으로 표기하면 된다. ex)	public < T> void aaa( T[] arr ){~~~}
					ㄴ 와일드 카드 '?' )
						ㄴ 제네릭을 정의하는게 아닌 사용하는 부분에서 T부분에 입력하는 자료형에 제한을 두는 방법.
						ㄴ 와일드카드 '?'를 쓰고, 위에서 제네릭 자료형 제한한것과 똑같이 'extends'나 'super'를 붙여 제한한다.
						ㄴ ex)	Child< ? extends Parents > x = new Child< (*Parrents를 상속하는 자료형*) > () ;
					ㄴ 인터페이스도 제네릭을 사용 할 수 있다.
					ㄴ 기본 자료형들은 제네릭에 사용될 수 없다.
				ㅡ 컬렉션 프레임워크 )<button>펼치기</button>
				<pre>
					ㄴ 기본
						ㄴ 데이터의 저장, 그리고 이와 관련있는 알고리즘을 미리 만들어놓은 것.
						ㄴ java_전체컬렉션.jpg 참조
						<img src="image/java_전체컬렉션.jpg"/>
					ㄴ 컬렉션들
						ㄴ Collection< E >
							ㄴ '인스턴스'만이 저장의 대상이다.
							ㄴ List < E >
								ㄴ 자료구조 '리스트'를 생각하면 될듯하다.
								ㄴ ArrayList < E > : '배열'을 이용한 '리스트'형식
									ㄴ 특징 )
										ㄴ 저장 용량을 늘리는 과정이 오래걸림.
										ㄴ 삭제 연산이 오래걸림
										ㄴ 데이터의 참조가 빠름.
								ㄴ LinkedList < E > : 흔히 알고있는 LinkedList를 말한다. 노드안에 값과 다음노드를 가리키는 프로퍼티를 가지고
													이 녿들이 쭉 연결된 형태.
									ㄴ 특징 )
										ㄴ 저장소 용량 늘리는 과정이 빠름.
										ㄴ 삭제연산이 빠름.
										ㄴ 데이터의 참조가 느림.
								* Iterator < E>
									ㅡ Collection < E> 인터페이스에 제공되는 인터페이스.
									ㅡ 컬렉션 내의 요소들에 대해 반복을 할때 쓰인다.
									ㅡ 사용법 )
										ㄴ 컬렉션 인스턴스에서 iterator()를 호출하면 해당 컬렉션 인스턴스에 대한 Iterator가 반환된다.
										ㄴ 이 Iterator객체를 가지고 여기에 들은 메소드들을 사용해 반복을 하면된다.
									ㅡ 메소드들 )
										ㄴ boolean hasNext() : 남아있는 요소가 있는지 확인한다.
										ㄴ E next() : 다음 차례의 요소를 반환한다.
										ㄴ void remove() : 바로 직전에 next()로 반환된 요소를 삭제.
							* sort() )
								ㅡ List< E>나 Arrays 클래스에 대해 내부 요소들을 정렬하는 sort()를 호출 할 수 있다.
									ㄴ Collections 인터페이스, List< E> 인터페이스, Arrays 클래스 안에 sort()메소드가 여러 형태로 정의되어있다.
									ㄴ Arrays 클래스의 public static void sort ( Object[] a ),
										public static < T> void sort ( T[] a, Comparator< ? super T> c)
									ㄴ Collections 인터페이스의 'public static < T extends Comparable< ? super T>> void sort​(List< T> list)',
										public static < T> void sort​(List< T> list, Comparator< ? super T> c)
									ㄴ List< E>의 default void sort​(Comparator< ? super E> c)
									* Collections 인터페이스 : 자바 컬렉션을 반환하거나 이와 관련된 연산을 해주는 static 메소드들이 정의되어있는 인터페이스.
								ㅡ natural ordering : 정렬되는 기준, 순서를 말하는 듯 하다.
								ㅡ Comparable < T>, Comparator < T> )
									ㄴ sort()호출시, 내부적으로 어떤 기준으로 정렬이 될지 설정을 해주는 인터페이스들이다.
									ㄴ Comparable < T> )
										ㄴ '정렬의 대상'이 되는 객체에 구현하여 'public int compareTo( T obj)'를 구현하여 정렬기준을 설정한다.
										ㄴ public int compareTo ( T obj ) )
											ㄴ obj가 더 크다면 음수, 작다면 양수, 같다면 0을 반환함으로서 기준 설정.
											ㄴ 작다고 판단된것이 앞에오는 식으로 정렬이 된다.
										ㄴ 대부분의 기본 Wrapper 클래스들은 이미 구현이 되어있다. (Integer, Byte, Boolean, ..., File, String, Date, CollationKey 등)
										ㄴ 이게 구현되어있지 않은 객체에 대해 sort()호출시 ClassCastException 이 발생한다.
										ㄴ 사용법 )
											ㄴ Arrays 클래스의 public static void sort ( Object[] a )
											ㄴ Collections 인터페이스의 public static < T extends Comparable< ? super T>> void sort​(List< T> list)
											ㄴ ??????????????????? List< E>의 default void sort​(Comparator< ? super E> c)
												ㄴ 인자로 Comparator를 받기는 하는데 null일경우 Comparable< T>를 사용하여 정렬한다는데 실습안해봐서 정확치않음.
									ㄴ Comparator < T> )
										ㄴ Comparable < T>를 구현하지 않는 객체를 정렬하거나, 이미 natural ordering이 정의된 객체를 다른 방식으로 정렬하고자 할때 사용할수 있는 인터페이스이다.
										ㄴ 사용법 )
											ㄴ Comparator < T>를 구현하는 객체를 만든뒤, int compare( T obj1, T obj2 )를 구현.
											ㄴ sort()호출시 정렬하려는 컬렉션과 함께 인자로 넘기면, Comparator< T>에 정의된 방법에 따라 정렬이 된다.
										ㄴ 메소드 )
											ㄴ int compare( T obj1, T obj2 ) : 두 객체간 크기비교를하는 메소드. obj1이 더 작으면 음수, 같으면 0, 아니면 양수 반환.
												ㄴ 작다고 판단된것이 앞에오는 식으로 정렬이 된다.
											ㄴ boolean equals( Object obj ) : ~~~~~~~~~~~
							ㄴ Set < E >
								ㄴ '집합'과 유사한 컬렉션. List < E>와 달리, '중복'을 허용하지 않고 '저장 순서'를 유지하지 않는 컬렉션이다.
								ㄴ 값을 저장할때 컬렉션을 탐색하여 중복을 체크한다음 저장한다.
								ㄴ HashSet < E >
									ㄴ 중복체크 )
										ㄴ 1차적으로 Object클래스의 hashCode()를 이용해 해쉬값을 확인
										ㄴ 해당 해쉬값에 속하는 요소들 중에서 Object클래스의 equals()를 이용해 중복이 있는지를 확인
									ㄴ 중복체크가 제대로 이루어지도록 하려면 Object클래스의 hashCode()와 equals()를 적절하게 오버라이딩해야한다.
								ㄴ TreeSet < E >
									ㄴ 기본 개념
										ㄴ 자료구조 '트리'를 기반으로하는 컬렉션.
										ㄴ 데이터를 '정렬'된 상태로 저장한다.
										ㄴ 저장하려는 인스턴스가 Comparable < T> 인터페이스를 구현하여 정렬의 기준이 정의되어 있어야 한다.
									ㄴ 정렬 방식정의 방법1
										ㄴ 위에 설명한대로 저장 대상인 클래스가 Comparable < T>인터페이스를 구현하게하여 정렬의 기준을 설정하는 방법이 있다.
									ㄴ 정렬 방식정의 방법2
										ㄴ 'Comparator 인터페이스'를 구현하는 클래스를 만들고 이 안에 int compare( T obj1, T obj2 )를 구현하여
											이 클래스를 TreeSet 생성자의 인자로 넘기는 방법.
							ㄴ Queue < E> 인터페이스 )
								ㄴ 자료구조 '큐'를 나타내는 인터페이스.
								ㄴ 주요 메소드 )
									ㄴ 삽입, 삭제, 탐색 기능의 메소드가 각각 두가지 형태로 존재한다.
										ㄴ 하나는 실패시 '예외'를 던지는 형태, 또하나는 실패시 정해진 값을 반환하는 형태(null이나 false등)
									ㄴ 예외 던지는 형태의 메소드 )
										ㄴ add (e) : FIFO 규칙대로 큐에 값을 넣는다. 큐의 capacity를 초과하면 실패. 실패시 예외 발생
										ㄴ remove() : 큐의 head를 반환하고 삭제한다. 큐가 비어있으면 예외발생.
										ㄴ element() : 큐의 head를 반환하기만 한다. 큐가 비어있으면 예외발생.
									ㄴ 정해진 값을 반환하는 형태 )
										ㄴ offer (e) : add()와 동일실패시 false 반환.
										ㄴ poll() : 큐가 비었을경우를 제외하면 remove()와 똑같이 동작한다. 큐가 비어있으면 null반환.
										ㄴ peek() : 큐가 비었을경우를 제외하면 element()와 똑같이 동작한다. 큐가 비어있으면 null반환.
								ㄴ Deque < E> )
									ㄴ 'deck'이라고도 알려진 'double-ended-queue'.
									ㄴ 양쪽 끝지점에서 삽입과 삭제가 모두 가능한 큐.
									ㄴ 따라서 스택으로도, 큐로도 사용 할 수 있다.
									ㄴ 메소드 )
										ㄴ addFirst(), offerFirst() : Deque의 head부분에 삽입을 한다.
										ㄴ addLast(), offerLast() : Deque의 tail부분에 삽입을 한다.
										ㄴ removeFirst(), pollFirst() : Deque의 head부분의 요소를 반환하고 삭제한다.
										ㄴ removeLast(), pollLast() : Deque의 tail부분의 요소를 반환하고 삭제한다.
										ㄴ getFirst(), peekFirst() : Deque의 head부분의 요소를 반환한다.
										ㄴ getLast(), peekLast() : Deque의 tail부분의 요소를 반환만한다.
										ㄴ 앞쪽에 적은 add**, remove**, get** 식의 이름을가진 메소드는 실패시 예외를 던지고 아닌것들은 실패시 정해진값을 반환한다. 										ㄴ ~~~~~
								ㄴ PriorityQueue < E> )
									ㄴ 우선순위 '힙'을 기반으로한 queue.
									ㄴ 요소들의 'natural ordering'에 따라서 요소들이 정렬이 되거나, PriorityQueeu생성자 인자로 전달된 Comparator < E>에 의해 정렬이 된다.
										ㄴ 'natural ordering'에 의해 정렬되는 PriorityQueue는 Comparable< E>를 구현하지 않는 객체를 요소로 받아들이지 않는다.
										ㄴ ???????우선순위가 동일하다면 알파벳순으로 정렬된다한다.
									ㄴ null요소를 허용하지 않는다.
									ㄴ '동기화'되지 않았다.
									ㄴ 메소드 )
										ㄴ add(E e)
										ㄴ offer ( E e)
										ㄴ peek()
										ㄴ poll()
										ㄴ remove( Object o )
						ㄴ Map< K, V >
							ㄴ key와 value형태로 데이터를 저장하는 컬렉션.
							ㄴ HashMap < K, V>
								ㄴ 특징 )
									ㄴ value에 상관없이 중복된 key의 저장은 불가능하다. 즉, key가 다르면 value는 같을 수 있다.
									ㄴ HashSet< E>과 마찬가지로 '해쉬' 기반으로 만들어져 빠른 검색속도를 가진다.
							ㄴ TreeMap < K, V>
								ㄴ TreeSet< E>과 마찬가지로 자료구조 'tree'를 기반으로 만들어져 데이터가 '정렬'된 상태로 저장된다.
									ㄴ 정렬은 'key'에 대한 정렬이다.
								ㄴ navigableKeySet()을 통해 Collection< E>의 Iterator< E>와 비슷한 반복 기능을 하는 NavigableSet< E>인터페이스를 얻을 수 있따.
					ㄴ 기본 제공 알고리즘 )
						ㄴ https://docs.oracle.com/javase/tutorial/collections/algorithms/index.html 참조
						ㄴ 자바에서 기본적으로 제공하고 있는 알고리즘에 대해 배운다.
						ㄴ Sorting, Shuffling, Routine Data Manipulation, Searching, Composition, Finding Extreme Values가 잇으며,
							모두 Collections 인터페이스에 메소드로 제공되고 있다.
						ㄴ Sorting, 정렬 )
							ㄴ Collections.sort() 메소드를 이용한다.
							ㄴ List 인터페이스를 대상으로 동작한다. (근데 Arrays 클래스를 통해 배열에서도 가능하다)
							ㄴ 내부적으로 '합병 정렬'을 사용한다.
								ㄴ  O(n) = n * log (n)
							ㄴ 위에 Collection< E> 항목의 *sort()에서 다룬 내용과 일치한다.
						ㄴ Shuffling )
							ㄴ Collection.shuffle() 메소드를 이용한다.
							ㄴ sorting과 정반대의 기능. 'List'의 정렬을 흐트러뜨린다.
							ㄴ ~~~~~~~~
						ㄴ Routine Data Manipulation )
						ㄴ Searching )
							ㄴ Collections.binarySearch() 메소드 이용
								ㄴ public static < T> int binarySearch(List< ? extends Comparable< ? super T>> list, T key)
									ㄴ List가 요소의 'natural ordering'에 따라 정렬되어ㅣㅇㅆ다고 가정하고 탐색한다.
								ㄴ public static < T> int binarySearch(List< ? extends T> list, T key,  Comparator< ? super T> c)
									ㄴ List가 인자로 넘어간 Comparator에 따라 정렬되어있다고 가정하고 탐색한다.
							ㄴ 정렬된 List에 대하여 '이진 탐색'을 실행한다.
						ㄴ Composition )
						ㄴ Finding Extreme Values )
				</pre>
			</pre>

			ㅇ 가비지 컬렉션, Garbage collector
				ㅡ 자바 실행환경이 객체에 대한 메모리 관리를 자동으로 해줌.
					ㄴ 더이상 참조되지 않는 객체인 경우, (즉, 특정 객체에 대한 참조값이 아무 변수에 할당되지 않는 상태이면)
						'가비지 컬렉터'가 해당 객체를 삭제하여 차지하고 있던 메모리를 비운다.

			ㅇ Annotation, 어노테이션
				ㄴ 직접적인 코드상의 연산 작업이 없이, 프로그램에 대한 metadata를 제공하는 일종의 정해진 형식.
				ㄴ 쓰임새
					ㄴ 컴파일러에게 정보 제공
					ㄴ 컴파일, 배포 시점에 소프트웨어 툴들이 어노테이션 정보를 이용해 코드, xml file 등을 생성할 수 있게함.
					ㄴ 런타임시에 참고.
				ㄴ 형식
					ㄴ ex )
						@Entity
						@Author(
							name="aaa", date="2023-01-01"
						)
					ㄴ 'sign character (@)'를 사용하여 이후의 내용이 어노테이션임을 컴파일러에게 알림.
					ㄴ '@'바로 뒤에 어노테이션 이름.
					ㄴ 이름이 있는/없는 인자를 가질 수 있음.
					ㄴ 여러개의 어노테이션이 명시될 수 있다.
					ㄴ Repeating annotation
						ㄴ 같은 어노테이션이 여러번 명시된 경우의 어노테이션을 말함.
				ㄴ 다른 어노테이션에 대한 어노테이션을 'meta-annotation'이라함.
				ㄴ 어노테이션 타입은 java.lang, java.lang.annotation 패키지에 정의된 타입 중 하나이다.
					ㄴ java.lang의 annotation
						ㄴ @Deprecated
							ㄴ 해당 요소가 deprecated되어 더이상 사용하면 안됨을 경고하는데 쓰이는 어노테이션.
							ㄴ 해당 어노테이션이 선언된 요소 사용시 경고창이 뜸.
						ㄴ @Override
							ㄴ 컴파일러에게 해당 요소가 상위 클래스의 요소를 overide 한것임 알림.
							ㄴ override하는 요소에 필수로 이 어노테이션을 선언해야 하는건 아니지만,
								선언하면 적절한 override 실패시 컴파일러가 에러를 발생시켜 준다.
						ㄴ @SuppressWarnings
							ㄴ 컴파일러에게 특정 warning을 무시라하고 명시.
							ㄴ ex )
								@SuppressWarnings({"deprecation", "unchekced"})
								void useDeprecatedMethod() {
									// deprecation warning
									// - suppressed
									objectOne.deprecatedMethod();
								}
								ㄴ 'deprecation', 'unchecked'란 category의 컴파일 warning을 무시하라 명시.
								* 컴파일러 warning은 특정 category에 속함. 자바 언어의 경우, 'deprecation', 'unchecked' category 존재.
						ㄴ @SafeVarargs
						ㄴ @FunctionalInterface
					ㄴ java.lang.annotaion의 annotation의 'meta-annotation'
						ㄴ 'meta-annotation'이란, 다른 annotation에 적용되는 annotation.
						ㄴ @Retention
							ㄴ annotation 선언시, 선언하는 annotation에 선언하면 적용.
							ㄴ 해당 annotation을 source code, class file, runtime 시 중 어느 시점까지 유지시킬지 결정.
							ㄴ 인자 )
								ㄴ value )
									ㄴ java.lang.annotation의 RetentionPolicy enum 값 중 하나 입력.
									ㄴ SOURCE : 어노테이션을 소스코드 상에서만 유지시킴. 컴파일러가 컴파일하여 class파일 생성시
										해당 어노테이션을 제거함.
									ㄴ CLASS : 어노테이션을 class파일까지 유지시킴. 컴파일러가 class파일 생성시 어노테이션을 제거하지 않음.
										JVM이 runtime시 제거함???
									ㄴ RUNTIME : 어노테이션을 runtime시까지 유지시킴. 컴파일러가 class파일 생성시 어노테이션을 제거하지 않고
										JVM이 runtime시 제거하지 않음.
							ㄴ @Retention meta-annotation 자체가 선언되지 않았으면, 'CLASS'가 디폴트로 설정.
						ㄴ @Documented
							ㄴ

				ㄴ 직접 정의도 가능하다.
				ㄴ 선언에 사용 가능.
					클래스, 함수, 변수에 대한 선언 등.
					ㄴ java 8부턴 타입에도 사용 가능. (type annotation)
						ㄴ ex )
							new @Interned MyObject();

							myString = (@NonNull String) str;

							class UnmodifiableList< T> implements
								@Readonly List<@Readonly T> { ... }

							void monitorTemperature() throws
								@Critical TemperatureException { ... }
				ㄴ annotation 정의
					ㄴ ex )
						// 정의.
						@interface ClassPreamble {
						String author();
						String date();
						int currentRevision() default 1;
						String lastModified() default "N/A";
						String lastModifiedBy() default "N/A";
						// Note use of array
						String[] reviewers();
						}

						// 사용..
						@ClassPreamble (
						author = "John Doe",
						date = "3/17/2002",
						currentRevision = 6,
						lastModified = "4/12/2004",
						lastModifiedBy = "Jane Doe",
						// Note array notation
						reviewers = {"Alice", "Bob", "Cindy"}
						)
						public class Generation3List extends Generation2List {

						// class code goes here

						}
					ㄴ @ 문자 뒤에 'interface'를 붙이는 형식으로 정의.
					ㄴ body에는 어노테이션의 인자 정의.
						ㄴ 디폴트값 설정 가능.

			ㅇ 쓰레드와 동기화 <button>펼치기</button>
			<pre>
				ㄴ 쓰레드 기초
					* 프로세스  : os로부터 메모리를 할당받아 실행중에 있는 프로그램.
					ㄴ 쓰레드란 ?
						ㄴ 하나의 프로세스 내에 있는 '프로그램의 흐름'
						ㄴ 하나 이상이 존재 할 수 있다.
					ㄴ 사용법 )
						ㄴ Thread 클래스 상속 )
							ㄴ 'Thread' 클래스를 상속하고 public void run()을 구현하고 이 상속클래스에서 start()를 호출함으로서 새로운 스레드를 실행시킬 수 있다.
								ㄴ public void run()은 Thread에게 main메소드와 같다. 이 메소드의 바디를 구현하여 스레드가 어떤 작업을 할지 결정할 수 있다.
							* Thread 클래스
								ㅡ ~~~
								ㅡ 필드 )
									ㄴ MAX_PRIORITY : 가질 수 있는 최대 우선순위
									ㄴ MIN_PRIORITY : 가질 수 있는 최소 우선순위
									ㄴ NORM_PRIORITY : 디폴트 우선순위.
								ㅡ 메소드 )
									ㄴ ~~~
									ㄴ void join() : 현재 스레드(join()을 호출하는 스레드)가 끝날때까지 (이명령을 실행하는 스레드를) wait시키는 명령어.
									ㄴ int getPriority() : 스레드의 우선순위를 반환
									ㄴ void setPriority( int priority ) : 스레드의 우선순위를 변경
						ㄴ 'Runnable' 인터페이스 구현 )
							* Runnable 인터페이스
								ㅡ 스레드에 의해 실행될 인스턴스가 구현하는 인터페이스이다.
								ㅡ run()을 구현해야 한다.
								ㅡ Thread 클래스가 구현하고있는 인터페이스이다.
								ㅡ 이를 이용하면 Thread클래스를 상속하지 않고도 구현하는 인스턴스를 스레드로 실행시킬 수 있다.
									ㄴ 인터페이스를 구현하고 run()을 구현하고 인스턴스를 Thread 클래스 생성자의 인자로 넘긴다음 Thread 인스턴스의 start()를 호출하면 Runnable을 구현한 클래스의 run()부분이 새로운 스레드에 의해 실행된다.

				ㄴ 스레드 특징
					ㄴ 우선순위와 스케줄링
						ㄴ 여러 스레드가 동시에 실행될 수 있기때문에 JVM은 스레드의 실행을 '스케줄링'해야 한다.
						ㄴ 스케줄링 원칙 )
							ㄴ 우선순위가 높은 스레드의 실행을 우선한다. 우선순위가 높은게 끝나야 다음우선순위가 실행 될 수 있다.
							ㄴ 우선순위가 동일하면 CPU의 할당시간을 분배하여 실행한다. (조금씩 번갈아가면서 실행되는 식이다)
						ㄴ Thread 클래스의 getPriority(), setPriority() 등을 통해 우선순위를 다룰 수 있다.
						ㄴ 주의 )
							ㄴ 자바차원에서 스레드 스케줄링을 조금 다룰 수 있게 되어있으나, 스레드는 실질적으로 os에 상당히 의존적이므로 결과에 변수가 있다고 한다.
							ㄴ 또한 스레드가 CPU를 필요로 하지 않는 입출력 연산 등을 할때, 자신의 우선순위가 높더라도 CPU를 양보해 낮은순위가 먼저 실행될 수도 있다.
					ㄴ 라이프 사이클
						ㄴ 스레드의 상태 )
							ㄴ New 상태 )
								ㄴ 스레드 클래스가 new를 통해 인스턴스화된 상태를 말한다.
								ㄴ JVM에 의해 관리되고 있는 상태는 아니다.
								ㄴ os상으로는 스레드라고 볼 수 없으나 자바상에선 이 시점부터 스레드라고 부른다.
							ㄴ Runnable 상태 )
								ㄴ 스레드 인스턴스에서 start()가 호출되면 들어가는 상태.
								ㄴ 이 상태에 들어가면 스케줄러에 의해 선택을 기다리게되며, 선택되면 run()을 실행한다.
							ㄴ Blocked 상태 )
								ㄴ 스레드에서 sleep(), join()을 호출하거나 입출력 연산등을 하여 CPU가 필요없어지면 CPU를 다른스레드에게 양보하고 본인은 'blocked'상태가 된다.
								ㄴ 이 상태에서는 스케줄러에 의해 선택받을 수 없다.
								ㄴ Blocked상태가 된 원인이 해결되면 다시 Runnable상태로 돌아간다.
							ㄴ Dead 상태 )
								ㄴ run()의 실행이 완료되어 run()을 빠져나오게 되면 'Dead'상태가 된다.
								ㄴ 스레드에 할당받았던 메모리나 각종 스레드 관련 정보가 삭제된다.
								ㄴ 다시 다른 상태가 될 수 없으면 그냥 스레드가 완전히 끝난다.
					ㄴ 메모리 구성
						ㄴ 스레드는 별도의 흐름을 만드는 것이기때문에 별도의 메모리가 필요하다.
						ㄴ 메모리 영역 중, '스택'영역만 별도로 할당되고, '메소드 영역', '힙 영역'은 main스레드와 공유된다.
							ㄴ 따라서 힙 영역의데이터를 이용해 스레드간에 데이터 교환이 가능하다.
				ㄴ 동기화
					ㄴ 동시접근 방지
						ㄴ 동기화의 필요성
							ㄴ 스레드 간에 메모리에서 '힙 영역'을 공유하기때문에 하나의 힙 영역 데이터에 둘 이상의 스레드가 동시에 접근하는 문제가 발생한다. 이를 해결하기 위해 '동기화'가 필요하다.
							ㄴ 동기화란? ) 한 스레드가 특정 데이터에 접근하는 동안 다른 스레드가 그 데이터에 접근하지 못하게 하는 것.
							* Thread - safe : 동기화 처리가 되어있다는 의미.
						ㄴ 동기화 방법1 : 동기화 메소드 )
							ㄴ 메소드에 'synchronized' 키워드를 붙여서 동기화.
							ㄴ 'synchronized'키워드가 붙은 메소드들 전체에 'lock'이 걸린다. 따라서 한 스레드가 'synchronized'가 붙은 메소드들중 하나를 호출하면 나머지 'synchronized'가붙은 메소드들이 전부 호출이 불가하게 된다.
							ㄴ lock의 범위가 매우 크기때문에 실행시간이 많이 늘어난다.
							ㄴ ex) public synchronized int add(int num){ ~~~ }
						ㄴ 동기화 방법2 : 동기화 블럭 )
							ㄴ 'synchronized()'블록을 씌워 해당 블록에 대해 lock을 건다.
							ㄴ ex)	public int add(int num){
									synchronized( (*key로서 사용할 아무 인스턴스의 참조값*) ){
										~~thread-safe해야하는 작업~~
									}
								}
							ㄴ 같은 'key'를 사용하고있는 '동기화 블록'끼리 묶여서 lock이 걸린다.
						ㄴ 동기화 방법3 : ReentrantLock 클래스 )
							ㄴ ReentrantLock 클래스의 lock(), unlock() 메소드를 통해 lock을 걸 수 있게해주는 클래스이다.
								ㄴ lock()이 호출된 부분부터 unlock()이 호출되는 부분까지 lock이 걸린다.
							ㄴ ex) 	private final ReentrantLock aaa = new ReentrantLock();
								~~~
								aaa.lock();
								~~~		//lock()부터 unlock()사이인 이부분을 실행할때 다른 스레드가 접근하지 못한다.
								aaa.unlock();

					ㄴ 순서 보장
						ㄴ 필요성
							ㄴ 스레드의 실행순서는 소스코드상의 순서와 같지 않다. 어떤 순서대로 실행될지 확실하게 알 수 있는 방법이 없다.
							ㄴ 따라서 여러가지 방법으로 실행순서를 보장해야 한다.
						ㄴ 방법1 : wait, notify, notifyAll )
							ㄴ 아래의 메소드들을 사용하여 실행순서를 보장한다.
							ㄴ 메소드들 )
								ㄴ public final void wait() throws InterruptedException : 스레드를 잠시 정지시킨다.
								ㄴ public fianl void nofity() : 하나의 스레드를 깨움.
								ㄴ publi final void notifyAll() : 모든 스레드를 깨움.
							ㄴ Object의 메소드들이다.
							ㄴ 위 세 메소드들은 동시에 실행되지 않도록 동기화처리 해야한다.
							ㄴ wait()는 동기화 처리가 되어있어도 스레드가 잠드는 순간 lock을 푼다.
						ㄴ 방법2 : await, signal, siganlAll )
							ㄴ ReentrantLock 인스턴스의 newCondition()호출시 Condition 인터페이스형 인스턴스가 반환되고 이것의 다음 메소드들을 통하여 실행순서를 보장할 수 있다.
							ㄴ 메소드들 )
								ㄴ await : 스레드를 잠시 정지시킨다.
								ㄴ signal : 하나의 스레드를 깨운다.
								ㄴ signalAll : 모든 스레드를 깨운다.
							ㄴ 나머지는 방법1과 같다.
			</pre>

			ㅇ 파일과 I/O 스트림 <button>펼치기</button>
			<pre>
				ㄴ 여기서 설명하는 주요 클래스들은 java.io 패키지에 들어있다.
				ㄴ 자바에서는 입출력 대상에 상관없이 입출력의 '기본적인 방식'이 동일하도록 별도의 'I/O 모델'이 마련되어잇다.
					ㄴ '기본적인 방식'이 동일할 뿐, 입출력 대상에 따라 사용하는 클래스나 메소드들은 다르다.
					* 자바에서 네트워크와 관련된 I/O 클래스들이 특히 훌륭하다고 한다.
				ㄴ 스트림의 이해와 입출력 스트림 )
					ㄴ 스트림 이란? ) 데이터의 흐름, 데이터의 흐름을 형성하는 통로를 의미한다.
					ㄴ 스트림의 종류 )
						ㄴ 입력 스트림 : 외부에서부터 프로그램으로 데이터를 읽어들이는 스트림
						ㄴ 출력 스트림 : 프로그램에서 외부로 데이터를 내보내는 스트림.
					ㄴ 아주 간단한 사용법 )
						ㄴ 관련 인스턴스의 생성을 통해 스트림을 형성할 수 있다.
						ㄴ 입력 스트림 )
							ㄴ ex)	InputStream in = new FileInputStream("run.exe");	//스트림 클래스인 FileInputStream을 생성하여 입력스트림을 생성하였다.
							ㄴ 파일 run.exe에 저장되어있는 데이터를 읽어들이는 스트림이 형성된것.
							ㄴ FileInputStream클래스의 메소드들로 데이터를 읽어들이면 된다.
							ㄴ 스트림을 사용하고 나면 생성했던 스트림을 소멸시켜야 한다.
							* InputStream 추상 클래스
								ㅡ 모든 입력 스트림 클래스들이 상속하는 최상위 클래스이다.
								ㅡ 바이트 단위로 데이터를 읽어들인다.
								ㅡ 대표적 메소드 )
									ㄴ public abstract int read() throws IOException )
										ㄴ 1바이트의 데이터를 읽어서 반환하는 메소드.
										ㄴ 입출력 대상에 따라 데이터를 읽어들이는 방식이 같을수가 없기때문에, 각 입출력 대상에 해당하는 입출력 클래스들에서 구현하도록하기위해 추상메소드이다.
										ㄴ 더이상 읽어들일 데이터가 존재하지 않으면 -1을 반환.
									ㄴ public int read ( byte[] b, int offset, int len ) throws IOException )
										ㄴ 내부적으로 read()를 반복호출하여 입출력 대상으로부터 len만큼의 바이트를 읽어들여 b의 offset위치에서부터 저장한다.
										ㄴ b는 한꺼번에 여러바이트의 데이터를 읽어오기위한 '버퍼'의 역할을 한다.
									ㄴ public void close() throws IOException )
										ㄴ 해당 스트림을 소멸시킨다.
						ㄴ 출력 스트림 )
							ㄴ 입력 스트림과유사하다.
							ㄴ ex) OutputStream out = new FileOutputStream("home.bin");
							* OutputStream 추상클래스
								ㅡ InputStream 클래스와 유사.
								ㅡ 주요 메소드 )
									ㄴ public abstract void write(int b) throws IOException )
										ㄴ InputStream의 read()와 유사하다.
										ㄴ 인자로 전달된 데이터의 '1바이트'를 출력스트림을 통해 내보낸다.
											ㄴ 1바이트 이상의 크기의 데이터가 인자로 넘어오면 하위 비트에서 1바이트만큼을 끊어서 내보낸다.
									ㄴ public void close() throws IOException )
				ㄴ 필터 스트림
					ㄴ 필터 스트림이란 ? )
						ㄴ 스트림을 통해 읽힌 데이터의 형태를 다양하게 조작하게 해주는 '스트림'의 일종.
						ㄴ 그 자체로 입출력 대상으로부터 데이터를 직접 읽어오는 기능은 없다.
						ㄴ 필터 스트림들은 FilterInputStream, FilterOutputStream을 상속한다.
					ㄴ Data 스트림 )
						ㄴ 데이터의 기본 자료형에 대한 변환을 도와주는 '필터 스트림'
						ㄴ 클래스 ) DataInputStream, DataOutputStream
						ㄴ 사용 )
							ㄴ ex) 	OutputStream out = new FileOutputStream("data.bin");
								DataOutputStream filterOut = new DataOutputStream(out);	//이렇게 필터스트림의 생성자로 입출력 스트림 인스턴스를 넘겨주어 해당 입출력 스트림에 대한 필터를 장착한다.
								filterOut.writeInt(275);	//정수형 자료형을 write하면 필터 스트림에 의해 자동으로 정수형 데이터가 바이트형으로 변환되어 넘어간다.
								filterOut.writeDouble(2.23);
					ㄴ Buffered 스트림 )
						ㄴ '버퍼'기능을 제공해주는 '필터 스트림'
						ㄴ 동작 방식 )
							ㄴ 내부적으로 '버퍼'(byte형 배열)를 가지고 있다.
							ㄴ read()의 호출과 상관없이  입출력 대상으로부터 데이터를 읽어와 항상 '버퍼'를 채워놓는다. 이후 read()호출시 버퍼로부터 데이터를 준다.
							ㄴ 출력 버퍼 스트림 사용시, 버퍼에 프로그램으로부터 write()한 데이터가 가득 차기전까지는 write작업을 하지 않다가 다 차면 한꺼번에 보낸다.
						ㄴ 클래스 ) BufferedInputStream, BufferedOutputStream
						* flush()
							ㅡ OutputStream을 버퍼와같이 사용하는 경우, 컴퓨터의 오류 등으로 인해 버퍼에 있는 데이터가 write되지 못하고 프로그램이 갑자기 종료되거나 하면 그 데이터는 그냥 날아가게된다. 이를 방지하기 위한 OutputStream과 관련된 클래스들의 메소드이다.
							ㅡ 호출시 버퍼에 남아있는 데이터를 바로 write한다.
					ㄴ 필터의 조합 )
						ㄴ 여러가지 필터를 다 붙여서 사용할 수 있으나 순서에 주의해야 한다.
						ㄴ ex)	OutputStream out = new FileOutputStream("data.bin");
							BufferedOutputStream bufFilterOut = new BufferedOutputStream(out);
							DataOutputStream dataFilterOut = new DataOutputStream(bufFilterOut);
							ㄴ 이경우, Program -> (Data 필터 스트림) -> (버퍼 필터 스트림) -> (파일 스트림) -> (입출력 대상) 의 순서이다.
							ㄴ 기본자료형으로 프로그램에서 넘겨주면 데이터 필터가 바이트형식으로 바꾸고 이를 버퍼 필터가 받아서 write하면 되는 아무ㅜ 문제없는 상황이다.
							ㄴ 근데 만약 데이터필터와 버퍼 필터의순서가 바뀐다면, Program -> (버퍼 필터 스트림) -> (Data 필터 스트림) -> (파일 스트림) -> (입출력 대상) 이된다.
							ㄴ 프로그램으로부터 기본자료형이 넘어오면 이걸 그냥 바이트로 취급하여 버퍼 필터가 데이터 필터에게 전해주고 데이터 필터는 기본자료형이 아닌 바이트 데이터를 받게된다.
					ㄴ 가장 마지막에 연결된 필터 스트림을 종료하면 연결된 모든 스트림들이 종료된다.
				ㄴ 문자 스트림 )
					ㄴ 문자스트림의 이해 )
						ㄴ os의 인코딩 방식에 맞게 자동으로 문자를 인코딩하여 read, write해주는 스트림.
							ㄴ 프로그램상에서 'A'를 '문자스트림'을 통해 write하면 문자 'A'를 os의 인코딩방식에 맞게 인코딩하여 파일에 write해주는 식. (자바에서 'A'는 char형 2바이트이지만 window os상에선 'A'는 1바이트를 차지한다. 따라서 window os상의 인코딩방식대로 1바이트가 저장된다)
							ㄴ read는 그 반대.
						ㄴ 클래스 ) Reader, Writer 추상클래스.
							ㄴ InputStream, OutputStream과 상속관계가 없는 클래스이다.
							ㄴ Reader는 InputStream에 대응하고 Writer는 OutputStream에 대응한다.
							ㄴ 문자 스트림에서 파일을 대상으로 하는 입출력 스트림은 FileReader, FileWriter이다.
								ㄴ 이런식으로 InputStream과 OutputStream과 거의 유사.
							ㄴ 주요메소드도 다 비슷하다 )
								ㄴ Reader의 주요메소드 )
									ㄴ public int read() throws IOException : 문자 하나를 읽어들여 반환.
									ㄴ public abstract int read ( char[] cbuf, int offset, int len ) throws IOException : len만큼의 문자를 읽어들여 cbuf의 offset부분부터 저장.
								ㄴ Writer의 주요메소드 )
									ㄴ public void write( int c ) throws IOException )
										ㄴ 문자 하나를 write.
										ㄴ 자바에선 문자하나가 2바이트이므로 int형 인자에서 뒤에 2바이트만 잘라서 write한다.
									ㄴ public abstract void write ( char[] cbuf, int offset, int len ) throws IOException : ~~~~~~~
					ㄴ 사용법 ) InputStream, OutputStream과 유사하다.
					ㄴ Buffered 문자 스트림 )
						ㄴ BufferedReader, BufferedWriter
							ㄴ BufferedInputStream, BufferedOutputStream에 대응한다.
						ㄴ 주요 메소드 )
							ㄴ BufferedReader의 public String readLine() throws IOException )
								ㄴ '개행'을 기준으로  '개행'이 나오기 전가지의 문자열 데이터를 읽어들인다.
									ㄴ '개행' 데이터는 읽어오지 않는다.
								ㄴ 더이상 없으면 null반환.
							ㄴ BufferedWriter의 public void write(String str) throws IOException
							ㄴ BufferedWriter의 newLine() )
								ㄴ '개행정보'를 write한다.
								ㄴ os마다 '개행'을 표현하는 방식이 다르기때문에 따로 만들어졌다고함.
					ㄴ PrintWriter )
						ㄴ '문자 스트림' Writer의 하위 클래스. 문자 출력 스트림 기능을 한다.
						ㄴ PrintStream과의 관계 )
							ㄴ System.out은 OutputStream을 구현하는 PrintStream 객체이다. (OutputStream은  '바이트 스트림'이다)
							ㄴ '문자 스트림'인 PrintWriter가 있지만 이미 PrintStream이 System.out.println()으로 널리쓰이고있다.
							ㄴ 따라서 System.out을 사용하는것 외에는 이왕이면 PrintWriter를 사용하라고 함.
				ㄴ 오브젝트 스트림 )
					ㄴ 자바의 인스턴스를 통째로 입출력 할 수 있게 해주는 스트림.
					ㄴ 클래스 ) ObjectInputStream, ObjectOutputStream
						ㄴ InputStream, OuputStream을 상속하기에 엄밀히따지면 '바이트 스트림'에 속하지만, 일반적으로는 그냥 '오브젝트 스트림'으로 분류한다고 한다.
						ㄴ 또한 사용방법이 '필터 스트림'과 유사하지만 '필터스트림'은 아니다.
					ㄴ 주요 메소드 )
						ㄴ public final void writeObject ( Object obj ) throws IOException : 인스턴스를 파일에 저장한다.
						ㄴ public final Object readObject() throws IOException, ClassNotFoundException : 파일로부터 인스턴스를 읽어온다.
					ㄴ 입출력의 대상이 되는 인스턴스의 클래스는 java.io.Serializable 인터페이스를 '직, 간접적'으로 구현해야 한다.
						* Serializable 인터페이스
							ㅡ 해당 클래스의 인스턴스가 직렬화를 해도 괜찮다는걸 표시하는 용도의 인터페이스이다.
							ㅡ 단순히 표시기능이기때문에 추가적으로 구현해야할 메소드가 존재하지 않는다.
					ㄴ 직렬화 : 인스턴스가 파일에 저장되는 과정을 말한다. 반대과정은 '역직렬화'라 한다.
						ㄴ 직렬화되는 인스턴스의 멤버변수가 참조하는 인스턴스도 Serializable이 직간접적으로 구현되어있다면 함께 직렬화된다.
							ㄴ 인스턴스를 참조하는 멤버변수 앞에 'transient' 키워드를 붙이면 함께 직렬화되지 않는다.
					ㄴ 간단한 사용법 )
						ObjectOutputStream out = new ObjectOutputStream ( new FileOutputStream ( "Object.ser" ) );
						out.writeObject(new Circle(1,2,3,4));
					ㄴ 주의 )
						ㄴ 직렬화, 역직렬화 과정은 자원소모가 많은 작업이므로 유의해야 한다.
				ㄴ RandomAccessFile 클래스 )
					ㄴ 위에서 계속 나오는 '스트림 클래스'는 아니지만 '파일'에 대하여 입출력을 해주는 클래스이다.
					ㄴ 특징 )
						ㄴ 입력과 출력이 동시에 이루어 질 수 있다.
						ㄴ 입출력의 위치를 조절할 수 있다.
						ㄴ '파일'을 대상으로만 동작한다.
					ㄴ 내부적으로 입출력의 위치를 계속해서 기록한다.
					ㄴ 간단한 사용법 )
						ㄴ 생성자 )
							ㄴ public RandomAccessFile ( String fileName, String mode ) throws FileNotFoundException
							ㄴ fileName이 파일이름, mode는 해당 파일을 어떤 용도로 사용할지를 전달하는 기능이다. 다음 두가지중 하나의 값을 가진다.
								ㄴ "r" : 파일을 읽기용도로 사용할것임
								ㄴ "rw" : 파일을 읽고 쓰는 용도로 사용할 것임.
					ㄴ 주요 메소드 )
						ㄴ 입력 메소드 )
							ㄴ public int read() throws IOException
							ㄴ public int read ( btye[] b, int off, int len ) throws IOException
							ㄴ public final int readInt() throws IOException
							ㄴ public final double readDouble() throws IOException
						ㄴ 출력 메소드 )
							ㄴ public void write( int b ) throws IOException
							ㄴ public void write ( byte[] b, int offset, int len ) throws IOException
							ㄴ public final void writeInt ( int v ) throws IOException
							ㄴ public final void writeDouble ( double v ) throws IOException
						ㄴ 입출력 위치 조절 )
							ㄴ public long getFilePointer() throws IOException : 파일의 현재 입출력 위치를 반환받는다.
							ㄴ public void seek ( long pos ) throws IOException : 입출력 위치를 변경
				ㄴ File 클래스 )
					ㄴ 파일이나 디렉토리와 관련된 동작을 하기위해 만들어진 클래스. (파일이나 디렉토리의 이동, 생성, 이름변경 등등)
					ㄴ pathname에 해당하는 파일이나 디렉토리를 추상적으로 나타내는 클래스이다.
					ㄴ 기본 사용법 )
						ㄴ 그냥 원하는 파일이나 파일경로를 File인스턴스로 만들고 메소드 사용해서 쓰면된다.
						ㄴ 필드 )
							ㄴ public static final String separator : 파일의 경로에서 디렉토리 또는 파일이름의 구분자를 os에 맞게 입력해주는 필드. String으로 표현되었다.
							ㄴ public static final char separatorChar : separator와 같은데 char형으로 표현된것.
							ㄴ public static final String pathSeparator : 여러 파일들을 경로로 입력할때, 각 파일들을 구분해주는 구분자를 os에 맞게 입력해주는 필드. String으로 표현되어ㅣㅆ다.
								ㄴ ex) wnidow에선 ';', unix에선 ';' 같은것.
							ㄴ public static final char pathSeparatorChar : pathSeparator와 같은데 char형으로 표현된것.
						ㄴ 생성자 )
							ㄴ new File ( String pathname );
								ㄴ pathname에 해당하는 File인스턴스를 만든다.
								ㄴ pathname는 파일의 경로를 의미하며, 실제 파일이 있건 없건 생성자 인자로 넘겨줄 수 있다. 실제파일이 없으면 빈 File인스턴스가 생기는것.
							ㄴ new File ( File parent, String filename ) : filename이 실제 파일명이고 parent가 filename이 위치하는 경로정보를 담고있는 File 인스턴스가된다.
						ㄴ 메소드 )
							ㄴ exists() : File인스턴스에 해당 파일이 실제로 존재하는지 확인.
							ㄴ public boolean mkdir() : File 인스턴스의 (*경로 정보*)에 해당하는 디렉토리를 만든다.
							ㄴ public boolean mkdirs() : File인스턴스의 (*경로 정보*)에 해당하는 디렉토리를 만들되, (*경로 정보*)상에는 있으나 실제로는 존재하지 않는 부모 디렉토리가 있을 경우 이것들을 모두 같이 생성해준다.
							ㄴ public boolean renameTo ( File dest ) : 현재 File인스턴스의 파일의 이름을 넘어온 인자의 파일이름으로 변경한다.
								ㄴ 파일의 이름은 File인스턴스 생성시 인자로 전달한 pathname을 말하는 것이고, '경로정보'를 포함한다.
									ㄴ "C:\Users\이관춘\Desktop\aaa.txt"라는 pathname이면 파일이름은 보통 aaa.txt를 생각하지만 그 앞의 C:\Users\이관춘\Desktop 부분도 같이 변경된다.
								ㄴ 파일 경로는 같고 이름만 변경하면 일반적으로 생각하는 파일 이름만 변경하는 것이 된다.
							ㄴ public File[] listFiles() : 디렉터리에 존재하는 파일과 디렉토리들 정보를 반환한다.
					ㄴ 스트림 클래스들의 생성자 인자로 String을 직접입력하기보다 File인스턴스를 사용하면 유용하다.
			</pre>

			ㅇ 자바 정규식 <button>펼치기</button>
			<pre>
				ㅡ java.util.regex.Pattern을 이용하여 패턴을 확인한다.
					ㄴ 사용법 )
						ㄴ public static boolean Pattern.matchs ( (*regex식*), (*검증하려는 문자열*) )
							: 패턴이 일치하면 true반환.
				ㅡ 정규 표현식 )<button>펼치기</button>
				<pre>
					ㄴ 아래의 것들을 이용해 패턴을 나타낸다.
					ㄴ ^ : 문자열 시작
					ㄴ $ : 문자열 종료
					ㄴ . : 임의의 단 한문자를 나타냄. ex) h. => h다음 임의의 문자하나가 오는 패턴을 매칭. "hf", "ha"등. "h"는 안됨.
					ㄴ * : 앞의 문자가 0개 이상. ex) [0-9]* 	=>0~9까지의 숫자가 0개 이상인 패턴을 의미.
					ㄴ + : 앞의 문자가 1개 이상.
					ㄴ ? : 앞의 문자가 1개 이하.
					ㄴ [ ]
						ㄴ 문자의 집합,범위 등을 나타냄.
						ㄴ ex)
							ㄴ [abc] : a,b,c중 하나인 패턴
							ㄴ [a-z] : a부터z까지 중 하나인 패턴
							ㄴ [^abc] : a,b,c를 제외한 다른 문자인 패턴
							ㄴ [a-zA-Z] : a부터z까지거나 A부터 Z까지거나인 패턴
							ㄴ [a-z&&[def]] : &&로 교집합처리가 되어 d,e,f중 하나인 패턴이된다.
					ㄴ { } : 횟수 또는 범위를 의미
						ㄴ ex)	\d{2,3} : 숫자정수 개수가 2~3개인 패턴
							\d{2,} : 2개 이상
							\d{2} : 딱 2개.
					ㄴ \ : 정규표현식에서 특수한 기능을 하는 문자. \(*일반문자*) 이면 특수하게 약속된 문자로 취급하고(\d, \w등), \(*특수문자*) 이면, 특수문자 자체를  의미한다.
						ㄴ \w : 알파벳이나 숫자
						ㄴ \W : 알파벳이나 숫자를 제외한 문자.
						ㄴ \d : 숫자 0~9
						ㄴ \D : 숫자를 제외한 문자.
						ㄴ ~~~~~
					ㄴ 정규식 그룹화 )
						ㄴ ()을 이용. ()안의 문자열은 하나로 묶어서 다룬다.
						ㄴ ex) '카츠동', '규동', '부타동'중에 하나인지 확인하려면, regex = (카츠 | 규 | 부타) (동) 으로 하면된다.
							(카츠 |규|부타)가 하나로 묶이고 (동)이 하나로 묶인다.
					ㄴ Lookahead ??? )
						ㄴ
					ㄴ 자주쓰이는 정규식 패턴 )
						ㄴ 휴대전화번호 : ^01(0|1|[6-9]) - (\d{3,4}) - [0-9]{4}$
						ㄴ 숫자만 : ^[0-9]*$
						ㄴ 영어만 : ^[a-zA-Z]*$
						ㄴ 한글만 : ^[가-힣]*$
						ㄴ 이메일 : \\w+@\\w+\\.\\w+(\\.\\w+)?
						ㄴ 주민번호 : \d{6} \- [1-4]\d{6}
				</pre>
			</pre>

			ㅇ 명령어 'java'
				ㅡ 자바 어플리케이션을 실행하는 명령어이다.
				ㅡ public static void main(String[] args) 메소드가 있어야한다.
				ㅡ 디폴트로, java [ (*옵션*) ] (*클래스명*) [ (*매개변수*) ]형태로 실행한다.
					ㄴ (*클래스명*)은 fully qualified class이다. 패키지가 있으면 이것까지 써야하는거.
					ㄴ -jar 옵션이 붙었으면 (*클래스명*)이 아닌 JAR파일명이온다.
					ㄴ 매개변수는 당연히 main메소드의 인자로 들어간다.
				ㅡ java runtime은 startup class를 찾고 나머지 클래스들은 가져와 사용한다.
					나머지 클래스들을 찾는 위치는 bootstrap class path, installed extension, user class path 세가지이다.

			ㅇ java classpath
				ㅡ CLASSPATH 변수는 프로그램에게 어디에 user classes가 있는지 알려주는 유일한 방법이다.
					ㄴ JRE,JDK의 클래스나 extension들은 bootstrap class path나 extensions directory에 잇다)
				ㅡ -cp 옵션을 통하여 class path를 추가할수도 있다. 해당 어플리케이션에만 적용되기때문에 권장된다한다.
					ㄴ CLASSPATH변수에 설정해두면 다른어플리케이션도 적용이 되므로.
					ㄴ ex) 	java -cp /usr/local/tomcat9~~/lib/~~.jar:/usr/local/~~/classes NoName2
						ㄴ -cp다음에 오는 path가 class path이다. 세미콜론(;)이 아닌 땡땡표시?( : )를 기준으로 여러 경로를 입력할 수 있다.
					ㄴ 여기에 적힌 경로를 참고하여 java명령어를 실행하는 듯하다. 따라서 import한 클래스들을 참고할 수 있는 경로는 물론이고 실행하려는
						class파일에 대한 경로도 있어야 하는 듯 하다.
			ㅇ 기타
				ㅡ immutable object, 불변 객체 )
					ㄴ '힙 영역'에 들어있는 '데이터 자체'가 변경되지 않는 객체를 의미한다.
					ㄴ 가령, 객체 A안에 num이란 필드가 들어있고, setterNum()이 정의되어있어 num값이 변경된다면 A가 들어있는 '힙 영역'안의 데이터가
						변경된것이므로 '불변 객체'가 아닌 '가변 객체'가 된다.
					ㄴ ????????????????????자세하게는 아직 잘 모르겠다.
						ㄴ 인스턴스의 참조변수를 필드로  가진경우, 그 필드의 참조값만 변경이 안되면 불변객체인지, 참조하는 인스턴스또한 변경이 안되어야 불변객체인지..?

			ㅇ JPA<button>more</button>
			<pre>
				ㅡ Java Persistence API
				ㅡ 자바에서 규정한 Persistence API에 대한 '표준'이다. (실구현체가 아닌)
					ㄴ spec, interface으로 따라야 하는 가이드라인을 명시해 둔 것.
					ㄴ 대표적 구현체가 HIbernate.
				ㅡ ~~~~~
				ㅡ Entity<button>more</button>
				<pre>
					ㄴ ~~~~~
					ㄴ 엔터티 관계 종류<button>more</button>
					<pre>
						ㄴ one-to-one )
							ㄴ

					</pre>
					ㄴ cascade 연산 <button>more</button>
					<pre>
						ㄴ 엔터티가 fk와 같이 다른쪽에 의존하고 있는 경우, 한 쪽 엔터티가 삭제되면 이에 의존하고 있는 다른 엔터티를 어떻게
						ㄴ 엔터티가 관계를 가지고 그 관계를 가진 엔터티에 의존성을 가지는 경우, 의존 대상인 엔터티의 처리에 따라
							하위 엔터티를 연달아 처리하는 것을 cascade 연산이라 한다.
						ㄴ 어떤 cascade
					</pre>
				</pre>

				ㅡ Entity 상속<button>more</button>
				<pre>
					ㄴ
				</pre>

				ㅡ Entity 관리<button>more</button>
				<pre>
					ㄴ entity들은 javax.persistence.EntityManager에 의해 관리된다.
					ㄴ 각 entityManager는 한 persistence context에 연결된다.
					ㄴ Persistence context )
						ㄴ 관리 되고 있는 entity들의 집합. ?????
						ㄴ 이 안의 엔터티들이 EntityManager에 의해 관리된다함.
						ㄴ 엔터티들이 store에서 불러와지거나 저장되는 일종의 캐시?
						ㄴ ????? 저장소와 어플 사이에 위치한다.
						ㄴ context는 관리되고 있는 엔터티의 변화를 트랜잭션 중에 추적하고 있다가, 트랜잭션 완료시 저장소로 flush한다.
						ㄴ 일종의 캐시.
							ㄴ 모든 엔터티와 관련한 업데이트, 생성, 삭제 등을 실 db에 대고 하지 않고 일종의 캐시 상에 적용한 다음
								모든 연산이 끝났을 때 한번에 db에 적용하는 방식.
							ㄴ 이 캐시에 대한 관리, 연산을 ENtityManager가 하는 것.
						ㄴ 스코프 )
							ㄴ transaction-scope persistence context )
								ㄴ 트랜잭션에 묶여서, 트랜잭션 완료시 context안의 내용이 바로 저장소에 반영된다.
								ㄴ 디폴트로 사용되는 스코프.
							ㄴ extended-scope persistence context )
					ㄴ EntityManager )
						ㄴ persistence context와 상호작용하게 해주는 interface
						ㄴ 이것의 메소드를 통해 엔터티 인스턴스를 생성, 삭제하거나 찾는 등의 기능 가능.
						ㄴ ????? 두 종류? )
							ㄴ??? container-managed entityManager )
								ㄴ 하나의 JTA 트랜잭션 내의 특정 EntityManager 인스턴스가 있다하면,
									이 인스턴스의 persistence context가 이 인스턴스를 사용하는 어플리케이션의 모든 컴포넌트에게 컨테이너에 의해 자동으로 전파된다???
							ㄴ ??? application-managed entitymanager )
								ㄴ

					ㄴ ????? Container-Managed Entity Manager )
						ㄴ
					ㄴ ????? Application-Managed Entity Manager )
					ㄴ EntityManager를 이용해 Entity 찾기 )
						ㄴ EntityManager.find()는 엔터티의 pk를 이용해 저장소로부터 엔터티를 찾는다.
					ㄴ 엔터티 인스턴스 라이프사이클 )
						ㄴ 상태 )
							ㄴ new : ????? persistence id가 없고 persistence context에 연결되지도 않음.
							ㄴ managed : persistence id를 가지고, persistence context에 연결됨.
							ㄴ detached : ????? id를 가지지만, 현재 persistence context에 연결되지 않음.
							ㄴ remove : id를 가지고 context에도 연결. 곧 저장소에서 제거될 예정.
						ㄴ 새로운 엔터티는 persist()호출 또는 cascade=PERSIST, ALL인 관계된 엔터티의 persist()호출을 통해
							관리되기 시작한다.
							ㄴ persist()르 ㄹ호출한 트랜잭션이 완료시, 이 관리되는 엔터티가 db에 저장됨.
							ㄴ 이미 관리되는 엔터티인 경우 persist()는 무시됨. ????? 관계된 casecade=PERSIST, ALL인 엔터티이어도?
							ㄴ ??? persist() 연산은 cascade=All 또는 PERSIST인 관계를 맺고 있는 모든 엔터티에 전파된다.
						ㄴ 엔터티 인스턴스 제거 )
							ㄴ 관리 중인 엔터티 인스턴스는 remove()호출이나 cascade로 인한 remove연산을 통해 제거된다.
					ㄴ 참고 )<button>more</button>
					<pre>
						ㄴ https://docs.oracle.com/javaee/6/tutorial/doc/bnbqw.html
						ㄴ https://tomee.apache.org/jpa-concepts.html
					</pre>
				</pre>

			</pre>

			ㅇ 라이브러리 정리<button>more</button>
			<pre>
				ㅡ com.drewnoakes 의 'metadata-extractor'
					미디어 파일로부터 메타데이터를 읽어들이는 라이브러리.<button>more</button>
				<pre>
					ㄴ <a href="https://github.com/drewnoakes/metadata-extractor" target="_blank">https://github.com/drewnoakes/metadata-extractor</a>
					ㄴ 설치 )
						ㄴ 메이븐 )
							< dependency>
							< groupId>com.drewnoakes< /groupId>
							< artifactId>metadata-extractor< /artifactId>
							< version>2.16.0< /version>
							< /dependency>
						ㄴ gradle )
							compile group: 'com.drewnoakes', name: 'metadata-extractor', version: '2.9.1'
					ㄴ ex )
						ㄴ 이미지 파일로부터 회전 정보 읽기. (모바일 촬영 이미지들은 찍는 각도에 따라 회전이 된다)
							int orientation2 = 1;
							int width = 0; // 이미지의 가로폭
							int height = 0; // 이미지의 세로높이

							Metadata metadata; // 이미지 메타 데이터 객체
							Directory directory; // 이미지의 Exif 데이터를 읽기 위한 객체
							JpegDirectory jpegDirectory; // JPG 이미지 정보를 읽기 위한 객체

							try {
								metadata = ImageMetadataReader.readMetadata(uploadFile);
								directory = metadata.getFirstDirectoryOfType(ExifIFD0Directory.class);
								jpegDirectory = metadata.getFirstDirectoryOfType(JpegDirectory.class);
								if(directory != null){
									orientation2 = directory.getInt(ExifIFD0Directory.TAG_ORIENTATION); // 회전정보, 1. 0도, 3. 180도, 6. 270도, 8. 90도 회전한 정보
								}
							}catch (Exception e) {
								orientation2=1;
							}
				</pre>

				ㅡ JDBC API<button>more</button>
				<pre>
					ㄴ ~~~
					ㄴ Statement
						ㄴ ~~~
						ㄴ Batch Update
							ㄴ 여러 update query를 하나씩이 아닌 한번에 db로 전송하는 기능.
							ㄴ 성능상의 이점이 있다.
							ㄴ ex )
								Statement stmt = con.createStatement();
								con.setAutoCommit(false);

								stmt.addBatch("INSERT INTO employees VALUES (1000, 'Joe Jones')");
								stmt.addBatch("INSERT INTO departments VALUES (260, 'Shoe')");
								stmt.addBatch("INSERT INTO emp_dept VALUES (1000, '260')");

								int [] updateCounts = stmt.executeBatch();  // insert query 3개가 한번에 나간다.
						ㄴ ~~~
					ㄴ ~~~

				</pre>
			</pre>

			ㅡ 무제 ) <button>more</button>
				ㄴ jar파일 수정하기 )
					ㄴ 기본적으로 그냥 압축 풀고, 수정하고 다시 jar로 압축하면 된다. 압축은 jar명령어로 해도 되고 다른 걸로 해도 되고.
					ㄴ 다시 압축시, 자바 버전에 주의해야 겠다.

		</pre>

		CSAPP<button>더보기</button>
		<pre>
			chapter10. System Level I/O<button>더보기</button>
			<pre>
				ㅡ i/o란 메인메모리의 데이터를 디스크드라이브, 터미널, 네트워크와 같은 외부장치르 복사하는 프로세스를 말한다.
					ㄴ input은 외부 장치로부터 메인메모리로 복사하는것. output은 그 반대.
				ㅡ 모든 언어의 런타임 시스템은 고수준 레벨의 io함수를 제공한다. (printf, scanf같이)
					ㄴ 그리고 이런 고수준 레벨 io함수들은 system 레벨의 Unix I/O함수를 통하여 구현된다. (Unix시스템에선)
				ㅡ Unix I/O를 배워야 하는 이유 )
					ㄴ io를 이해하는것이 다른 시스템이해에  도움이 된다.
						ㄴ i/o는 시스템의 연산과 필수불가결한 관계이다.
						ㄴ 프로세스의 생성과 실행은 io와 상호 의존성을 가진다. 따라서 어느한쪽을 이해하려하면 다른한쪽을 이해해야한다.
					ㄴ unix i/o만 할 수 있는것들이 있다)
						ㄴ 파일 메타데이터에 접근하거나 네트워킹 프로그래밍을 할때에는 이를 사용해야한다.
				ㅇ Unix I/O
					ㅡ 모든 io장치들 (네트워크, 디스크, 터미널 등)은 '파일'로서 설계되었다.
					ㅡ 따라서 모든 input, output은 파일에 대한 read,write로 작동한다.
					ㅡ 이런 바탕으로 인해 unix 커널에선 단순하고 로우레벨의 인터페이스 Unix i/o가 나올수있었다하며, unix io는 모든 input output을
						통일되고 일관된방식으로 수행할수 있게해준다함.
					ㅡ 파일 열기, 읽기, 쓰기 동작 )
						ㄴ 열기 )
							ㄴ 어플리케이션이 커널에게 io장치에 대한 접근을 요청.
							ㄴ 커널은 해당 파일에 대한 디스크립터(음이아닌 정수)를 반환해주며, 이후 연산에서 이 숫자가 해당 파일을 가리키는 값이 된다.
							ㄴ 유닉스에서 모든 프로세스는 stdin, stdout, stderr 이렇게 세가지 파일이 열린상태로 시작된다.
						ㄴ 읽기 쓰기 )
							ㄴ 열린 파일에 대해 커널은 file position(파일의 바이트 커서같은거)을 추적하며, 이는 처음에 0으로 설정.
							ㄴ 어플리케이션은 seek연산을 통해 커서의 위치를 설정할 수 있다.
							ㄴ 읽기 연산은 n 바이트 만큼의 데이터를 파일에서 메모리로 복사하고 file position k를 n만큼 옳겨가며 연산한다.
							ㄴ k가 파일의 크기(m)을 초과하면 (k>m) EOF(end of file)이 발생한다.
							ㄴ 쓰기연산은 마찬가지로 n바이트만큼 메모리에서 파일로 복사를하며, k위치에 추가한다.
						ㄴ 파일 닫기 )
							ㄴ 어플리케이션이 파일에 대한 접근을 마치면 close요청을 커널에게 보낸다.
							ㄴ 커널은 파일이 열릴때 만들었던 data structure을 해제하고 파일 디스크립터를 풀로 돌려놓음으로서 닫기연산을 한다.
							ㄴ 프로세스가 종료되면 커널은 자동으로 모든 열린 파일을 닫는다.



			</pre>
			chapter11. network porgramming<button>더보기</button>
			<pre>
				ㅡ 컴퓨터 장치에서 network adapter가 잇어서 이곳을 통해 네트워크와데이터를 주고받는다고한다.
					ㄴ 이곳의 io버스가 네트워크와의 물리적 인터페이스를 제공한다.
					ㄴ 데이터는 adapter로부터 io버스로, 메모리로 복사된다. 반대도 마찬가지.
				ㅡ LAN (Local Area Network)
					ㄴ 빌딩이나 대학교 같은 범위에서 사용되는 네트워크
					ㄴ 가장 대표적인 기술은 'Ethernet'
					ㄴ Ethernet
						ㄴ 전선과 '허브'로 구성되어있다.
						ㄴ 전선의 한쪽끝은 허브의 포트와 연결되어있고, 나머지는 위에서말한 호스트의 network adapter에 연결.
						ㄴ 허브는 포트로부터 온 데이터들을 복사한다.
						ㄴ 한 이더넷은 'bridge'를 통해 다른 LAN과 연결이 가능하다. 이 방식을 통해 빌딩 전체나 대학교전체를 연결하는것.
				ㅡ 라우터
					ㄴ 이 양립할수없는 LAN들을 '라우터'라는 특별한 컴퓨터를 통해 연결이 가능하고 이를 '인터넷'이라 부름??
					ㄴ 라우터는 각 네트워크마다 이에 해당하는 하나의 포트를 가지고 있다.
					ㄴ WAN (Wide Area Networks) : LAN보다 범위가 지리적으로 크기때문에 이렇게 이름붙었다.
					ㄴ LAN과 WAN들이 모여서 '인터넷'이 된다.
				ㅡ 인터넷의 큰 특징은 서로 다른 기술들으로 이루어진 LAN, WAN들로 구성될 수 있다는 것이다.
					ㄴ 이것이 가능한 이유는 호스트와 라우터에서 동작하는 프로토콜 소프트웨어 계층 덕분이다.
					ㄴ 이 소프트웨어는 호스트와 라우터들이 데이터를 서로 전송하기위해 어떻게 상호작용해야하는지를 관리하는 '프로토콜'을 구현한다.
				ㅡ 프로토콜
					ㄴ 프로토콜은 두가지 기본 요소를 제공해야한다.
					ㄴ Naming scheme : 기술이 다르면 호스트에 주소를 할당하는 방식도 다르기마련인데, 프로토콜에서 이 차이점을 해결하여 유일한 주소를
						할당하여야 한다.
					ㄴ Dilivery mechanism : 기술이 다르면 전선의 전송하려는 비트들을 인코딩하는 방식이 다르기마련. 프로토콜은 이를 '패킷'이라 불리는
						작은 데이터 덩어리로 비트들을 묶도록 하여야한다. 패킷은 'header'와 payload로 이루어져 잇다.
					ㄴ 프로토콜에 따른 데이터 전송과정 : 890~891페이지.
				ㅡ 각각의 호스트들은 프로토콜을 구현하는 소프트웨어를 실행한다.
				ㅡ 현대의 대부분의 컴퓨터 시스템들은 tcp/ip 프로토콜을 구현하는 소프트웨어를 지원한다.
				ㅡ client server는 '소켓 인터페이스'와 unix i/o function을 이용하여 소통한다.
					ㄴ 소켓 인터페이스는 커널단에서 제공하는 시스템콜로서, 내부적으로 여러 커널모드의 함수들을 호출한다.
			</pre>
		</pre>

		network<button>더보기</button>
		<pre>
			ㅇ 데이터 통신 <button>더보기</button>
			<pre>
				ㅡ 데이터 통신이란 : 통신 매채를 사용하여 두 장치간에 데이터를 주고받는 것.
				ㅡ 데이터 통신의 기본 특성
					ㄴ 전달 : 정확한 목적지에 전달
					ㄴ 정확성 : 데이터를 정확하게 전달해야한다. 중간에 변형되어서는 안된다.
					ㄴ 적시성 : 적절한 시간내에 전달
					ㄴ 파형 난조 : 패킷 도착 시간이 조금식차이가나 품질이 일정치않음.
				ㅡ 구성요소
					ㄴ 메세지, 송신지, 수신지, 프로토콜, 전송매체
					ㄴ 프로토콜 : 통신을 하기위한 약속. 어떤식으로 통,수신을 하기로하자는 규약.
					ㄴ 메세지 : 통신 대상이 되는 정보. 그림 소리 문자 등등.
					ㄴ 송, 수신자
					ㄴ 전송매체 : 메세지가 이동하는 물리적 경로.
				ㅡ 데이터 표현 : 전송되는 데이터의 종류, 형태
					ㄴ 문자, 수, 이미지, 음성, 영상
					ㄴ 문자 : 코드, 아스키, 유니코드등 비트의 순차열로 표현
					ㄴ 숫자 : 비트로 표현.
					ㄴ 이미지 : 픽셀, 해상도를 통해 표현.
					ㄴ 음성 : ??? PCM 변환 등을 통해 비트로 전달되나
					ㄴ 동영상 : ???모름.
				ㅡ 데이터 흐름 방향
					ㄴ 단방향 방식 : 말그대로. 한쪽은 수신만, 나머지한쪽은 송신만가능. 방송, 키보드 모니터 등.
					ㄴ 반이중 방식(half-duplex mode) : 통신개체들이 송수신 모두 가능하나, 한번에 한가지 역할만 가능한방식. 무전기같은거.
					ㄴ 전이중 방식(full-duplex mode) : 통신개체들이 송수신 모두 가능하고, 항상 두 역할을 수행할수 있는것. 전화같은거.
			</pre>

			ㅇ 네트워크 <button>더보기</button>
			<pre>
				ㄴ 통신하는개체가 한쌍이 아니라 여러개가 되면 네트워크. 여러 컴퓨터들이 서로 통신가능하게 연결되어 있는것.
				ㄴ 이를 통해 '분산처리'를 할수있다. (분산처리란? 하나의 작업을 여러컴퓨터들이 나누어서 처리하는 것)
				ㄴ 여러 네트워크들이 있고 이것들을 평가하는 기준이 있다.
					ㄴ 네트워크 평가기준)
						ㄴ 성능 : 전달시간, 응답시간, 처리율(단위시간동안 얼마나 많은데이터 통신가능한지), 지연
						ㄴ 신뢰성(reliability) : 네트워크가 얼마나 믿을만한지. 잘작동되고, 고장안나고, 고장나도 금방고쳐지고 등.
						ㄴ 보안
				ㅡ 네트워크의 분류 )
					ㄴ 물리적 구조에 따른 유형분류 )
						ㄴ 연결형태
							ㄴ 점대점( point to point) : 링크 하나에 단 두 기기만 통신.
							ㄴ 다중점 (multipoint) : 링크 하나에 여러 기기 연결.
						ㄴ 접속형태
							ㄴ 그물형 : 네트워크안에있는 모든 노드가 서로다른 모든 노드와 연결되어잇는형태.
								ㄴ 모든 장치는 다른 모든 장치와 점대점 연결이 되고, 안정성, 보안 등의 장점이있으나, 자원이 많이듬.
							ㄴ 스타형 (일명 hub형) : 허브라는 중앙제어장치를 중심으로 노드들이 연결되어있는형태. 허브와 노드들은 점대점 연결.
								노드(장치)간의 직접통신은 안되고 허브를통해서만 가능. 그물형과반대로 자원이 적게들지만 허브고장시 전체가 멈춘자는 단점.
							ㄴ 버스형 : 다중점형태. 선이 있고 그 선 중간중간에 '탭'이 있어 이부분에 컴퓨터가 연결된 방식.
								설치가 쉽고 가장적은 양의 케이블을 사용하여 자원이 가장적게든다. 재구성이 어려움.
							ㄴ 링형 : 버스형태에서 케이블의 끝이 없이 원형으로 되어있는형태. 신호가 한바퀴 돌아감.
								ㄴ 자신의 양쪽에 위치한 장치와 점대점회선
								ㄴ ?? 중계기?
					ㄴ 네티워크 망의 규모에따른 유형분류
						ㄴ Nanoscale network
							ㄴ 생체 시스템 같은 곳에서 사용되는 단위.
						ㄴ Personal area network (PAN)
							ㄴ 한 개인이 사용하는 범위 내에서 서로 다른 컴퓨터나 장치 사이의 네트워크. 약 10미터 이내.
							ㄴ 데스크탑, 프린터, 핸드폰 등.
							ㄴ 블루투스나 적외선, usb이용.
							ㄴ wired 장치일 수도, wireless 장치 일 수도 있다.
						ㄴ Local-area network (LAN), 근거리 통신망
							ㄴ 집, 학교, 건물하나, 인접한 여러 건물 등.
							ㄴ wired인 경우 대부분 '이더넷'기반.
							ㄴ WAN과의 차이는 데이터 전송량, 규모의 크기, '임대 라인'의 사용.
								ㄴ '임대 라인'이란 개인 회선, 사업적으로 임대해 주는 회선?
							ㄴ 링형, 버스형, 스타형 사용.
						ㄴ Home area network (HAN)
							ㄴ 한 가정 안에서의 LAN을 의미. 개인 컴퓨터들이나 모바일 장치, 프린터 등이 연결.
						ㄴ ????? Storage area network (SAN)
							ㄴ ????? consolidated, block-level의 데이터 storage에 대한 접근을 제공하는 목적으로 사용되는 네트워크이다.
							ㄴ ?????
						ㄴ Campus area network (CAN)
							ㄴ 네트워크 장비(스위치, 라우터)와 전송 장비(optical fiber, copper plant 등)을 통해 특정 구역에 한해서
								LAN들이 서로 연결된 네트워크.
							ㄴ 기업, 대학교, 정부 규모에서 이런 형태가 보인다.
						ㄴ Backbone network
							ㄴ 전송량이 큰 장치가 포함된 네트워크?
							ㄴ 여러 LAN들이나 subnet들을 하나로 연결한다.
							ㄴ 큰 회사나 대학교, 빌딩들 단위의 규모.
								ㄴ 이런 큰 규모에서 각각의 지점들의 LAN들을 연결된 네트워크를 말함.
									(이더넷이던, 무선이던 그 LAN들을 연결해주는 네트워크 자체를 의미)
						ㄴ Metapo~~-area network (MAN) : 도시하나정도.
						ㄴ Wid-area network (WAN), 광역통신망
							ㄴ 국가, 대륙, 전세계 범위의 규모.
							ㄴ 거리가 매우멀어 설치어렵
							ㄴ 위성, 해저케이블, 전파망 등사용
							ㄴ 대부분 점대점연결. 또는 교환형이다.
							ㄴ 교환형 (switched) WAN : 설치에 비용이 많이들어 하나깔아놓고 망?을 변경해가면서 사용하는방식?
					* open network, closed network
						ㅡ open network : 여러 그룹들이 표준에 따라 모두 사용하기 위해 만든것.
						ㅡ closed network : 특정 벤더들이 그들만 사용하기 위해 만든것.
			</pre>

			ㅇ 인터넷<button>더보기</button>
			<pre>
				ㅡ internetowrk : 두 개 이상의 네트워크가 연결되어 있는 것을 말함.
				ㅡ 인터넷 역사
					ㄴ 원래는 internetwork를 구현한 최초의 사례가 미국의 '아파넷'이었는데, 널리쓰이다보니 굳이 구분하지않고 그냥 '인터넷'이라고 부르는듯하다.
				ㅡ 표준 )
					ㄴ 인터넷 표준을 제시하고있는 기구들
						ㄴ IEEE, IETF, ITU, ISO, W3C 등
					ㄴ 각 계층마다 표준안을 담당하고있는 단체가 다르다함.
						ㄴ application 계층은 W3C
						ㄴ transport, internet은 IETF
						ㄴ data link는 IEEE
					ㄴ IETF에 의한 표준 )
						ㄴ 처음 '인터넷 초안(draft standard)' 형태로 IETF에 제안된다.
						ㄴ 그다음 검토를 거쳐 '인터넷 표준(internet standard)'가 된다.

			* WWW, World Wide Web(웹)
				ㄴ 웹이란? 인터넷상의 정보를 하이퍼텍스트 방식과 멀티미디어 환경에서 검색할 수 있게 해주는 정보검색 시스템이다.
					ㄴ 웹 브라우저를 통해 웹페이지를 검색하고 이 페이지에서 여러 다른페이지들로 이동하며 정보를 보게해주는것이 웹을 이용하고있는것.
				ㄴ 인터넷 상의 여러 서비스들중 하나. (다른 서비스들로는 메일, ftp등)
			</pre>

			ㅇ 프로토콜 <button>더보기</button>
			<pre>
				ㅡ 통신을 하기위한 약속. 어떤식으로 통,수신을 하기로하자는 규칙.
					ㄴ 프로토콜은 단순히 통신하는데 사용되는 규칙일 뿐이다.
					ㄴ 이 규칙들은 계층에 따라서 소프트웨어나 기계어 또는 하드웨어를 이용해 구현된다. (어플리케이션, 전송계층 등은 소프트웨어, 데이터링크층은 하드웨어 이런식)
					ㄴ https://stackoverflow.com/questions/1942304/how-are-network-protocols-implemented

				* protocol suite
					ㅡ 일반적으로 여러 프로토콜을 같이사용하게 되며 이런걸 묶어서 protocol suite라고도 한다.
					ㅡ ex) TCP/IP Internet protocol suite
				ㅡ 프로토콜 계층 <button>more</button>
				<pre>
					ㅡ 통신을 여러 계층으로 나누어서 다루는 방식
						ㄴ 커다란 프로그램을 모듈화하듯이 프로토콜역시 여러계층으로 나뉘어 각각의 기능들을 별도의 프로토콜로 구현하여 기능을 수행한다.
					ㅡ 이유 : 각 계층의 모듈화, 독립성.
					ㅡ 계층화 원칙
						ㄴ 각 계층은 한 종류의 상반되는 두가지 작업수행이 가능해야한다. 암호화와 복호화, 보내기와 받기 등
						ㄴ 각 계층의 객체는 동일해야 한다. (전달되는 데이터 말한는듯)
					ㅡ 논리적 연결 : 각 계층끼리 연결된 것을 말함.
					* 인터넷 프로토콜 스위트, Internet Protocol Suite )
						ㅡ 인터넷에서 사용되는 프로토콜들의 모음을 말한다.
					ㅡ TCP/IP 프로토콜 슈트 )
						ㄴ TCP/IP 프로토콜을 중심으로 많이 사용되는 프로토콜의 모음을 말한다.
							ㄴ 가장 널리 쓰이는 방식이다.
						ㄴ TCP/IP 계층 : TCP/IP 프로토콜 슈트에 따라 인터넷 계층을 나눈것을 말한다. 일반적으로 다음과 같다.
						<img src="image/네트워크_5계층.png" height="300px"/>
						* 기타지식(10)
							ㅡ Switch	가 LAN에서 쓰인거고 라우터가 WAN에서 쓰이는것.
							ㅡ 라우터를 통해 인터넷 상에서 통신하는 것.
						ㄴ 한 어플리케이션에서 다른에플리케이션으로 데이터를 보내려는것.
						ㄴ physical : 실제 구리선같은 물리적 선을통한 통신 계층. 이계층부터 하드웨어. 그 위는 소프트웨어.
						ㄴ 계층들의 논리적 연결 )
							ㄴ data계층, 물리 계층은 라우터까지만 논리적 연결이 되어잇음.
							ㄴ 나머지는 소스와 목적지까지가 연결.
						ㄴ 계층별 객체)
							ㄴ 각 계층마다 전달하는 정보를부르는 이름이 있다.
							ㄴ 어플리케이션단 : 메세지, 전송단 = 데이터그램 또는 세그먼트, 네트워크단 = 데이터그램, 데이터단 = 프레임, 물리단 = 비트
					ㅡ 각 계층 설명 )
						ㅡ 물리층)
							ㄴ 비트들의 묶음인 '프레임'이란 단위.
							ㄴ 이 '프레임'을 다음 목적지로 전달.
							ㄴ 다양한 프로토콜 사용가능
						ㅡ 데이터 링크 층 )
							ㄴ IEEE 표준에 의해 두개의 sub-layer로 나뉜다.
								ㄴ LLC, Logical Link Control )
									ㄴ addressing, demultiplexing기능을 담당.
								ㄴ MAC, Media Access Control )
									ㄴ 공유매체에 어떻게 접근해야하는지를 정한 표준.
							ㄴ MAC 주소 )
								ㄴ 2계층과 관련있는 Ethernet에서 사용하는 주소.
								ㄴ '물리적 주소' 또는 'Ethernet 주소'라고도 불린다.
								ㄴ NIC (network interface card)에 따라 할당된다.
								ㄴ 구성 )
									ㄴ 48bit로 구성. 12자리 십진수로도 표현.
									ㄴ 절반은 NIC를 생성한 벤더 등의 고유주소와 관련된 번호 할당. (이를 OUI라함)
									ㄴ OUI의 맨앞 1바이트는 주소의 종류(unicast인지 multicast인지 ???글로벌인지 로컬인지)를 나타낸다.
									ㄴ 나머지 절반이 NIC의 고유번호.
									* 유니캐스트, 멀티캐스트, 브로드캐스트 주소 )
										ㅡ 주소의 종류를 나타내며, 누구한테 보내는지에 따라 분류.
										ㅡ 유니캐스트 : 네트워크상의 특정 한 컴퓨터에게 보내는 주소
										ㅡ 브로드캐스트 : 네트워크상의 모든 컴퓨터에게 보내는 주소
										ㅡ 멀티캐스트 : 네트워크상의 여러 컴퓨터에게 보내는 주소.
							ㄴ MAC 프로토콜 )
								ㄴ 공유 매체에 노드가 어떻게 접근해야하는지에 대한 규칙을 지정한 2계층의 프로토콜.
								ㄴ ~~~~~~~~~~~~~~~~~~~~~
							ㄴ '프레임' 전달 책임.
							ㄴ 상위 계층으로부터 '데이터그램'을 받아 '프레임'으로 캡슐화
							ㄴ 다양한 링크층 프로토콜에 따라 서로 다른 서비스 제공.
						ㅡ 네트워크 층)
							ㄴ 어플리케이션에 관계없고, 컴퓨터를 대상으로 통신한다.
							ㄴ 흐름제어, 오류제어, 혼잡제어 기능을 제공한다.
							ㄴ 대표적 프로토콜로 IP, Internet protocol.
							ㄴ DHCP : IP주소를 동적으로 할당해주는것. 인터넷쓰려면 기본적으로IP필요.
						ㅡ 전송 층)
							ㄴ '통신 종단'이라고 하는게 있고 그걸대상으로 통신한다.
							ㄴ 응용층으로부터 메세지를 전달받아 '패킷'으로 캡슐화.
							ㄴ 4계층에서의 통신 방식 두가지 )
								ㄴ stream 패러다임
									ㄴ 송수신자가 연결된상태에서 통신
									ㄴ 전화통화와 비슷
									ㄴ 1대1통신
									ㄴ 일련의 바이트들을 전송
									ㄴ 보내는 데이터의 크기도 정해져있지않음.
									ㄴ 대부분의 응용프로그램에서 사용
									ㄴ TCP 프로토콜에서사용
								ㄴ message 패러다임
									ㄴ 송수신자가 연결되지않은상태에서 통신
									ㄴ 엽서와 비슷
									ㄴ 다 대 다 통신
									ㄴ 적절한크기의 메세지를 전송
										ㄴ 세가지 방식으로 전송 : Unicast(1대1), Multicast(1대 다), Broadcast(1대 모두)
									ㄴ 특정한 목정의 응용프로그램에서 사용
									ㄴ UDP프로토콜에서 사용.
									ㄴ 메세지가 lost, duplicated, out-of-order될 수 있다.
							ㄴ 대표적 프로토콜로 TCP, UDP, SCTP
							ㄴ TCP : 연결형. 흐름제어, 오류제어, 혼잡제어 제공.
							ㄴ UDP : 비연결형. 편지같은것. 그냥 전달만해줌. 순서나 중간에없어지는것등을 신경안씀. (제어 서비스 제공 안함)
						ㅡ 응용 층)
							ㄴ 프로세스간 통신
							ㄴ 대표적 프로토콜 : HTTP, SMTP, FTP, DNS, TELNET, SSH, SNMP
					ㅡ 캡슐화 역캡슐화)
						ㄴ 캡슐화 : 상위 계층의 데이터에 통신에 필요한 여러가지 정보가 담긴 '헤더'를 추가로 붙이는 작업.
						ㄴ 역캡슐화 : 캡슐화한것을 푸는 과정.
						ㄴ 상위계층으로부터 받은 데이터를 'payload'라고 한다.
					ㅡ 주소지정)
						ㄴ 정보르 받는 목ㅈ거지가 누군지 알려주기위해 주소사용
						ㄴ 어플리케이션층 = 이름, 전송층 = 포트번호, network계층 = logical address(ip 주소), 데이터 링크 층 = 링크층 주소
					ㅡ 다중화, 역다중화)
						ㄴ 계층마다 사용하는 프로토콜들이 다양하고 여러가지라, 계층 넘어갈때 이를 잘 처리해주어야한다.
						ㄴ 소스쪽에서 이런걸 하는것을 다중화라 하고 목적지쪽에선 역다중화라한다.
				</pre>

				ㅡ 인터넷 프로토콜 스위트, Internet Protocol Suite<button>더보기</button>
				<pre>
					ㄴ 인터넷에서 사용되는 통신규약(프로토콜)의 모음을 말함.
						ㄴ TCP/IP가 가장 많이 사용되기때문에 TCP/IP프로토콜 슈트라고도 불린다.
					ㄴ 종류 )
						ㄴ ~~~~~
						ㄴ HTTP <button>더보기</button>
						<pre>
							ㄴ ~~~~~
							ㄴ 헤더<button>더보기</button>
							<pre>
								ㄴ ~~~~~
								ㄴ Content-Type )
									ㄴ 개요 )content에 들은 내용이 어떤 유형의 데이터인지 알려주는 필드.
									ㄴ 구성 )
										ㄴ media-type )
											ㄴ 리소스 혹은 데이터의 MIME type
											* MIME type )<button>더보기</button>
											<pre>
												ㅡ https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/MIME_types 참고
												ㅡ 개요 )
													ㄴ  Multipurpose Internet Mail Extensions or MIME type 또는 media type
													ㄴ IANA라는 단체에서 이 MIME type에 대한 정의를 관리한다.
													ㄴ 브라우저는 파일 확장자가 아닌 MIME type을 기준으로 url을 처리한다.
												ㅡ 구조 )
													ㄴ 기본적인형태로, (*type*)/(*subtype*) 형태로, whitespace없이 스트링으로 이루어져있다.
														ㄴex) text/html, text/plain,
													ㄴ (*type*) )
														ㄴ video, text 등 데이터타입이 속한 일반적인 대분류같은것.
														ㄴ 두개의 클래스로 분류된다 : 'discrete', 'multipart'
															ㄴ discrete : text파일하나, 오디오파일 하나 등, 파일이 하나인 타입을 말한다.
																ㄴ 종류 )
																	ㄴ application : 다른 타입으로 정할수없는 모든 종류의 파일이 속한다.
																		어떤 특정 방법으로 해석되거나실행될수있는 파일, 다른 특정 프로그램을
																		필요로하는 이진파일 등.
																		ㄴ ex) application/pdf, application/pkcs8, and application/zip
																	ㄴ audio : audio, music파일. ex) audio/mpeg, audio/vorbis
																	ㄴ example :
																	ㄴ font : 폰트 타입 데이터. ex) font/woff, font/ttf, and font/otf.
																	ㄴ image : 이미지, 그래픽 데이터. bitmap vector, animated image, gif등 포함
																		ㄴ ex) image/jpeg, image/png, and image/svg+xml.
																	ㄴ model : 3D object나 scene. ex) model/3mf and model/vml
																	ㄴ text : 텍스트로만 이루어진 데이터. 사람이 읽는 텍스트건 소스코드건.
																		ㄴ ex) text/plain, text/csv, and text/html.
																	ㄴ video : mp4와 같은 비디오 파일.
															ㄴ multipart : 여러개의 파일, 또는 여러개의 타입들로 이루어진 타입임을 나타낸다.
																ㄴ 종류 )
																	ㄴ message : ?????
																	ㄴ multipart : 여러종류의 MIME type을 가진 여러 컴포넌트들이 들어있는 데이터임을
																		나타내는 타입.
																		ㄴ ex) multipart/form-data (html form데이터에 쓰이는것)
													ㄴ (*subtype*) )
														ㄴ 대분류 아래서 구체적으로 MIME 데이터 타입이 무엇인지 결정하는 항목
													ㄴ 추가적인 parameter )
														ㄴ 기본적인 형태 다음부분에 추가적인 파라미터를 추가할 수있다.
															ㄴ (*type*)/(*subtype*);(*parameter*)=(*value*)
															ㄴ ex) text/plain;charset=UTF-8
												ㅡ 자주쓰이는 MIME type 들 )
													ㄴ application/octet-stream )
														ㄴ 이진파일의 디폴트값. unknown binary file같다고 보면되고 브라우저는 이파일을 실행하지 않는다.
													ㄴ application/x-www-form-urlencoded
														ㄴ get메소드 사용시 파라미터를 쿼리스트링으로 ?(*파라미터명*)=(*값*)&(*파라미터명2*)=(*값2*)와
															같은식으로 설정하는것과 같은 방식으로 =으로 값을 설정하고 &으로 파라미터들을 구분하는 방식으로
															데이터를 보냄을 나타내는 형식.
													ㄴ text/plain
														ㄴ 디폴트 텍스트 파일.
													ㄴ text/css
														ㄴ css파일을 나타내는 타입.
														ㄴ css파일은 반드시 이 타입으로 넘어와야함. 아닐경우 css가 입혀지지않음.
													ㄴ text/html
														ㄴ html을 나타내는 타입. html파일들은 반드시 이 타입으로 넘어와야한다.
													ㄴ text/javascript
														ㄴ javascript를 나타내는타입. javascript파일은 반드시 이 타입으로 넘어와야한다.
													ㄴ image/apng
													ㄴ image/avif
													ㄴ image/gif
													ㄴ image/jpeg
													ㄴ image/png
													ㄴ image/svg+xml
													ㄴ image/webp
													ㄴ 오디오 타입들 ~~~~~
													ㄴ multipart/form-date
														ㄴ 'boundary'로 구분된 여러개의 부분으로 구성되어있으며, 각각의부분들은 각각의 http header와
															Content-Disposition, Content-Type, 각각의 데이터들을 가지고 있다.
													ㄴ multipart/byteranges
														ㄴ ~~~~~
											</pre>
										ㄴ charset : 문자 인코딩
										ㄴ boundary )
											ㄴ 일반 content-tyep이 application/x-www-form-urlencoded인 패킷을 보낼때 파라미터를 url뒤에
												name=John&age=12와 같이 &로 파라미터를 구분해서 보내듯이,
												multipart/form-data형으로 보낼때 파라미터구분을 boundary로 하는것.
											ㄴ 	--XXX	//임의로 설정한 boundary값.
												Content-Disposition: form-data; name="name"

												John
												--XXX
												Content-Disposition: form-data; name="age"

												12
												--XXX--
											ㄴ 이렇게 boundary에 설정한 값으로 파라미터를 구분하여 패킷을 만든다.
								ㄴ Cache-Control 
									ㄴ 브라우저와 shared cache(CNDs 등)에서 캐싱관련 설정에 쓰이는 directive들이 설정된 필드. 
									ㄴ ex ) Cache-Control: max-age=604800
									ㄴ response 에서 사용되는 directive들 
										ㄴ max-age 
											ㄴ response가 생성된시점부터 몇 초동안 'fresh'한 상태로 취급될지 설정. 
									ㄴ request에서 사용되는 directive들 
										ㄴ ~~~ 
								ㄴ Vary (response header) 
									ㄴ response 생성에 영향을 미친 request header를 명시하는 필드. (request의 url, method는 빼고. 당연히 영향을 미쳤을테니) 
										ㄴ 가령, 'Vary: Accept-Encoding'이면 이 응답이 requets의 url, method, Accept-Encoding header 값에 따라 생성된 response라는 것을 명시한것. 
									ㄴ ??? The same Vary header value should be used on all responses for a given URL, including 304 Not Modified responses and the "default" response.
									ㄴ 가능한 값 
										ㄴ * (와일드카드)
											ㄴ request header 이외의 요소에 기반하여 response가 생성되었음을 의미. 
										ㄴ 콤마(,)기반 header name 문자열 목록 
											ㄴ ex ) Vary: Accept-Encoding, Accept-Language 
											ㄴ 해당 request header들에 기반하여 response가 생성되었음을 명시. 
								ㄴ ~~~
							</pre>
							ㄴ response header
								ㄴ ~~~
								ㄴ X-Frame-Options
									ㄴ 브라우저가 response 페이지를 < frame>, < iframe>, < embed> html tag 안에서
										렌더링해도 될지 말지를 명시하는 헤더.
										값으로 'DENY', 'SAMEORIGIN' 가 있으며,
										'DENY'이면, rseponse의 페이지를 < iframe> 등에서 렌더링을 금지,
										'SAMEORIGIN'이면 origin이 같은 경우에만 허용.
										브라우저가 이 response의 header를 읽고 렌더링하거나 말거나 하는 것이기 때문에
										브라우저에서 이 'X-Frame-Options' 헤더 기능을 지원해야 동작한다.
										사이트에 대한 'click-jacking' 공격 방지 등을 위해 사용된다.
						</pre>
						ㄴ TLS/SSL )<button>더보기</button>
						<pre>
							ㄴ 개요 )
								ㄴ 보안 목적의 일종의 암호 규약.
								ㄴ Transport Layer Security, TLS, 전송 계층 보안 : SSL이 표준화 되면서 이름이 바뀐것.
								ㄴ Secure Sockets Layer, SSL, 보안 소켓 레이어
								ㄴ TCP/IP 통신에 적용된다.
								ㄴ transport 계층의 종단간 보안과 데이터 무결성을 보장해준다.
								ㄴ url상에 https를 사용하는게 tls/ssl을 사용하고있는것이다.
							ㄴ 동작과정 )<button>more</button>
							<pre>
								ㄴ TLS record )<button>more</button>
								<pre>
									ㄴ TLS 프로토콜을 통한 통신은 'record'라는 것을 교환하는 방식으로 이루어진다.
									ㄴ 'record'란 특정한 형식대로 내부의 데이터를 캡슐화한 데이터 덩어리???
									ㄴ 'content type' 필드('record'가 어떤 데이터를 캡슐화했는지 지칭), TLS version 필드 등을 가진다.
									ㄴ 'content type'필드에 해당 'record'가 따르는 'Record Layer Protocol Type'이 명시되며,
										이 protocol type에 맞게 'rocord'의 형식이 구성된다.
										ㄴ 종류는 'ChangeCipherSpec', 'Alert', 'Handshake', 'Application', 'Heartbeat'
										ㄴ 각 type의 content type필드값은 20, 21, 22, 23, 24.
									ㄴ 'record' 공통적인 형식
										<img src="image/TLS_record_format.png"/>
									ㄴ ChangeCipherSpec 프로토콜
										ㄴ 'record' 형식
											ㄴ ~~~
									ㄴ Handshake 프로토콜
										ㄴ
										ㄴ 'record' 형식
											<img src="image/TLS_record_format_for_handshake_protocol.png"/>
											ㄴ tls 'record' 중, content type이 'handshake'인 경우에 갖는 format.
										ㄴ format에서 'message type'에 가능한 값들. (code, message type 쌍)
											0	HelloRequest
											1	ClientHello
											2	ServerHello
											4	NewSessionTicket
											8	EncryptedExtensions (TLS 1.3 only)
											11	Certificate
											12	ServerKeyExchange
											13	CertificateRequest
											14	ServerHelloDone
											15	CertificateVerify
											16	ClientKeyExchange
											20	Finished
									ㄴ Alter 프로토콜
										ㄴ ~~~
									ㄴ ChangeCipherSpec 프로토콜
										ㄴ ~~~
								</pre>
								ㄴ TLS Handshake 과정 )
									ㄴ 'content type' 22(TLS의 'Record Layer Protocol type' 중 Handshake 프로토콜)인 'record'를 전달하는 것으로 tls 연결 시작.
									ㄴ 클라이언트와 서버 상황이나 여건 등에 따라 여러가지 방식 중 하나로 handshake 과정이 진행된다.
									ㄴ 세션 id, random number, ~~~
										ㄴ ~~~
									ㄴ 기본 handshake 과정
										ㄴ negotiation phase
											ㄴ client가 서버로 'ClientHello' 메세지 전송.
												ㄴ 클라이언트가 지원 가능한 가장 최신의 TLS버전, 랜덤 숫자, 지원 가능한 'cipher suite' 목록,
													지원 가능한 압축 방식 목록 명시.
												ㄴ handshake 단계를 재개하려는 것이면 session id 전달.
												ㄴ ??? If the client can use Application-Layer Protocol Negotiation, it may include a list of supported application protocols, such as HTTP/2.
											ㄴ 서버가 client에게 'ServerHello' 메세지 전송.
												ㄴ 선택한 TLS 버전, 랜덤 숫자, 클라이언트가 전해준 'cipher suite', 압축 방식 목록 중 선택된 것들을 명시.
												ㄴ TLS 버전은 클라이언트와 서버 둘다 지원가능한 버전 중 가장 최신 버전 선택.
											ㄴ 서버가 'Certificate' 메세지 전달.
											ㄴ ??? 서버가 'ServerKeyExchange' 메세지 전달?
											ㄴ 서바가 'ServerHelloDone' 메세지 전달. negotiation 단계가 완료되었음을 명시.
											ㄴ ??? 클라이언트가 'ClientKeyExchage' 메세지 전달.
											ㄴ ???
										ㄴ 클라이언트가 'ChangeCipherSpec' 메세지 전송
											ㄴ ~~~
										ㄴ 서버가 'ChangeCipherSpec' 메세지 전송
											ㄴ ~~~
										ㄴ application phase
											ㄴ handshake 단계 완료이고, 'record'의 'content type' 23을 통하여
												application protocol('Record Layer Protocol type' 중 application protocol)이 활성화된다.
									ㄴ Client-authenticated TLS handshake
										ㄴ ~~~
									ㄴ Resumed TLS handshake
										ㄴ ~~~
									ㄴ TLS 1.3 handshake
										ㄴ ~~~
								ㄴ [웹브라우저] SSL로 암호화된 페이지를 요청하게 된다. (일반적으로 https://가 사용된다)
								ㄴ [웹서버] Public Key를 인증서와 함께 전송한다.
								ㄴ [웹브라우저] 인증서가 자신이 신용있다고 판단한 CA(일반적으로 trusted root CA라고 불림)로부터 서명된 것인지
									확인한다. (역주:Internet Explorer나 Netscape와 같은 웹브라우저에는 이미 Verisign, Thawte와 같은 널리
									알려진 root CA의 인증서가 설치되어 있다) 또한 날짜가 유효한지, 그리고 인증서가 접속하려는 사이트와 관련되어
									있는지 확인한다.
									ㄴ 인증서가 CA에서 나온 것인지 검증하는 방법
										ㄴ 보통 브라우저는 CA의 공개키를 가지고 있다
										ㄴ CA의 인증서는 CA의 비밀키로 암호화 되어 있다.
										ㄴ 브라우저가 서버로부터 받은 인증서가 CA의 공개키로 복호화에 성공한다면 CA로부터 나온 인증서라 검증할 수 있다.
								ㄴ 통신에 사용할 '세션키(대칭키)?' 결정
									??? 아래 두 가지 중 어떤 방식이 실제로 적용되는지는 모르겠다. 이론으로만 확인한 것이라. 비슷한 내용이긴 한데..
									ㄴ 웹브라우저와 웹서버가 이후의 보안 통신에 사용할 '세션키'를 생성한다.
										ㄴ 생성 방법
											ㄴ 브라우저가 웹서버에서 넘어온 공개키로 임의의 랜덤 숫자를 암호화하여 서버로 전달. 서버는 개인키로 이를 복호화하고,
												이 랜덤 숫자를 이용하여 세션키 생성.
											ㄴ ??? Diffie-Hellman key exchange 사용?
										ㄴ 이후, 이 '세션키'를 사용하여 이후의 통신이 암호화, 복호화된다. (통신 데이터 암호화의 대칭키인셈)
									ㄴ [웹브라우저] Public Key를 사용해서 랜덤 대칭 암호화키(Random symmetric encryption key)를 비릇한 URL,
										http 데이터들을 암호화해서 전송한다.
										그리고 [웹서버] Private Key를 이용해서 랜덤 대칭 암호화키와 URL, http 데이터를 복호화한다.
								ㄴ [웹서버] 요청받은 URL에 대한 응답을 웹브라우저로부터 받은 랜덤 대칭 암호화키를 이용하여 암호화해서 브라우저로
									전송한다
								ㄴ [웹브라우저] 대칭 키를 이용해서 http 데이터와 html문서를 복호화하고, 화면에 정보를 뿌려준다
							</pre>
							ㄴ ??? 도메인에 적용되는 것이기 때문에 한 도메인을 여러 서버에서 사용하는 경우, 각 서버들에 인증서를 설치하여 ssl접속을 할 수 있다.
							ㄴ 인증서 )
								ㄴ ~~~
								ㄴ 도메인별 분류 )
									ㄴ single domain
										ㄴ 한 인증서에 단 하나의 도메인에 대해서만 인증이 가능.
										ㄴ ex ) deepq.kr
									ㄴ multi domain
										ㄴ 한 인증서에 여러개의 도메인에 대해서 인증 가능.
										ㄴ ex ) app.deepq.kr, www.deepq.kr, deepq.kr, www.bbdlab.kr
									ㄴ wildcard domain
										ㄴ 한 인증서에 와일드카드 패턴과 일치하는 도메인에 대해서 인증 가능.
										ㄴ ex ) *.deepq.kr => app.deepq.kr (O), aaa.deepq.kr (O), www.aaa.deepq.kr (X),
								ㄴ 등급별 분류 )
									ㄴ
									ㄴ DV (Domain Validation)
										ㄴ 도메인의 소유 정보만을 인증.
									ㄴ OV (Organization Validation)
										ㄴ 소속되어있는 회사, 조직 정보 인증
									ㄴ EV (Extended Validation)
										ㄴ OV에서 추가적인 부분 인증.
										ㄴ 인증을 받기 위한 추가적인 까다로운 조건 존재.
										ㄴ 은행 및 공공기관.
							ㄴ 질문 )
								ㄴ ??? 왜 공개키, 비밀키를 이용해 통신 데이터를 암호화하지 않고 대칭키를 따로 만드나?
									ㄴ 당연히 공개키는 모든 브라우저가 가지고 있는 것이고,
										브라우저에서 보내는 데이터는 해독 못한다쳐도 이는 서버에서 개인키로 암호화된 데이터가 제3자에 의해 해독될 수 있다는 것이니까?
										그래서 세션키를 공개키로 암호화해서 보내고 이후부터는 세션키로 데이터를 암호화하는 것?
							ㄴ SNI (=Server Name Indication)<button>more</button>
							<pre>
								ㄴ TLS의 확장 프로토콜.
								ㄴ 클라이언트가 어떤 호스트명의 서버에 대해 ssl연결을 시도하는지(ssl handshake 과정을 하려하는지)를
									지정하게 해주는 프로토콜.
									ㄴ 클라이언트가 tls handshake단계(client hello)시에 가상 도메인명을 함께 보냄.
									ㄴ 이를 통하여, 서버가 동일한 ip, port에 대해 여러개의 ssl 인증서가 있을 때,
										이중 어떤 것을 handshake 과정에서 넘겨주어야 하는지 알 수 있게 해준다.
									ㄴ 멀티 인증서나 와일드카드 인증서를 통해, 단 하나의 인증서에 모든 도메인을 담을 필요 없이,
										여러 인증서를 가지고 있으면서 도메인명에 따라 선택적으로 알맞은 ssl 인증서를 넘겨줄 수 있다.
									ㄴ 함께 전달되는 호스트명은 암호화되지 않는다.
								ㄴ 배경 )
									ㄴ tls handshake 단계에서 인증서를 교환해야 하는데, 이는 application protocol 이전 단계라고 한다.
										ㄴ 특정 프로토콜이 정확히 어떤 계층에 속하는지 분명하게 구분될 수는 없지만
											tls handshake 단계는 https와 같은 application 프로토콜이 동작하기 이전 단계라고 한다.
									ㄴ 따라서, tls handshake 단계에선 도메인명과 같은 http header정보를 읽을 수 없다.
									ㄴ 기존 TLS연결에선, 클라이언트가 서버로 어떤 사이트에 대한 요청을 보내는 것인지 명시할 수 없었다.
										따라서, 한 서버에서 여러 사이트를 호스팅하고 이 사이트들에 대한 인증서들이 각자 있는 경우,
										서버가 어떤 사이트에 대한 인증서를 넘겨주어야 할지 알 수 없었다.
										~~~
										HTTP 연결에선 'name-based virtual hosting'을 통하여 한 서버, 한 ip에서 여러 dns를 호스팅하는게 가능하다.
									ㄴ HTTPS 연결에선, TLS handshake 단계에선 http header를 읽을 수 없기 때문에 이러한
										'name-based virtaul hosting'이 불가능하다.
										이로인해, 인증서가 여러개 있는 경우, 호스트명에 따라 어떤 인증서를 넘겨줘야 하는지 알 수 없다.
								ㄴ 클라이언트와 서버 둘다 SNI를 구현해야 동작한다.
									ㄴ 2022.12.26기준 대부분의 주요한 브라우저, 서버, 소프트웨어들이 이를 구현하고 있다.
										ㄴ 참조 ) https://en.wikipedia.org/wiki/Server_Name_Indication#Support

								ㄴ SNI was added to the IETF's Internet RFCs in June 2003 through RFC 3546,
									Transport Layer Security (TLS) Extensions.
							</pre>
						</pre>
						ㄴ DHCP <button>more</button>
						<pre>
							ㄴ Dynamic Host Configuration Protocol
							ㄴ Internet Protocol Suite에서 application layer에 속하는 프로토콜이다.
							ㄴ Internet protocol에서 ip address를 할당할 때 사용된다.
								ip를 자동으로 할당하여 개별 장치마다 수작업으로 ip설정을 할 필요 없게 해준다.
							ㄴ ??? HAN ~ CAN 범위까지 모두 구현이 가능하다?
							ㄴ ??? 많은 라우터와 지역 게이트웨이에 적용이 가능하다?
							ㄴ 라우터가 ISP로부터 유일한 ip address를 받으면, dhcp가 로컬 장치들에게 로컬 ip address들을 자동으로, 동적으로 할당해준다.
							ㄴ IP v4, v6에 적용되는 프로토콜이다.
							ㄴ ??? 컴퓨터나 장치가 네트워크에 접속하면 DHCP 클라이언트가 DHCP broadcast 쿼리 요청을 보낸다.
								네트워크 내의 DHCP서버는 이 요청을 처리한다. 관리자에 의해 이전에 설정된대로 특정한 정보를 반환해주거나, 전체 네트워크와 특정 시간동안 유효한 ip address 및 정보들을 반환해준다.
								DHCP서버는 가능한 ip address pool과 각 클라이언트들의 설정 정보(디폴트 게이트웨이, 도메인명, name servers, time servers 등)을 가지고 관리한다.
								DHCP 클라이언트는 부팅시에 또는 DHCP서버로부터 받은 정보 유효시간 만료 직전에 쿼리요청을 보낸다.
							ㄴ ??? On large networks that consist of multiple links, a single DHCP server may service the entire network when aided by DHCP relay agents
								located on the interconnecting routers. Such agents relay messages between DHCP clients and DHCP servers located on different subnets.
							ㄴ DHCP 서버는 ip 할당을 위한 세가지 방법을 가진다
								ㄴ 동적할당 )
									ㄴ 관리자에 의 해 설정된 ip address 범위가 정해져있고, 클라이언트는 네트워크 초기화시 서버에 ip 주소를 요청하도록 되어있다.
									ㄴ 서버는 유효 기간이 있는 ip주소를 할당하고 이후 이를 회수 후 재할당하는 방식.
								ㄴ 자동할당 )
									ㄴ 관리자에 의해 설정된 ip address 범위 내에서, DHCP서버가 클라이언트에게 영구적인 ip주소를 할당한다. 서버가 과거 ip 할당 테이블을 가지고 있어 이전에
										클라이언트가 가지고 있던 ip가 할당되도록 한다.
								ㄴ 수동 할당 )
									ㄴ static DHCP 할당, fixed address 할당, reservation, MAC/IP address binding이라고도 불린다.
									ㄴ 서버가 클라이언트로부터 받은 클라이언트의 유일한 식별값(id 또는 mac address)과 ip를 연결해 고정한다.
									ㄴ 실패시 다른 방법을 사용한다.
							ㄴ 동작과정 )
								ㄴ ??? connectionless 서비스 모델을 따른다?
								ㄴ udp 프로토콜을 사용하여 클라이언트와 서버가 통신한다. 서버는 67 port, 클라이언트는 68port 사용.
								ㄴ 서버 인식, 임대 요청, 임대 제공, 임대 인식의 단계를 가진다.
								ㄴ 시작은 클라이언트가 네트워크로 브로드캐스트 요청을 전송.
									한번 요청하여 할당받은 후, 다음 요청시엔 서버의 ip를 앎으로 unicast 요청을 전송.
								ㄴ ~~~
						</pre>
						ㄴ DNS, Domain Name System <button>more</button>
						<pre>
							ㄴ ~~~
							ㄴ Reverse DNS Lookup (=rDNS)
								ㄴ DNS Lookup과 반대로, ip address로부터 이와 연결된 도메인을 찾는 것.

						</pre>
						ㄴ SSH, Secure Shell <button>more</button>
						<pre>
							ㄴ 네트워크상에서 다른컴퓨터에 로그인 | 원격 명령 전잘&실행 | 파일복사 등을 하는데 사용되는 프로토콜.
								(또는 이걸가능하게 해주는 프로그램을 지칭하기도)
							ㄴ 배경
								ㄴ Unix-like os에서
									Telnet, Berkeley의 'Remote Shell' 등의 보안처리되지 않은 Unix shell protocol, rlogin, rexec 등을
									대체하기 위해 설게.
							ㄴ??? 'Transport Layer Protocol', 'User Authentication Protocol', 'Connection Protocol'로 구성.
								이 프로토콜들을 이용하여 서버 인증, 유저 인증, 명령어 전달 등 ssh의 기능을 실행한다.
								ㄴ transport layer protocol
								ㄴ user authentication protocol
									ㄴ 클라이언트 유저의 인증을 담당하는 프로토콜.
									ㄴ ??? 인증과정은 client-driven? 서버는 단지 클라이언트의 인증 요청에 응답만 할뿐?
									ㄴ 인증 알고리즘들 제공.
										ㄴ password
										ㄴ public key
										ㄴ keyword-interactive
										ㄴ GSSAPI authentication
								ㄴ connection protocol
							ㄴ RFC 링크 ) http://www.snailbook.com/protocols.html
							ㄴ 22번 port 사용.
							ㄴ ~~~

						</pre>
						ㄴ ~~~~~

				</pre>

				ㅡ 목록 
					ㄴ SMTP (Simple Mail Transfer Protocol)
						ㄴ 'email'부분 참고. 
					ㄴ RDP (Remote Desktop Protocol)
						ㄴ 다른컴퓨터에 원격 연결하여 그래픽인터페이스를 제공해주는 프로토콜. 
						ㄴ 윈도우에서 원격 데스크톱 등에 사용. 
						ㄴ 취약점 
							ㄴ 약한 유저 인증 
								ㄴ 일반적으로 비밀번호 등으로 원격 인증을 하는데 유저가 약한 비번을 사용하면 비번이 쉽게 뚫림. 
							ㄴ ~~~

				ㅡ WebSocket
					ㄴ 하나의 TCP연결에서 양방향 통신을 가능하게 해주는 프로토콜
					ㄴ IETF RFC 6455에서 표준화.
					ㄴ OSI model 7계층, TCP 4계층에 해당. HTTP와 엄연히 구분됨.
					ㄴ ??? HTTP port(443, 80)과 HTTP proxy를 지원한다함. 즉, HTTP와 호환되도록 설계됨.
						ㄴ 호환을 위해 WebSocket handshake 단계에서 'HTTP Upgrade header'를 사용하여
							http protocol을 websocket protocol로 변경한다함.
					ㄴ 배경
						ㄴ 과거 웹 상에서 클라이언트와 서버 사이에 양방향 통신을 위해선
							http polling 방식 사용.
							tcp연결을 두개를 사용하며 한쪽은 c->s 방향으로 데이터 전송,
							한쪽은 s->c로의 데이터 받기 위해 서버로 요청 보내 받아오는 방식.
							~~~
						ㄴ 이러한 HTTP를 이용한 양방향 통신 기법을 대체하고자 생김.
					ㄴ ??? 두 부분으로 구성?
						ㄴ handshake
							ㄴ opening handshake
								ㄴ http와 호환되도록 설계.

						ㄴ data transfer
							ㄴ 양쪽에서 데이터 전송이 가능한 통신.
							ㄴ client와 server가 "message"라 불리는 데이터를 주고 받음.

				ㅡ CIDR 표기법
					ㄴ IP주소를 표기하는 방법. 범위를 나타낸다.
					ㄴ ex ) 192.168.1.0/24
					ㄴ ip주소는 8bit짜리 숫자 4개가 모여 구성됨. 192.168.0.72 이런식.
						이때, '/' 뒤에 붙은 숫자는 앞에서부터 고정시킬 비트수를 의미.
						192.168.1.0/24라 하면 앞에서부터 24비트 즉, 192.168.0부분을 고정시킨다는 의미이고
						고정되지 않은 비트부분은 어떤값이든 올 수 있다 하여, 192.168.1.0 ~ 192.168.1.255 까지의 주소를 가리키게 된다.
					ㄴ '/32'를 사용하면 모든 비트가 고정되는 것이므로 앞에 적힌 ip주소 단 하나만을 나타내게 된다.
						ㄴ ex ) 192.168.0.72/32 는 192.168.0.72 단 하나의 주소만을 나타냄.

			</pre>

			ㅇ OSI 모델
				ㅡ 국제 표준화 기구 (ISO)에서 만든 계층 모델.
				ㅡ OSI 7계층 )
					ㄴ Application, presenstation, session, transport, network, data link, physical 으로 나뉜다.
				ㅡ TCP/IP에 밀려 널리 사용되지 못함.

			ㅇ 회선 교환 방식, 패킷 교환 방식<button>더보기</button>
			<pre>
				ㅡ Packet Switched Network ) 패킷 교환 방식
					ㄴ 보내려는 데이터를 '패킷'이라는 단위로 잘라 보내는식으로 통신하는 방식.
					ㄴ 인터넷 등의 기반이되는 방식.
					ㄴ '공유 매체'를 통하여 여러 사용자가 이를 나누어 통신한다.
					ㄴ 비동기 통신이라 볼수있다.
				ㅡ Circuit Switched Network ) 회선교환방식
					ㄴ 두 종단이 한 회선을 일정시간동안 독점적으로 차지하고 통신을 하는 방식.
					ㄴ 통신의 쌍 사이에 point-to-point 통신을 제공해준다.
					ㄴ circuit를 creation, use, termination 단계를 거친다.
					ㄴ Circuit는 영구적일수도있고 아닐수도있다.
			</pre>

			ㅇ 포트
				ㅡ 네트워크 상에서 어떤 컴퓨터를 특정하기 위해 필요한게 ip주소이고, 그 컴퓨터 안에서 어떤 프로그램에 데이터를 넘겨줄지를 특정하기 위해 필요한것이 포트번호이다.
				ㅡ 컴퓨터에서 프로그램마나 포트 번호를 할당하여 해당 포트로 데이터가 넘어올시, 그 프로그램으로 데이터를 전송해주는 방식.
				ㅡ 포트 번호 )
					ㄴ 일반적으로 0~1023 은 미리 특수용도로 지정되어 있다고한다.
					ㄴ 21 : ftp
					ㄴ 22 : ssh
					ㄴ 25 : smtp
					ㄴ 80 : http 등등.
				ㅡ 포트 포워딩 )
					ㄴ

			ㅇ 소켓 프로그래밍
				ㅡ 웹을통해 request, response을 이용한 통신말고도 소켓을 이용한 프로그램의 통신도 가능하다.
					ㄴ 대충간단히말해, 임의의 포트를 이용해 연결을 만든뒤, 이 경로로 통신하는 방식?
					ㄴ socket api를 이용한다.

			ㅇ Proxy 서버
				ㅡ 일단은 그냥 클라이언트와 서버 사이에 위치하여, 요청,응답이 중간에 한번 거쳐가는 중계하는 서버.
					ㄴ 클라이언트로부터 요청을 받아 내부처리를 하고, 서버로 보내주고, 서버로부터 데이터를 받아서 클라이언트에게 보내준다.
					ㄴ 요청과 응답을 중간에서 가로채서 할 수 있는 다양한 기능들을 한다.
				ㅡ 유형 )
					ㄴ forwrad proxy )
						ㄴ Client - proxy - internet - server
							위 위치에 존재하는 프록시 서버.
					ㄴ reverse proxy )
						ㄴ Client - internet - proxy - server
							위 위치에 존재하는 프록시 서버.
				ㅡ 보안상의 목적(서버는 클라이언트에대해 아는게 없게된다), 개인정보, 로드벨런싱 등의 목적으로 사용한다고함.
				ㅡ 스크래핑에서의 프록시 )
					ㄴ forward 프록시를 사용하여,
						ip추적을 통한 스크래핑 차단을 방지한다.
					ㄴ 쉽게 찾을 수 있는 free proxy들은 전세계의 누구나 사용 가능한 ip들이기 때문에 금방 막히고 보안상 안전하지도 않다.

			ㅇ 네트워크 일부..
				ㅡ NOS : 컴퓨터간 네트워킹이 가능하게 해주는 os.
					ㄴ 따라서 윈도우나 리눅스 등도 nos에 속하는것.

			ㅇ 웹서버
				ㅡ ??? 그냥 클라이언트 서버 관계에서 서버역할을 하는 소프트웨어를 추상적으로 가리키는 말인가?
				* 프로그램에서 file open의 의미 : 파일 io는 os에서 담당해준다하고, file open을 시켜주는 api를 사용하는것은 os에게 현재 프로그램이 해당 파일과
					작업을 할것임을 알리는 기능이라함. 당연히 권한에 따라 가능하면 허가, 아니면 불가.
					ㅡ 이 라이브러리를 통해 데이터 input/output을 위한 '스트림'을 생성하는 것이라함.
					ㅡ stdin, stdout역시 스트림을가리키는 포인터라고함. 프로그램실행시 os가 자동으로 만든다고한다.

			ㅇ Global IP Internet<button>more</button>
			<pre>
				ㅡ ip 프로토콜
					ㄴ naming scheme와 delivery mechanism을 제공한다.
					ㄴ '데이터그램'이라 불리는 패킷을 보낸다.
					ㄴ'unreliable'하다. 중복이나 손실된 데이터그램에 대한 처리가 없기때문.
				ㅡ tcp 프로토콜
					ㄴ 호스트간이 아니라 프로세스간 양방향 연결을 하게해주는 프로토콜.
				ㅡ 프로그래머의 관점에서, 우린 인터넷을 다음 세가지 조건을 만족하는 넓은 호스트들의 집합이라고 볼 수있다.
					ㄴ 호스트들은 32비트 ip주소와 매핑된다.
					ㄴ ip주소들은 인터넷 도메인 이름과 매핑된다.
					ㄴ 호스트에있는 프로세스는 다른 호스트에 있는 프로세스와 통신 할 수 있다.
				ㅡ IP Address )
					ㄴ 개요 )
						ㄴ unsigned 32 bit integer 값이다.
						ㄴ 네트워크 프로그램들은 ip 주소를 'IP address structure'에 저장한다.
							ㄴ 구조체에 저장하는 이유는 특별한게 없고 처음에 그렇게 만들었는데 바꾸기엔 너무 늦어서.
						ㄴ 호스트마다 바이트 정렬 순서가 다를 수 있기 때문에 tcp/ip 프로토콜에서 '빅엔디안'으로 통신하도록 바이트정렬순서를 정의 .
						ㄴ 유닉스에선 호스트용 바이트 정렬순서와 네트워크용을 상호 변환해주는 함수들을 제공한다.
						ㄴ ip주소는 'dotted decimal notation'형태로 사람들에게 보여진다. ex) 128.2.194.242
							ㄴ 이를 변환해주는 함수 역시 제공.
					ㄴ 0.0.0.0
						ㄴ 따로 지정된 주소가 없음을 의미하는 주소.
						ㄴ '0.0.0.0:0'은 주소뿐 아니라 포트도 따로 지정된게 없음을 의미.
				ㅡ Internet Domain Names )
					ㄴ 사람들이 쓰기 쉽도록 ip주소와 이름을 매핑시켜주는것
					ㄴ 계층적 형태이다.
						ㄴ 예로 kittyhawk.cmcl.cs.cmu.edu 라는 도메인 주소가 있으면
						ㄴ 뒤에서부터 edu가 첫번째 레벨의 도메인 이름, cmu가 그다음 이런식.
					ㄴ 옛날엔 HOSTS.txt라는 일반 텍스트 파일에 저장되었는데 현대에는 분산 world-wide 데이터베이스 (DNS)에서 유지관리하고잇다.
						ㄴ 이안에 'host entry structure'의 형태로 무수히 많은 entry들이 저장되어 있으며 (896페이지에 entry structure 형태)
						ㄴ 각 entry는 도메인 이름과 ip주소를 가지고있어 매핑을 할수있게해준다.
						ㄴ 도메인이름이나 ip주소를 인자로 넘겨 해당 entry를 가져오는 함수를 제공한다. ( gethostbyname(), gethostbyaddr() )
					ㄴ 'localhost'는 해당 같은 기계에서 동작하는 클라이언트와 서버를 참조하기 위해 사용되는 편리한 방법이다.
					ㄴ 한 도메인 네임이 하나의 ip주소와 매핑될 수도 있지만, 여러 도메인이 한 ip주소에 매핑되거나, 여러 도메인이 여러 ip주소에매핑되거나
						도메인이 ip주소에 매핑되지 않을 수도 있다.
				ㅡ Internet Connection )
					ㄴ 클라이언트와 서버는 connection을 통해 바이트 스트림을 주고받는것을 통하여 통신한다.
						ㄴ 이는 '점대점'이며, '양방향'이다.
					ㄴ 소켓은 connection의 종단점이다. 각 소켓은 internet 주소와 16bit port로 이루어진 '소켓 주소'를 가진다. (*address*) : (*port*) 로 표현.
					ㄴ 클라이언트의 소켓주소는 커널에 의해 자동적으로 할당된다. 반면 서버의 소켓주소는 well-known port와 연결된다.
					ㄴ 양끝단의 소켓주소 쌍을 통해 연결은 유일해지며, 이쌍을 tuple이라고 부른다.
						( 클라이언트주소 : 클라이언트 포트 ,  서버주소 : 서버 포트 )
			</pre>

			ㅇ 소켓 인터페이스
				ㅡ 네트워크 어플리케이션을 만들기위해 Unix i/o 함수와 함께 사용되는 함수의 집합.
				ㅡ CSAPP책 901페이지 소켓의 동작 전체 뷰.
				ㅡ 소켓 API : 컴퓨터에 내장되어있는 프로토콜 통신 프로그램.

			ㅇ

		</pre>

		JPA, Hibernate(하이버네이트)<button>더보기</button>
		<pre>
			ㅇ 소개<button>더보기</button>
			<pre>
				ㅡ JPA의 간단 설명 : SQL언어를 직접 코딩하여 db를 사용할 필요없이 간단한 메소드 등을 사용하는 것만으로 할 수있게해준다.
				ㅡ 강의 목표 )
					ㄴ 객체와 테이블 설계 : JPA가 강력하기는 하나, 객체와 테이블의 매핑을 제대로 하지 못하면 실무의 복잡한 상황에서 사용하기 어렵다.
					ㄴ JAP 내부 동작 방식이해 : 이걸 제대로 이해못하면 당연히 제대로 사용하지 못함.
						ㄴ JPA가 어떤 SQL을 만드는지
						ㄴ 이 SQL을 JAP가 언제 실행하는지
				ㅡ JPA학습 방법 )
					ㄴ 표준 스펙만 500페이지라 혼자 공부하기 어렵.
					ㄴ 강의에서는.. )
						ㄴ 이론과 라이브 코딩으로 설명
						ㄴ 6단계의 실전 예제
						ㄴ 강의를 메인으로 하고 책을 참고하는걸 추천. (강의에선 실무적인 느낌이 강하고 책에서 더 디테일한 내용들이 있으므로)
				ㅡ JPA 많이 사용하는지 )
					ㄴ 전세계적으로 한국에서의 경쟁자인 mybatis에 비해 훨씬많고
					ㄴ 한국안에서는 mybatis가 더많기는 하나 거의 따라잡았다고한다.
				ㅡ 강사의 JPA실무 경험담 )
					ㄴ sql 작성 노가다에 드는 시간이 없어져서 다른곳에 투자가능했다는게 가장 좋았다.
			</pre>

			ㅇ JPA 소개<button>더보기</button>
			<pre>
				ㅡ SQL중심적인 개발의 문제점 )<button>더보기</button>
				<pre>
					ㄴ 현재는 객체지향언어와 관계형DB가 가장 많이 쓰인다. 따라서 객체를 관계형 DB에 저장하여 관리해야함.
					ㄴ 근데 관계형DB를 다루기위해서 SQL언어를 사용해야하는데 이러다보니 코드상에 중심이 sql문이라 할정도로 많이 사용되어야
						한다는 문제점이 있다.
						따라서 무한반복, 단순하고 지루한 코드가 된다.
						ㄴ 매번 똑같은 select, insert, update sql문들이 반복됨.
						ㄴ 이러한 코드상에 있는 sql문들이 유지보수 및 수정, 개발과정에서 좋은 요소가 아닌라는 점.
						ㄴ 이렇게 반복되는 sql코드들을 jpa를 이용하면 엔터티라는 객체를 중심으로 하는 코드로 대체할 수 있다.
							ㄴ 엔터티 객체에 대해 속성을 수정하고(update), 새 객체를 생성하고(insert), 객체를 가져오고(select) 등.
					ㄴ 패러다임의 불일치 )
						ㄴ 객체지향과 관계형 데이터베이스의 패러다임이 너무 다르다.
						ㄴ 근데 이걸 같이 사용하려고하니까 문제가 생김.
					ㄴ 객체와 관계형 데이터베이스의 차이 )
						ㄴ 상속 )
							ㄴ 객체에는 상속관계라는게 있다. RDB에서는 'Table슈퍼타입 서브타입 관계'라는게
								객체의 상속관계와 그나마 가장 유사하다.
								<img src="image/객체지향의 상속과 RDB.png" height="300px"/>
							ㄴ 'Table슈퍼타입 서브타입관계'로 객체의 상속을 표현하려고하면 매우 복잡하다.
								ㄴ 강좌에서 간단한 예로 설명.
							ㄴ 만약 데이터를 자바 컬렉션에 저장한다면? )
								ㄴ list.get, list.add()등으로 간단하게 데이터의 삽입과 삭제가 가능하고
								ㄴ 컬렉션은 자바 클래스이니까 상속관계도 잘 표현할수있다.
								ㄴ 근데 컬렉션이 아닌 RDB로 상속을 표현하려하니 매우 복잡.
						ㄴ 연관관계 )
							ㄴ 객체는 '참조'를 사용하여 다른 객체를 가져와 사용. RDB는 PK, Fk를 통해 조인을하여 참조.
							ㄴ 객체A가 객체B를 참조하면, A는 B를 참조하지만 그렇다고 B가 A를 참조할수있지는 않다.
								RDB는 조인으로 양방향 참조가 가능하다. (자세한건 이후에 설명)
						ㄴ ~~~~~~~~~~~~~~~~~
				</pre>

				ㅡ JPA 소개 )<button>더보기</button>
				<pre>
					ㄴ Java Persistence API. 자바 진영의 ORM기술 표준.
					ㄴ ORM 이란? )
						ㄴ Object-relational mapping. 객체와 관계형 데이터베이스간의 매핑을 말함.
						ㄴ 객체는 객체지향대로 개발하고, RDB는 RDB답게 개발을 하면 ORM이 중간에서 잘 연결을 해주는것.
					ㄴ JPA의 동작 )
						ㄴ 어플리케이션과 JDBC사이에서 동작
							ㄴ 어플이 JPA에게 명령하면 JPA가 JDBC API를 사용하여 db와 작업을 하는식.
						ㄴ 저장 ) JPA에게 객체를 넘기면 JPA가 그 객체를 분석하고 적절한 SQL을 생성하고 JDBC api를
							이용해서 RDB와 통신.
						ㄴ 조회 ) PK와 함께 정보를 JPA에게 넘겨주면 JPA가 적절한 SQL을 생성해서 JDBC사용하여
							RDB와 통신. 결과 ResultSet을 객체에 다 매핑해줌.
					ㄴ 역사 )
						ㄴ 처음엔 EJB라는 자바 표준 ORM을 사용.
							ㄴ 여러면에서 부족했음.
						ㄴ 하이버네이트라는 오픈소스가 나옴.
						ㄴ 자바 진영에서 하이버네이트를 참고하여 JPA라는 자바표준 ORM을 발표.
					ㄴ 사실상 JPA는 인터페이스의 모음.
						ㄴ 대표적 구현체 3가지 : 하이버네이트가 가장 많이쓰임.
					ㄴ JPA 장점 )
						ㄴ 생산성 )  jpa.persist(member), jpa.find(memberId), member.setName("~~"), jpa.remvoe(member)
							와 같이 간단하게 RDB에 CRUD를 수행할수있다.
						ㄴ 유지보수 ) 수정사항이 생겼을때 코드상의 SQL문을 수정할 필요가 없다.
						ㄴ 패러다임의 불일치 해결 )
							ㄴ 상속 )
								ㄴ <img src="image/객체지향의 상속과 RDB.png" />
								ㄴ JPA가 알아서 내부적으로 조인을 수행하여 필요한 정보들을 가져옴.
						ㄴ 성능 최적화 )
							ㄴ JPA를 사용해서 성능이 떨어지지 않을까라는 이슈가 있다.
							ㄴ JPA라는 중간계층이 있기때문에 버퍼링, 캐싱기능을 가질수있어 성능최적화가 가능하다.
							ㄴ 캐싱 (유사한) 기능 )
								ㄴ 같은 트랜젝션 안에서는 같은 엔터티를 반환한다.
								ㄴ ex)	String memberId = "100";
									Member m1 = jpa.find(Member.class, memberId);
									Member m2 = jpa.find(Member.class, memberId);
									=>m1, m2가 한 트랜젝션 안에서 수행된다면 같은 엔터티 객체를 반환.
							ㄴ 지연 기능 )
								ㄴ 트랜젝션 '커밋'기능이 있어 이걸 하기전에 여러 작업을 하고 커밋을 하면
									한번에 작업내용들이 전송된다.
								ㄴ 작업할때마다 db와 통신할필요가 없기때문에 성능 최적화 효과가 있다.
									ㄴ 작업한 내용을 모아두었다가 한꺼번에 보내는 '버퍼링'같은 효과가 있다.
								ㄴ JDBC BATCH SQL기능을 내부적으로 사용한다.
							ㄴ 지연 로딩과 즉시 로딩 )
								ㄴ 지연 로딩 : jpa를 통해 가져온 객체를 실제 사용할때 로딩하여 가져온다.
								ㄴ 즉시 로딩 : 지연로딩이 아닌 항상 데이터를 모두 가져오는 방식.
					ㄴ ORM은 객체와 RDB 두 기둥 위에잇는 기술이다.
						ㄴ 객체지향과 RDB 둘다 잘해야 ORM을 잘 사용할 수 있다
				</pre>
			</pre>

			ㅇ JAP 시작하기<button>더보기</button>
			<pre>
				ㅡ hello jpa 프로젝트 생성 )
					ㄴ h2 db, maven,사용
						ㄴ
					ㄴ jpa 사용을 위해 'persistency.xml'을 resource/MEAT-INF 안에 만들어야함.
						ㄴ
					* 데이터베이스 방언
						ㄴ jpa는 특정 db에 종속되지 않도록 설계.
						ㄴ db마다 표준적으로 같은 부분이 많지만 문법같은게 조금씩 다른부분이 있는데 이런 부분을 db방언이라고 한다.
						ㄴ jpa가 이런부분들을 알아서 변환해준다.
							ㄴ jpa persistence.xml에 'dialect' 속성으로 설정만 해주면 이 방언을 알아서 변환해준다.
				ㅡ hello jpa 어플 개발 )
					ㄴ jpa 구동 방식 )
						ㄴ 'Persistence'라는게 persistence.xml의 설정정보를 확인하여 'EntityManagerFactory'를 만들고 이 팩토리에서
							'EntityManager'라는걸 생성해내는 식이다.
					ㄴ entitymanagerfactory : db당 하나만 생성
					ㄴ entityManager : 요청이 올때마다 생성.
						ㄴ 스레드간 공유해서는 안된다.
					ㄴ JPA의 모든 데이터 변경은 '트랜잭션'안에서 수행되어야 한다.
					* JPQL )
						ㄴ ex) entityManager.createQuery("select m from Member as m", Member.class)
							.setFirstResult(5)
							.setMaxResults(8)
							.getResultList();
						ㄴ 하나의 엔터티 객체가 필요한게 아니라 원하는 임의의 형태의 데이터를 검색하려할때 결국 검색쿼리를 사용해야 하는데,
							이때 엔터티 객체를 대상으로 쿼리문을 만들어 사용하는거라고 보면 된다.
							ㄴ 실제 rdb 테이블이 아닌 엔터티 객체를 대상으로 쿼리를 작업함으로서 rdb에 종속되지 않고 객체지향을
								유지할수있다.
						ㄴ sql문법에 있는 select, from, where, group by, join 등이 지원.
						ㄴ db에 따라서 다른 db 방언을 알아서 변환해줌.
						ㄴ 이후에 자세히 공부한다.
			</pre>

			ㅇ ??? 아키텍처
				ㅡ SessionFactory
					ㄴ ???
					ㄴ jakarta의 EntityManagerFactory와 동일.
				ㅡ Session
					ㄴ ???
					ㄴ jakarta의 EntityManager와 동일
					ㄴ jdbc의 connection을 wrap.
					ㄴ org.hibernate.Transaction의 팩토리처럼 사용???
				ㅡ Transaction
					ㄴ ???
					ㄴ jakarta의 EntityTransaction과 동일.

			ㅇ 영속성 컨텍스트<button>더보기</button>
			<pre>
				ㅡ 영속성 컨텍스트란?
					ㄴ JPA의 논리적 개념.
					ㄴ 엔터티를 영구 저장하는 곳을 의미. EntityManager의 persist( (*객체*) )를 통해 이곳에 저장할수있다.
					* EntityManager
							ㅡ 영속성 컨텍스트와 상호작용하는데 사용되는 interface.
								entityManager가 제공하는 api들을 통하여 영속성 컨텍스트와 상호작용하여 엔터티들을 다룰 수 있다.
					ㄴ 영속성 컨텍스트에 저장만 되는것이고 db에 저장된느건 아님.
						ㄴ db저장은 이후 transaction.commit()을 통해 영속성 컨텍스트에 있는 정보들이 db에 저장됨.
					ㄴ EntityManager하나당 PersistenceContext가 하나 생성된다.
					ㄴ 영속성 상태들, 엔터티 생명주기 )
						ㄴ 비영속(transient) : 그냥 객체만 생성된상태
						ㄴ 영속(managed, persistent) : 영속성 컨텍스트에 저장된상태
						ㄴ 준영속(detached) : 영속이었다가 detached를 통해 영속성 컨텍스트에서 분리된상태
						ㄴ 삭제(removed) : 	db삭제 상태.
				ㅡ 영속성 컨텍스트의 이점 )
					ㄴ 캐싱과 유사한 기능 )
						ㄴ 영속성 컨텍스트 안에는 '1차 캐시'
						ㄴ 엔터티 객체를 저장시 1차 캐시에 저장된다.
						ㄴ pk값과 Entity객체 쌍으로된 값을 1차캐시에 저장된다.
						ㄴ 엔터티 객체 조회시 1차 캐시에서 먼저 찾는다.
						ㄴ 없으면 db에서 찾아서 있으면 이를 1차캐시에 저장하고 값을 넘겨준다.
						ㄴ 실무에서 사실상 큰 도움은 안되는 이점. 동작을 이해한다는 면에서 도움.
					ㄴ 엔터티의 동일성 보장 )
						ㄴ 같은 트랜잭션 안에서 가져온 같은 엔터티 객체는 '동일'하다. ('동등'말고)
					ㄴ 쓰기 지연 )
						ㄴ 위의 'JPA의 장점' - '성능 최적화' 부분의 '지연 기능'과 같은 이야기.
						ㄴ EntityManager의 persist()를 통해 엔터티 객체를 영속성 컨텍스트에 저장하면,
							바로 db에 반영되는 것이 아니라, 1차캐시에 저장됨과 동시에
							적절한 SQL문이 생성되어 '쓰기 지연 SQL저장소'에 이 SQL문이 저장된다.
						ㄴ transaction의 commit()을 실행하면, 영속성 컨텍스트의 내용들이 한꺼번에 'flush'되어 db에 적용된다.
						ㄴ 버퍼링같은 효과가 있다.
						ㄴ persistence.xml에서 속성으로 hibernate.jdbc.batch_size값 설정을 통해 크기조정가능.
					ㄴ 엔터티 수정 - 변경 감지 )
						ㄴ Dirty Checking )
							ㄴ JPA에서 트랜잭션이 끝나는 시점에, 모든 entity객체에 대해 변경사항이 생겼는지 확인하는 것.
							ㄴ 변경사항을 자동으로 db에 반영해준다.
							ㄴ 변경사항이 있다의 기준은 '최초 죄회 상태'. 이때를 기준으로 1차 캐시안에 엔터티에 대한 '스냅샷'을 만들어둠.
								이 스냅샷과 비교하여 변경사항이 있으면 '쓰기지연SQL저장소'에 적절한 update sql문을 만들어 저장한다.
							ㄴ '영속성 컨텍스트가 관리하는 엔터티'에만 적용된다.
				ㅡ flush )
					ㄴ 영속성 컨텍스트의 변경내용이 db에 적용, 동기화되는것을 말함.
					ㄴ dirty checking, '쓰기 지연 sql 저장소'의 쿼리를 db에 전송.
					ㄴ flush 하는 방법 )
						ㄴ em.flush() 직접 호출
						ㄴ 트랜잭션 커밋을 통한 자동 호출
						ㄴ JPQL 쿼리 실행을 통한 자동호출 : JPQL 쿼리를 실행하면 바로 flush()가된다.
					ㄴ flush 모드 옵션 : 굳이 필요없다함. 디폴트인 'auto'값 쓰라함.
					ㄴ 기타 )
						ㄴ 영속성 컨텍스트의 내용들이 db에 반영이 되는과정일뿐, 1차 캐시, 영속성 컨텍스트의 내용이
							비워지고 그렇지는 않음.
				ㅡ 준영속 상태 )
					ㄴ 영속상태의 엔터티가 컨텍스트에서 분리(detached)된 상태.
						ㄴ 영속성 컨텍스트에서 더이상 관리하지 않음.
					ㄴ 비영속과의 차이점
						ㄴ 특별히 유의할만한 차이점은 없다.
							그냥 비영속은 엔터티 생성 후 아직 한번도 영속성에 추가된 적이 없는 것이고,
							준영속은 영속성 관리가 되고 있다가 detach()나 트랜젝션이 종료되어
							말 그대로 영속성 관리가 되고 있지 않은 상태.
					ㄴ 준영속 상태로 만드는 방법 )
						ㄴ EntityManger의 detach() 이용 : 특정 엔터티만 준영속으로 만들때 사용.
						ㄴ EntityManger의 clear() : 영속성 컨텍스트의 내용 전체를 지움.
						ㄴ EntityManger의 close() : 영속성 컨텍스트를 '닫는다'???????????
					ㄴ !!!!!!!!!!!이후에 웹쪽 연결해서 자세하게 배운다함.
			</pre>

			ㅇ 식별자(Identifier)<button>more</button>
			<pre>
				ㅡ 엔터티를 식별하는 식별자를 말한다. 엔터티의 pk인셈. 엔터티를 유일하게 식별해낸다.
				ㅡ 식별자 속성
					ㄴ 엔터티에서 '식별자' 역할을 하는 속성(또는 속성들)을 말함.
					ㄴ '엔터티 식별자'인 속성이 db상의 pk인 컬럼과 일치하는 속성일 필요 없다.
						엔터티를 유일하게 식별 가능한 속성이면 된다.
						ㄴ ex )<button>more</button>
						<pre>
							in db table.. ) 아래와 같이 정의된 테이블이 '이미' 존재한다 가정.
							create table noname
							(
								pk   integer not null
									constraint noname_pkey
										primary key,
								name varchar(255),
								id   bigint  not null
							);

							in entity.. )  위와 같이 '이미' 존재하는 테이블에 아래와 같이 엔터티를 정의하여 테이블 매핑.
							@Entity
							@Table(name = "noname")
							public class NoName {
								// '엔터티 식별자'로 쓰이는 속성. jpa에선 이 속성을 기준으로 엔터티를 식별.
								// 따라서 jpa가 어플단에서 not null, unique, immutable 제약을 걸어 위반시 오류발생.
								// db 상에선 그냥 일반 컬럼.
								@Id
								private Long id;

								@Column
								private String name;

								// db의 pk로 쓰이는 속성.
								private int pk;

								public NoName(
										Long id, String name, int pk
								){
									this.id = id;
									this.name = name;
									this.pk = pk;
								}

								~~~
							}

							in app logic.. )
							// '엔터티 식별자'인 id는 자동 생성, db의 pk인 pk속성은 1로 직접 할당함.
							// noname1, noname2의 id컬럼이 같을 경우 어플단에서 '식별자'가 같다고 오류,
							// pk컬럼이 같을 경우 db단에서 primary key가 같다고 오류.
							NoName noname1 = new NoName(1L, "sample1", 11);
							NoName noname2 = new NoName(2L, "sample2", 22);
							em.persist(noname1);
							em.persist(noname2);

							em.flush();
							em.clear();
							em.commit();

							// '엔터티 식별자'인 NoName의 id속성을 기준으로 find.
							// db의 pk가 아닌 '엔터티 식별자'가 식별 기준이므로.
							NoName foundNoname = em.find(NoName.class, noname1.getId());

						</pre>
						ㄴ 참고 )
							ㄴ https://en.wikibooks.org/wiki/Java_Persistence/Identity_and_Sequencing#No_Primary_Key
							ㄴ https://stackoverflow.com/questions/3820897/jpa-entity-without-id
							ㄴ https://docs.jboss.org/hibernate/orm/6.1/userguide/html_single/Hibernate_User_Guide.html#entity-pojo-identifier
					ㄴ ??? hibernate, jpa는 '엔터티 식별자' 속성에 해당하는 db 컬럼이
						unique, not null, immutable 하다고 가정한다.
						ㄴ ??? 무슨말인진 알겠는데 이 가정이 구체적으로 어떤 영향을 미치는지?
					ㄴ 모든 엔터티는 '식별자'를 반드시 가져야한다.
						상속 계층 엔터티의 경우, 부모 엔터티만 가지면 된다.
				ㅡ 단일 식별자(simple identifier), 복합 식별자(composite identifier) <button>more</button>
				<pre>
					ㄴ 단일 식별자
						ㄴ 단일 속성에 매핑되며, @Id를 통해 표시된다.
						ㄴ 가능한 타입
							ㄴ JPA
								자바 원시 타입, 자바 원시 타입의 wrapper, String, java.util.Date, java.sql.Date,
								BigDecimal, BigInteger
							ㄴ Hibernate : jpa보단 더 많은 타입이 가능하다함.
						ㄴ 식별자 값 할당 vs 생성
							ㄴ 식별자의 값을 어플 로직이 직접 할당할 수도, 자동으로 생성되게 할 수도 있다.
							ㄴ 자동 생성 )
								ㄴ hibernate가 해당 엔터티 영속성 추가 직전에 '자동 생성 전략'에 따라 식별자 값을 자동 생성하여 할당.
								ㄴ 식별자 속성에 jakarta.persistence.GeneratedValue 어노테이션을 붙여 사용.
					ㄴ 복합 식별자
						ㄴ ??? 하나 이상의 속성들에 해당한다?
						ㄴ JPA 사용시, JPA 스펙에 따라 복합식별자는 다음을 지켜야 한다. (Hibernate만 사용시 다름)
							ㄴ 'primary key class'로 정의되어야하고, primary key class는
								jakarta.persistence.EmbeddedId, jakarta.persistence.IdClass annotation으로 정의될 수 있다.
							ㄴ public class이어야 하고, public no-argu 생성자가 있어야한다.
							ㄴ ??? 해당하는 db table과 일치하게 equals(), hashCode()를 override해야 한다.
						ㄴ ??? 복합식별자를 구성하는 속성들은 기본, 복합, @ManyToOne이 될 수 있다?
							컬렉션과 one-to-one은 안 된다.
						ㄴ @EmbeddedId 를 이용한 복합식별자 )
							ㄴ ~~~
						ㄴ @IdClass 를 이용한 복합식별자 )
							ㄴ ~~~
						ㄴ 연관관계 속성을 이용한 복합식별자 )
							ㄴ ??? hibernate에서 제공하는 기능. JPA는 안 된다?
							ㄴ ~~~
						ㄴ 자동 값 생성 속성을 이용한 복합식별자 )
							ㄴ 기본적으로 복합식별자를 구성하는 속성은 '자동 값 생성' 속성이어선 안된다.
								(@Generated, @CreationTimestamp 등)
							ㄴ ??? ~~~

				</pre>
				ㅡ 자동 생성 식별자 값<button>more</button>
				<pre>
					ㄴ hibernate는 여러 타입에 대해 자동 생성 식별자 값을 지원하지만, jpa의 경우, integer 타입 자동 식별자 값만 지원한다함.
					ㄴ jakarta.persistence.GeneratedValue 어노테이션을 사용하여 지정한다.
						ㄴ 속성 'strategy'에 'jakarta.persistence.GenerationType' enum값 중 하나를 설정하여
							자동 생성 전략을 선택할 수 있다.
					ㄴ jakarta.persistence.GenerationType
						ㄴ AUTO )
							ㄴ 설정시, hibernate가 자동으로 적절한 전략을 선택.
							ㄴ 선택 방식
								ㄴ ??? 식별자 타입이 UUID인 경우, 'UUID IDENTIFIER'를 사용.
								ㄴ 식별자 타입이 숫자형(integer, long)인 경우,
									ㄴ 해당 db가 sequences를 지원한다면 SEQUENCES방식을,
									ㄴ 아니라면 TABLE 방식을 선택.
						ㄴ IDENTITY )
							ㄴ db의 IDENTITY 컬럼을 이용하여 식별자값 생성.
							ㄴ 문제점 )
								ㄴ db에게 위임하게 되므로, db에 접속해서 insert를 해야 pk값을 알수있다.
								ㄴ 따라서 db에 반영하기 전인 '영속성 컨텍스트'상에서는 엔터티의 pk값이 없는
									없는 상태이므로 문제가 생김.
							ㄴ 해서, GenerationType.IDENTITY 전략일때는 persist()로 영속성컨텍스트에 추가되는 시점에
								바로 db에 접속해 insert sql을 실행하는식으로 동작한다. (commit()할때 적용되는게
								아니라) 실행하고 pk값을 받아와서 영속성 컨텍스트에 저장한다.

						ㄴ SEQUENCE )
							ㄴ db의 'sequence'를 이용해 식별자 값 생성.
							ㄴ hibernate의 'org.hibernate.id.enhanced.SequenceStyleGenerator'을 이용하여 식별자값 생성.
								ㄴ ??? SequencestyleGenerator는 db가 sequence를 지원하지 않더라도 작동할 수 있다.
							ㄴ ex )

							ㄴ db로부터 sequence값을 받아와서 pk에 저장해야하므로,
								GenerationType.IDENTITY의 경우와 유사하게 영속성 컨텍스트 저장시점에
								db에 접속하여 'sequence 값만' 받아와서 이를 pk로 저장시켜준다.
								(IDENTITY와 달리 insert sql을 실행하지는 않는다)
							ㄴ 영속성 컨텍스트에 저장하려 할때마다 db에 네트워크를 타고 접속해서 sequence번호를
								받아오기때문에 성능 이슈가 있을수있다. 해서 jpa에서는
								@SequenceGenerator의 속성 allocationSize 값만큼의 sequence번호를 한번에 받아와
								저장해둔다.
						ㄴ GenerationType.TABLE )
							ㄴ db table을 이용하여 자동 식별자 값 생성.
							ㄴ 키 생성 전용 테이블을  따로만들어서 db sequence같은 기능을 하게하는 전략.
							ㄴ 모든 db에 적용이 가능하다는 장점이 있다.
							ㄴ ????????????성능이 떨어지는 단점이 있다.
							ㄴ ???????????????????

					ㄴ 권장하는 식별자 전략 )
						ㄴ 기본키 제약조건 : null이 아니고, 유일하고, 변하면 안된다.
							ㄴ '변하면 안된다'는 조건이 어렵다. 몇년이 될지 모르는 먼 미래까지 변하면 안되는 값이어야 하므로.
						ㄴ 이러한 조건을 만족하는 '자연키'를 찾기 어려우므로 '대체키'를 사용하는것 권장.
						ㄴ 권장 : Long형 + 대체키 + 키 생성전략
							ㄴ Long형은 이후에 키값이 10억을 넘겼을때도 문제가 없도록.
						ㄴ 비즈니스 영역의 값을 키로 사용하는것 권장하지 않음.
							ㄴ ex)	주민번호를 키로 사용하는것 비추.
				</pre>

			</pre>

			ㅇ 엔터티 매핑<button>더보기</button>
			<pre>
				ㅡ JPA에서 가장 중요한 두가지. JPA의 내부동작 방식에 대한 이해, 객체와 RDB사이의 매핑 방식에 대한 이해.
					이번 챕터에서는 후자에 대해 배움.
				ㅡ 객체와 테이블 매핑 )
					ㄴ @Entity
						ㄴ JPA가 관리하는 클래스임을 선언. '엔터티'라고 한다.
						ㄴ JPA로 테이블과 매핑할 클래스는 붙여주어야 한다.
						ㄴ 주의 )
							ㄴ 기본 생성자가 필수로 있어야 한ㄷㅏ.
							ㄴ final 클래스, enum, interface, inner 클래스에는 사용불가.
							ㄴ 저장할 필드에 final 사용 불가.
						ㄴ @Table
							ㄴ 해당 엔터티와 매핑할 테이블에 대한 설정.
							ㄴ 속성 )
								ㄴ name : 매핑할 테이블의 이름 지정.
								ㄴ uniqueConstraints )
									ㄴ ddl auto generate시, unique 제약조건을 추가.
									ㄴ ex ) <button>more</button>
									<pre>
										@Entity
										@Table(
											name = "indicator_value",
											uniqueConstraints = {
												@UniqueConstraints(
													name = "(*제약조건명*)",
													columnNames = {
														(*컬럼1명*), (*컬럼2명*)
													}
												),
												@UniqueConstraints(~~~)
											}
										)
										class IndicatorValue{
											~~~
										}
									</pre>
								ㄴ indexes )
									ㄴ ddl auto generate시, index 추가.
									ㄴ ex ) <button>more</button>
									<pre>
										@Entity
										@Table(
											name = "author",
											indexes =  {
												@Index(
													name = "idx_author_first_last_name",
													columnList = "first_name, last_name",
													unique = false
												),
												@Index(~~~)
											}
										)
										public static class Author {
											~~~
										}
									</pre>
								ㄴ ~~~~~~~~~~~~~~
				ㅡ db 스키마 자동생성 )
					ㄴ 항상 사용되는건 아니지만, 엔터티를 설정해두면 어플 시작시점에 엔터티 클래스들을 보고 적절한 테이블들을 자동으로
						생성해주는 기능이 있다.
					ㄴ 즉, DDL을 어플 실행시점에서 자동생성해주는 기능.
					ㄴ???????????? 이렇게 생성된 DDL을 개발장비에서만 사용하고  운영서버에서는 사용해선 안됨.
					ㄴ persistence.xml에 hibernate.hbm2ddl.auto 속성으로 설정 가능. 사용가능한 값의 종류는 아래와 같다.
						ㄴ create : 기존 테이블 삭제 후 다시생성
						ㄴ create-drop : create와 같으나 종료시점에 테이블 drop.
						ㄴ update : 변경부분만 변경 (alter table사용)
							ㄴ 컬럼이 지워지지는 않음. 추가만된다.
						ㄴ validate : 엔터티와 테이블이 정상 매핑되었는지 확인.
						ㄴ none : 기능 사용하지 않음.
					ㄴ db 스키마를 직접 자동으로 변경하는 기능이기 때문에 매우 위험하여 가급적 사용하지 않는것을 권장.
						ㄴ 운영서버의 db 테이블이 실수로 drop되거나 컬럼 변경으로 데이터가 날아갈 위험이 있다.
						ㄴ 'update' 등으로 데이터가 날아가는 일은 없더라도, jpa에서 자동으로 db를 정의, 수정하기 때문에
							섬세하지 못하거나 어떻게 수정할지 알 수 없으므로 예상치 못한 경우도 우려되므로.
						ㄴ 번거롭더라도 db스키마 등은 직접 db에서 처리하고 엔터티를 그에 맞게 수정하는 식으로 작업하고
							이 옵션은 validate나 none으로 사용하라.
				ㅡ 필드와 컬럼 매핑 )
					ㄴ 어노테이션 )
						ㄴ @Column : 컬럼 매핑
							ㄴ name 속성 : 매핑할 테이블 컬럼 이름
							ㄴ insertable, updatable : 해당 컬럼을 삽입, 수정했을때 적용을 할지말지 결정.
								true또는 false. 디폴트값 true
							ㄴ nullabe = (*true or false*) : null값을 가질수있는지
							ㄴ unique = (*true, false*) : 유니크 제약조건을 걸때 사용.
								(@Table의 uniqueConstraints와 동일)
								ㄴ 엔터티 정의를 통해 jpa에서 ddl을 직접 생성할 때만 제약조건을 추가
									기존 존재하는 테이블이면 제약조건을 추가하지 않음.
									ㄴ 항상인지는 모르겠음.
							ㄴ columnDefinition = (*컬럼 정의 설정을 sql문으로직접 입력*) : 컬럼정보를 직접 입력.
								ㄴ ex)
									//값이 sql ddl에 그대로 들어감.
									@Column( columnDefinition="varchar(100) default 'EMPTY'")
							ㄴ length = (*숫자*) : 문자 길이 제약조건 입력
							ㄴ precision, scale
						ㄴ @Temporal : 날짜 타입 매핑
							ㄴ 자바8부터는 그냥 LocalDate, LocalDateTime타입으로 필드를 정의하면 된다.
							ㄴ 그 이전 버전에서만 사용됨.
						ㄴ @Enumerated : enum타입 매핑
							ㄴ value = (*EumType.ORDINAL, EnumType.STRING*) : EnumType.ORDINAL은 enum의 순서, 즉, 0,1,2,... 값을
								저장하는 방식이고 EnumType.STRING은 enum의 이름을 db에 저장하는 방식이다. 디폴트는 ORDINAL.
								ㄴ EnumType.ORDINAL 사용시, 이후 enum클래스상에서 변경이 발생하면 순서는 바뀌었는데 db상에선
									예전 순서대로 저장이 되어있기때문에 문제가 발생한다. 따라서 EnumType.STRING 권장.
						ㄴ @Lob : BLOB, CLOB 매핑
							ㄴ 속성이 없음.
							ㄴ 필드가 문자면 CLOB으로, 나머지는 BLOB으로 매핑됨.
						ㄴ @Transient : 해당 필드는 컬럼에 포함시키지 않음.
				ㅡ 기본 키 매핑 )
					ㄴ 직접 할당 : @Id만 사용.
					ㄴ 자동 생성 )
						ㄴ auto_increment같은걸로 자동으로 만들어주는 설정방법.
						ㄴ @GeneratedValue 사용하면된다.
						ㄴ 속성 )
							ㄴ strategy = (*아래값중 하나*) )
								ㄴ GenerationType.AUTO : db 방언에 맞게 자동생성.
								ㄴ GenerationType.IDENTITY : db가 알아서 하도록 위임.
									ㄴ ex) mysql의 경우, auto_increment를 넣는등.
									ㄴ 문제점 )
										ㄴ db에게 위임하게 되므로, db에 접속해서 insert를 해야 pk값을 알수있다.
										ㄴ 따라서 db에 반영하기 전인 '영속성 컨텍스트'상에서는 엔터티의 pk값이 없는
											없는 상태이므로 문제가 생김.
									ㄴ 해서, GenerationType.IDENTITY 전략일때는 persist()로 영속성컨텍스트에 추가되는 시점에
										바로 db에 접속해 insert sql을 실행하는식으로 동작한다. (commit()할때 적용되는게
										아니라) 실행하고 pk값을 받아와서 영속성 컨텍스트에 저장한다.
								ㄴ GenerationType.SEQUENCE : 'sequence'를 이용해 설정. ????????????????시퀀스란?
									ㄴ db로부터 sequence값을 받아와서 pk에 저장해야하므로,
										GenerationType.IDENTITY의 경우와 유사하게 영속성 컨텍스트 저장시점에
										db에 접속하여 'sequence 값만' 받아와서 이를 pk로 저장시켜준다.
										(IDENTITY와 달리 insert sql을 실행하지는 않는다)
									ㄴ 영속성 컨텍스트에 저장하려 할때마다 db에 네트워크를 타고 접속해서 sequence번호를
										받아오기때문에 성능 이슈가 있을수있다. 해서 jpa에서는
										@SequenceGenerator의 속성 allocationSize 값만큼의 sequence번호를 한번에 받아와
										저장해둔다.
								ㄴ GenerationType.TABLE )
									ㄴ 키 생성 전용 테이블을  따로만들어서 db sequence같은 기능을 하게하는 전략.
									ㄴ 모든 db에 적용이 가능하다는 장점이 있다.
									ㄴ ????????????성능이 떨어지는 단점이 있다.
									ㄴ ???????????????????
					ㄴ 권장하는 식별자 전략 )
						ㄴ 기본키 제약조건 : null이 아니고, 유일하고, 변하면 안된다.
							ㄴ '변하면 안된다'는 조건이 어렵다. 몇년이 될지 모르는 먼 미래까지 변하면 안되는 값이어야 하므로.
						ㄴ 이러한 조건을 만족하는 '자연키'를 찾기 어려우므로 '대체키'를 사용하는것 권장.
						ㄴ 권장 : Long형 + 대체키 + 키 생성전략
							ㄴ Long형은 이후에 키값이 10억을 넘겼을때도 문제가 없도록.
						ㄴ 비즈니스 영역의 값을 키로 사용하는것 권장하지 않음.
							ㄴ ex)	주민번호를 키로 사용하는것 비추.
				ㅡ 실전 예제 1 )
					ㄴ 예제와 같이 엔터티끼리 관계를 맺고있을때, 한 엔터티가 다른 엔터티의 pk를 가지고있음으로서 관계를 표현하는 방식은
						객체지향스럽지 않다. 이건 객체지향을 RDB에 맞춘것이다.
					ㄴ 객체지향적이려면 pk값이 아닌 해당 객체 자체를 가지고 있어야 한다.
			</pre>

			ㅇ 연관관계 매핑 기초<button>더보기</button>
			<pre>
				ㅡ 단방향 연관관계 )<button>more</button>
				<pre>
					ㄴ 객체의 참조와 테이블의 외래키를 매핑.
					ㄴ 다중성 : RDB에서 사용되는 개념
					ㄴ 연관관계의 주인 : 포인터같은거?
					ㄴ 객체지향 설계의 목표는 자율적인 객체들의 협력 공동체를 만드는 것이다.
						ㄴ '객체지향의 사실과 오해' 책
						ㄴ '오브젝트' 책
					ㄴ 예제 시나리오 )
						ㄴ 회원과 팀 존재
						ㄴ 회원과 팀은 N:1관계.
					ㄴ 객체를 테이블에 맞추어 모델링 )
						ㄴ 연관관계가 객체가 다른 테이블의 pk를 필드값으로 가짐으로서 표현되는 방식.
						ㄴ 객체는 참조를 통해 관계를 맺는데, RDB는 외래키 조인을 통해 관계를 맺는다.
							이러한 연관관계에 대한 차이가 있다.
					ㄴ 객체 지향적인 모델링 )
						ㄴ pk값을 필드로 가지는게 아니라, 엔터티객체의 참조를 필드로 가지고 있는것이 객체지향적인 연관관계의 표현이다.
						ㄴ Member{
							int id;
							Team team;	//연관관계가 있는 객체에 대한 참조를 가지고 있음.
							~~~
						}
					ㄴ 단방향 연관관계 )
						ㄴ 위에서 나온 회원:팀 관계같이 N:1관계의 경우, 다음과같이 하면된다.
							public class Member {
								~~~
								@ManyToOne	//회원이 N이고 팀이 1이니까 Many to one. 다대일관계임을 나타낸다.
								//rdb상에서 연관관계이므로 조인을 해야하는데, 조인할 컬럼이 뭔지 명시.
								@JoinColumn(
									name = "team_id",  // 사용할 외래키명
									referencedColumnName="id"  // 외래키가 참조할 대상 테이블의 컬럼명. default=참조하는 테이블의 기본키 컬럼명.
									foreignKey

								)
								private Team team;
								~~~
							}
						ㄴ 사용 )
							//팀 저장
							Team team = new Team();
							team.setName("TeamA");
							em.persist(team);
							//회원 저장
							Member member = new Member();
							member.setName("member1");
							member.setTeam(team); 	//객체 Team을 그냥 setter로 저장하면 jpa가 알아서 team에서 pk값을 가져와 fk값으로 사용한다.
							em.persist(member);

							Member findMember = em.find(Member.class, member.getId());
							Team findTeam = findMember.getTeam();	//이렇게 getter로 team객체를 가져오면 fk로 연결된 엔터티가 바로나온다.
				</pre>

				ㅡ 양방향 연관관계와 연관관계의 주인 )<button>more</button>
				<pre>
					ㄴ 양방향 연관관계 )
						ㄴ 양쪽이 서로 참조를 할 수 있는 것.
						ㄴ rdb의 경우에는 fk지정만으로 양쪽에서 서로를 참조할수있다.
							ㄴ pk, fk로 조인하면 된다.
						ㄴ 객체지향에서는 각 엔터티가 상대방 엔터티 객체에 대한 참조를 가지고 있어야 한다.
						ㄴ 방법 )
							ㄴ N : 1 의 경우,
								N에 해당하는 쪽에선 위에 단방향에서와 같이 @ManyToOne와 @JoinColumn을 붙이면 된다.
								1에 해당하는 엔터티에선
								@OneToMany (
									mappedBy = " (*연관관계가 있는 상대방엔터티에서 자신이 연결되어있는 객체 참조변수의 이름*) "
								)
					ㄴ 연관관계의 주인 )
						ㄴ 객체의 양방향 관계는 사실상 단방향 관계가 두개 있는것과 마찬가지이다.
							양쪽 모두 서로에 대한 객체참조를 가지고 있으므로.
							ㄴ 그에비해 RDB는 fk라는 하나의 관계로 양방향이 가능하니 양방향관계 하나있는것.
						ㄴ 객체로 양방향을 표현한경우, 둘중 어떤쪽을 변경하여 rdb의 양방향 관계를 업데이트할지 애매한데,
							이 기준점을 '연관관계의 주인'이라함.
						ㄴ 연관관계의 주인만이 외래키에 해당하는 엔터티 참조값을 변경가능하다.
						ㄴ 주인이 아닌쪽은 읽기만 가능하다.
							ㄴ 주인이 아닌 쪽에서 참조값을 변경하면 해당 로직이 그냥 무시된다.
								ㄴ ex )
									KRXDailyData가 연관관계의 주인이라 할 때,

									StockBasicInfo basicInfo2 = em.find(StockBasicInfo.class, 4L);
									// KRXDailyData dailyData3=basicInfo2.getKrxDailyDataList().get(0);
									// dailyData3.setStock(null);
									// 연관관계 주인이 아닌 basicInfo에서 KRXDailyData를 변경해도 적용되지 않는다.
									basicInfo2.getKrxDailyDataList().add(new KRXDailyData(new Date(), new Float(3000)));

						ㄴ mappedBy 속성값이 연관관계의 주인이 누군지 나타낸다.
							ㄴ mappedBy 속성이 설정된 엔터티의 상대 엔터티가 연관관계의 주인이 된다.
							ㄴ ex)
								public class Member{
									~~~
									@OneToMany(mappedBy = "member")	//Member엔터티가 주인이 아닌게 되고,
									private List< Order> list; 	//주인이 아닌쪽의 연관관계에 속해있는 객체로는 조회만 가능하다.
									~~~
								}
								~~~
								public class Order{
									~~~
									@ManyToOne	//Order가 연관관계의 주인이 되고,
									@JoinColumn(name="member_id")
									private Member member;	//주인쪽의 객체를 통해서 데이터 변경이 가능하다.
									~~~
								}
							ㄴ 이게 선언된 엔터티객체를 통해서는 읽기만 가능한것.
						ㄴ 관례적으로, fk값을 가지고 있는 테이블에 해당하는 엔터티 객체를 주인으로 지정한다.
							ㄴ 반대쪽을 주인으로 지정할경우, 그 주인 엔터티를 변경하면 뭐 아무튼 헷갈린다함.
							ㄴ rdb상에선, fk를 가진쪽이 1:n관계에서 n에 해당한다.
							ㄴ '관계의 주인'이라고 하니까 의미적으로 헷갈릴수있는데 의미부여하지말자. 그냥 관례적으로만 하라.
						ㄴ 주의점 )
							ㄴ 객체지향적으로 보면, 양방향 관계에서 양쪽 엔터티 참조객체에 모두다 변경사항을 저장해주는게 맞다고함.
								ㄴ 또한, EntityManager의 flush(), clear()을 하면 영속성 컨텍스트의 내용이 모두 db에 적용되고 비워지고,
									연관관계 주인을 통해 연결된 엔터티들이 업데이트가 되니 문제가 없지만,  flush(), clear()를 하지않은
									영속성 컨텍스트 안에서 작업하는 경우에는 연관관계 주인을 통한 업데이트가 되지 않으므로 양쪽 객체에
									값을 다 업데이터해주는게 좋다고 한다. db에 직접 연결하지 않는 테스트 케이스 상황에서도 연관관계
									주인을 통한 값 업데이트가 되지 않으므로 양쪽다 업데이트해주는 방식이 좋다.
									ㄴ 즉, db와의 연결되지 않는 순수 객체 상태인 환경을 고려하여 항상 양쪾에 값을 업데이트해야한다.
								ㄴ 양쪽에 일일히 넣어주는게 번거롭고실수의 여지가 많기때문에 전용 편의 메소드를 만들어두는걸 추천.
							ㄴ 컨트롤러에서 엔터티를 반환하지 마라.
								ㄴ 양방향 연결이 되어있을 경우, 객체를 string으로 변환하려할때 무한루프에 빠질수있다.
									ㄴ 서로를 참조하고있으므로, 한쪽에서 string으로 만드려고 보니 참조객체가 있고 이걸 string으로 만드려고
										보니 또 참조객체가 있고... 이런식으로
								ㄴ 이후에 엔터티에 변화가 생길경우, restful api의 스펙자체가 변경된다.
								ㄴ 엔터티 대신 DTO를 이용해라.
							ㄴ 양방향 매핑.. 지향해라..? )
								ㄴ 단방향 매핑만으로 테이블, 엔터티간 연관관계를 충분히 나타낼 수 있다. 단지 역방향 조회의 경우에 필요한것.
									따라서 단방향 매핑만으로 설계를 끝내는걸 추천한다함.
									ㄴ 설계상에서 비즈니스 부분을 적절하게 판단하여 불필요하게 양방향이 쓰이지 않도록 해야함.
								ㄴ 사실상 단방향 매핑과 양방향 매핑의 차이점은 rdb상에는 전혀없고, 객체상에서 단방향 매핑에서 반대쪽에서
									참조객체를 하나 추가한것에 불과하다. 따라서 일단 단방향매핑만으로 설계하고, 나중에 필요하면 양방향으로
									추가하는것도 좋은 방법이다.
				</pre>

			</pre>

			ㅇ다양한 연관관계 매핑 )<button>더보기</button>
			<pre>
				ㄴ
				ㄴ 일대다 )
					ㄴ 1쪽이 연관관계의 주인.
					ㄴ 그러나 테이블상에서는 N쪽에 fk가 존재하기때문에, 1쪽인 엔터티에서 N쪽의 엔터티를 추가하면 객체지향적으로는
						1쪽에서 N을 추가한것처럼 보이지만, db상으로는 N쪽 테이블에서 fk를 업데이트하여 1쪽 테이블의 값을
						추가하는식으로 동작함.
					ㄴ Collection, List, Set, Map 중 하나를 사용하여 연관관계 필드를 만들어야 함.
						ㄴ ex)
							@OneToMany
							List< Member> memberList;
					ㄴ 단방향과 양방향 )
						ㄴ 단방향 )
							ㄴ @OneToMany만 정의하여 단방향 매핑 생성 가능(반대쪽 엔터티에선 아무런 연관관계 없음)
							ㄴ @JoinColumn 설정 필요. 없을시, '조인 테이블' 전략으로 매핑을 하여, manyToMany방식처럼 중간
								테이블이 생기는 방식으로 매핑됨.
							ㄴ sql 동작 방식. <button>more</button>
							<pre>
								ㄴ 이를 통한 연관관계 조작시, N 쪽의 테이블의 외래키 컬럼을 update하는 식으로 동작한다.
								ㄴ ex )
									Member, Team 이 n:1 인 경우,
									class Team{
										~~~
										@OneToMany
										@JoinColumn
										private List< Member> memberList;
										~~~
									}

									class Member{
										~~~
									}

									// in 로직..
									Member member = new Member(~~~);
									Team team = new Team(~~~);
									// 리스트에 값 추가. 테이블 상에선 member가 team에 대한 외래키값을 가지게됨.
									team.getMemberList().add(member);

									em.persist(team);
									em.persist(member);
									em.flush();

									// em.flush()시, sql..
									insert into member(~~~) values (~~~)
									insert into team(~~~) values (~~~)
									// member insert시 외래키를 한번에 넣지 않고 비워두었다가 이후 update문으로
									// 외래키 값을 채워넣는다.
									// 이는 그냥 oneToMany 리스트에 값을 추가 삭제할 때뿐 아니라 지금 예제처럼
									// member를 생성함과 동시에 이를 리스트에 추가해도 update문이 따로 나간다.
									update member set member_id=~~~ where id=~~~
								ㄴ 위와 같이 update문이 따로 나가는 방식이라 N쪽의 외래키 컬럼은 db상에서 nullable이 된다.
									ㄴ @OneToMany 컬럼에 @JoinColumn(nullable=false) 를 부여하여도 db상에선 nullable이고
										jpa상에서 제약조건을 확인한다.
									ㄴ 이렇게 개복잡하니 @ManyToOne 단방향 또는 양방향 쓰자.
							</pre>
						ㄴ 양방향 ) <button>more</button>
						<pre>
							ㄴ ex )
								class StockBasicInfo{
									~~~
									@OneToMany(mappedby="stock")
									// @JoinColumn
									private List< KRXDailyData> krxDailyDataList;
									~~~
								}

								class KRXDailyData{
									~~~
									@ManyToOne
									private StockBasicInfo stock;
									~~~
								}

								StockBasicInfo basicInfo = new StockBasicInfo();
								KRXDailyData dailyData = new KRXDailyData();

								// 연관관계 주인이 아니기 때문에 db에 아무런 변화가 없다. jpa에서 db상으로 적용을 한 하는 것.
								basicInfo.getKrxDailyDataList().add(dailyData);
								// 연관관계 주인이기 때문에 KRXDailyData 테이블에 stock컬럼을 업데이트 친다.
								dailyData.setStock(basicInfo);

							ㄴ @OneToMany에 연결된 엔터티 쪽에서 @ManyToOne을 설정하고
								@OneToMany에 mappedby="(*반대쪽 엔터티에서 현재 엔터티로의 연관관계를 나타내는 필드명*)" 설정시
								양방향 @OneToMany가 설정된다.
								ㄴ mappedby 속성으로 어떤 필드 변경시 db에서 실질적으로 외래키가 변화하는지를 정한 것이고
									위 예제에선 KRXDailyData의 "stock"필드를 조작해야 실질적으로 db값이 변경됨을 정의
									이를 '연관관계 주인'이라 한다.
								ㄴ 다대일, 일대다 관계에서 연관관계 주인은 항상 N쪽이다. (jpa 스펙상?)
									1쪽이 연관관계 주인이 될 수 없다.
									ㄴ 즉, @OneToMany 양방향에선 항상 @OneToMany 쪽에 mappedby가 설정되는 것.
							ㄴ 양방향과 단방향 2개 매핑 차이 )<button>more</button>
							<pre>
								ㄴ mappedby를 설정하지 않고 반대쪽에 @ManyToOne을 설정시,
									이는 양방향 관계매핑이 아닌 단방향 2개가 매핑된다.
								ㄴ ex )
									class StockBasicInfo{
										~~~
										@OneToMany
										@JoinColumn(name="stock_id")  // KRXDailyData쪽과 동일하게 맞추면 컬럼 하나 생김.
										private List< KRXDailyData> krxDailyDataList;
										~~~
									}

									class KRXDailyData{
										~~~
										@ManyToOne
										@JoinColumn(name="stock_id")
										private StockBasicInfo stock;
										~~~
									}

									StockBasicInfo basicInfo = new StockBasicInfo();
									KRXDailyData dailyData = new KRXDailyData();

									// 값 변경됨. 그냥 단방향 @OneToMany로 값변경하는 것과 동일한 것.
									basicInfo.getKrxDailyDataList().add(dailyData);
									// 값 변경됨. 그냥 단방향 @ManyToOne 값변경하는 것과 동일.
									dailyData.setStock(basicInfo);

								ㄴ jpa가 @OneToMany에 의한 단방향 매핑 한개, @ManyToOne에 의한 단방향 매핑 한개로 인식하여
									KRXDailyData 테이블에 KRXDailyData->StockBasicInfo 인 fk가 두 개만들어지고
									서로 각각의 필드를 조작하게 된다.
									ㄴ 두 필드에 @JoinColumn(name="")으로 이름을 동일하게 하면 fk가 하나만 생기고
										양쪽에서 조작이 가능하기는 한데
										김영한 책에서는 언급하고 있지 않은 것 같아 자세히는 모르겠다.
										일단 쓰면 많이 꼬일 것 같다.
								ㄴ 정석은 아니지만,
									위와 같이 단방향 두개 식으로 매핑한 뒤, 한 쪽에
									insertable=false, updatable=false를 설정하여 한쪽에서만 조작 가능하도록 하여
									연관관계 주인처럼 사용할 수 있다.
							</pre>
							ㄴ 어플리케이션 단에서의 동기화
								ㄴ 연관관계 주인이 어느 쪽이든, 단방향 2개인 식으로 정의되었든, flush()시 db에는
									적절하게 반영이 되고 그 후 엔터티 로드시 양쪽 모두 정상적으로 값들이 들어있으나,
									db 적용하기 전 어플리케이션 로직 단에서는 한 쪽에서 값을 변경하면 자동으로
									반대쪽에서 값 변경이 동기화되지 않으므로 buggy할 수 있다.
									명시적으로 양쪽에 반영해 주어야 한다.
								ㄴ ex )
									위 예와 같은 엔터티 정의라 할 때...

									StockBasicInfo basicInfo = new StockBasicInfo();
									KRXDailyData dailyData = new KRXDailyData();

									// 이렇게만 하면 dailyData의 stock필드에는 여전히 값이 비어있다.
									// 명시적으로 반대쪽에도 값을 반영해 주어야 좋다.
									basicInfo.getKrxDailyDataList().add(dailyData);
									// dailyData.setStock(basicInfo);


						</pre>
					ㄴ 객체지향과 관계형db의 방식이 달라서 이런방식이되는것인데
					ㄴ 이렇게 조금 꼬여있는듯한 방식이 복잡도를 올려 버그의 위험성이 커짐.
					ㄴ 김영한은 이걸쓰느니 다대일 양방향을 추천한다함.

				ㄴ 일대일 )<button>more</button>
				<pre>
					ㄴ 양 테이블 중 어느테이블에 외래키를 넣을지 선택할 수 있다.
					ㄴ 외래키에 db 유니크 제약조건이 추가되어야 한다.
					ㄴ 주테이블에 fk vs 대상테이블에 fk )
						ㄴ 정확한 정의는 모르겠으나 전자가 주인이 된다하여 주테이블, 후자가 주인이 아닌 것쯤?
							두 대상을 비교하여 상대적으로 더 주인이라는 의미에 적합한 개념이 주태이블(주엔터티)이 되는 듯 싶다.
							가령, member, locker가 있으면 전자가 주테이블, 후자가 다상테이블?
						ㄴ 주테이블에 fk인 경우,
							좀 더 객체지향적?
						ㄴ 대상테이블에 fk인 경우,
							전통적인 rdb 방식?, 일대일에서 일대다로 변경되어도 구조상의 큰 변화가 없다.
					ㄴ 단방향 )
						ㄴ 그냥 @OneToOne을 사용하여 매핑.
						ㄴ @OneToOne이 선언된 엔터티에 fk가 생성.
						ㄴ @OneToOne을 선언한 반대쪽에서 fk를 가지도록은 jpa스펙상 불가능함.
					ㄴ 양방향 )
						ㄴ 양쪽에 @OneToOne을 선언 후, 연관관계 주인 반대쪽에 mappedby 설정.
							ㄴ 당연히, 연관관계 주인쪽에 fk 생성.
					ㄴ 정리 )
						ㄴ 주 테이블에 외래기 설정한 경우 )
							ㄴ ex) Member가 주테이블, Locker가 대상테이블일때, Member 테이블이 Locker에 대한 fk를
									가지고있는 구성인 경우.
							ㄴ 주 테이블 조회만으로 대상테이블 데이터를 알수 있어 jpa사용이 편리하고 객체지향적으로 개발가능.
							ㄴ 주테이블에 대상테이블에 대한 값이 없으면 null을 허용해야함.
						ㄴ 대상 테이블에 외래키 설정한 경우 )
							ㄴ ex ) Member가 주테이블, Locker가 대상테이블일때, locker가 member에 대한 fk를 가지고있고
								member와 locker가 일대일 양방향 관계로 구서되어있을때,
								ㄴ member 엔터티 조회시, member의 locker를 조회하려면 어차피 locker에 대한 쿼리문이 나가야
									하기때문에 locker를 '지연로딩'하지 않고 항상 '즉시로딩'을 한다.
				* db 설계, 엔터티 설계 관련 ... )
					ㄴ Member, Locker의 예를 보면, Member엔터티가 Locker를 가지고잇게 하느냐, 그 반대이느냐, oneToMany이냐
						ManyToOne이냐, 테이블상 member 가 locker에 대한 fk를 가지고있느냐, 그반대이느냐 등에 따라 당장 개발할때와
						미래에 수정사항이 생길때 어떻게 될지 등이 바뀐다. 해서 어떻게 db, 엔터티 설계를 하느냐가 중요하다.
				</pre>

				ㄴ 다대다 )<button>more</button>
				<pre>
					ㄴ rdb상에선 다대다 매핑을 테이블 두개만으로 표현할 수 없기때문에 중간 테이블을 하나 더 두어서 다대일,
						일대다 형태로 대다대를 표현.
						ㄴ ex) Member와 Product간 다대다일 경우, member_and_product란 중간테이블을 두어 구현
					ㄴ 객체지향상에서는ㄴ 다대다 매핑이 가능하다. 양쪽에 서로에 대한 필드를 추가해주면되기때문에.
						ㄴ ex) Member엔터티에 Product필드, Product엔터티에 Member필드 추가.
					ㄴ 사용법 )
						ㄴ 다대다 필드에 @ManyToMany, @JoinTable 선언
						ㄴ @JoinTable의 속성 설정
							ㄴ name : 중간 테이블명
							ㄴ joinColumns : 중간테이블의 현재 엔터티를 나타내는 필드에 대한 설정 정보
							ㄴ inverseJoinColumns : 중간테이블의 상대 엔터티를 나타내는 필드에 대한 설정 정보
							ㄴ ex )
								@ManyToMany
								@JoinTable(
										// 중간테이블명 설정.
										name = "noname_basic_info",
										// noname_basin_info 테이블의 noname fk에 대한 설정.
										joinColumns = @JoinColumn(name="noname"),
										// noname_basic_info 테이블의 stock_basic_info fk에 대한 설정.
										inverseJoinColumns = @JoinColumn(name = "stock_basic_info")
								)
								private List< StockBasicInfo> stockBasicInfoList = new LinkedList<>();
						ㄴ 양방향시,
							반대쪽에도 @ManyToMany(mappedby=~~~) 선언 후 사용하면 된다.
							동일하게 mappedby로 연관관계 주인을 설정하며,
							@JoinTable 선언은 연관관계 주인쪽에서 해야한다.
					ㄴ 단점 )
						ㄴ jpa를 통해 생성된 중간테이블에는 매핑정보만들어갈 수 있고, 추가적인 다른데이터를 넣을 수 없어
							복잡한 실무에서 사용하기에 제한이 많다.
						ㄴ 중간테이블을 사용하여 쿼리가 생성되기때문에 복잡한 쿼리가 나간다.
					ㄴ 단점의 극복 )
						ㄴ @ManyToMany로 중간테이블을 사용하는게 아니라, 중간에 아예 새로운 엔터티를 설계하고 이 엔터티에 대해
							원래 다대다 연결하려던 두 엔터티를 @OneToMany, @ManyToOne을 사용하여 매핑해주는 방식.
							ㄴ ex) Member와 Product를 다대다연결하려면 @ManyToMany를 사용하는게 아닌 Order라는 새로운 엔터티를
									만들고 Member와 Order을 연결하고 Order와 Product를 연결하는 방식.
							ㄴ 즉, 다대다 매핑 쓰지말고 비즈니스 설계상 새로운 엔터티를 설계하여 이를 중간테이블처럼 사용하라는것.
					* JPA 복합키 사용법<button>more</button>
					<pre>
						ㅡ ex )
							in 복합키로 정의할 엔터티 클래스...
							@Entity
							@IdClass(NoNameStockBasicInfoId.class)
							public class NoNameStockBasicInfo {
								@Id
								private Long id1;

								@Id
								private Long id2;

								private String name;
							}

							in 식별자 클래스...
							public class NoNameStockBasicInfoId implements Serializable {
								private Long id1;
								private Long id2;

								@Override
								public boolean equals(Object o){
									~~~
								}
								@Override
								public int hashCode(){
									~~~
								}
							}

							in table...
							create table nonamestockbasicinfo
							(
								id1  bigint 		not null,
								id2  bigint       	not null,
								name varchar(255),
								constraint nonamestockbasicinfo_pkey
									primary key (id1, id2)
							);
						ㅡ 엔터티 클래스에 @IdClass( (*식별자 클래스 타입*) ) 선언
						ㅡ 식별자 클래스 정의
							ㄴ Serializable 구현해야함
							ㄴ equals(), hashCode()를 overide해야함.
							ㄴ 기본생성자 필수, 클래스는 public.
						ㅡ 식별자 클래스의 필드들과 같은 이름의 필드가 엔터티 클래스에서 찾아 매핑되어
							이 필드들이 엔터티의 복합키로서 정의된다?
							ㄴ 식별자 클래스의 필드명이 엔터티 클래스의 필드에 없으면 오류 발생,
								엔터티 클래스에서 식별자 클래스의 필드명과 같은 필드 이외의 필드가 @Id로 선언되면
								무시되고 일반 필드로 정의되는 듯?
							ㄴ 식별자 클래스의 필드 타입과 엔터티 클래스의 필드 타입이 다를 경우, 영속성 추가시 오류발생.
								ㄴ 단, 엔터티 클래스의 필드가 연관관계 매핑 필드이고 매핑된 엔터티의 id와 식별자 클래스의
									필드 타입이 같으면 문제 없음.
									ㄴ ex )
										in  복합키로 정의할 엔터티 클래스...
										@Entity
										@IdClass(NoNameStockBasicInfoId.class)
										public class NoNameStockBasicInfo {
											@Id
											@ManyToOne
											private NoName id1;

											@Id
											@ManyToOne
											private StockBasicInfo id2;

											private String name;
										}
					</pre>
					ㄴ 다대다가 아닌 중간 연결 엔터티 방식 )
						ㄴ 위에 나온 복합키를 사용하여 다대다를 대신할 연결 테이블을 만들 수 있다. (위 예제 참고)
						ㄴ 복합키를 이용한 다대다 연결 엔터티 방식 vs 대리키를 이용한 다대다 연결 엔터티 방식
							ㄴ 대리키를 이용한 다대다 연결 엔터티 방식이란,
								위와 같이 jpa복합키를 사용하는 연결 엔터티를 정의하는 것이 아닌,
								jpa에서 자동으로 생성해주는 Long값 같은 idx값을 기본키로 사용하고 연관관계는 그냥
								일반 fk필드처럼 사용하는 방식.
							ㄴ 김영한의 추천 : 대리키를 이용한 연결 엔터티 방식.
								ㄴ jpa에서 복합키 이용시 설정이 손이 많이감.
								ㄴ 대리키 사용시 비즈니스에 의존하지 않음.

				</pre>

				ㄴ 실전예제 3 - 다양한 연관관계 매핑 )
					ㄴ

			</pre>

			ㅇ 고급 매핑 <button>더보기</button>
			<pre>
				ㅡ 상속관계 매핑 <button>더보기</button>
				<pre>
					ㄴ 객체의 상속 관계를 db 테이블에서 어떤식으로 구현할지에 대해.
						ㄴ db 테이블에는 상속 개념이 없어 아래 방식 중 하나로 상속 관계를 구현한다.
							1. '조인 방식' ) 개념적으로 O를 상속하는 A,B,C가 있다 하면,
								O 테이블을 만들고 A,B,C가 O를 fk로 참조하도록 하는 방법.
							2. 단일 테이블 ) 테이블을 하나만 만들어 모든 필요한 컬럼을 다 포함시키고 A,B,C 중 어떤 것인지
								구분하는 컬럼을 두는 방법.
							3. A,B,C에 해당하는 테이블을 각각 만드는 방법.
					ㄴ 엔터티에서 다른 엔터티를 클래스 상속하면 JPA에서 알아서 상속관계 형태로 테이블을 생성해 준다.
						ㄴ 디폴트 방식은 2번 방식이다.
						ㄴ 다른 방식으로 하려면, 엔터티 클래스에 어노테이션 '@Inheritance(strategy = InheritanceType.(*원하는 타입*) )'을
							추가하면 해당 방식으로 상속관계 형태의 테이블이 생성된다.
					ㄴ join 방식 )
						ㄴ base 엔터티 클래스에서 @Inheritance(strategy = InheritanceType.JOINED) 를 설정시 사용.
						ㄴ ex ) <button>more</button>
						<pre>
							상위 엔터티 클래스... )
							@Entity
							@Inheritance(strategy = InheritanceType.JOINED)
							@DiscriminatorColumn(name="dtype")
							public class NoName {
								@Id @GeneratedValue(strategy = GenerationType.AUTO)
								private Long id;

								protected String name;
								protected int price;

							하위 엔터티 클래스... )
							@Entity
							@DiscriminatorValue("b")  // 디폴트는 엔터티 클래스 명.
							public class Book extends NoName{
								@Id @GeneratedValue(strategy = GenerationType.AUTO)
								private Long id;

								private String author;
								private String isbn;

								public Book(){}
								public Book(String name, int price, String author, String isbn){
									this.name = name;
									this.price = price;
									this.author = author;
									this.isbn = isbn;
								}
							}

						</pre>
						ㄴ 하위 엔터티의 id값이 상위 엔터티의 id값이 된다.
						ㄴ 하위 엔터티 객체를 생성하여 영속성이 추가시, 상위 엔터티의 값도 생성된다.
						ㄴ 상위 엔터티 클래스에 '@DiscriminatorColumn(name="(*컬럼명*)")'
							ㄴ 상위 엔터티 클래스에 자동으로 컬럼 추가. 디폴트 컬럼명은 'dtype'
								이 컬럼은 상속관계 엔터티 중에서 어떤 하위 엔터티 생성과 관련하여 이 상위 엔터티가 생성되었는지를 나타낸다.
								ㄴ 가령, O를 상속하는 A,B 엔터티가 있다고 하면, A엔터티 생성이 되면 O의 'dtype' 컬럼에 A엔터티명이
									들어간다.
								ㄴ 하위 엔터티 클래스에 '@DiscriminatorValue( "(*dtype명*)" )'으로 상위 엔터티의 'dtype'에 들어갈
									이름을 결정할 수 있다.
						ㄴ 기본적으로 정석.
							ㄴ 외래키 기능도 사용할 수 있고, 객체 상속 형태에 가장 잘 들어맞는다.
					ㄴ 단일 테이블 )
						ㄴ 상위 객체가 O, 하위 객체가 A,B,C라고 하면, 한 테이블에 A,B,C의 모든 컬럼이 들어가고, dtype으로 이 레코드가
							A,B,C 중 어떤건지 구분만 하는 방식.
						ㄴ @Inheritance(strategy = InheritanceType.SINGLE_TABLE) 을 통하여 설정.
						ㄴ dtype 컬럼이 자동으로 추가된다.
						ㄴ 특징 )
							ㄴ 모든 컬럼을 때려넣기 때문에 사용하지 않는 컬럼에 대한 null처리 등이 필요하다.
							ㄴ 한 테이블을 사용하므로 쿼리가 단순하여 성능에 이점이 있다.
					ㄴ 각각의 테이블 생성 )
						ㄴ O의 컬럼을 포함하고 있는 A,B,C 테이블을 각각 만드는 방식.
						ㄴ @Inheritance(strategy = InheritanceType.TABLE_PRE_CLASS) 을 통하여 설정.
						ㄴ dtype컬럼은 필요 없다.
						ㄴ 특징 )
							ㄴ 상위 객체에 해당하는 컬럼이 똑같이 여러 컬럼에 나뉘어 들어가기 때문에 관리가 어렵다.
							ㄴ select시, 상위 객체에 속한 정보로 검색을 할 경우, 하위 객체에 해당하는 테이블을 모두 검색해야 하여
								매우 buggy해진다.
				</pre>
				ㅡ MappedSuperclass<button>more</button>
				<pre>
					ㄴ ex ) <button>more</button>
					<pre>
						@Getter
						@Setter
						@MappedSuperclass
						public abstract class Timestamped {  // 따로 생성할 일이 없으므로 보통 abstract.

							private LocalDateTime createdDate;  // 여기서 정의한 속성이 그대로 이를 상속하는 클래스에 들어간다.
							private LocalDateTime modifiedDate;
						}

						@Entity
						public class User extends Timestamped {  // MappedSuperclass를 상속. createdDate, modifiedDate를 속성으로 가짐.

							@Id
							@GeneratedValue(strategy = GenerationType.AUTO)
							@Column(name = "USER_ID")
							private Long id;

							@Column(nullable = false)
							private String username;
							...
						}
					</pre>
					ㄴ 엔터티에서 공통적인 속성을 뽑아내어 클래스를 만들고 이를 엔터티 클래스가 상속하게 함으로써 공통된 속성을 엔터티에
						추가할 수 있게 하는 기능.
					ㄴ 공통으로 뽑아낸 클래스에 '@MappedSuperclass' 선언을 해준다.
					ㄴ 상속과 유사해 보이지만 단순히 엔터티의 속성을 똑같이 재사용하는 것.
						특히, 상속 전략 중 'table per class'와 많이 유사해 보인다.
						속성이 공통되게 들어간다는 점은 똑같지만, 엔터티 상속은 orm에 의해 객체 지향의 상속처럼 처리되지만 mappedSuperclass는
						단순히 속성이 똑같을 뿐.
						상속이 아니므로 당연히 엔터티가 아니며 독립적으로 엔터티가 생성될 일이 없다.
					ㄴ 당연히, 공통으로 뽑아낸 클래스에 컬럼에 대해 여러 어노테이션을 주면 공통적으로 적용된다.
				</pre>
				ㅡ 상속관계 매핑 vs MappedSuperclass vs embedded
					ㄴ 당연히 뭐가 딱 좋다하기 어렵.
						비슷한 기능을 하지만 다른 점들도 있고, 각각의 특징을 잘 고려하여 상황에 적절히 사용.
					ㄴ 항상 완벽하게 이상적이라 생각되는 형식이 아니더라도 상황에 맞게 적절하게 개발해야함.

			</pre>

			ㅇ 프록시와 연관관계 관리<button>더보기</button>
			<pre>
				ㅡ 프록시 <button>더보기</button>
				<pre>
					ㄴ 배경? )
						ㄴ Member 엔터티 안에 Locker라는 연관관계가 매핑되어있을때, Member 조회시, Locker까지 한번에
							읽어오느냐 member만 읽어오느냐의 문제. locker를 사용하지도 않는데 locker까지 쿼리로 조회하면
							이는 분명 낭비이다.
						ㄴ 하여, jpa의 기능 중에는, orm을 통해 엔터티를 불러올 때, 한번에 모든 정보를 불러오는 게 아닌 일부만 불러와 놓고,
							그 엔터티에 대해 실제 데이터를 읽어야 할 때 엔터티의 정보를 불러오는 기능이 있고 이 임시로 불러와진 것을 '프록시'라 한다.
					ㄴ 프록시 객체?? )
						ㄴ 해당하는 실제 엔터티 클래스를 상속한다.
					ㄴ EntityManager의 getReference()
						ㄴ EntityManager의 find()와 다르게 db에서 실제 엔터티 객체를 조회하는게 아닌, db에서 조회를 미루는
							가짜(프록시) 엔터티를 조회한다.
						ㄴ 이미 엔터티의 모든 정보가 읽어와진 상태라면(영속성 컨텍스트 안에 있는 엔터티라면), 프록시가 아닌 실제 엔터티
							객체를 가져온다.
						ㄴ 특정 엔터티에 대해, getReference()와 find() 중, getReference()가 먼저 호출되었다면, find()에서도 프록시를 반환,
							그 반대 순서로 호출되었다면 getReference()에서도 실제 엔터티 객체를 반환한다.
							ㄴ ex )
								Book bookByFind = em.find(1L);  // 실제 엔터티 객체 반환.
								Book bookByGetReference = em.getReference(1L);  // 실제 엔터티 객체 반환. (프록시 아님)

								Member memberByGetReference = em.getReference(1L);  // 프록시 반환.
								Member memberByFind = em.find(1L);  // 프록시 반환. (실제 엔터티 객체 아님)
					ㄴ detach나 EntityManager.clear() 등을 통해 준영속 상태일 때, 프록시를 통해 엔터티 객체의 데이터를 로드하려 하면
						프록시를 초기화 할 수 없어 오류 발생. (LazyInitializationException)
						ㄴ 프록시에서 실제 데이터를 읽으려 할 때 실제 엔터티 객체를 불러와 읽어야 하는데 준영속 상태라 읽을 수 없는 것.
						ㄴ 당연히, 프록시 객체가 아닌 실제 엔터티 객체는 준영속 상태와 상관없이 읽을 수 있다.
					ㄴ EntityManagerFactory의 PersistenceUnitUtil의 isLoaded( (*프록시객체*) )
						ㄴ 해당 프록시 객체가 초기화 되었는지 확인.
					ㄴ Hibernate의 initialize( (*프록시객체*) ) : 프록시 객체 강제 초기화.

				</pre>

				ㅡ 즉시 로딩과 지연 로딩 <button>more</button>
				<pre>
					ㄴ 엔터티A가 엔터티B에 대해 연관 관계를 가지고 있을 때, 연관 관계를 가지는 엔터티A를 읽어올 때, 엔터티B를 바로 db로부터
						읽어올지, 나중에 읽어올지를 설정할 수 있고 이를 '즉시 로딩'과 '지연 로딩'이라고 한다.
						ㄴ 즉시 로딩 : 엔터티A를 읽을 때, db에서 엔터티B에 대한 데이터도 같이 쿼리해서 읽어옴.
						ㄴ 지연 로딩 : 엔터티A를 읽을 때, db에서 엔터티A에 대한 데이터만 가져오고 엔터티B는 프록시로 읽어옴. 이후, 엔터티B에
										대해 실제 데이터가 필요할 때, db로부터 엔터티B의 데이터를 읽어옴.
							ㄴ '엔터티B의 실제 데이터가 필요할 때'란, 엔터티B의 속성을 읽어들여야 하거나 엔터티B를 변수에 할당할 때?
					ㄴ 엔터티 정의 클래스에서 연관 관계가 있는 속성의 어노테이션에 'fetch = FetchType.(*값*)'을 부여하여
						해당 연관관계의 엔터티를 즉시로딩할지, 지연 로딩할지 결정할 수 있다.
						ㄴ 지연 로딩 ex )<button>more</button>
						<pre>
							@Entity
							public class BBB extends Base {
								@Id
								@GeneratedValue(strategy = GenerationType.AUTO)
								private Long id;

								@ManyToOne(fetch = FetchType.LAZY)  // '지연 로딩'으로 설정.
								@JoinColumn
								private NoName noname;

							~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
							BBB bbb = new BBB(noname);
							em.persist(bbb);

							em.flush();
							em.clear();  // context 비움.

							// BBB엔터티를 읽어옴(db에 쿼리가 나가 BBB엔터티의 데이터를 읽어옴).
							// BBB엔터티의 NoName은 '지연 로딩'이므로 db에 NoName에 대한 쿼리가 나가지 않고 프록시 상태로 가져와짐.
							BBB bbb2 = em.find(BBB.class, bbb.getId());
							System.out.println(bbb2.getNoname().getClass());  // NoName의 프록시 객체 출력.
							// NoName 엔터티의 값을 변수에 할당함으로서 실제 데이터가 필요해짐. 이 시점에 db에 쿼리가 나가 NoName에 대한
							// 데이터 읽어옴.
							NoName noname12 = bbb2.getNoname();
							System.out.println(bbb2.getNoname().getClass());  // 여전히 프록시.
						</pre>
						ㄴ 즉시 로딩 ex ) <button>more</button>
						<pre>
							@Entity
							public class BBB extends Base {
								@Id
								@GeneratedValue(strategy = GenerationType.AUTO)
								private Long id;

								@ManyToOne(fetch = FetchType.EAGER)  // '지연 로딩'으로 설정.
								@JoinColumn
								private NoName noname;

							~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
							BBB bbb = new BBB(noname);
							em.persist(bbb);

							em.flush();
							em.clear();  // context 비움.

							// BBB엔터티와 함께 NoName의 데이터를 읽어옴(db에 쿼리가 나가 BBB엔터티와 NoName의 데이터를 읽어옴).
							// BBB엔터티의 NoName은 '즉시 로딩'이므로 NoName은 엔터티 상태로 가져와짐.
							BBB bbb2 = em.find(BBB.class, bbb.getId());
							System.out.println(bbb2.getNoname().getClass());  // NoName의 엔터티 객체 출력.
							NoName noname12 = bbb2.getNoname();
							System.out.println(bbb2.getNoname().getClass());  // 여전히 엔터터ㅣ 객체.
						</pre>
					ㄴ 특징 )
						ㄴ 즉시 로딩을 사용하게 되면, 엔터티 조회시마다 연관된 테이블들이 모두 join으로 읽히기 때문에 주된 성능 저하의 원인이 된다.
						ㄴ JPQL에서의 N+1 문제 )
							ㄴ JPQL을 사용하여 즉시로딩인 연관 관계가 있는 엔터티를 조회하게 되면, 내부 동작이 다음과 같다.
								JPQL을 sql로 번역하여 쿼리가 나감. 이때, jpql은 EntityManager의 find()와 다르게, 연관관계 즉시로딩인 엔터티들을
								한번에 쿼리해 오지 않는다. 그냥 대상이 되는 엔터티만 쿼리해옴.
								그 다음에 결과로 나온 엔터티 목록에 대해 연관관계 즉시로딩인 엔터티들을 하나씩 쿼리하여 읽어들임.
								결과 목록이 N개이면, N번을 따로 쿼리하여 즉시로딩인 연관관계 엔터티들을 읽어들이게 된다.
							ㄴ 하나의 조회 명령에 대해 쿼리가 여러번 나가게 된다.
							ㄴ 해결 )
								ㄴ 일단 모든 연관관계에 지연 로딩을 사용한다.
								ㄴ 'fetch join' 사용. (이후 나옴)
								ㄴ 그 외에 어노테이션을 사용하거나 batch 사용 등..
						ㄴ @ManyToOne, @OneToOne은 디폴트 fetchType이 즉시로딩으로 되어있다. 명시적으로 지연 로딩으로 설정해 주어야함.

				</pre>

				ㅡ 영속성 전이 ( Cascade ) <button>more</button>
				<pre>
					ㄴ 엔터티A 정의가 연관관계인 엔터티 속성을 가질 때,
						엔터티A를 영속성에 추가하거나 삭제 등의 연산을 할 때 연관 관계를 가지는 하위 속성 엔터티들에도 같이
						해당 연산을 적용시켜주는 기능.
						ㄴ ex )<button>more</button>
						<pre>
							@Entity
							public class BBB extends Base {
								@Id
								@GeneratedValue(strategy = GenerationType.AUTO)
								private Long id;

								@ManyToOne(fetch = FetchType.LAZY, cascade = CascadeType.ALL)
								@JoinColumn
								private NoName noname;  // 엔터티BBB가 연관 관계 하위 속성으로 엔터티 NoName을 가지고 있고,
														// 이게 영속성 전이의 대상이다.

								public BBB(){}
								public BBB(NoName noname){
									this.noname = noname;
								}

							~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

							NoName noname  = new NoName("hello1", 1000, 10000);
							// em.persist(noname);  // noname을 영속성컨텍스트에 저장하지 않음.

							BBB bbb = new BBB(noname);
							em.persist(bbb);  // BBB를 영속성 컨텍스트에 저장하면 cascade all이기 때문에 BBB의 하위 속성인 noname이 같이 영속성 컨텍스트에 저장.
												// cascade설정이 없었으면, flush()할때, BBB의 noname이 저장되지 않은 데이터라고 오류 발생.
												// (이 경우, noname을 먼저 영속성 저장 후 BBB를 영속성 저장해야 함)

							em.flush();
							ㄴ cascade all인 상태에서 noname을 영속성 저장 후, bbb를 영속성 저장해도 알아서 jpa가 noname과 bbb를
								db에 넣는다.
								단, noname을 영속성 저장 후, flush()를 하게 되면, noname이 db에 저장되고, 이후 bbb를 영속성 저장 후
								flush()를 하면 noname이 이미 db에 존재하기 때문에 오류 발생.
						</pre>
					ㄴ 종류 )
						ㄴ CascadeType.ALL : 모든 경우에 적용
						ㄴ CascadeType.PERSIST : 영속성 저장할 때만 적용.
						ㄴ CascadeType.REMOVE : 엔터티 삭제시 적용.
						ㄴ CascadeType.MERGE
						ㄴ CascadeType.REFRESH
						ㄴ CascadeType.DETACH
					ㄴ ALL, PERSIST, REMOVE 정도만 사용하고 쓰지 않음.
						ㄴ REMOVE도 신중하게 사용해야 함.

				</pre>

				ㅡ 고아 객체<button>more</button>
				<pre>
					ㄴ 엔터티A가 @OneToOne, @OneToMany 연관관계를 가지는 하위 엔터티B가 있다고 할때, 'orphanRemoval=true' 옵션을 붙이면,
						엔터티A에서 엔터티B를 삭제시, 엔터티B를 '고아'라고 하고 이를 제거하는 기능.
					ㄴ ex )<button>more</button>
					<pre>
						class Parent{
							(*id*)

							// ??? 정확한 이유는 모르겠지만 CascadeType.PERSIST가 같이 있어야 orphanRemoval이 동작한다.
							@OneToMany(orphanRemoval = true, cascade = CascadeType.PERSIST)
							@JoinColumn
							List< Child> childList;
							~~~~~
						}

						class Chilc{
							(*id*)

							~~~~~
						}

						~~~~~~~~~~~~~~~~~~

						Child child = new Child();
						Parent parent = new Parent();
						parent.addChild(child);  // parent의 childList에 child를 추가했다침.

						~~~~~
						Parent parent2 = em.find(Parent.class, parent.getId());
						parent2.getChildList().remove(0);  // child가 고아취급되어 삭제된다.
					</pre>
					ㄴ 실무 팁 )
						ㄴ 엔터티를 내부적으로 알아서 삭제하는 기능이기 때문에 당연히 주의해서 사용해야 한다.
						ㄴ cascadeType.ALL과 orphanRemoval=true를 모두 사용하면,
							부모 엔터티 안에서 자식 엔터티의 생명주기를 모두 관리할 수 있다.
							ㄴ ??? DDD의 'aggregate root'에 유용하다.
				</pre>

			</pre>

			ㅇ 데이터 타입<button>more</button>
			<pre>
				ㅡ hibernate는 'Type' 기능을 통해 java의 데이터 타입과 db의 데이터 타입을 자유자재로 처리할 수 있다.
				ㅡ hibernate는 데이터 타입을 두가지로 분류. 'entity type', 'value type'
				ㅡ 엔터티 타입
					ㄴ 알고 있는 그 엔터티 타입을 말함. 식별자를 통해 계속 추적 가능.
				ㅡ 값 타입<button>more</button>
				<pre>
					ㄴ int, Integer, String 등 단순히 값으로 사용되는 원시 타입이나 객체. 당연히 변경되면 추적은 안되고 그냥 사라짐.
					ㄴ 분류 )
						ㄴ 자바 기본
							ㄴ 자바 타입과 db 컬럼 타입 사이의 매핑.
							ㄴ 상세한 매핑 정보는 다음 참고
								ㄴ https://docs.jboss.org/hibernate/orm/6.1/userguide/html_single/Hibernate_User_Guide.html#basic
								ㄴ 위 페이지를 타고 jdbc spec doc에서 B-3,4테이블
							ㄴ 기본 타입 매핑 )<button>more</button>
							<pre>
								ㄴ @Basic
									ㄴ 엔터티 클래스의 속성에 부여.
									ㄴ 속성에 디폴트로 부여됨. (명시하지 않아도 @Basic이란 뜻)
									ㄴ 매개변수 )
										ㄴ optional )
											ㄴ boolean 값
											ㄴ 해당 속성이 nullable인지.
											ㄴ default = true
										ㄴ fetch )
											ㄴ javax.persistence.FetchType 값
											ㄴ eager fetch할지 lazy fetch할지
											ㄴ default = FetchType.EAGER
								ㄴ @Column
									ㄴ 명시적으로 db column명 지정.
									ㄴ 사용 안 하면 디폴트로 '네이밍 전략'에 따라 자동 부여
								ㄴ @Formula
									ㄴ sql 게산식 문자열을 인자로 받아 엔터티 로딩시에 계산식대로 계산하여 엔터티의 속성으로 가져옴.
									ㄴ db상에는 당연히 존재하지 않는 속성.
									ㄴ
								ㄴ ???기본 타입을 매핑하기 위해 hibernate가 고려하는 것들
									ㄴ 자바 타입을 어떻게 비교하는지, hash값을 어떻게 구하는지, 다른 타입과 동등성 비교는 어떻게 하는지
									ㄴ jdbc 타입과의 변환
									ㄴ db에서 가져오고 넣을 때 해야 하는 변환 작업
									ㄴ 내부 값이 immutable한지 mutable한지. ex ) String처럼 값이 변할 수 없는지 Date처럼 변할 수 있는지
								ㄴ ???
								ㄴ enum type )
									ㄴ ex )
										@Entity(name = "Phone")
										public static class Phone {

											@Id
											private Long id;

											@Column(name = "phone_number")
											private String number;

											@Enumerated(EnumType.STRING)
											@Column(name = "phone_type")
											private PhoneType type;

											//Getters and setters are omitted for brevity

										}
									ㄴ 속성이 enum class 타입인 경우이고,
										@Enumerated 또는 @MapKeyEnumerated를 붙여 enum 타입을 매핑.
									ㄴ enum 값 전략 )
										ㄴ @Enumerated( (*enum전략*) )
											위와 같이 인자로 jakarta.persistence.EnumType의 값을 받음.
										ㄴ 이 값으로 enum값을 어떻게 저장할지 설정.
											ㄴ EnumType.ORDINAL : enum의 ordinal position을 값으로 저장. (enum순서값)
											ㄴ EnumType.STRING : enum의 name을 값으로 저장.
								ㄴ ~~~
							</pre>
						ㄴ 임베디드 타입<button>more</button>
						<pre>
							ㄴ 클래스를 정의하고 이를 엔터티의 속성으로 포함시켜 '값 타입'으로서 사용하는 것.
							ㄴ ex )
								embedded 객체...
								@Embeddable  // 임베디드 타입 클래스를 정의하는 곳에 선언해야 함.
								public class EmbeddedClass{
									public int property1;
									public String property2;
								}

								~~~~~~~~~~~~
								embedded객체를 포함할 엔터티...
								@Entity
								public class NoName{
									~~~~~
									@Embedded  // 임베디드 타입 클래스를 정의하는 속성에 선언해 주어야 함.
									private EmbeddedClass embeddedClass;
								}
								ㄴ noname의 컬럼으로 EmbeddedClass의 속성인 property1, property2가 추가된다.
							ㄴ 여러 엔터티에서 공통적으로 사용하는 속성들을 추출해 내는데 유용하다.
							ㄴ 관련있는 속성들을 객체화 할 수 있다.
								ㄴ 클래스이므로 당연히 임베디드 클래스 안에서 여러 메소드를 정의하여 사용할 수 있다.
							ㄴ 한 엔터티에서 한 임베디드 타입을 두개 이상 사용하려 하면, 중복된 속성으로 인해 오류 발생.
								이때는 '@AttributeOverrides' 사용.
							ㄴ 어쨋든 객체이기 때문에, 여러 엔터티에 공유해서 영속성 저장할 경우, 임베디드 객체를 변경하면 공유하고 있는
								다른 엔터티에서도 모두 수정이 되게되고, flush()시 해당 엔터티들에 대해 update가 되게된다.
								ㄴ ex )
									EmbeddedClass embeddedClass = new EmbeddedClass();

									NoName noname = new NoName();
									noname.setEmbeddedClass(embeddedClass);

									BBB bbb  = new BBB();
									bbb.setEmbeddedClass(embeddedClass);  // noname과 동일한 embeddedClass를 공유해서 저장.

									embeddedClass.setProperty1(5);  // embeddedClass의 속성 변경.

									em.flush()  // noname, bbb 모두에서 embeddedClass의 property1이 5로 update된다.
								ㄴ 영속성 context가 비워지고, embeddedClass를 공유하던 엔터티들을 새롭게 가져오면 더이상 같은
									embeddedClass 객체가 아니므로 동기화되지는 않는다. (db에서 각 엔터티의 속성값으로 새로운
									EmbeddedClass객체를 만들기 때문)
									context가 비워지지 않으면, 여전히 context안에 embeddedClass를 공유하는 noname, bbb가 들어있기
									때문에 그 안의 embeddedClass도 동일한 객체이고, embeddedClass는 동기화된다.
								ㄴ 하여, 당연히 임베디드 값 타입 객체를 공유하면 buggy하고, 객체를 복사해서 사용해야 한다.
									ㄴ 그래도, 실수로 복사하지 않고 그냥 같은 객체를 넣어버리면 컴파일러 상에서 오류로 잡을 수 없다.
									ㄴ 그래서, 값 타입 객체는 '불변 객체'로 설계한다.
										ㄴ 불변 객체? 객체 생성시점 이후에, 내부 값을 변경할 수 없는 객체를 의미.
											setter 등을 만들지 않거나 하여 만들 수 있다.
							ㄴ == 비교
								ㄴ 객체이기 때문에 == 비교는 당연히 참조값을 비교하게 된다. (동일성)
									equals()를 재정의하여 적절하게 '동등성' 비교를 해야한다.
								* equals(), hashCode() 오버라이드시 IDE의 자동생성기능을 사용하는 것이 좋다.
						</pre>
						ㄴ 컬렉션 타입<button>more</button>
						<pre>
							ㄴ 엔터티 정의에 속성으로 @OneToMany 등과 같이 엔터티 컬렉션을 가지는 게 아니라, 값 타입에 대한 컬렉션을
								속성으로 가지는 것.
								ㄴ ex )
									@Entity
									class NoName{
										~~~~~

										//@ElementCollection을 통해 컬렉션 값 타입임을 명시.
										// @CollectionTable으로 새로 생성될 테이블에 대한 설정을 한다. name은 테이블명,
										@ElementCollection
										@CollectionTable(name="propertyList1", joinColumns = @JoinColumn(name="id"))
										Set< String> propertyList1;

										@ElementCollection
										@CollectionTable(name="propertyList2", joinColumns = @JoinColumn(name="id"))
										List< EmbeddedClass> propertyList2;

									}
							ㄴ 컬렉션 속성은 해당 엔터티 테이블 안에 넣을 수 없으므로 따로 테이블이 생성되고 그 안에 엔터티와 컬렉션의
								값 타입의 값이 매핑되어 저장되게 된다.
								ㄴ 위 예의 경우,
									table propertyList1
										id (*NoName의 id*)
										String (*propertyList1 안에 들은 문자열 하나*)
									위와 같이 테이블이 생성되어 컬렉션의 목록이 각 row로 저장된다.
									ㄴ EmbeddedClass의 경우, EmbeddedClass의 속성들이 테이블의 속성이 되고.
							ㄴ 지연 로딩이 디폴트이다.
							ㄴ 값 타입 컬렉션의 수정 )
								ㄴ 기본적으로, 값 타입 컬렉션을 수정하면, db상에서 해당 엔터티와 연결된 모든 row를 삭제하고 현재 엔터티의
									그 값타입 컬렉션 안에 들은 값들을 새로 다시 모두 insert하는 방식으로 동작한다.
								ㄴ 엔터티의 id와 값타입 컬렉션의 데이터로만 테이블이 구성되기 때문에, 그 컬렉션의 요소 하나에 해당하는
									row들을 하나하나 추적하기 어렵기 때문에.
							ㄴ 값 컬렉션 vs 엔터티 )
								ㄴ 테이블 구성이 위에 나온 것과 같이 만들어지기 때문에 값타입 컬렉션의 각 요소들을 다루기 까다롭다.
									(각 요소들을 selct, 수정, 삭제 해야하는 경우 등)
								ㄴ 각 요소들이 pk를 따로 가지지 않고 연결된 엔터티의 id와 값으로만 구성되기 때문.
								ㄴ 하여, 컬렉션 값 타입을 쓸지, 엔터티로 만들어 일대다 연관관계를 할지 생각해보고 잘 결정해야 한다.
								ㄴ 정말 단순하고 간단하게만 사용하는 경우가 아니면, 값 타입 컬렉션보다는 엔터티로 만들어 사용하는 것을 추천한다함.

						</pre>
					ㄴ 서로 다른 엔터티끼리 '값 타입'의 데이터를 공유하면 안 된다.
					* 원시 타입은

				</pre>

			</pre>

			ㅇ Batch<button>more</button>
			<pre>
				ㅡ Hibernate는 JDBC의 Batching 기능을 사용할 수 있다.
					ㄴ JDBC batching이란 : 여러 sql 연산들을 한번의 db call에 보내는 기능. 성능상의 이점이 있다.
				ㅡ bathcing 관련 설정들 <button>more</button>
				<pre>
					ㄴ hibernate.jdbc.batch_size : batch size 설정. 양수 지정시, batch기능이 동작한다.
						ㄴ JPA의 식별자 자동 generate 기능을 사용하는 경우 동작하지 않는다.
						* Intellij에서 디버깅모드 실행시 동작하지 않는다? 일반 실행시 동작한다.
					ㄴ hibernate.jdbc.batch_versioned_data
					ㄴ hibernate.jdbc.batch.builder
					ㄴ hibernate.order_updates
					ㄴ hibernate.order_inserts
				</pre>

			</pre>

			ㅇ 객체지향 쿼리 언어<button>더보기</button>
			<pre>
				ㅡ JPA에서 쿼리를 만들 수 있는 다양한 기능을 지원.
					ㄴ JPQL, JPA Criteria, QueryDSL, native sql 등
					ㄴ JPA Criteria, QueryDSL은 자바 코드 형식을 사용하여 쿼리할 수 있게 해주는 문법, 기능이며, 내부적으로
						작성한 자바 코드에 맞춰 JPQL을 생성하여 동작한다.
					ㄴ 대부분은 앞의 3개로 커버가 가능하나, 쿼리가 매우 복잡하거나 db에 의존적인 경우
						native query를 사용해야 할 때도 있고 이런 기능도 지원.
				ㅡ JPQL )<button>more</button>
				<pre>
					ㄴ 개요 )
						ㄴ Java Persistence Query Language
						ㄴ JPA를 사용하면 엔터티 객체를 중심으로개발.
						ㄴ 검색을 할때도 테이블이 아닌 엔터티 객체를 대상으로 검색하는게 필요.
						ㄴ JPQL : JPA에서 SQL을 추상화한 객체지향 쿼리언어
						ㄴ 엔터티 객체를 대상으로 쿼리를 한다.
					ㄴ ex)
						TypeQuery< Member> query = em.createQuery ( "select m from Member m where m.username = :username ", Member.class );
						query.setParameter("username", "john")  // 변수명으로 JPQL에 변수 입력.
						Query query2 = em.createQuery("select m.age, m.name from Member m");

						List< Member> resultList = query.getResultList();  // 쿼리의 결과를 리스트로 반환받음. 없으면 빈 리스트.
						Member resultOne = query.getSingleResult();  // 쿼리의 결과하 하나일 때 사용. 0개나 2이상이면 예외.
						ㄴ Member는 테이블이 아닌 엔터티 객체를 말함.
						ㄴ JPA가 적절한 쿼리를 만들어서 db에 보냄.
						ㄴ 문법 )
							ㄴ 엔터티 명과 속성명은 대소문자 구분.
							ㄴ 엔터티명은 클래스명이 아닌 '엔터티명'. @Entity(name=" (*엔터티명*) ")으로 지정 가능.
								ㄴ ex )
									@Entity(name="noname")
									class NoName2 { ~~~ }
							ㄴ JPQL의 sql키워드들은 대소문자 구분 안함.
							ㄴ 테이블 이름이 아닌, 엔터티 이름으로 JPQL을 작성.
							ㄴ 엔터티에 별칭 필수.
						ㄴ 반환형 )
							ㄴ TypeQuery< (*select로 가져오는 데이터 타입*) > : 반환형이 하나이고 명확할 때 사용.
								ㄴ ex )
									TypedQuery< BBB> query = em.createQuery(
										"select b from BBB b join NoName n on b.noname=n", BBB.class
									);
									Object q1Result = query.getResultList();
								ㄴ EntityManger의 createQuery( (*쿼리문자열*), (*반환 엔터티 클래스명*) ) 은 쿼리문에서 어떤
									엔터티를 받을지 명확하게 지정하는 메소드.
									ㄴ 쿼리문에서 select하는 엔터티와 (*반환 엔터티 클래스명*)이 다르면 안된다.
								ㄴ 이렇게 명확하게 하나의 엔터티를 반환받는 쿼리면 TypedQuery<>을 사용.
								ㄴ getResultList()는 List< BBB>를 반환.
							ㄴ Query : 반환형이 여러개이거나 명확치 않을 때 사용.
								ㄴ ex )
									Query query2 = em.createQuery(
										"select b, b.createdTime, b.embeddedClass, n from BBB b join NoName n on b.noname=n");
									Object q2Result = query2.getResultList();
								ㄴ EntityManager의 createQuery( (*쿼리문자열*) )은 쿼리문에서 어떤 엔터티를 받을지 명확하게 지정하지 않는 메소드.
								ㄴ 예제와 같이 엔터티, 엔터티의 속성, 다른 엔터티 등 여러 데이터형을 반환받으려면 Query사용.
								ㄴ getResultList()는 반환받을 데이터들이 Object[] 안에 담겨 이 Object[]의 List를 반환.
									ㄴ List< Object[]> ?
									ㄴ ex ) 위 예제의 경우, q1Result 안에 [ Object[4], Object[4], ... ] 이런식으로 List가 들어있고,
											각 Object[4] 안에, [ BBB, BBB의 createdTime, BBB의 embeddedCalss, NoName ] 이런식으로 들어있음.
						ㄴ 위치기반 쿼리 파라미터는 헷갈리기 쉬워 buggy하다.
						ㄴ 위의 과정을 체인을 사용하여 쓸 수 있다.
							ㄴ ex )
								TypeQuery< Member> query = em.createQuery (
										"select m from Member m where m.username = :username ", Member.class )
									.setParameter("username", "john")
									.getResultList();
					ㄴ 프로젝션 (Projection)
						ㄴ JPQL의 selct부분에서 조회할 데이터를 정하는 것.
						ㄴ 기본 )
							ㄴ select m from m  // 엔터티를 조회.
							ㄴ select m.age from Member m  // Member의 속성 age 조회.
							ㄴ select m.embeddedClass from Member m  // 임베디드 타입인 속성을 조회.
							ㄴ 연관관계이 ㄴ엔터티, 여러개 속성 모두 가능하다.
						ㄴ 여러개인 경우, 반환 타입
							ㄴ DTO를 만들어 JPQL안에서 생성자처럼 호출해 줌으로서 DTO를 반환받을 수 있다.
							ㄴ ex )
								List< MemberDTO> result = em.createQuery(
									"select new jpql.MemberDTO(m.age, m.name) from Member m", MemberDTO)
								ㄴ 생성자 부분에 패키지명을 전체 적어주어야 함. JPQL이 문자열이기 때문에 자동으로 되지 않음.
					ㄴ 페이징 )
						ㄴ setFirstResult(), setMaxResult()를 이용하여 페이징 기능을 사용할 수 있다.
						ㄴ ex )
							TypeQuery< Member> query = em.createQuery ( "select m from Member m where m.username = :username ", Member.class )
									.setFirstResult(1)  // 목록 중 몇 번째 row부터 반환할지 결정.
									.setMaxResult(10)  // 목록 중 몇 번째 row까지 반환할지 결정.
									.getResultList();
					ㄴ 조인 )
						ㄴ createQuery()의 쿼리문자열에 'join', 'left join', 'on' 등의 키워드를 사용하면 sql의 조인을 사용할 수 있다.
						ㄴ ex )
							ㄴ List< Object> query4 = em.createQuery("select n, b from NoName n left join n.bbb b").getResultList();
								ㄴ NoName과 연관관계에 있는 BBB에 대해 연결된 것끼리 알아서 조인(또는 left join)하여 반환.
									(즉, 자동으로 select n, b from NoName n left join BBB b on b.noname=n 을 한 것같이 쿼리실행)
								ㄴ join, left join 키워드 후에 'n.bbb'와 같이 조인 대상을 연관관계를 가진 엔터티의 속성으로서 적어야함.
							ㄴ List< Object> query7 = em.createQuery("select b,n from BBB b left join NoName n on b.noname=n").getResultList();
								ㄴ 위 예와 같이, 연관관계를 가지고 있는 엔터티에 대해 조인이 아니더라도, 'on' 키워드를 사용하여
									연관관계가 없는 엔터티와도 조인이 가능하다.
								ㄴ join, left join 키워드 후에, 'NoName n'과 같이 조인 대상을 적어주어야함.
					ㄴ 서브쿼리 )
						ㄴ createQeury()의 쿼리문자열에 서브쿼리 기능을 사용할 수 있다.
						ㄴ exists, all, any 등의 키워드 사용 가능.
						ㄴ ex )
							List< Object> query8 = em.createQuery("select n from NoName n " +
																	"where exists (select b from BBB b where b.noname=n)").getResultList();
							List< Object> query8 = em.createQuery("select n from NoName n " +
																	"where n.price > All (select n2.price from NoName n2 where n2.name='hello3')").getResultList();
						ㄴ jpa 스펙상, where, having 절에서만 서브 쿼리가 사용 가능.
							ㄴ 하이버네이트에선 select 절에서도 가능.
						ㄴ 하이버네이트에서도 from 절에서의 서브쿼리 불가.
							ㄴ 현재 기능 지원을 안 함.
							ㄴ 대체 방안 )
								ㄴ from절 서브 쿼리 대신 조인.
								ㄴ 네이티브 쿼리
								ㄴ 일단 쿼리 후, 어플리케이션 단에서 처리.
					ㄴ JPQL 안에서의 데이터 타입 표현 )
						ㄴ 문자 ) 작은 따옴표 사용. ex ) 'hello'  / 작은 따옴표를 쓰려할 땐 작은 따옴표 두개('')로 표현. 'he''s'
						ㄴ 숫자 ) 10L(long), 30D(double), 20F(float)
						ㄴ boolean ) TRUE, FALSE
						ㄴ enum ) 패키지명을 포함한 enum값을 적어주어야 함. ex ) select m from Member m where m.type = (*패키지명*).ADMIN
						ㄴ 엔터티 타입 ) 엔터티 클래스 명. ex ) select m from Member m
							ㄴ JPQL 내부에서 type( (*엔터티*) ) 를 통해 엔터티의 타입 체크 가능.
								ㄴ ex ) select m from Member where type(m) = Person
								ㄴ 상속관계인 경우 쓰일 수 있다.
						ㄴ sql에서의 키워드 대부분 동일하게 사용 가능.
							ㄴ exists, in, and, or, not, <, >, =, <=, between, like, is null

						ㄴ setParameter()를 사용해서 넣으면 JPQL 문자열에 이런식으로 하드코딩 할 필요 없다.
				</pre>

				ㅡ JPA Criteria )
					ㄴ queryDSL처럼 JPQL을 자바 코드 형식으로 생성할 수 있게 해주는 기능.
					ㄴ jpql은 문자열로 된 쿼리기이 때문에 오타로 인한 오류가 컴파일로 잡히지 않음.
						criterai사용시, 이를 컴파일 시점에서 캐치가능.
					ㄴ 문법과 코드가 매우 복잡한편.
					ㄴ ex )	query.select(m).where(~~~)
					ㄴ 강사는 문법의 가독성이 떨어져 유지보수가 어렵다며 쓰지 않고, 자세히 내용을 소개하지 않음.
				ㅡ QueryDSL )
					ㄴ 오픈 소스.
					ㄴ Criteria와 같은 기능인데 문법의 가독성이 더 좋아 추천됨.
				ㅡ JDBC 직접 사용
					ㄴ 실db와 바로 직접 상호작용하므로, jpa와 같이 사용시 jpa에서 아직 flush되지 않은 영속성 컨텍스트 내의 내용들과
						충돌하지 않도록 주의 필요.

			</pre>

			ㅇ 관련 이슈 <button>more</button>
			<pre>
				ㅡ 영속성 추가시(em.persist()),
					IllegalArgumentException: Can not set java.lang.Long field id to entity
					와 같은 오류 발생.
					ㄴ 영속성 추가시, 해당 필드에(주로 pk 필드) 값을 할당하지 못 한다는 오류인데
					ㄴ 정확한 원인은 찾지 못했지만, 의존성에 'org.springframework.boot:spring-boot-devtools'가 있을시
						이런 오류 발생.
						ㄴ 참고 ) https://stackoverflow.com/questions/59510867/hibernate-illegalargumentexception-while-persisting-entity-object-cannot-set-fi

			</pre>
		</pre>

		Spring Framework<button>더보기</button>
		<pre>
			토비의 스프링>>><button>펼치기</button>
			<pre>
				1장. 오브젝트와 의존관계<button>펼치기</button>
				<pre>
					ㅇ 1.1 초난감 DAO
						ㅡ 리팩토링 : 코드의 기능에는 변경이 없으면서, 코드의 구조,  즉 어떤식으로 코딩이 돼있는지만 개선되는 것.
							ㄴ 코드가 이해하기 쉬워지고 변화에 더 잘 대응한다고 한다.
						ㅡ 메소드 추출 : 코드에서 공통적인 부분, 중복되는 부분을 따로 뽑아내는 것. 리팩토링의 기법 중 하나.
						ㅡ 템플릿 메소드 패턴 )
							ㄴ 전체적인 구조, 전체적인 로직, 작업, 알고리즘의 전체적인 틀은 정해놓고, 이 틀안에서 일부분만 유동적으로 변경하는 패턴.
							ㄴ 보통 상속구조로 상위클래스에서 전체적인 구조와 대부분의 메소드를 다 정의해놓고,
								이 중 일부를 추상메소드로 만들어 서브클래스에서 이 메소드부분만 유동적으로 정의할 수 있게하는식으로 만든다.
							ㄴ ex)
								public abstract class UserDao {
									public void add(){~~~~}	=>대부분의 메소드는 다 내용까지 정의해둔다.
									public User get(){~~~~}
									public abstract Connection getConnection();	=>유동적으로 변경할 부분을 추상메소드로만들어둠.
								}
								~~~
								public class NUserDao extends UserDao{	=>UserDao를 상속해 전체적인 알고리즘 구조는 유지되도록,
									public Connection getConnection(){ ~~~}	=>그러면서 유동적으로 변경할 부분인 getConnection() 추상메소드만
								}												재정의함.
						ㅡ 팩토리 메소드 패턴 )
							ㄴ 부모클래스에서 정확하게 어떤 객체를 생성하는지 모르게 자식클래스에서 객체를 생성하는 패턴.
							ㄴ 객체의 생성을 다른 클래스에서 담당하여 만들어주는 패턴.
							ㄴ 코드의 결합도를 낮추는 장점이 있다고한다.
							ㄴ ex) (내가 대충 만든 예제)
								public abstract class Number
								public class Number1 extends Number
								public class Number2 extends Number
								public class Number3 extends Number

								public abstract Factory{			=> 상위 추상클래스.
									public abstract Number createNumber(String name);	//구체적으로 어떤 객체를 생성할지 알지 못한다.
								}
								public NuberFactory extends Factory{		=> 자식클래스에서 구체적으로 어떤 객체를 생성할지를 결정하고 있다.
									@Override
									public Number createNumber(String name){
										switch(name){
											case "1" : return new Number1();
											case "2" : return new Number2();
											case "3" : return new Number3();
										}
									}
								}

								public class Main{
									public static void main(String[] args){
										NumberFactory nf = new NumberFacotry();
										Number num1 = nf.createNumber("1");
										Number num2 = nf.createNumber("2");
									}
								}
						ㅡ 1.3.4 원칙과 패턴 )
							ㄴ 개방 폐쇄 원칙
								ㄴ 클래스나 모듈은 확장에는 열려있어야 하고, 변경에는 닫혀있어야 한다.
							ㄴ 높은 응집도, 낮은 결합도
								ㄴ 높은 응집도 : 하나의 모듈, 클래스가 하나의 관심, 책임만을 가지는것.
								ㄴ 낮은 결합도 : 책임과 관심이 다른 클래스, 모듈사이에는 '느슨한 연결'을 유지하는 것.
									ㄴ 결합도 : 하나의 오브젝트에서 변경이 일어나면 연속적으로 관계를 맺고있는 다른 오브젝트에서도 변화가 일어나야하는 정도.
									ㄴ '느슨한 연결'이란? 관계를 유지하는데 꼭 필요한 최소한의 방법만 간접적으로 제공하고 나머지는 서로 독립적이고 알 필요도 없게하는것.
									ㄴ 변화에 대응하기 쉬워지고 구성이 깔끔해지고 확장에 용이해진다.
							ㄴ 전략 패턴 )
								ㄴ 디자인 패턴의 일종.
								ㄴ 개념 )
									ㄴ 자신의 기능 맥락(context) (대충 일련의 기능들 중) 중에서 필요에 따라 변경이 필요한 관심,기능(알고리즘)을 인터페이스로
										통째로 분리시키고, 이 인터페이스를 구현한 구체적인 클래스를 선택적으로 사용함으로서 기능을 다양하게 변경할 수 있는 방식이다.
								ㄴ 알고리즘을 바꿔가는걸 '전략'을 대체한다 하여 전략패턴이라고함.
							ㄴ 스프링은 이와같은 원칙과 패턴들이 잘 적용되도록 만들어진 프레임워크이다.
						ㅡ 1.4 제어의 역전 (IoC) )
							ㄴ 일반적인 프로그램에서는 main과 같이 시작하는 부분에서 어떤 오브젝트를 사용할지 결정하고 또 이를 생성하고 이것의 메소드를 호출하고 등등
								다른 오브젝트를 사용한다. 그리고 그 안에서 또 사용할 오브젝트를 결정하고, 생성하고...
								이런식으로 오브젝트의 사용자(즉, 오브젝트의 클라이언트)에서 모든 작업을 제어한다.
							ㄴ IoC란 이러한 제어의 흐름을 역전시키는 것이다. 모든 오브젝트는 자신이 사용할 오브젝트를 결정하지도, 생성하지도 또한
								자신이 어디에 사용되는지도 알지 못한다. 모든 제어는 이 제어권을 위임받은 특별한 대상에 의해 수행된다.
							ㄴ 리스트 1-14,15에 나오는 것처럼 UerDao, ConnectionMaker가 DaoFactory에 의해 결정되고, 생성되고 있으므로 제어가
								역적되었다고 볼 수 있다.
							* 라이브러리와 프레임워크의 차이 )
								ㅡ 라이브러리의 경우에는 제어권이 라이브러리를 사용하는쪽(보통 개발자의 코드)에 있고,
								ㅡ 프레임워크의 경우에는 제어권이 (모두인지는 모르겠다) 프레임워크쪽에 있다. 개발자가 코드를 만들어 놓으면
									프레임워크(주로 컨테이너 등)에서 이 코드를 가져다 호출하고 사용하는 식.
							ㄴ ?????????? 디자인 패턴이 원래 이렇게 추상적인 내용이어서 그런지, 내가 이해를 못한건지는 모르겠지만 이해가 명쾌하게 된것같지는 않다.
								두루뭉실하게 대충 이런게 IoC이구나 라는정도..
						ㅡ 스프링의 IoC )
							ㄴ 스프링의 핵심은 '빈 팩토리', '어플리케이션 컨텍스트'이며, 이전 주제에서 다룬 DaoFactory를 일반화한것이라고 볼 수 있다.
							ㄴ 스프링 빈 : 스프링 컨테이너가 제어권을 가지고 생성, 관계설정 등을 해주는 오브젝트를 말한다.
							ㄴ 스프링의 '빈 팩토리' : 스프링에서  스프링 '빈'을 제어하는 IoC오브젝트를 말함.
							ㄴ 스프링의 '어플리케이션 컨텍스트' : '빈 팩토리'의 일종. '빈 팩토리'를 조금 더 확장한 것이다. IoC컨테이너, 스프링 컨테이너 라고도 불린다.
							ㄴ '빈 팩토리', '어플리케이션 컨텍스트'는 별도의 '설정정보'를 읽어들여 이에 따라 '빈'들을 제어한다.
							ㄴ 간단한 어플리케이션 컨텍스트의 동작방식 )
								ㄴ 클라이언트에서 어플리케이션 컨텍스트에게 특정 이름의 '빈'을 요청하면 어플리케이션컨텍스트가 관리하고 있는 '빈' 목록중에서
									해당 이름을 가진 '빈'이 있는지 확인.
								ㄴ 있으면, 그 '빈'객체를 클라이언트에게 넘겨줌.
						ㅡ 1.6 싱글톤 레지스트리와 오브젝트 스코프 )
							* 스프링과 서버 어플리케이션
								ㅡ 스프링은 자바 엔터프라이즈에 적합한, 서버 어플리케이션에 사용되기위해 만들어진 기술이라고 한다.
								ㅡ 그래서 스프링은 주로 서버환경에서 사용된다함.
							ㄴ 서버환경에서는 무수히 많은 요청이 들어올 수 있고, 만약 각 요청마다 새로운 인스턴스를 생성해서 사용하게 되면 많은 부하가 생기게 된다.
							ㄴ 그래서 어플리케이션 컨텍스트는 따로 설정이 되어잇지 않으면 기본적으로 '빈'에 '싱글톤 패턴'을 적용하여 하나의 인스턴스만 생성하고 요청이
								들어올때마다 이를 반환해준다.
							* 싱글톤 패턴 : 어플리케이션 안에 클래스의 오브젝트를 단 하나만 생성하여 이를 사용하는 방식.
							ㄴ 싱글톤 패턴의 문제점 )
								ㄴ 자바에서 싱글톤 패턴을 구현하는 방식은 일반적으로 다음과 같다 )
									ㄴ 단 하나의 인스턴스만 생성해야 하므로 생성자를 private로 단 하나만 만든다.
									ㄴ 단 하나 생성하는 인스턴스를 저장하기 위한 자기자신 인스턴스를 저장할 static 변수를 만든다.
									ㄴ static 팩토리 메소드인 getInstance()를 만들고 이 메소드가 처음 단한번 호출시 private생성자를 통해 인스턴스를 생성하고
										이를 static변수에 저장하고 이를 반환, 그 이후부터는 그냥 static변수를 반환하게 한다.
								ㄴ 이에 따른 문제점들은 다음과같다 )
									ㄴ 생성자가 private이기때문에 싱글톤 패턴이 적용된 클래스에는 상속을 적용할 수 없다.
									ㄴ ??????????? 테스트하기가 어렵다.
									ㄴ 클래스 로더나 JVM분산 여부에 따라 싱글톤패턴이라도 단 하나의 인스턴스만 생성된다는것을 보장할 수 없다.
									ㄴ ?????????? 어디서든 누구든 접근할 수 있는 '전역 상태'가 될수있기때문에 적절하지 않다.
							ㄴ 스프링의 '싱글톤 레지스트리' )
								ㄴ 스프링에서는 '싱글톤 레지스트리'를 통해 위처럼 싱글톤 패턴대로 구현된것이 아닌 일반 자바 클래스도 싱글톤처럼 사용될 수 있게 해준다.
								ㄴ 오브젝트의 생성, 관계설정, 사용 등에 대한 제어권을 컨테이너에게 넘기기때문에 컨테이너가 '빈'을 싱글톤처럼 사용할 수 있게하는게 가능.
								ㄴ 해서 스프링 컨테이너는 '싱글톤 레지스트리'라고도 불린다.
							ㄴ 싱글톤 객체의 '상태' )
								ㄴ 오브젝트의 상태란 필드, 멤버변수를 말한다.
								ㄴ 멀티스레드 환경에서는 당연히 싱글톤 인스턴스는 변수를 가지는것에 유의해야 한다. 여러스레드에 의해 동시접근되므로.
								ㄴ 읽기전용의 값이면 당연히 괜찮다.
							ㄴ 스프링 '빈'의 스코프 )
								ㄴ 스프링에선 빈의 스코프를 통해 빈의 범위를 조절할 수 있다.
								ㄴ 종류 )
									ㄴ 싱글톤 : 디폴트 스코프.
									ㄴ 프로토 타입 스코프 : 빈을 요청할때마다 새로운 인스턴스를 생성하는 것.
									ㄴ 요청 스코프 : http요청이 들어올때마다 새로 생성하는것.
									ㄴ 세션 스코프 :
									ㄴ .....
						ㅡ 1.7 의존 관계 주입, DI )
							ㄴ DI : 넓은 범위에서는 IoC안에 포함되기는 하는데, 스프링에서 제공하는 특별한 IoC방식을 DI라고 따로 명명햇다함.
							ㄴ 스프링 프레임워크의 핵심 개념이라함.
							ㄴ 의존 관계 )
								ㄴ 'A가 B에 의존하고 있다'는건 가령, A가 B의 메소드를 사용하고 있는 식으로 의존하고있다는 의미.
								ㄴ 따라서 B에서 변경이 발생하면 A에도 영향을 미치는 관계이다.
								ㄴ 의존관계에는 '방향성'이 있다. A는 B에 의존하고있지만 B는 A에 의존하지 않는 식으로.
								<img src="image/스프링_의존관계.png" />
							ㄴ 설계 관점의 의존관계, 런타임 의존관계 )
								ㄴ 클래스 상, 코드상의 의존관계를 말한다. 예에서 UerDao클래스와 ConnectionMaker인터페이스는 의존관계를 가지지만,
									ConnectionMaker인터페이스를 구현한 NConnectionMaker, DConnectionMaker와 UerDao는 설계관점상에선 의존관계가 없다.
								ㄴ 그러나 런타임시에 UserDao는 ConnectionMaker인터페이스 형태의 인자로 NConnectionMaker나 DConnectionMaker 객체를
									받게되므로 의존관계가 생긴다. 이를 '런타임 의존관계'라 하고 이렇게 런타임시에 의존관계를 맺는 대상을 '의존 오브젝트'라 한다함.
									(실제로 있는것인지 저자가 만든개념인지는 모르겠음)
							ㄴ 의존관계 주입은 위처럼 '런타임'시에 오브젝트간에 의존관계를 만들어주는것을 말한다.
							ㄴ 예에서 DaoFactory가 DI를 해주고 있으며, DaoFactory를 DI컨테이너라고 할 수 있다.
							ㄴ 의존 관계 검색 )
								ㄴ 의존 관계 주입과 더불어 IoC 방식으로 의존관계를 형성하는 또다른 방법이다.
								ㄴ 여전히 의존하는 인스턴스에 대한 결정이나  생성 등에 대한 제어권은 없지만 이를 받아오는 방법이 DI처럼 메소드 인자등으로 주입받는게 아니라
									직접 컨테이너로부터 검색하여 받아오는 식이다.
								ㄴ 가령, UserDao가 필요한 DConnectionMaker를 인자로 받는게 아니라 DI컨테이너인 DaoFactory를 직접생성하고
									이 객체의 메소드를 통해 DConnectionMaker 객체를 받아오는식.
								ㄴ 스프링의 '어플리케이션 컨텍스트'에서 getBean( (*빈 이름*) )을 통해 의존관계 검색 방법을 사용할 수 있다.
								ㄴ 의존관계검색을 사용하는 경우, 검색의 주체는 스프링 빈일 필요가 없다.
							ㄴ DI 장점 )
							ㄴ 메소드를 이용한 의존관계 주입 )
								ㄴ 꼭 생성자를 사용하지 않고도 의존관계를 주입할 수 있다.
								ㄴ setter메소드 또는 일반 메소드를 사용 할 수 있다.
						ㅡ XML을 이용한 설정 )
							ㄴ 뒤에나옴.

						* 빈 정의<button>펼치기</button>
						<pre>
							ㅡ 컨테이너에 의해 관리되고, 어플을 구성하는 object를 스프링에서 bean이라 부른다.
							ㅡ config metadat가 필요하며 다음으로 구성되어있다.
								ㄴ 어떻게 bean이 생성되어야하는지
								ㄴ 빈의 라이프사이클이 어떻게 되는지
								ㄴ 의존성은 어떻게되는지
							ㅡ 빈 정의는 다음의 프로퍼티들로 구성된다
								ㄴ class : 빈 정의에 사용될 class를 명시하는부분. 필수사항이다.
								ㄴ name : bean identifier를 명시한다. id또는 name 속성으로 명시할 수 있다.
								ㄴ scope : ...
								ㄴ constructor-arg : ...
								ㄴ properies
								ㄴ autowiring mode
								ㄴ lazy-initialization mode : 컨테이너에게  해당 빈생성을 시작할때가 아닌 처음 요청이 들어왔을때 해달라고 명시하는것.
								ㄴ initialization method : 빈의 모든 필요한 프로퍼티들이 컨테이너에 의해 세팅되고나서 호출되는 콜벡함수
								ㄴ destruction method : 빈을 포함하고있는 컨테이너가 파괴된후 호출되는 콜벡함수.
								ㄴ ex)
									< beans xmlns = "http://www.springframework.org/schema/beans"
									xmlns:xsi = "http://www.w3.org/2001/XMLSchema-instance"
									xsi:schemaLocation = "http://www.springframework.org/schema/beans
									http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">

									<!-- A bean definition with lazy init set on -->
									< bean id = "..." class = "..." lazy-init = "true">
										<!-- collaborators and configuration for this bean go here -->
									< /bean>

									<!-- A bean definition with initialization method -->
									< bean id = "..." class = "..." init-method = "...">
										<!-- collaborators and configuration for this bean go here -->
									< /bean>
									< /beans>
							ㅡ config metadata를 컨테이너에게 전달하는 방법 )
								ㄴ xml-based config file
								ㄴ Annotation-based config
								ㄴ Java-based config
						</pre>
						* 빈 라이프사이클<button>펼치기</button>
						<pre>
							ㅡ 빈이 인스턴스화되거나 더이상 필요없어질때 내부적으로 빈에 대한 처리가 일어난다.
							ㅡ 빈의 생성과 파괴단계에 호출될 메소드를 설정할 수 있다.
								ㄴ 초기화 콜백 )
									ㄴ org.springframework.beans.factory.InitializingBean interface이용 )
										ㄴ 이 인터페이스 안에 void afterPropertiesSet() throws Exception 라는 함수가있고,
											이함수는 빈이 인스턴스화 되고나서 호출되는 메소드이다.
										ㄴ 이 함수 몸체에 원하는 내용을 작업하면된다.
									ㄴ xml-based 이용)
										ㄴ < bean>의 속성으로 init-method를 주고 속성값으로 메소드이름을 설정하면, 해당 빈이 인스턴스화된 직후
											설정한 메소드가 호출된다.
								ㄴ 파괴 콜백 )
									ㄴ org.springframework.beans.factory.DisposableBean interface 이용)
										ㄴ 초기화와 동일. 이 인터페이스의 void destroy() throws Exception 메소드이용.
									ㄴ xml-based이용)
										ㄴ 초기화와 동일. < bean>의 destroy-method속성이용.
								ㄴ < beans> (< bean>이 아닌 < beans>이다) 의 속성값으로 default-init-method, defualt-destroy-method를
									통해 하위의 모든 빈정의에 대해 init-mehod, destroy-method를 설정할 수 있다.
						</pre>
						* 빈 정의 상속<button>펼치기</button>
						<pre>
							ㅡ 빈 정의에 자바의 상속 개념을 도입할 수 있다.
							ㅡ xml ex)
								< ?xml version = "1.0" encoding = "UTF-8"?>

								< beans xmlns = "http://www.springframework.org/schema/beans"
								xmlns:xsi = "http://www.w3.org/2001/XMLSchema-instance"
								xsi:schemaLocation = "http://www.springframework.org/schema/beans
								http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">

								< bean id = "helloWorld" class = "com.tutorialspoint.HelloWorld">
									< property name = "message1" value = "Hello World!"/>
									< property name = "message2" value = "Hello Second World!"/>
								< /bean>

								< bean id ="helloIndia" class = "com.tutorialspoint.HelloIndia" parent = "helloWorld">
										=>parent 속성값을 통해 상속받을 빈을 설정해준다. 부모 빈의 message1,2는 그대로 가지게되며,
									< property name = "message1" value = "Hello India!"/>				=>message1의 경우  이를 오버라이드해주고있다.
									< property name = "message3" value = "Namaste India!"/>				=>새로 추가된 message3.
								< /bean>
								< /beans>
							ㅡ 다음과 같이 bean definition template를 사용하여 상속할 수도있다.
								< ?xml version = "1.0" encoding = "UTF-8"?>

								< beans xmlns = "http://www.springframework.org/schema/beans"
								xmlns:xsi = "http://www.w3.org/2001/XMLSchema-instance"
								xsi:schemaLocation = "http://www.springframework.org/schema/beans
								http://www.springframework.org/schema/beans/spring-beans-3.0.xsd">

								< bean id = "beanTeamplate" abstract = "true">	=>abstract값을 true로 줌으로서 bean template로 설정.
																						이 빈은 인스턴스화 불가능하다.
									< property name = "message1" value = "Hello World!"/>
									< property name = "message2" value = "Hello Second World!"/>
									< property name = "message3" value = "Namaste India!"/>
								< /bean>

								< bean id = "helloIndia" class = "com.tutorialspoint.HelloIndia" parent = "beanTeamplate">
														=>위의 template bean을 상속한다.
									< property name = "message1" value = "Hello India!"/>
									< property name = "message3" value = "Namaste India!"/>
								< /bean>
								< /beans>
						</pre>
				</pre>
				4장. 스프링 MVC>>><button>펼치기</button>
				<pre>
					ㅇ 4.1 @RequestMapping 핸들러 매핑
						ㅡ 스프링 MVC에서는 메소드 단위에서의 매핑이 가능하다. 어노테이션을 사용하기때문에 가능.
						ㅡ mvc의 핸들러 매핑을 위해서는 DefaultAnnotationHandlerMapping이 필요하다. 따로 핸들러 매핑 빈을 등록할 수도있다.
						ㅡ DefaultAnnotationHandlerMapping은 @RequestMapping을 이용하여 매핑을한다.
							ㄴ 타입레벨의 @RequestMapping을 우선적으로 기준으로 삼고 메소드레벨의 @RequestMapping정보를 사용한다.
						ㅡ @RequestMapping )<button>펼치기</button>
						<pre>
							ㄴ 사용가능한 값 )
								ㄴ value
									ㄴ 디폴트 형태로 string 배열타입이다.
									ㄴ url 패턴을 명시할때사용된다.
									ㄴ ex) @RequestMapping("/hello"), @RequestMapping("/admin/**/user"),  @RequestMapping{"/hello", "/hi"} 등
									ㄴ 여러 url패턴을 지정할수있다.
									ㄴ 값으로 'uri템플릿'이란것도 사용가능
										ㄴ @RequestMappign("/user/{userid}"
										ㄴ {}을 사용해서 템플릿을 사용하며 이안의 값은 컨트롤러 메소드로부터 인자로 받아올수있다.
										ㄴ {}안에 들어가는 이름을 '패스변수'라 한다.
								ㄴ http 요청 메소드
									ㄴ 값으로 http request 메소드를 지정할 수 있다. GET,POST, DELETE 등
									ㄴ ex) @RequestMapping(value="/user/add", method=RequestMethod.GET), @RequestMapping(method=RequestMethod.GET)
								ㄴ 요청 파라미터
									ㄴ requst의 파라미터에 대해서도 매핑을 적용할 수 있다.
									ㄴ params 값을 사용하며, '타입 = 값' 형식으로 지정한다.
									ㄴ ex) @RequestMapping(value="/user/edit", params="type=admin")	=>요청 파라미터로 type이란 인자의 값이 admin일 경우 매핑.
									ㄴ POST로 전송한 파라미터도 적용대상이다.
									ㄴ 특정 파라미터가 존재하지 않는다는 조건도 지정가능하다. '!'을 사용한다.
										ㄴ @RequestMapping(value="~~", params="!type")
									ㄴ 역시 배열선언이라 여러개 지정가능하다.
								ㄴ Http 헤더
									ㄴ http 헤더에 따라 매핑가능하다
									ㄴ 형식은 params과 비슷하다. '헤더이름=값'형식으로 지정한다.
									ㄴ ex) @RequestMapping(value="~~", headers = "content-type=text/*")
							ㄴ 타입 레벨 매핑과 메소드 레벨 매핑 )
								ㄴ 메소드 레벨 매핑은 타입레벨 매핑을 상속받는다 보면된다.
							ㄴ 타입 레벨 매핑에 아무런 부여할 조건이 없어도 어노테이션은 선언해주어야한다. 매핑대상이라고 지정은 해주어야해서.
							ㄴ 타입레벨 단독 매핑
								ㄴ ??????????????????????????????????//////
							ㄴ 4.1.2 매핑 정보의 상속 )
								ㄴ @RequestMapping이 적용된 인터페이스나 클래스 상속시, 이 매핑정보는 상속된다고 보면된다. 물론 자식에서 재정의하면 덮어씌울수있다.
								ㄴ ~~~~~~~~~~~~~~~~~~~~~~~~...473페이지부터
						</pre>
					ㅇ 4.2 @Controller ) <button>펼치기</button>
					<pre>
						ㄴ 컨트롤러의 역할을 할 class를 지정하는 기능을 한다.
						ㄴ 컨트롤러를 만들때, HttpServletRequest같은 객체가 직접적으로 필요할 때도 있고, 이런 종속적인 인자없이 간단하게 만들 수 도 있다.
						ㄴ 근데 @MVC의 컨트롤러를 만드는 방식대로하면 HttpServletRequest같은 종속적인 객체를 가져오지않아도 이를 사용할 수있고, 이런 객체가 필요없으면 그냥 일반 인자만을 사용해서
							컨트롤러를 정의 할 수 있다고한다.
						ㄴ @Controller 어노테이션을 사용하여 만든다.
							ㄴ 이는 빈 자동인식에서 사용되는 스테레오 타입 어노테이션이다.
							ㄴ 컨트롤러에 해당하는 메소드의 파라미터 타입, 개수, 리턴 타입 등을 자유롭게 설정 할 수 있다. (물론 완전 자유는 아닌 몇가지 정해져있는거지만 이전 컨트롤러방식에 비해 월등하다)
						ㄴ 4.2.1 사용가능한 메소드 파라미터의 종류 ) <button>펄치기</button>
						<pre>
							ㄴ 스프링이 파라미터 타입과 이름, 어노테이션을 보고 적절한 파라미터값을 제공해준다고한다.
							ㄴ HttpServletRequest, HttpServletResponse : 거의쓸일이 없긴하다함
							ㄴ HttpSession
							ㄴ WebRequest, NativeWebRequest : HttpServletRequest와 거의 유사한데, 서블릿api에 종속적이지
								않은 request객체라고 보면된다.
							ㄴ Locale : java.util.Locale을 말하며, DispatcherServlet의 Locale Resolver가 결정한 Locale객체를
								받을 수 잇다.
							* java.util.Locale : 간단히말해 해당 지역긔 나라, 언어 정보를 얻을 수 있는 객체.
							ㄴ InputStream, Reader : HttpServletRequest의 getInputStream()으로 받던 스트림과 Reader타입을 받을 수 있다.
							ㄴ OutputStream, Writer : HttpServletResponse의 getOutputStream()으로 받던 스트림과 Writer를 받을 수 있다.
							ㄴ @PathVariable
								ㄴ ex) @RequestMapping("/user/view/{id}")
									public String view(@PathVariable("id") int id){ ~~ }
								ㄴ url설정에서 템플릿형태로 설정해둔다음 이 템플릿변수를 메소드에서 @PathVariable의 인자로 넘겨주어 파라미터에 선언해주면 해당 url의 값이
									들어오게된다.
								ㄴ 이때 반드시 일치하는 형태의 변수가 url에 들어와야하며, 그렇지않으면 예외가발생한다.
							* 템플릿 변수 ????(명칭 정확하지않음)
								ㅡ @RequestMapping을 이용해 uri를 지정할때 동적으로 이 url을 설정할 수 있다.
								ㅡex) @RequestMapping(value="/company/{companyId}/dept/{depId}~~~", method=GET)
									ㄴ {}로 둘러싸인 부분이 동적으로 url를 설정할 수 있는 부분이고 '템플릿 변수'??라고 하는 듯하다.
									ㄴ 이렇게 {}로 둘러싸인 저 변수를 저 @RequestMapping이 적용되는 범위 안에서 @PathVariable( " (*템플릿변수명*) " )을 통해,
										값에 따라 매핑 할 수 있다.
							ㄴ @RequestParam : form등으로 보내는 request안의 parameter를 가져올 수 있게 해주는 어노테이션이다.
								ㄴex) public String view(@RequestParam("id") int id){~~}
									ㄴ request.getParameter("id")에서 나온 값을 인자 id에 넣어준다.
								ㄴ 당연히 여러개를 선언할 수 있으며
								ㄴ 파라미터 이름을 지정하지 않고 파라미터를 받는 변수의 타입을 Map< String, String>으로 설정하면 request에 담긴 모든 파라미터가 전달된다.
									ㄴ ex) public String add(@RequestParam Map< String,String> params) {~~}
								ㄴ 옵션 )
									ㄴ ex) public void view(@RequestParam(value="id", required=false, defaultValue="-1") int id) {~~ }
									ㄴ reuired : 디폴트는 true. 해당 request 파라미터가 필수로 존재해야하는지 아닌지를 설정. true로 설정시 해당 파라미터가 없으면 예외발생.
									ㄴ defaultValue : 요청 파라미터가 없을시 적용할 디폴트값.
								ㄴ 메소드의 인자이름과 request 파라미터의 이름이 일치하면 @REquestParam만 사용해도 된다. 알아서 매핑됨.
								ㄴ request의 파라미터를 메소드의 인자 데이터 형에 맞게 알아서 변환해주며, 변환이 안될시 400에러가 난다.
								ㄴ
							ㄴ @RequestPart )
								ㄴ multipart/form-data형태의 요청을 받을때 사용되는 어노테이션이라함.
								ㄴ ~~~~~
								ㄴ
							ㄴ @CookieValue : http request에 들어있는 Cookie의 값을 받을 수 있다.
								ㄴ @RequestParam과 사용법이 거의 유사하다.
								ㄴ ex) public String check(@CookieValue("auth") String auth) {~~}
									ㄴ 쿠키의 이름을 @CookieValue에 값으로 넘겨주면 해당 쿠키의 값을 메소드 인자에 매핑해준다.
									ㄴ 쿠키의 이름과 메소드 인자의 이름이 같다면 @CookieValue만 선언해주어도 된다. 알아서 매핑해준다.
								ㄴ ex) public String check(@CookieValue(value="auth", required=false, defaultValue="NONE" String auth) {~~}
									ㄴ @RequestParam의옵션과 동일하다.
							ㄴ @RequestHeader : request의 헤더정보를 가져와주는 어노테이션. 헤더의 이름값을 어노테이션에 넘겨주면 해당 헤더의 정보를 준다. 사용법은 @RequestParam, @CookieValue와 동일하다.
							ㄴ Map, Model, ModelMap
								ㄴ View에서 쓰이는 Model 타입을 인자로 받을 수 있다.
							* Model, ModelMap
								ㅡ 스프링에서 View에 데이터 랜더링할때 쓰이는 model을 말함.
								ㅡ Map형식으로 데이터를 저장한다는 기능에서는 동일. 다른점은 Model은 인터페이스이고 ModelMap은 클래스.
							ㄴ @ModelAttribute
								ㄴ 컨트롤러에서 Http request정보를 사용할 때, 이 값들을 하나씩 받는게 아니라 자바빈처럼 여러 종류의 값을 객체형식으로 한꺼번에 받으려 할때 사용하는 어노테이션이다.
								ㄴ ex)	public class UserSearch {
										int id;
										String name;
										~~
									}
									이렇게 데이터를 담을 객체를 만들고,
									@RequestMapping("/user/search")
									public String search(@ModelAttribute UserSearch userSearch) {	=> 스프링은 @ModelAttribute가 선언된 객체를 이 객체의 디폴트 생성자를 이용해
																										생성하고 이 객체의 프로퍼티에 각각 이름이 같은 요청 파라미터의 값을 넣어준다.
										List< User> list = userService.search(userSearch);
										model.addAttribute("userList",list);
										~~
									}
									ㄴ request의 파라미터로 id,name이라는 이름이 있다면 자동으로 스프링이 UserSearch객체의 프로퍼티에 추가해준다.
									ㄴ @ModelAttribute가 선언되는 객체는 당연히 빈 형태로 setter/getter가 존재해야한다.
									ㄴ @ModelAttribute가 선언되는 객체는 디폴트 생성자가 있어야한다.
								ㄴ 이 어노테이션이 선언된 객체는 컨트롤러가 이후 model을 반환할때 같이 model로서 반환된다. 이름은 객체 타입과 같거나 @ModelAttribute(" (*model이름*) ")으로 지정해 줄 수 있다.
								ㄴ @RequestParam과 같이 request의 파라미터가 @ModelAttribute가 선언된 객체의 프로퍼티와 타입이 맞는지 확인을 하지만 @RequestParam과 다르게 400예외가 클라이언트로 날아가지는 않는다.
									타입변환이 불가한경우 BindException객체에 예외를 담아서 컨트롤러에게 전달해준다.
							ㄴ Errors, BindingResult )
								ㄴ 예외를 나타내는 인터페이스이다.
									ㄴ 구조 ) Errors interface
												ㄴ BindingResult interface
													ㄴ BindException class
								ㄴ @ModelAttribute를 사용할 때, @ModelAttribute의 타입변환 검사에서 발생하는 BindException에 대비해 반드시 같이 컨트롤러 메소드의 인자로 넣어주어야한다.
									ㄴ 컨트롤러 메소드 인자의 순서로, 반드시 @ModelAttribute가 선언된 인자 뒤에 와야한다.
								ㄴ 특정 객체에 대해, 바인딩 과정에서 생긴 변환오류와 validation 중에 발생한 오류에 대한 정보가 담긴다.
							ㄴ SessionStatus )
								ㄴ ?????????????????????????????????
							ㄴ @RequestBody )
								ㄴ 이 어노테이션이 선언된 메소드인자에 request body를 그대로 전달시켜주는 어노테이션이다.
									ㄴ json, xml등에서 유용하다.
								ㄴ ????????????????????????????
							ㄴ @Value
								ㄴ DI에 사용되던 이 @Value도 사용이 가능하며 사용방법은 동일하다.
							ㄴ @Valid
								ㄴ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
								ㄴ 나중에 자세히 나온다함.
						</pre>
						ㄴ 4.2.2 리턴 타입 종류 ) <button>펼치기</button>
						<pre>
							ㄴ @MVC컨트롤러에서 사용가능한 리턴타입에 대해 알아본다.
							ㄴ 최종적으로는 결국 ModelAndView 형태를 반환하게 된다고 한다.
							ㄴ 자동으로 반환되는 모델에 추가되는 것들 )
								ㄴ @ModelAttribute가 선언된 객체
								ㄴ Map, Model, ModelMap 파라미터 : 이 세가지 형태가 메소드인자로 정의되면, 이객체들은 자동으로 반환되는 모델에 추가된다.
								ㄴ @ModelAttribute 메소드의 반환값
									ㄴ @ModelAttribute는 컨트롤러 메소드의 인자 뿐 아니라 컨트롤러 클래스의 일반 메소드에도 선언 할 수 있다.
										ㄴ 이 경우, 메소드인자에 설정했을때와는 다른기능을 한다.
										ㄴ 이 어노테이션이 선언된 메소드가 반환하는 값은 해당 메소드가 존재하는 컨트롤러 클래스의 다른 컨트롤러 메소드가 반환하는 model에 자동으로 추가된다.
										ㄴ 일반적으로 컨트롤러 클래스의 여러 컨트롤러메소드가 공통적으로 사용하는 model을 설정하기 위해 사용한다함.
									ㄴ ex) 	@ModelAttribute("aaa")
											public String aaa() {
												return "hello";		=>리턴값 "hello"는 컨트롤러가 반환하는 model의  "aaa"란 이름으로 자동으로 설정된다.
											}
								ㄴ BindingResult
									ㄴ @ModelAttribute를 컨트롤러메소드의 인자로 사용할때 같이 정의해주어야한다던 그 BindingResult이다.
									ㄴ 'org.springframework.validation.BindingResult.(*model이름*)' 이란 키값으로 들어간다.
									ㄴ ?????????????스프링의 JSP, 프리마커, 벨로시티 등의 뷰에 사용되는 커스텀 태그, 매크로에 사용된다함.
							ㄴ 리턴 타입의 종류 )
								ㄴ ModelAndView )
									ㄴ 다른 더 좋은 리턴타입이 많아 잘 안쓰이기는 하지만 가능하기는하다.
								ㄴ String )
									ㄴ 반환하는 문자열은 View의 이름이된다.
									ㄴ model은 따로 모델객체를 인자로 받아서 설정해 주어야 한다.
								ㄴ void )
									ㄴ 뷰 이름이 제공되지 않으므로 RequestToViewNameResolver에 의해 자동으로 뷰이름이 설정된다.
										ㄴ 컨트롤러에 해당하는 url이름으로 뷰이름이 설정된다.
								ㄴ 모델 객체 )
									ㄴ 미리 지정된 타입이나 void가 아닌 일반 객체를 반환할경우, 스프링은 이를 모델로 인식해서 자동으로 추가해준다.
									ㄴ 이름은 그 객체의 타입으로 지정된다.
									ㄴ 뷰 이름은 RequestToViewNameResolver에 따르고, 저장할 모델이 하나뿐일때 유용하다.
								ㄴ Map, Model, ModelMap )
									ㄴ ex)	@RequestMapping("/view")
											public Map view(@RequestParam int id){
												Map userMap = userService.gerUserMap(id);
												return userMap;
											}
									ㄴ 위 예처럼 Map객체를 반환할 모델에 인자로 추가하는 것이 아닌 Map객체 자체를 반환해버리면, 이 객체가 인자로 추가되어 model에서 사용 가능한것이 아니라
										이  Map자체가 model 맵이 되어서 userMap안에 있는 인자들이 model로 쓰인다.
									ㄴ userMap을 model의 인자로 사용하려면 다음과 같이해야한다.
										ㄴ ex)	@RequestMapping("/view")
												public Map view(@RequestParam int id, Model model){
													model.addAttribute("userMap", userService.gerUserMap(id));
												}
								ㄴ View )
									ㄴ 뷰 이름말고 뷰객체 자체를 반환해도 된다.
								ㄴ @ResponseBody )
									ㄴ 메소드레벨에 부여되면 해당 메소드의 반환값은 http response의 body에 그대로 들어간다.
									ㄴ ?????????????/메세지 컨버터에 의해 변환되어 보내진다고한다.
									ㄴ @RequestBody와 마찬가지로 xml, json사용에 자주쓰인다.
						</pre>
						ㄴ 4.2.3 @SessionAttribute, SessionStatus )
							ㄴ ~~~~~~~~~~~~~~~~~~~~~~~~~~세션이 없을시 문제점 예시 ) 회원정보 수정 기능.
							ㄴ @SessionAttribute )
								ㄴ 클래스 레벨에 부여하는 어노테이션.
								ㄴ ex)	@Controller
										@SessionAttribute("user")
										public class UserController{ ~~ }
								ㄴ 컨트롤러가 만드는 model중 @SessionAttribute에 넘겨주는 이름과 일치하는것이 있을시, 이를 Http 세션에 저장시켜준다.
								ㄴ @ModelAttribute가 컨트롤러 메소드의 파라미터로 선언되어있을시, 이 @ModelAttribute에 해당하는 model과 @SessionAttribute에 부여된 이름이 같을시
									스프링은 @ModelAttribute가 선언된 객체를 새로만들지 않고 세션에서 가져와 사용한다.
							ㄴ SessionStatus )
								ㄴ 세션안의 데이터를 다 사용하고나면 제거해주어야한다.
								ㄴ SessionStatus의 setComplete()를 통해 세션에 저장해주었던 객체를 제거할 수 있다.
								ㄴ 4.2.1에서도 나왔지만 SessionStatus는 컨트롤러 메소드로 바로 사용할 수있는 내장 타입이다.
							ㄴ tip)
								ㄴ 스프링 @MVC에선 일반적으로 수정이든 등록이든 폼을 입력할때 세션에 객체를 저장해서 이를 가지고 폼을 뿌려준다고함.
							ㄴ @SessionAttribute 기능 테스트하기 )
								ㄴ AbstractDispatcherServletTest를 이용해 테스트할때, request로부터 HttpSession을 받아와 request.setSession( (*세션객체*) )로 추가해주는식으로
									세션을 테스트한다.
					</pre>
					ㅇ 4.3 모델 바인딩과 검증 ) <button>펼치기</button>
					<pre>
						ㄴ 스프링에서 바인딩이란 ? 객체의 프로퍼티에 값을 넣는 것을 말한다.
							ㄴ ex) xml을 이용한 빈 정의시, < property>를 이용해 빈의 프로퍼티들을 넣어주는 것.
									@ModelAttribute를 컨트롤러 메소드 파라미터에 선언시, request의 데이터를 이 어노테이션이 선언된 객체에 넣어주는 것 등.
							ㄴ 1. 적절한 형변환 과정
								ㄴ 위의 xml의 예의 경우, < property name="driverClass" value="com.mysql.jdbc.Driver"/>같은 문자열값을
									적절한 객체형태로 변환해서 값을 바인딩해주거나
								ㄴ 위의 @ModelAttribute의 예의 경우, 문자열 형태인 request의 데이터를 바인딩할 파라미터의 프로퍼티의 형태로 적절하게 변환하는 등
							ㄴ 2. setter를 호출해 값 넣기.
						ㄴ 검증이란 ? 바인딩에서 타입에 대한 검사를 끝내고 그 다음에 추가적으로 해당 값에 대해 검사하는걸 말하는 듯함.
							ㄴ 숫자가 지정된 값의 범위를 넘었거나, 문자열의 포멧이 틀렸거나, 값이 없거나, 쓸 수 없는 값이거나 등등.
							ㄴ 스프링에선 컨트롤러 로직과 검증 로직을 분리할 수 있다고 한다.
						ㄴ 스프링의 바인딩의 형변환에 쓰이는 API )
							ㄴ 4.3.1 PropertyEditor )
								ㄴ 원래는 스프링의 API가 아닌 자바빈의 인터페이스이다.
									ㄴ 문자열과 자바빈의 프로퍼티 타입 사이의 형변환 기능을 담당했었다.
								ㄴ 디폴트 PropertyEditor : 기본적으로 스프링이 제공하는 프로퍼티 에디터의 종류가 있고 해당 타입일 경우 그냥 사용할 수 있다.
														디폴트가 아니라면 직접 프로퍼티 에디터를 만들 수 있다.
								ㄴ 커스텀 PropertyEditor )
									ㄴ 디폴트 프로퍼티 에디터는 자바의 기본타입 20여가지밖에 안된다고한다. 따라서 커스텀 프로퍼티 에디터가필요하다.
									ㄴ ex)	public enum Level {
											~~~
											}
											이런 enum타입을 커스텀 PropertyEditor를 통해 자동으로 형변환이 되어서
											/user/search?level=1
											이렇게 요청을 보냈을때
											@RequestMapping("/user/search")
											~~ search(@RequestParam Level level){ ~~~ }
											이런 컨트롤러가 형변환 에러없이 enum Level형태를 받을 수 있도록 만들것이다.

								ㄴ 커스텀 PropertyEditor 등록방법 )
									ㄴ @InitBinder를 이용)
										ㄴ 알아두어야 할 내용 )
											ㄴ @Controller메소드를 호출하는 AnnotationMethodHandlerAdapter는 @RequestParam, @ModelAttribute 등과같이
												HTTP요청을 메소드 파라미터에 바인딩해야하는 어노테이션을 만나면 WebDataBinder를 만든다.
											ㄴ WebDataBinder의 기능 중 하나는 Http request으로부터 가져온 문자열을 메소드 파라미터에 맞게 형변환을 해주는것이고
												이 과정에서 PropertyEditor를 사용한다.
										ㄴ WebDataBinder에 커스텀 PropertyEditor를 등록해줌으로서 커스텀된 형변환이 가능하게 할 수 있다.
											ㄴ WebDataBinder의 형변환과정은 내부적으로돌아가므로 직접 PropertyEditor를 넣어줄 순없고
											ㄴ 스프링이 제공하는 @InitBinder를 통해서 넣어줄 수있다.
										ㄴ ex)	@InitBinder
												public void (*임의의 메소드이름*) ( WebDataBinder binder ) {
													binder.registerCustomEditor( (*에디터가적용될 타입*), (*커스텀 PropertyEditor객체*));
												}
											ㄴ @InitBinder가 붙은 메소드는 메소드 파라미터를 바인딩하기전에 자동으로 호출된다.
											ㄴ WebDataBinder를 인자로 받아 registerCustomEditor()를 호출한다.
												ㄴ 이 메소드가 커스텀 프로퍼티에디터를 등록시켜주는 메소드.
											ㄴ 같은 컨트롤러안에있는 모든 메소드에서 Http request 바인딩이 발생할때마다 적용된다.
												ㄴ @RequestParam, @CookieValue, @RequestHeader, @PathVariable, @ModelAttribute 파라미터 사용시 적용된다.
										ㄴ 커스텀 프로퍼티에디터 등록 방법 두가지 )
											ㄴ 기본적으로 위의 예에서처럼 registerCustomEditor( (*에디터가적용될 타입*), (*커스텀 PropertyEditor객체*))을 이용하여 등록하는 방ㅂ버.
												ㄴ 해당 타입이 나오면 항상 적용이된다.
											ㄴ 두번째는 특정 이름을 가진 프로퍼티의 경우에만 적용되게 등록하는 경우이다.
												ㄴ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
									ㄴ WebBindingInitializer 이용 )
										ㄴ @InitBinder의 경우 속해있는 컨트롤러 안에있는 메소드들에 대해서만 적용이된다.
										ㄴ WebBindingInitializer를 이용하면 모든 컨트롤러에 한번에 적용 가능하다.
										ㄴ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
									ㄴ 프로토타입 빈 프로퍼티 에디터 )
										ㄴ ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

							ㄴ 4.3.2 Converter, Formatter )
								ㄴ PropertyEditor는 매번 새로운 객체를 생성해야 한다는 점에서 단점이 있다.
									ㄴ ?????????????? 스코프 부분에서 추가적인 설정이 필요하고 스레드관련 위험이 따르기때문.
								ㄴ Converter 인터페이스 )
									ㄴ PropertyEditor와 달리 인스턴스를 저장하지않고 메소드를 하나만 호출하여 변환하므로 멀티스레드 환경에서 안전하다.
									ㄴ 당연히 싱글톤으로 만들어 사용할 수 있다.
									ㄴ 형태 )	public interface Converter< S, T > {
												T covert( S source );
											}
										ㄴ S가 scouce를 의미하고 T가 target을 의미. S에서 T로의 형변환을 해준다.
					</pre>
				</pre>

				5장 Validation, Data Binding, and Type Conversion <button>펼치기</button>
				<pre>
					ㅡ 원래 보통 검증은 로직단계에서 하는데 스프링은 이와 다르게 검증 부분을 만들었다함.
					ㅡ 스프링에서 검증은 웹 같은 특정 계층에 속하지 않고 구성이 자유롭도록 만들었으며, 이를 Validator 인터페이스를 통해 구현하였다함.
					ㅡ validation 패키지 안에 DataBinder, Validator가 있으며 전자가 데이터 바인딩을 담당하고 후자가 검증을 담당.
					ㅡ ??? BeanWrapper가 이들을 구성하는 기반적인 개념이라함. 근데 직접 사용하지는 않는다함.
				</pre>

					ㅇ spring 프로젝트 구조 )
						ㅡ src폴더 )
							ㄴ
							ㄴ main 폴더 )
								ㄴ java
									ㄴ .java파일들이 모여있는곳
								ㄴ resource
									ㄴ java코드에서 사용할 resource들이 모여있는곳.
								ㄴ webapp
									ㄴ web에서 사용하는 자원들이 모여있는 곳. jsp, js, css, xml 등
									ㄴ web application의 루트 path인듯 하다.
							ㄴ test 폴더 )
								ㄴ TDD관련하여 쓰이는 폴더.
			</pre>

			ㅇ Maven<button>펼치기</button>
			<pre>
				ㅡ Maven이란 ?
					ㄴ 개발 규모가 커질수록 사용하는 라이브러리의 수도 수십가지가 되는데 이러한 라이브러리들을 관리해주는 도구. 사용하는 라이브러리뿐 아니라 그 라이브러리가 필요로하는 라이브러리까지 네트워크를 통해 자동으로 다운받아주는 도구이다.
					ㄴ pom.xml에 필요한 라이브러리를 명시해 놓으면 자동으로 처리된다.
					ㄴ java에서 쓰이는 기술이다.
					ㄴ pom.xml )
						ㄴ Project Object Model
						ㄴ maven에서 project configuation의 핵심.
				ㅡ https://maven.apache.org/guides/getting-started/index.html 참조.
				ㅡ 설치 )
				ㅡ configuration )
					ㄴ maven은 3개의 레벨로 환경설정이 이루어짐.
						ㄴ Project : 대부분의 설정은 pom.xml에서 이루어진다.
							ㄴ 유저가 누군지 상관없이 프로젝트에 대한 설정을 한다.
						ㄴ installation : maven설치시 설정되는 것
						ㄴ User : 특정 유저에 대한 설정.
				* archetype : 일종의 프로젝트 template.
				ㅡ maven 프로젝트 만들기
					ㄴ 원하는 디렉토리로 가서 다음 명령어를 입력하면 pom.xml과 함께 maven프로젝트가 저장될 폴더가 만들어진다.
					ㄴ mvn -B archetype:generate  -DarchetypeGroupId=org.apache.maven.archetypes  -DgroupId=com.mycompany.app  -DartifactId=my-app
				ㅡ POM )
					ㄴ maven은 본질적으로 프로젝트 중심적이고, 그 프로젝트에 대한 모든 내용이 이 pom.xml안에 들어있다.
					ㄴ 기본적 구성 )
						ㄴ project : 모든 maven pom.xml파일의 최상위 요소.
						ㄴ modelVersion : pom이 사용하고있는 모델의 버전. 의무이다.
						ㄴ groupId : 해당 프로젝트를 생성한 조직또는 group의 identifier.
						ㄴ artifactId : 프로젝트에 의해 생성된 primary artifact의 base name.
							ㄴ 일반적으로 primary artifact는 jar파일이라한다.
							ㄴ secondary artifact인 source들은 마지막이름의 일부로서 artifactId를 사용한다함.
							ㄴ maven에 의해 생성된 artifact들은 일반적으로 다음의 이름 형식을 따른다함.
								ㄴ (*artifactId*) - (*version*) . (*extension*)   (가령, myapp-1.0.jar)
						ㄴ packaging : 이 artifact에 의해 사용될 패키지 타입을 지칭한다. JAR,WAR, EAR등. 디폴트는 JAR.
							ㄴ 패키지 타입뿐 아니라 build lifecycle을 명시한다함.(나중에 나옴)
						ㄴ version : 프로젝트에 의해 생성된 artifact의 버전을 명시.
							ㄴ snapshot 이란것을 볼수있음. (나중에 나온다함)
						ㄴ name : 프로젝트에서 사용하는 display name을 의미.
						ㄴ url : 프로젝트의 site의 위치.
						ㄴ description : description

					ㄴ 더 자세히는 https://maven.apache.org/guides/introduction/introduction-to-the-pom.html 참조.
				ㅡ 컴파일 방법 )
					ㄴ pom.xml이 위치한 폴더에서 mvn compile 명령을 시행한다.
					* Apache Ant : maven과 마찬가지로 자바에서 제공하는 프로젝트 빌드 도구.
					ㄴ 자동으로 컴파일된 파일이 target/classess아래에 위치하는데 이런한 내용들은 Maven의 standard convention이라고하며, 많은 내용들이 이것에 의해 설정되어있어 pom.xml에는 실질적으로 아주 적은 내용만 명시적으로 설정하여도 된다고
						한다.
				ㅡ unit test 방법 )
					ㄴ mvn test 명령어 수행.
					ㄴ test시에 maven은 추가적인 dependency들을 다운받는다. 이는 컴파일에 필요한 dependency와 다르며(컴파일시에 필요한건 이미받았고 다시받지않는다), test 실행에 필요한 dependency들이다.
					ㄴ maven은 test를 컴파일하고 실행하기전에 main code들을 컴파일한다.
					ㄴ test 소스를 컴파일만 하고싶다면, mvn test-compile 명령 수행.
				ㅡ JAR생성 및 local repository에 설치 )
					ㄴ mvn package : JAR파일 만드는 명령어.
						ㄴ POM.xml에 있는 packaging 속성값에 따라 패키지타입이 결정된다.
						ㄴ target 폴더에 jar파일이 설치된다.
					ㅡ mvn install : 생성된 artifact ( jar파일)을 local repository에 설치하는 명령어
						ㄴ .mr/repository 가 디폴트 위치이다.
					ㅡ surefire plugin은 naming convention에 일치하는 이름을 가진 test파일을 찾는다.
						ㄴ **/*Test.java, **/Test*.java, **/*TestCase.java, **/Abstract*Test.java, **/Abstract*TestCase.java
				ㅡ 위의 까지의 내용들은 거의 대부분 pom에 의해 자동으로 세팅되어 편하게 사용할수 있는 것들이다. ant같은것을 사용했으면 이런것들을 설정하기위해 훨씬 긴 코드가 필요할 것이라한다.
				ㅡ 무수히 많은 maven plugin들이 있다. (ex) mvn site : 대충 웹사이트를 생성하게 해주는 명령어.
				ㅡ ???snapshot version )
					ㄴ pom에서 < version>값으로 ~~-SNAPSHOT 이라는 값형태가 있는데, 이는 코드가 안정되지 않고 바뀔수 있는 '최신'버전임을 의미한다.
					ㄴ release 이전의 'development'버전임을 의미한다.
					* ???release ???
				ㅡ plugin 사용법 )
					* Plugin )
						ㅡ maven은 플러그인 실행 프레임워크라고도 할 수 있다. 모든것이 플러그인에 의해 실행된다.
						ㅡ 두가지 종류의 플러그인이 있다.
							ㄴ Build plugin : build되는동안 실행되는 플러그인이고, pom의 < build>아래에 설정되어야 한다.
							ㄴ Reporting plugin : site generation동안 실행되는 플러그인이고, pom의 < reporting>아래에 설정되어야한다.
						ㅡ 위에서 나온 install, site 등도 모두 플러그인이고 maven에서 제공하는것이건 외부로부터 가져오는것이건 가져다쓰면되는 함수같은 느낌이다.
				ㅡ JAR에 리소스 추가하는법 )
					ㄴ ...
				ㅡ 리소스파일 filter하는 법 )
					ㄴ ...
				ㅡ ...
				ㅡ 나머지는 더 필요하면 공부하도록..
			</pre>

			ㅇ Spring Boot <button>펼치기</button>
			<pre>
				ㅡ ~~~~~
				ㅡ spring boot 구조 )
					ㄴ spring boot는 특별한 코드 구조를 강요하지 않음.
						단지 추천하는 최적의 관례가 있을 뿐.
				ㅡ spring boot에서 사용가능한 뷰 목록
					ㄴ JSP/JSTL
					ㄴ Thymeleaf
					ㄴ FreeMarker
					ㄴ Velocity
					ㄴ Groovy Template Engine
					ㄴ Tiles
				ㅡ thymeleaf 사용하기
					ㄴ dependency를 추가하면 기본적으로 resource폴더 안에 template안에있는 html파일들이 매칭된다.
				ㅡ jsp 사용하기
					ㄴ 설정
						ㄴ application.properties 또는 application.yml에 다음과 같이 설정
							spring.mvc.view.prefix=/WEB-INF/home
							spring.mvc.view.suffix=.jsp
							ㄴ 뷰를 반환시 뷰이름에 prefix아ㅗ suffix를 붙여 jsp파일을 매핑시키는것.
						ㄴ dependency에 다음과 같이 설정
							compile('org.apache.tomcat.embed:tomcat-embed-jasper')
							compile('javax.servlet:jstl:1.2')

					ㄴ 일반적으로 src/main/webapp/WEB-INF/(*임의의 폴더*) 안에 jsp파일들을 위치시킨다.
				ㅡ 요청 인자를 LocalDate으로 받기 )
					ㄴ 인자로 받는 dto에 @DateTimeFormat(~~~~~)을 선언해주면된다.
						ㄴ ex)
							@DateTimeFormat(iso = DateTimeFormat.ISO.DATE)
							private LocalDate issueStartDate;
						ㄴ 어노테이션의 속성값으로 pattern을 주어 날짜형식을 설정할수도있다.
						ㄴ 예시에서나온 iso=DateTimeFormat.ISO.DATE는 'yyyy-MM-dd'형식으로 인자값을 받는 방식이다.
			</pre>

			ㅇ Spring Data JPA <button>more</button>
			<pre>
				ㅡ 의존성 )
					ㄴ ~~~~~
				ㅡ 설정 )
					ㄴ spring boot
						ㄴ application.properties
							ㄴ ex )
								spring.datasource.url= jdbc:postgresql://localhost:5432/deepqcopy
								spring.datasource.username= (*username*)
								spring.datasource.password= (*pw*)
								spring.datasource.driver-class-name= org.postgresql.Driver

								spring.jpa.database-platform= org.hibernate.dialect.PostgreSQLDialect
								spring.jpa.hibernate.ddl-auto=create  // jpa를 통한 테이블 정의 옵션. create, update 등..
								spring.jpa.show-sql= true

				ㅡ

				ㅡ 무제 )<button>more</button>
				<pre>
					ㄴ 기본적으로 Spring Data JPA의 목적은 db와 관련된 보일러플레이트 코드를 줄이기 위함.
					ㄴ 핵심 인터페이스는 'Repository'. 도메인 클래스와 이의 id 타입을 받는다.
						ㄴ marker interface의 역할을 한다함. 인터페이스의 타입을 지정하는 것과 이를 상속하는 인터페이스를 식별하게 하는 기능.
					ㄴ CrudRepository )
						ㄴ 기본적인 crud 기능을 제공해주는 인터페이스.
						ㄴ 일부 상세 )
							public interface CrudRepository< T, ID> extends Repository< T, ID> {

							< S extends T> S save(S entity);

							Optional< T> findById(ID primaryKey);

							Iterable< T> findAll();

							long count();

							void delete(T entity);

							boolean existsById(ID primaryKey);

							// … more functionality omitted.
							}
						ㄴ 특정 영속성 기술에 특화된 추상 repository interface도 제공하고 있다. (JpaRepository, MongoRepository)
							ㄴ 이들은 CrudRepository를 상속한다.
					ㄴ CrudRepository 끝에 PagingAndSortingRepository 추상화도 존재한다. 페이징을 쉽게 해주는 구현체.
					ㄴ 쿼리 메소드 )
						ㄴ ????? CRUD기능의 repository는 내부적으로 쿼리들을 가지고 있다
						ㄴ 이 쿼리들은 다음의 과정을 통해 선언된다.
							ㄴ 'Repository' interface나 그 하위 인터페이스를 상속하는 인터페이스를 선언하고 이것에게 도메인 클래스와 id type을 정해준다.
								ㄴ ex ) interface PersonRepository extends Repository< Person, Long> { … }
							ㄴ 이 인터페이스에 메소드를 정의히나다.
								ㄴ ex ) 	interface PersonRepository extends Repository< Person, Long> {
											List< Person> findByLastname(String lastname);
											}
							ㄴ ????? 자바 빈 주입을 말하는 드 하다.
							ㄴ repository 메소드 사용.
					ㄴ repository interface 정의하기 )<button>more</button>
					<pre>
						ㄴ 일반적으로, 'Repository', 'CrudRepository', 'PagingAndSortingRepository'을 상속하여 repository를 만든다.
							이를 사용하지 않으려면, @RepositoryDefinition을 이용하여 repository를 만들 수 있다.
						ㄴ CrudRepository 인터페이스 안에는 엔터티를 조작할 모든 메소드가 노출된 상태로 있다.
							이를 선택적으로 노출시키려면, CrudRepository를 상속하는 커스텀 repository를 만든 뒤, 이 커스텀 repository에
							노출시키고자 하는 메소드들만 정의한 뒤, 이를 내가 사용하려는 repository가 상속하게 하면 된다.
							ㄴ ex) 	@NoRepositoryBean
									interface MyBaseRepository< T, ID> extends Repository< T, ID> {

									Optional< T> findById(ID id);

									< S extends T> S save(S entity);
									}

									interface UserRepository extends MyBaseRepository< User, Long> {
									User findByEmailAddress(EmailAddress emailAddress);
									}
							ㄴ ????? 이렇게 노출시킨 메소드들은, 스프링 데이터에서 개발자가 선택한 기본 repository로 route된다?
							* @NoRepositoryBean : 스프링이 빈으로 생성하지 않기를 바라는 중간 repository에 선언.
						ㄴ ????? 여러개의 스프링 데이터 모듈을 사용하는 경우 )
							ㄴ 한 개의 스프링 데이터 모듈을 사용하는 경우와 달리, 여러개를 사용하면
								스프링 데이터가 자동으로 엄격한 설정 모드로 바뀌고 특정한 규칙에 따라 repository 정의에 어떤 모듈을 사용할지 결정한다.
							ㄴ 규칙 )
								ㄴ repository가 특정 모듈의 repository를 상속한 경우, 그 특정 스프링 데이터 모듈의 후보가 된다.
									ㄴ ex )
										interface MyRepository extends JpaRepository< User, Long> { }  // String Data JPA Module의 JpaRepository가 상속되었기 때문에, MyRepository는 이 모듈의 후보가 된다.

										@NoRepositoryBean
										interface MyBaseRepository< T, ID> extends JpaRepository< T, ID> { … }  // 마찬가지.

										interface UserRepository extends MyBaseRepository< User, Long> { … }
									ㄴ ex 2 )
										interface AmbiguousRepository extends Repository< User, Long> { … }  // 한 종류의 Spring Data Module을 사용하는 경우는 아무 문제 없으나, 아닌 경우, 이것만으로 어떤 모듈을 사용해야 하는지 스프링이 구분할 수 없다.

										@NoRepositoryBean
										interface MyBaseRepository< T, ID> extends CrudRepository< T, ID> { … } // 마찬가지.

										interface AmbiguousUserRepository extends MyBaseRepository< User, Long> { … }

								ㄴ repository에 선언된 domain class가 특정 모듈의 type annotation이 선언되었다면,
									그 특정 스프링 데이터 모듈의 후보가 된다.
									ㄴ ex )
										interface PersonRepository extends Repository< Person, Long> { … }  // JPA모듈의 @Entity가 붙은 Person domain class를 사용하는 repository이므로, JPA모듈의 후보가 된다.

										@Entity
										class Person { … }

										interface UserRepository extends Repository< User, Long> { … } // 마찬가지로 MongoDB모듈의 후보가 된다.

										@Document
										class User { … }
									ㄴ ex 2 )
										interface JpaPersonRepository extends Repository< Person, Long> { … }  // Person domain class에 JPA모듈, MongoDB모듈의 어노테이션이 모두 붙었기 때문에 스프링은 어떤 모듈을 바인딩할지 결정할 수 없다.

										interface MongoDBPersonRepository extends Repository< Person, Long> { … }

										@Entity
										@Document
										class Person { … }
								ㄴ ????? repository의 basePackage를 설정하여 모듈 특정 가능.
									ㄴ basePackage : repository 정의 서칭시 시작 지점.
									ㄴ 당연히, 적절한 패키지 위치에 repository 정의 필요.
					</pre>

					ㄴ 쿼리 메소드 정의 <button>more</button>
					<pre>
						ㄴ repository가 메소드명으로부터 저장소(보통 db)에 맞는 쿼리를 만들어 내는 전략이 있다.
							ㄴ 메소드명에서 직접 가져오는 방식.
							ㄴ 수동으로 정의된 쿼리를 가져오는 방식.
						ㄴ xml 설정의 'query-lookup-strategy', 자바 config의 @Enable${store}Repositories의 queryLookupStrategy 속성으로 lookup 전략 설정 가능.
						ㄴ 전략 )
							ㄴ CREATE
								ㄴ 쿼리 메소드 이름으로 저장소에 맞는 쿼리를 생성하는 전략.
									기본적인 방식은 메소드 이름에서 특정 prefix들을 제거하고 나머지 부분으로 쿼리 생성.
							ㄴ USE_DECLARED_QUERY
								ㄴ 미리 선언된 쿼리를 사용하는 전략. 발견하지 못하면 예외.
									미리 선언된 쿼리는 다른 곳에 있는 어노테이션이나 다른 방법으로 정의할 수 있다.
							ㄴ CREATE_IF_NOT_FOUND
								ㄴ 위 두 옵션을 합친 전략. USE_DECLARED_QUERY를 먼저 적용하고 없을시, CREATE를 적용.
									디폴트 전략.
						ㄴ 쿼리 create ) <button>more</button>
						<per>
							ㄴ 쿼리 메소드명은 쿼리로 만들어지기 위해 '주부'와 '술부'로 나뉘어 진다. (주부는 주어, 대상 같은 것. 술부는 동사 같은 것)
								ㄴ 'find~~~~~By', 'exists~~~~~By' 등이 '주부'를 구성하고 그 뒷부분이 '술부'를 구성한다.
								ㄴ ?????
						</per>
						ㄴ ~~~~~

					</pre>

					ㄴ repository 인스턴스 생성 <button>more</button>
					<pre>
						ㄴ 정의된 repository 인터페이스를 자바 빈으로 정의하고 인스턴스를 생성하는 방법에 대해 다룸.
						ㄴ xml 이용 )
						ㄴ 자바 config 이용 )
						ㄴ ????? standalone )


					</pre>

					ㄴ ~~~~~

					ㄴ JPA Repository <button>more</button>
					<pre>
						ㄴ Spring Data JPA 설정
							ㄴ XML 설정
							ㄴ 자바 Config 설정
						ㄴ Persisting Entity )
							ㄴ CrudRepository.save()가 JPA EntityManager를 통해 엔터티를 persist 또는 merge해준다.
							ㄴ 해당 엔터티가 persist 되지 안은 경우, EntityManager가 persist()를 호출하고 아닌 경우, merge()를 호출.
							ㄴ 해당 엔터티가 persist 상태인지 아닌지는 Spring Data JPA가 다음 전략에 따라 결정한다.
								ㄴ ??? version 속성, id 속성 확인 )
								ㄴ

					</pre>

				</pre>

			</pre>


		</pre>

		Linux<button>펼치기</button>
		<pre>
			~~~

			ㄴ FHS (=Filesystem Hierarchy Standard)
				ㄴ unix-like 시스템의 파일시스템 구조에 대한 컨벤션.
					ㄴ ex ) 맨 위에 root( / ), 그 아래 /etc, /bin 등등이 있는 구조를 말함.
			ㄴ Unix-like os의 파일 시스템
				ㄴ 가상 파일 시스템을 만든다.
				ㄴ 이 가상 파일 시스템에서는 단 하나의 루트 디렉토리가 존재하고 다른 모든 파일, 디렉토리들은 이 하위에 존재한다. (계층형)
				ㄴ 마운팅
					ㄴ 어떤 장치 안에 들어있는 파일들이 파일 시스템 상의 특정 위치에 보이도록하여 사용자가 접근할 수 있게 하는 기능.
					ㄴ ex ) usb의 파일들을 마운트하여 /media 위치에서 이 파일들에 접근할 수 있음.
					ㄴ 이때 파일들을 접근 가능하게 된 위치를 'mount point' 라고 함. ex ) /media

			ㄴ chroot
				ㄴ UNIX-like os에서 모든 프로세스는 root directory를 가짐. 대부분은 시스템의 루트 디렉토리와 동일.
				ㄴ chroot 명령어를 통해 이 루트 디렉토리를 변경할 수 있다.
				ㄴ 보통 고립된 환경을 세팅하기 위해 사용된다.
					??? 레거시 라이브러리를 필요로하는 소프트웨어 구동을 위해서 또는 소프트웨어 설치와 디버깅의 단순화?
				ㄴ 프로세스가 root directory 밖으로 탈출할 수 있기 때문에 보안용도로는 사용되지 않는다.

			ㄴ namespace
				ㄴ ???namespace라는 것을 두고, 프로세스들과 커널 자원들을 특정 네임스페이스에 속하게 하고
					각자가 속한 네임스페이스 내의 자원들만 '볼수???' 있도록하는 기능?
				ㄴ ??? '볼 수 없는 것'이란?
					ㄴ 이해 및 실습을 하지 않아 정확하지는 않지만, 글에서 현상적으로 보았을 때,
						그냥 해당 네임스페이스 안에 있으면 다른 볼 수 없는 네임스페이스(부모나 형제 네임스페이스)의
						자원들(프로세스, 네트워크 인터페이스, 마운트 포인트 등)이 존재하지 않는 것처럼 동작함. 인식이 안됨.
				ㄴ PaaS 등에서 컨테이너로서 사용되고,
					같은 os kernel 자원을 사용하고 있지만 마치 별도의 vm 위에 있는 것처럼 ns별로 독립적으로 할당받은 자원을 사용하는 것.
				ㄴ ???컨테이너 처럼 가두거나 할때 쓰이고?
				ㄴ ns는 프로세스당 최대 하나 할당 가능.
				ㄴ linux에서 보통 /proc/(*pid*)/ns 에 네임스페이스가 있다.
				ㄴ 새 프로세스 생성시, 모든 네임스페이스가 상속된다.
				ㄴ clone 또는 unshare syscall로 ns 생성 가능.
					ㄴ clone 사용시, 새로운 ns를 가진 프로세스 생성.
					ㄴ unshare 사용시, 새로운 ns를 생성하고 현재 프로세스를 이 ns로 이동.
				ㄴ 종류
					ㄴ PID namespace
						ㄴ process tree를 고립시킨다.
						* 리눅스 프로세스들은 계층형 트리 구조를 가진다.
							예전엔 리눅스는 단 하나의 프로세스 트리를 가졌다.
							이 프로세스 트리는 procfs라는 파일시스템에 의해 관리.
							pid 1번이 보통 프로세스 트리에서 root 프로세스가 되며, systemd인 경우가 많다.
						ㄴ pid namespace를 통하여 중첩 process tree 생성 가능.
							ㄴ 각 중첩 프로세스 트리의 루트 프로세스는 자신을 루트 프로세스로 인식 가능하며, 중첩 트리 안에서 pid=1
							ㄴ 중첩 프로세스 트리 내 다른 프로세스들도 중첩 프로세스 트리에 해당하는 pid들을 각각 가짐.
								즉, 한 프로세스가 여러개의 pid를 가질 수 있음.
							ㄴ 부모 pid namespace에선 루트 프로세스로부터 뻗어간 프로세스 트리가 모두 보이나,
								특정 pid namespace에선 해당 프로세스 트리 밖에 보이지 않으므로 보이지 않는 프로세스들과 상호작용할 수 없음.
						ㄴ ??? 다른 ns 종류들과 다르게, clone(), fork()를 통하여 새 프로세스가 생성될 때에만 생성가능.
					ㄴ mount namespace
					ㄴ network namespace
					ㄴ ~~~
				ㄴ 각 namespace 종류들에 대한 설명 및 실습 참고
					ㄴ https://medium.com/@saschagrunert/demystifying-containers-part-i-kernel-space-2c53d6979504
					ㄴ https://blog.quarkslab.com/digging-into-linux-namespaces-part-1.html
					ㄴ google 검색 키워드 : "how to work linux namespace"

			ㄴ SELinux
				ㄴ

			ㄴ RPM, RPM Package manger, Red Hat Package Manger
				ㄴ free opensource package 관리 시스템.
				ㄴ 파일 포멧 : .rpm
				ㄴ linux 배포판들에서 사용.
				ㄴ ~~~
				ㄴ front end
					ㄴ yum
						ㄴ Fedora Linux, Centos 5 이상, Red Hat Enterprise Linux 5 이상, Scientific Linux, Yellow Dog Linux, Oracle Linux 에서 사용.
						ㄴ ~~~
					ㄴ DNF
						ㄴ Fedora Linux 18 이상, Red Hat Enterprise 8 이상, AlmaLinux 8, CentOS Linux 8 에서 사용.
						ㄴ ~~~

			ㄴ systemd <button>more</button>
			<pre>
				ㄴ 
				ㄴ 기본 사용법 
					ㄴ 서비스 등록 
						ㄴ /etc/systemd/system 아래에 (*임의의 서비스명*).service 생성. 
						ㄴ (*임의의 서비스명*).service 파일 내용을 정해진 형식에 맞게 작성. 
							ㄴ ex )  			
								[Unit]
								Description=프로메테우스 node exporter 실행.

								[Service]
								# 실행할 명령어 또는 실행 파일. 
								ExecStart=/home/node_exporter-1.8.2.linux-amd64/node_exporter --web.listen-address=:8091

								[Install]
								WantedBy=multi-user.target  # ??? service를 enable하려면 설정해야한다함. 

						ㄴ systemctl enable (*임의의 서비스명*) 실행. 
							ㄴ 해당 서비스가 부팅시 자동 실행. 
						ㄴ systemctl start (*임의의 서비스명*) 실행. 
							ㄴ 해당 서비스 실행. 
						ㄴ systemctl stop, systemctl restart 도 마찬가지. 
						ㄴ 실행할 명령어들의 권한 유의. 

				ㄴ 'Upstart' 를 대체. 
				ㄴ systemd unit 
					ㄴ systemd에서 사용되는 추상적 개념. 
					ㄴ Unit type 
						ㄴ service unit 
							ㄴ https://man7.org/linux/man-pages/man5/systemd.service.5.html
							ㄴ Restart
								ㄴ service 프로세스가 종료되었을 때 다시 실행시킬지, 
									어떤 경우에 재실행시킬지 등 설정. 
								ㄴ 값 목록 
									ㄴ always 
										ㄴ 서비스 프로세스가 정상 종료되었건 비정상 종료되었건, 
											타임아웃으로 종료되었든 시그널에 의해 중단되었든 재실행시킴. 
									ㄴ ~~~ 
							ㄴ ~~~ 
						ㄴ target unit 
						ㄴ Automount
						ㄴ device
						ㄴ mount 
						ㄴ path 
						ㄴ scope
						ㄴ slice 
						
					ㄴ ~~~
				ㄴ 설정 파일 위치 
					ㄴ /usr/lib/systemd/system/ 
						ㄴ ??? ~~~
					ㄴ /run/systemd/system/
						ㄴ ??? ~~~
					ㄴ /etc/systemd/system/ 
						ㄴ ??? ~~~
				ㄴ 
			</pre> 
			
			ㄴ 명령어들 <button>more</button>
			<pre>
				ㄴ du <button>more</button>
				<pre>
					ㄴ 형식 )
						du [OPTION]... [FILE]...
						du [OPTION]... --files0-from=F
					ㄴ 명시된 파일들의 디스크 용량 정보 제공.
					ㄴ ex )
						du /home /var/lib/pgsql     => /home, /var/lib/pgsql 에 대한 디스크 용량 정보 출력.
					ㄴ 디렉터리인 경우 하위로 recursive한다.
					ㄴ 옵션
						ㄴ --max-depth=N (-d)
							ㄴ 현재 위치에서 하위 N만큼 깊이까지의 디렉토리에 대해서만 확인.
							ㄴ 가령, 구조가
								/home
								/home/dir1
								/home/dir2
								/home/dir2/dir2_1
								/home/dir2/dir2_2
								/home/dir2/dir2_2/dir2_2_1
								/home/dir2/dir2_2/dir2_2_2
								위와 같고 현재위치가 /home이면,
								du --max-depth=0 => /home의 전체용량만 요약해서 나열.
									다음과 같이,

									256G    .

								du --max-depth=2 => /home 하위 2단계 깊이의 서브디렉토리까지의 전체 용량만 요약해서 나열하는식.
									다음과 같이,

									256G    .
									123G    ./dir1
									123G    ./dir2
									80G     ./dir2/dir2_1
									42G     ./dir2/dir2_2
						ㄴ --human-readable (-h) : 사람이 읽기 쉽게. 용량을 MB,GB등으로 변환해서 보여줌.
				</pre>
				ㄴ df <button>more</button>
				<pre>
					ㄴ df [OPTION]... [FILE]...
					ㄴ 해당 파일들을 포함하고 있는 파일시스템의 이용률을 보여줌.
						ㄴ ex )
							df /var/lib/pgsql   => pgsql이 저장되어있는 파일시스템(예를들어, /에 마운트된 /dev/xvdal)의 이용률 보여줌.

							Filesystem  1K-blocks   Used    Available   Use%    Mounted on
							/dev/xvdal  123123213   23123   12123213    13%     /

							df /var/lib/pgsql /dev  => pgsql과 /dev가 젖아되어있는 파일시스템의 이용률 보여줌.

							Filesystem  1K-blocks   Used    Available   Use%    Mounted on
							/dev/xvdal  123123213   23123   12123213    13%     /
							devtmpfs    123321      0       123321      0%      /dev

					ㄴ 파일을 명시하지 않으면, 마운트된 모둔 파일시스템을 보여줌.
				</pre>
				ㄴ ssh-keygen 
					ㄴ 
				ㄴ ssh <button>more</button>
				<pre>
					ㄴ OpenSSH의 ssh client
					ㄴ ssh protocol을 이용하여 remote에 로그인 기능 제공.
					ㄴ ssh protocol 1,2 지원. 디폴트는 2.
					ㄴ 유저 인증
						ㄴ 사용 가능한 인증 방법 목록
							ㄴ GSSAPI 인증
							ㄴ host-based 인증
							ㄴ public key 인증 
								ㄴ public, private eky를 이용하는 방법. 
									ssh서버가 public key를, 오직 유저만이 private 키를 가지고, 
									이 키를 이용하여 인증 요청하면 ssh가 알아서 인증을 진행. 
								ㄴ server의 ~/.ssh/authorized_keys 파일에 public key의 내용이 한줄씩 리스팅되고, 
									클라이언트가 private키와 함께 어떤 키쌍으로 인증할지 명시하여 요청하면, 
									서버가 인증을 진행하는식. 
								ㄴ 'ssh-keygen'명령어를 사용하여 쉽게 키쌍 생성 가능. 
							ㄴ challenge-response 인증
							ㄴ password 인증
						ㄴ 위 인증 방법 목록의 위에서부터 순서대로 시도된다. ssh protocol 2의 경우 디폴트 설정가능하다함.
							(PreferredAuthentications 설정)
					ㄴ 인증 완료되면, remote는 ssh 명령어에 주어진 명령을 실행하거나
						인증된 유저를 remote에 로그인시키고 remote의 shell을 넘겨준다.
						이때 실행되는 명령어나 shell과의 통신은 암호화된다.
					ㄴ 옵션<button>more</button>
					<pre>
						ㄴ -i 
							ㄴ identity_file 
							ㄴ 어떤 private key파일을 사용하여 인증할지 명시. 
						ㄴ ~~~

					</pre>

					ㄴ 참고
						ㄴ https://linux.die.net/man/1/ssh
						ㄴ https://www.digitalocean.com/community/tutorials/how-to-configure-ssh-key-based-authentication-on-a-linux-server
						ㄴ https://www.sectigo.com/resource-library/what-is-an-ssh-key
				</pre>
				ㄴ scp <button>more</button>
				<pre>
					ㄴ 네트워크 상으로 호스트간 파일 복사.
					ㄴ 데이터 전송과 인증을 위해 ssh 명령어를 사용한다함. ???내부적으로 알아서 사용하는듯?
				</pre>
				ㄴ sshpass <button>more</button>
				<pre>
					ㄴ ssh 관련 명령어 사용시 비밀번호를 input으로 직접 입력할 필요 없게 해주는 명령어. 
						파일, 환경변수 등에 비번을 미리 입력해두고 이를 자동으로 입력해줌. 
					ㄴ 옵션 
						ㄴ -f 
							ㄴ 비밀번호를 파일로부터 읽어옴. 파일 맨 처음부터 비번문자열이 와야함. 
						ㄴ -p 
							ㄴ 비번을 명령어 인자로 입력. 
							ㄴ ex ) sshpass -p '123asdf' scp ~~~ 
						ㄴ -e 
							ㄴ 비번을 환경변수 'SSHPASS' 로부터 읽어옴. 
							ㄴ??? 파일의 경우보다 많은 프로세스가 접근할 수 있으므로 더 위험? 

					ㄴ ex ) 
						sshpass -f /home/postgres/data/standby_server.txt scp -o StrictHostKeyChecking=no (*파일*) postgres@192.168.0.190:/home/postgres/wal_archive/(*파일명*) 
				</pre>
				ㄴ top <button>more</button>
				<pre>
					ㄴ ??? ~~~
					ㄴ 결과창
						ㄴ ~~~
						ㄴ 요약 영역
							ㄴ ~~~
							ㄴ 메모리
								ㄴ 첫번째줄 : 메모리
									ㄴ total : 전체 메모리 크기
									ㄴ free
									ㄴ
									ㄴ buff/cache
								ㄴ 두번째 줄 : 스왑 메모리
						ㄴ 디테일 영역
							ㄴ 컬럼
								ㄴ ~~~
								ㄴ RES : 랩에서 사용 중인 메모리
								ㄴ SHR : 다른프로세스와의 공유 메모리
								ㄴ TIME+ : 프로세스가 사용한 토탈 cpu시간. 
					ㄴ 결과창에서의 명령어
						ㄴ M : 메모리 사용량 순으로 정렬
						ㄴ P : cpu 사용량 순으로 정렬
						ㄴ T : 프로세스 실행시간 순으로 정렬
						ㄴ N : pid 순으로 정렬
					ㄴ 참고 ) https://man7.org/linux/man-pages/man1/top.1.html

				</pre>

				ㄴ cp <button>more</button>
				<pre>
					ㄴ 
					ㄴ ~~~
					ㄴ 옵션 
						ㄴ -r : 디렉토리 하위 파일들까지 복사.
						ㄴ -v : 진행상태 출력
				</pre>
				ㄴ file <button>more</button>
				<pre>
					ㄴ 개요 
						파일의 type을 확인하는 명령어. 
						내부적으로 'filesystem test', 'magic test', 'language test'를 하여 파일의 타입이 뭔지 결정하고 반환. 
					ㄴ ex ) 
						file test.txt  
						=> test.txt: ASCII text 

						file test.svg 
						=> test.svg: SVG Scalable Vector Graphics image
					ㄴ magic test 
						ㄴ 개요 
							file 명령어에서 수행하는 test 중 하나로서, 파일의 컨텐츠에 특정 'magic pattern'이 포함되어있는지를 테스트하여 
							파일의 type을 결정하는 방식. 
							magic pattern이란, 파일 형식에 따라 파일 컨텐츠에서 나타나는 특정 데이터 패턴을 의미. 
						ㄴ ??? 대략 동작 방식 
							ㄴ magic file의 row들을 테스트하며 통과하는 케이스들이 있으면 해당 타입으로 결정하는식. 
						ㄴ magic patterns database 
							ㄴ 테스트 되어야할 magic pattern들의 정보가 저장되어있는 파일. 
							ㄴ 일반적 위치 ) /usr/share/file/misc/magic.mgc, /usr/share/file/misc/magic 
						ㄴ ??? libmagic 라이브러리 
							ㄴ magic patterns database에 대해 수행되는 magic test관련 연산을 하는 라이브러리. 
					ㄴ 참고 
						ㄴ https://man.archlinux.org/man/file.1.en#first
						ㄴ https://man.archlinux.org/man/magic.5.en
						ㄴ https://man.archlinux.org/man/core/file/libmagic.3.en

				</pre>

			</pre>

			Centos 7<button>펼치기</button>
			<pre>
				...

				ㄴ 기본 명령어들 )
					ㄴ cp )
						ㄴ 복사 명령어
						ㄴ cp (*복사대상파일*) (*파일이름*) : 복사대상을 복사하여 두번째인자인 파일을 만든다.
						ㄴ cp (*복사대상파일*) (*디렉토리*) : 복사대상파일을 해당 디렉토리로 복사한다. (복사대상을 여러개 선택할수있다) ex) cp file1 file2 file3 (*디렉토리*)
					ㄴ rm )
						ㄴ 삭제명령어
						ㄴ rm (*파일*) : 해당 파일 삭제
							ㄴ ex) rm *.dat :  .dat으로 끝나는 모든 파일 삭제.
							ㄴ rm * : 모든파일삭제.
						ㄴ rm -r (*디렉토리*) : 디렉토리삭제. 안에파일이 있어도 삭제함.
					ㄴ pwd : print working directory. 현재 작업중인 디렉토리 위치 출력.
					ㄴ ??? route )
						ㄴ 라우팅 테이블 확인.
						ㄴ ex )
							Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
							default         gateway         0.0.0.0         UG    100    0        0 em4  # 디폴트 게이트웨이???
							192.168.0.0     0.0.0.0         255.255.255.0   U     100    0        0 em4
					ㄴ netstat
						ㄴ ~~~
						ㄴ output 요소
							ㄴ ~~~
							ㄴ local address
								ㄴ 소켓 연결에서 로컬 엔드포인트의 address:port.
							ㄴ foreign address
								ㄴ 소켓 연결에서 remote 엔드포인트의 address:port.

				ㄴ rpm
					ㄴ Redhat사에서 개발한 패키지 관리 프로그램.
					ㄴ Maven처럼 프로그램설치시 필요한 의존성이 있으면 자동으로 필요한 패키지들을 함께 설치해 준다.
					ㄴ ~~.rpm 형식의 파일이름을 가지며, 이름부분에는 정해진 규칙을 따르는 패키지명을 가진다.
						ㄴ (*패키지이름*)-(*소스버전*)-(*릴리즈버전*).(*배포관리버전*).(*아키텍쳐*).rpm
						ㄴ ex) mysql-connector-java-5.1.25-3.el7.noarch.rpm
					ㄴ 명령어 )
						ㄴ 기본형태 )  rpm [옵션] [rpm 패키지파일 또는 rpm 패키지이름]
						ㄴ 패키지 설치여부 조회 )
							ㄴ rpm -qa :
							ㄴ rpm -qa (*패키지이름*) : 해당 패키지 조회
							ㄴ rpm -qa | grep : 좀더 세밀한 조회
						ㄴ 설치명령어 )
							ㄴ rpm -Uvh (*패키지파일*) : 해당 패키지파일 설치명령어. -Uvh는 옵션. U는 패키지가 이미설치되어있으면 upgrade를 진행, v는 설치과정 출력, h는 진행률 출력.
						ㄴ 패키지 삭제 )
							ㄴ rpm -e (*패키지파일*)

				ㄴ yum
					ㄴ rpm의 대용으로 나온 패키지 관리 프로그램.
					ㄴ 명령어 )
						ㄴ yum install (*패키지명*)
						ㄴ yum groupinstall (*그룹명*)
						ㄴ yum check-update : 업데이트가 되어있는 패키지목록 확인
						ㄴ yum update : 설치된 패키지들을 최신버전으로 업데이트
						ㄴ yum update (*패키지명*) : 해당 패키지를 업데이트
						ㄴ yum list installed : 설치된 패키지 확인
						ㄴ yum list : 설치가능한 패키지 목록 확인
						ㄴ yum info (*패키지명*) : 패키지 정보보기
						ㄴ yum localinstall : local에 있는 rpm파일을 설치할때 사용된다.

				ㄴ inetd, xinetd
					ㄴ 개인적 개요 )
						ㄴ 리눅스의 인터넷 데몬같은것?
					ㄴ xinetd : extended inetd
					ㄴ 인터넷 서비스를 제공해주는 프로그램을 실행시킨다.
					ㄴ conf파일에 설정되어있는 모든 포트에 대해 listen을 하고 있다가 request가 도착하면 이에 맞는 적절한 서버를 실행시켜준다.
					ㄴ 'super server'라고도 불린다.

				ㄴ inetd 모드, standalone 모드
					ㄴ inetd 모드 : inetd를 통해서 서비스가 실행되는 모드를 말한다.
					ㄴ standalone 모드 : inetd없이도 혼자서 서비스가 실행되는 모드를 말한다.

				ㄴ vsftpd
					ㄴ ftp서버 프로그램.
					ㄴ ...
					ㄴ 사용법 )
						ㄴ  vsftpd.conf )
							ㄴ vsftpd에 관한 설정파일. https://linux.die.net/man/5/vsftpd.conf 참조.
							ㄴ anon_upload_enable : wirte_enable항목이 YES일때만 효과가 적용되며, 익명사용자가 업로드를 할수있게하는 항목.
							ㄴ write_enable :
							ㄴ userlist_file : userlist_enable항목이 활성화되어있을때 사용된다. 여기에 적힌 파일로부터 username list를 가져온게된다.
								디폴트는 /etc/vsftpd/user_list.
							ㄴ userlist_enable : 활성화되면, userlist_file에 적힌 파일로부터 user list를 가져와 이들이 로그인하는걸 막는다.
								(비번을 요구하기전에 거부된다). 디폴트는 NO이다.
							ㄴ userlist_deny : userlist_enable이 활성화되어있을때 사용된다. NO이면 userlist_file에 있는 유저만 접근이 가능하다.
								yes인경우 userlist_file에 있는 유저들의 접근을 거부한다. (비번을 요구하기전에 거부된다) 디폴트는 YES이다.

				ㄴ firewall 방화벽
					ㄴ iptables 명령어를 이용한 설정 : 이전버전에서 사용되었고 사용이 어렵다는 단점이 있다.
					ㄴ firewall-cmd, firewall-config
						ㄴ 새롭게 방화벽설정에 사용되는 명령어. 전자가 cmd환경에서, 후자가 gui환경에서 사용가능하다.
						ㄴ --permanent 옵션 )
							ㄴ firewall-cmd 명령어에 --permanent 옵션을 붙일 수 있다.
							ㄴ 이는 해당명령의 정책을 영구적으로 적용하라는 의미이다.
							ㄴ 이 옵션으로 정책설정후, firewall-cmd --reload 명령어를 입력하거나 재부팅을 해야 적용이된다. 그전엔 적용안됨.
							ㄴ 이게 없을시, 영구적용이 아닌 임시로 적용하게되며, 재부팅 또는 firewall-cmd --reload 명령시 리셋된다.
					ㄴ 사용법 )
						ㄴ firewall이 구동중인지 확인 : firewall-cmd --state
						ㄴ 설치 : yum install firewalld
						ㄴ firewall이 실행되도록 설정 )
							systemctl enable firewalld
							systemctl start firewalld
						ㄴ 특정 포트 및 서비스 방화벽 허용 )
							firewall-cmd --permanent --add-port=80/tcp
							firewall-cmd --permanent --add-service=http
							ㄴ --zone=(*zone이름*) 을 추가하여 네트워크zone을 설정할수도있다. 없으면 디폴트설정된걸로 설정.
						ㄴ 허용하고있는 port확인 )
							firewall-cmd --list-ports

				ㄴ centos7 mysql 설치 및 실행
					ㄴ 설치 )
						ㄴ rpm파일을 다운받는다.
						ㄴ yum install mysql-community-server로 mysql을 설치한다.
						ㄴ mysql을 실행한다. systemctl start mysqld
						ㄴ mysql을 처음설치하면 /var/log/mysqld.log안에 temporary password가 존재한다. 이를 이용하여 맨 처음 mysql에 접속할 수 있다.
							ㄴ 처음 접속한 뒤, 반드시 비밀번호를 변경해주어야한다. 안하면 아무 명령도 실행안됨.
							ㄴ  alter user 'root'@'localhost' identified by '(*새 비밀번호*)';
						ㄴ mysql에 접속한다. mysql -u root -p
							ㄴ 이거치면 비번입력하라뜨고 위의 temporary password로 입력하고 비번바꿔주면된다.
						ㄴ 이후 mysql을 사용하면된다.
					ㄴ 설정 )
						ㄴ centos에서는 mysql설정이 명령어 또는 전용 설정파일에서 가능하다.
						ㄴ 전용 설정파일은 여러종류가 있는듯하고 각각 적용범위에 차이가 있는듯하다.
						ㄴ my.cnf 설정 )
							ㄴ 전용 설정 파일들중 하나이다.
							ㄴ (*프로퍼티*) = (*값*) 형태로 설정내용들을 적는다.
							ㄴ 세세한 프로퍼티들은 다음을 참조. https://dev.mysql.com/doc/refman/8.0/en/server-system-variables.html

				ㄴ ip 설정<button>more</button>
				<pre>
					ㄴ ~~~
					ㄴ 고정 ip 설정<button>more</button>
					<pre>
						ㄴ /etc/sysconfig/network-script 위치에 'ifcfg-(*네트워크 인터페이스명?*)'과 같은 형식으로 각 네트워크 인터페이스의 설정파일들이 존재.
							ㄴ ex) ifcfg-em1
							ㄴ ex )
								TYPE="Ethernet"
								PROXY_METHOD="none"
								BROWSER_ONLY="no"
								BOOTPROTO="dhcp"
								DEFROUTE="yes"
								IPV4_FAILURE_FATAL="no"
								IPV6INIT="yes"
								IPV6_AUTOCONF="yes"
								IPV6_DEFROUTE="yes"
								IPV6_FAILURE_FATAL="no"
								IPV6_ADDR_GEN_MODE="stable-privacy"
								NAME="em4"
								UUID="87c24268-dc3a-437f-ba8b-8c758b841ea1"
								DEVICE="em4"
								ONBOOT="yes"
						ㄴ 파일 내의 다음 항목들을 수정하고 systemctl restart network 하여 적용 가능하다.
							ㄴ BOOTPROTO = "none"  # dhcp값이면 dhcp로 자동할당되므로 수정.
							ㄴ PIADDR = (*고정할 ip주소*)
							ㄴ PREFIX = (*넷마스크 prefix*)
							ㄴ GATEWAY = (*gateway ip*)
							ㄴ DNS1 = (*dns ip*)
							ㄴ DNS2 = (*dns ip*)
							ㄴ ONBOOT = "yes"  # yes 이어야 부트시 네트워크 설정이 진행.
						ㄴ 또는 nmtui 명령어로 설정 가능.
							ㄴ systemctl status NetworkManager 로 'NetworkManager'가 실행중인지 확인.
								ㄴ ??? NetworkManager란?
							ㄴ nmtui 명령어 입력하면 설정 gui창이 뜨고 ip설정이 가능하다.
					</pre>
				</pre>

			</pre>

		</pre>

		의존성 관리<button>more</button>
		<pre>
			ㄴ 의존성 코드들의 업데이트 필요성 
				ㄴ 의존하고 있는 코드가 오래될 수록, 취약점이 점차 발견 및 퍼짐. 
				ㄴ 미룰 수록 업데이트 후 통합 비용이 증가하거나 오류 가능성 커짐. 
				ㄴ 의존하고 있는 프로그램들의 개선사항들을 반영 못함.  
			ㄴ 이슈 
				ㄴ 버전 충돌. 
					ㄴ 두 의존 프로그램이 같은 제 3프로그램을 사용하ㅡㄴ데 그 프로그램에 대해 필요로하는 버전이 다른 경우. 
			ㄴ Package Manager, 패키지 매니저
				ㄴ 컴퓨터에서 프로그램을 설치, 업데이트, 설정, 삭제하는 과정을 일관된 방식으로 자동화해주는 소프트웨어의 모음. 
					linux에서 dnf 등으로 특정 프로그램을 설치, 버전변경, 삭제하거나 pip로 특정 모듈을 설치, 버전변경, 삭제하는 것처럼 
					특정 프로그램, 라이브러리 등을 컴퓨터 어딘가에 설치, 삭제, 업데이트 및 기타 관리 작업을 해주는 소프트웨어를 말함. 
				ㄴ ex ) RHEL의 dnf, js의 yarn, npm, python의 pip, conda, Debian의 apt 
				ㄴ archive file의 데이터, 소프트웨어 배포, 패키지를 다룬다.
					ㄴ 패키지의 메타데이터 안에는 소프트웨어의 이름, 설명, 버전, vendor, checksum, 필요한 의존성 목록 등이 포함.
				ㄴ 소프트웨어 패키지를 서칭, 설치, 관리, 삭제하는 작업을 해준다.
				ㄴ 기능
					ㄴ??? 'file archiver'로 패키지 archive 추출.
					ㄴ??? checksum, digital certificate를 통한 패키지의 integrity 와 authenticity 보장.
					ㄴ??? software repository나 app store로부터 프로그램들을 서칭, 다운로드, 설치, 업데이트.
					ㄴ ??? 유저 혼란을 줄이기 위한 패키지 그룹화
					ㄴ??? 패키지의 의존성 관리.
					ㄴ repository 업데이트 
				ㄴ registry (=software repository, package repository) 
					ㄴ 패키지 저장소? 
					ㄴ 패키지 파일들이 퍼블리싱되어 있는 곳. 패키지를 다운받을 수 있는 곳. 
					ㄴ 보통 여러 단체에서 전용 서버를 관리하며, 여기에 패키지들이 저장되고 퍼블리싱됨. 
					ㄴ linux의 경우, main 저장소를 mirror하는 여러 저장소가 존재한다함. 
					ㄴ ex ) python용 PyPI, Node.js용 npm, yarn, G용 CRAN, java용 Maven 
					ㄴ C, C++ 외 많은 언어들의 경우, 이렇다할 핵심적인 repository가 없다함. 
					ㄴ ???git repository와 차이 
						ㄴ 일단 당연히 git repo는 깃상에서의 개념인 리포지토리를 의미하고 소스코드, 버전관리, 혹은 바이너리 파일까지 다운, 관리 가능. 
						ㄴ 프로그램, 라이브러리의 코드 또는 바이너리를 다운받는다는 점에서 유사하긴 한듯. 
						ㄴ 근데, git repo는 하나의 프로그램에 대해서만이고 registry는 여러 프로그램들이 올라가있고, 이들에 대한 
				ㄴ ~~~
				ㄴ 참고 
					ㄴ https://developer.mozilla.org/en-US/docs/Learn_web_development/Extensions/Client-side_tools/Package_management

		</pre>

		보안 <button>펼치기</button>
		<pre>
			ㅡ 방화벽이란?
				ㄴ 네트워크상의 트레픽에 대해, 이를 모니터링하고 미리정해둔 규칙에 따라 제어하고 차단하는 시스템.
				ㄴ 소프트웨어 또는 하드웨어 일 수 있다.

			ㅡ 암호화<buton>more</buton>
			<pre>
				ㄴ 일방향 암호화 )
					ㄴ 암호화 후에, 복호화가 불가한 암호화 방식.
					ㄴ Hash 암호화
						ㄴ
				ㄴ 양방향 암호화 )
					ㄴ 암호화 후에, 복호화가 가능한 암호화 방식.
					ㄴ 대칭키 암호화 : 하나의 키로 암호화와 복호화가 진행되고 이때의 키를 말한다.
					ㄴ 비대칭키 암호화 (=공개키 암호화) )
						ㄴ 대칭키와 다르게 두개의 키로 암호화, 복호화를 진행하는 방식에서 사용되는 키이다.
						ㄴ 키 중에 하나로 암호화를 하면, 다른 하나로 복화하가 가능하고, 그 반대도 가능하다.
						ㄴ 보통 키 중 하나는 여러 곳에 배포하고 다른 하나는 자신만 조심해서 가지고 있기 때문에 전자를 '공개키', 후자를 '개인키'라고 한다.
							ㄴ 하여 비대칭키 암호화를 공개키 암호화 방식이라고도 한다.
						ㄴ 공개키로 암호화를 진행하고 개인키로 복화를 한다.
			</pre>

			ㅡ CORS(Cross-Origin Resource Sharing), SOP(Same-Origin Policy) )<button>more</button>
			<pre>
				ㄴ SOP )<button>more</button>
				<pre>
					ㄴ 한 origin에서 나온 document, script, media file들이 다른 origin과 상호작용할 수 없도록 제약하는 정책.
					ㄴ origin이란? )
						ㄴ url의 프로토콜, host(또는 ip), 포트의 조합을 의미.
					ㄴ ????? web 초창기에 단순히 document만을 보여주던 것과 달리, js와 DOM api 등이 나오면서 웹에서 여러 기능이
						가능해졌고, 이와 동시에 이러한 웹에서 CSRF와 같은 공격의 위험이 생겨났다.
						이에 대해 netscape에서 소개한 정책이다.
						ㄴ 고정된 표준이 아닌, 브라우저들이 각자 알아서 적용하는 일반적인 보안 정책.
					ㄴ 위험의 예? )
						ㄴ 페북 사이트를 iframe으로 가지고 있는 악성 웹사이트가 있다고 치면,
							페이크 사이트인 줄 모르고 여기서 페북으로 로그인을 하게되면, 악성 사이트에서 스크립트 등으로 iframe 안의
							페북 사이트에 접근하여 개인 정보 유출 등이 가능하다.
					ㄴ 내용 )
						ㄴ ????? 초기 원문? http://css.csail.mit.edu/6.858/2015/lec/l11-web-security.txt
						ㄴ ????? 이에 대한 해석? https://docs.microsoft.com/ko-kr/archive/blogs/ieinternals/same-origin-policy-part-1-no-peeking
						ㄴ js code, DOM, 쿠키, XmlHTTPRequest에 적용된다.
						ㄴ 모든 자원에 대해 적용되는 게 아니다.
							ㄴ cross origin으로 포함시킬 수 있는 html 태그들은 다음과 같다.
								ㄴ iframe, img, script, video, link, object, embed, form
								ㄴ '포함'시킬 수 있는 것이지, 이러한 cross origin 태그에 대해 읽기 작업은 가능하지 않다.
						ㄴ !!!!! 구체적으로 브라우저별, 또는 공통적으로 어떤 제약 내용이 있는지, 어디에 나와 있는지는 모르겠다.
							ㄴ https://datatracker.ietf.org/doc/html/rfc6454#section-3.4 참고?
						ㄴ 각 페이지들은 각각의 origin을 가진다.
						ㄴ 각 페이지들은 각각의 resource들을 가진다. (쿠키, DOM, js namespace 등)
						ㄴ script는 이것의 원 출처가 아닌, 로드된 origin의 context 안에서 실행된다. 즉, 최종적으로 script가
							실행되는 origin의 context.
						ㄴ 미디어, 이미지 resource들은 'passive resource'?로서, 로드된 origin의 context의 object나 resource에
							접근하지 않는다.
					ㄴ 해체 및 완화 )
						ㄴ js의 document.domain 수정 )
							ㄴ document.domain = "~~~~~"
							ㄴ origin을 직접 수정하여 sop 제약을 해결할 수 있다.
							ㄴ 단, 수정하려는 origin이 현재 origin의 subdomain이어야 한다.
						ㄴ CORS, Cross-Origin Resource Sharing 사용 )
							ㄴ
				</pre>
				ㄴ CORS )<button>more</button>
				<pre>
					ㄴ 교차 출처 리소스 공유 (Cross-Origin Resource Sharing)
					ㄴ 일반적으로는 SOP를 따르기 때문에 불가하지만,
						HTTP 헤더를 사용하여 다른 origin의 자원에 대한 접근 권한을 브라우저가 부여하도록 하는 정책.
						ㄴ origin이란 )
							ㄴ
						ㄴ 특정 조건이란, 요청하려는 다른 origin에서 준 응답 안의 CORS헤더에 현재 요청을 보내는 origin이 포함되어 있어야함.
							ㄴ 응답의 CORS 헤더란,
					ㄴ 이렇게 다른 origin으로 보내는 요청을 'Cross-origin request'라 하고, CORS 정책에 따라 처리된다.
					ㄴ js의 fetch api 등은 이 CORS 정책을 따른다.
					ㄴ 내용 )
						ㄴ 적용 시점 )
							ㄴ XMLHttpRequest, Fetch API 호출시.
							ㄴ ????? 웹 폰트
							ㄴ ????? WebGL 텍스쳐
							ㄴ ????? drawImage()
							ㄴ ????? 이미지로부터 추출하는 CSS Shapes
						ㄴ 동작 방식 세 가지 )
							ㄴ simple request )<button>more</button>
							<pre>
								ㄴ 다음 조건을 만족하는 요청으로서, 'Preflight request' 없이 바로 서버로 전송된다.
									(https://fetch.spec.whatwg.org/#cors-safelisted-request-header 참고)
									ㄴ request method가 GET, POST, HEAD 중 하나.
									ㄴ Fetch 명세에서 'forbidden header name'으로 정의한 헤더와
										'accept', 'accept-language', 'content-language', 'content-type' 이외에
										커스텀 헤더가 없는 경우.
									ㄴ content-type 헤더의 경우, 다음 값 중 하나인 경우.
										ㄴ application/x-www-form-urlencoded
										ㄴ multipart/form-data
										ㄴ text/plain
								ㄴ simple request의 경우, 바로 서버로 전송된다.
								ㄴ 보내면 서버에서 'Access-Control-Allow-Origin' 헤더가 포함된 응답을 주면, 이 헤더 안의 값으로
									현재 origin이 cors요청이 허용되는지 확인할 수 있다. 헤더 값은 없거나, 현재 origin이거나 와일드카드(*)이다.
									현재 origin이 서버에서 허용되면 현재 origin값이 들어있고, 모든 origin에 대해 허용하고 있으면 와일드카드,
									허용 안 하면 값이 없다.
								ㄴ ex )
									http://localhost:8000인 origin에서 다음 요청.
									$.ajax({
										url: "http://dlencdiv.kr/pages/ajax/addCustomSocialKeyword",
										type: "POST",
										data: JSON.stringify({}),
										contentType: "text/plain"
									})
									ㄴ 조건이 simple request에 해당하므로, 바로 요청이 들어가고 다음과 같은 오류가 뜨며 실패. (서버에서 CORS설정 안 해둔 상태)
										ㄴ Access to XMLHttpRequest at 'http://dlencdiv.kr/pages/ajax/addCustomSocialKeyword' from origin 'http://localhost:8001' has been blocked by CORS policy: No 'Access-Control-Allow-Origin' header is present on the requested resource.
							</pre>
							ㄴ Preflight request )<button>more</button>
							<pre>
								ㄴ simple request의 조건을 만족하는 경우가 아닌 경우에,
									브라우저가 cors요청 전에 서버에게 'OPTION' request 메소드로 여러 정보를 보내어
									본 cors request를 보내기 전에 cors요청이 수용 가능한지 체크한다.
								ㄴ preflight request, response 예 )<button>more</button>
								<pre>
									ㄴ preflight request )
										OPTIONS /resources/post-here/ HTTP/1.1
										Host: bar.other
										User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:71.0) Gecko/20100101 Firefox/71.0
										Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
										Accept-Language: en-us,en;q=0.5
										Accept-Encoding: gzip,deflate
										Connection: keep-alive
										Origin: http://foo.example
										Access-Control-Request-Method: POST
										Access-Control-Request-Headers: X-PINGOTHER, Content-Type
										ㄴ 'Access-Control-Request-Method'는 실제 전송 떄, 어떤 메소드로 요청할 것인지를 알려줌.
										ㄴ 'Access-Control-request-Headers'는 실제 전송 떄, 어떤 사용자 정의 헤더가 포함되는지 알려줌.

									ㄴ preflight response )
										HTTP/1.1 204 No Content
										Date: Mon, 01 Dec 2008 01:15:39 GMT
										Server: Apache/2
										Access-Control-Allow-Origin: https://foo.example  // cors요청이 허용된 origin을 나타내는 헤더.
																							// 모든 origin에 대해 cors요청을 허용하면 와일드카드값이고, 현재 요청보내는 origin에 대해 허용시, 현재 요청을보내는 origin이 값이다.
										Access-Control-Allow-Methods: POST, GET, OPTIONS  // 이 메소드들로 요청 가능한 리소스임을 알려줌.
										Access-Control-Allow-Headers: X-PINGOTHER, Content-Type  // 이 헤더들을 커스텀하여 요청할 수 있음을 알려줌.
										Access-Control-Max-Age: 86400  // 이 preflight 요청에 대한 응답을 브라우저가 캐싱해 두어, 다음 요청시 preflight request가 필요 없도록 함. 이 떄 캐싱하는 최대 시간값을 나타냄.
										Vary: Accept-Encoding, Origin
										Keep-Alive: timeout=2, max=100
										Connection: Keep-Alive

									ㄴ 본 request )
										POST /resources/post-here/ HTTP/1.1
										Host: bar.other
										User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:71.0) Gecko/20100101 Firefox/71.0
										Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
										Accept-Language: en-us,en;q=0.5
										Accept-Encoding: gzip,deflate
										Connection: keep-alive
										X-PINGOTHER: pingpong
										Content-Type: text/xml; charset=UTF-8
										Referer: https://foo.example/examples/preflightInvocation.html
										Content-Length: 55
										Origin: https://foo.example  // 요청을 보내는 origin.
										Pragma: no-cache
										Cache-Control: no-cache

										< person>< name>Arun< /name>< /person>

									ㄴ 본 response )
										HTTP/1.1 200 OK
										Date: Mon, 01 Dec 2008 01:15:40 GMT
										Server: Apache/2
										Access-Control-Allow-Origin: https://foo.example
										Vary: Accept-Encoding, Origin
										Content-Encoding: gzip
										Content-Length: 235
										Keep-Alive: timeout=2, max=99
										Connection: Keep-Alive
										Content-Type: text/plain

										[Some GZIP'd payload]
								</pre>
								ㄴ ex )
									http://localhost:8000인 origin에서 다음 요청
									$.ajax({
										url: "http://dlencdiv.kr/pages/ajax/addCustomSocialKeyword",
										type: "POST",
										data: JSON.stringify({}),
										contentType: "text/plain"
									})
									ㄴ 조건이 simple request에 해당되지 않으므로 preflight request로 들어간다.
										OPTIONS메소드로 요청이 먼저 날아가고 다음 에러 뜨며 실패. (서버에서 CORS설정 안 해둔 상태)
										Access to XMLHttpRequest at 'http://dlencdiv.kr/pages/ajax/addCustomSocialKeyword' from origin 'http://localhost:8001' has been blocked by CORS policy: Response to preflight request doesn't pass access control check: Redirect is not allowed for a preflight request.
								ㄴ preflight 후 리다이렉트 이슈 )
									ㄴ ?????
							</pre>
							ㄴ CORS 요청시, credential 정보 포함 )
								ㄴ 기본적으로, cors 요청시, credentail 정보(쿠키, authentication, certificate)를 포함시키지 않는다.
									이를 전달하기 위해선 요청 생성시 특정할 플래그 값을 주어서 이를 포함시킬 수 있다.
								ㄴ XMLHttpRequest의 경우 )
									ㄴ 	const req = new XMLHttpRequest();
										req.open("GET", url, true);
										req.withCredentials = true;  // withCredentials란 값을 true로 하여, 요청시 credential값들을 포함시켜 보낼 수 있다.
										req.onreadystatechange = handler;
										req.send();
								ㄴ 이에 대한 응답 헤더에 'Access-Control-Allow-Credentials': true 가 없을 경우, 브라우저는 이를 실패 취급한다.
								ㄴ preflight request의 경우 )
									ㄴ preflight request는 credential정보를 절대 포함하지 않고, preflight에 대한 응답에서
										"Access-Control-Allow-Credentials": true가 포함된 경우에, 원 요청에서 credential을 포함시킨다.
								ㄴ credential request인 경우, 응답 헤더의 조건 )
									ㄴ 요청이 crednetial request인 경우, 응답 헤더는 다음 조건을 충족해야 한다.
										ㄴ "Access-Control-Allow-Origin"이 와일드 카이이어선 안되고 특정 origin을 명시해야 한다.
										ㄴ "Access-Control-Allow-Headers"가 와일드 카드이어선 안되고 헤더 이름의 목록을 명시해야 한다.
										ㄴ "Access-Control-Allow-Methods"가 와일드 카드이어선 안되고 메소드 명을 명시해야 한다.
									ㄴ 조건을 충족하지 않을 경우, 브라우저는 해당 응답을 실패처리한다.
						ㄴ https://fetch.spec.whatwg.org/#cors-protocol 참고.

					ㄴ 서버가 어떤 origin이 cross origin을 통해 요청을 보낼 수 있을지 결정하게 해준다.
						ㄴ 즉, 알 수 없는 임의의 origin이 마음대로 서버로 요청을 보내어 공격하는 경우(POST, PUT 메소드 요청 등을 통해
							서버에 수정을 가하거나 등)를 어느 정도 방지해 준다.
				</pre>
				ㄴ 정책의 구현 )
					ㄴ 클라이언트 side) 이 정책들에 대한 구현은 브라우저 내부적으로 'XMLHttpRequest'를 통해 구현이 되어있으므로, 프로그래밍적으로 손댈 일은 드물다.
					ㄴ 서버 side ) 사용하는 서버쪽 언어나 프레임워크에 맞게 설정이 필요하다.
				ㄴ 보안적 risk )
					ㄴ 당연하게, 서버단의 access-control-allow-origin은 퍼블릭 api가 아닌 경우 와일드카드가 되어선 안된다.
				ㄴ 참고 )
					ㄴ https://developer.mozilla.org/ko/docs/Web/HTTP/CORS
					ㄴ https://www.netsparker.com/whitepaper-same-origin-policy/
					ㄴ https://www.acunetix.com/blog/web-security-zone/what-is-same-origin-policy/
					ㄴ https://www.codecademy.com/article/what-is-cors
					ㄴ https://www.packetlabs.net/cross-origin-resource-sharing-cors/
					ㄴ https://fetch.spec.whatwg.org/#http-cors-protocol
			</pre>

			ㅡ 웹 보안<button>more</button>
			<pre>
				ㄴ ~~~
				ㄴ 정형화된 이론이 있다기보다, 여러 공격 방법들이 있고 이들에 대해 각각 대응하는 모양새.
					ㄴ 치명적이거나 많이 발생하고 당하는 공격들만 대응하거나 꼼꼼하게 모두 대응하거나.
				ㄴ ~~~
				ㄴ 취약점, 공격 방식 <button>more</button>
				<pre>
					ㄴ XSS ( Cross-site script )
						ㄴ 사용자의 웹페이지에 자바스크립트 코드를 삽입하는 방법.
							클라이언트로부터 인증 토큰이나 세션id 등을 탈취할 수 있음.
						ㄴ ex )
							ㄴ 게시물에 스크립트 코드를 작성하여 저장하고, 이 게시물 내용을 유저가 웹페이지에 띄울시 스크립트가 실행되는 방식.
							ㄴ
						ㄴ 대응 )
							ㄴ
					ㄴ CSRF (Cross-Site Request Forgery)
						ㄴ
						ㄴ 대응 )
							ㄴ http Referer 체크
								ㄴ http referer header를 이용하여 허용된 referer의 요청만 허가하여 막는 방법.
								ㄴ http 변조를 통해 쉽게 뚫린다함.
							ㄴ CSRF Token 체크
								ㄴ
							ㄴ CAPTCHA
					ㄴ 인젝션, Injection
						ㄴ SQL injection
							ㄴ sql을 삽입하여 공격하는 방식.
							ㄴ 유저로부터 입력받은 값을 sql에 그대로 사용시, 악의적 sql을 입력하여 공격 가능.
							ㄴ ex )
								ㄴ 입력값이 서버에서 그대로 sql 조건문으로 넘어가는 경우, 입력값에 적당한 sql을 집어넣어 간접적으로
									db에 명령을 실행하는 등.
							ㄴ 대응 )
								ㄴ 입력값을 그 대로 sql에 사용하지 말고, sql에 사용되는 예약문자들 필터링. (큰따옴표, 작은따옴표, 세미콜론 등)
							ㄴ 현재 대부분의 sql관련 라이브러리, 프레임워크에서 기본적으로 방어해준다함.
					ㄴ 세션 관련
						ㄴ 세션 고정 취약점
							ㄴ 로그인 전 세션을 로그인 후에도 그대로 사용하는 경우,
								공격자가 사전에 페이지에 접속하여 세션id를 받아두고 기다렸다가
								다른 유저가 로그인하면 이 세션id를 도용하는 케이스.
							ㄴ 로그인시마다 새로운 세션id를 발급
						ㄴ 세션 만료 시간
							ㄴ 세션 만료 시간이 너무 긴 경우, 로그아웃되지 않은 컴퓨터에서 다른 사용자가 사용할 수 있음.
							ㄴ 서비스에 따라 적절히 설정.
						ㄴ 세션 스니핑
							ㄴ 패킷을 중간에 탈취하여 세션 정보를 알아내는 방법.
							ㄴ 대응 )
								ㄴ ssl 적용.
						ㄴ 세션 id 노출
							ㄴ 세션 id가 url에 노출되어선 안됨.
						ㄴ 세션 id 무작위 대입.
							ㄴ 세션 id가 단순한 경우, 세션 id의 패턴을 분석하여 때려맞추는 식으로 탈취 가능.
							ㄴ 대응 )
								ㄴ 세션 id 암호화.
								ㄴ 길고 랜덤하게.
								ㄴ 시도 횟수 제한.
					ㄴ 아이디, 비밀번호 관련
						ㄴ 유저들이 같은 id, pw를 돌려쓰는 경우가 많기 때문에, 한곳에서 탈취된 id, pw은 해커에게 판매되어
							다른 계정을 뚫는데 사용된다.
							ㄴ 보안상 중요한 동작에 '다중 인증'을 걸어 id, pw만으로 동작할 수 없도록.
								ㄴ '다중 인증' : id, pw 이외에 email OTP나 생체인증 등의 추가적인 인증을 요구하는 것.
						ㄴ 패스워드 무차별 대입
							ㄴ 무작위로 무수히 많은 id, pw을 시도하여 탈취하는 방법.
							ㄴ 대응 )
								ㄴ 강력한 pw 정책.
									ㄴ 1234, qwer, 이름, id가 포함 등의 단순한 비밀번호 말고
										영문, 특수문자 등을 포함시킨 강력한 비번을 설정하도록.
								ㄴ 로그인 시도 횟수 제한.
						ㄴ 패스워드가 평문으로 노출되는 곳이 없도록.
							비번 찾기는 새 비번으로 변경으로 대체.
						ㄴ 로그인 실패시 메세지 단일화. id, pw 중 어디가 틀렸는지 알려주지 말것.
					ㄴ 암호화
						ㄴ 해시 사용시 솔트(salt) 사용 필수.
							ㄴ 솔트를 사용하지 않을시, 무작위 평문 대입으로 동일한 해시값을 갖는 값을 찾을 수 있다.
						ㄴ 자체 개발 암호화보단 공인 암호화 알고리즘(3DES, SEED, AES 등) 사용.
					ㄴ 프런트 로직은 안전하지 않다.
						프런트 로직에서 암호화, 마스킹 등을 하지 말것. 무조건 백엔드에서 하고 프런트로 전달.
						ㄴ 프런트로 일단 보안처리가 안된 데이터가 넘어오면 상대적으로 매우 취약해짐.
					ㄴ 접근 권한 관련
						ㄴ 접근 권한이 필요한 리소스 접근시, 반드시 권한을 확인하도록.
						ㄴ 특히, 한 프로세스가 여러 페이지로 구성된 경우 유의.
					ㄴ 파일 업로드 관련
						ㄴ 악성 스크립트 업로드
							ㄴ 악성 스크립트가 있는 파일을 게시판 첨부파일, 이미지 파일 등으로 서버에 업로드시켜 스크립트의 악성 명령들을
								실행시키는 방식. 
							ㄴ 실행파일형식은 받지 않도록. 
							ㄴ 파일 형식이 실행파일이 아니더라도 악성 스크립트가 포함될 수 있음. 
							ㄴ 대응 )
								ㄴ 파일 업로드시, 확장자 필터링(.jsp, .asp, .php, .inc ... )
									ㄴ 필터링시, 확장자명을 대소문자 구분없이 처리해야함. .Jsp, .jSp 등으로 우회 방지. 
								ㄴ 컨텐츠 조사 
									ㄴ 확장자 등이 문제 없더라도 악성 내용이 파일에 포함될 수 있음. 
										??? 이런 경우, 파일 내용을 확인하는 방법 밖에 없다? 
										간단하지 않으므로 보통 3rd party 라이브러리 사용한다함. 
								ㄴ??? 이미지인 경우, image rewriting 으로 악성컨텐츠 제거 가능? 
								ㄴ??? Microsoft document인 경우, 'Apache POI' 사용 ㄱ능? 
								ㄴ zip 파일은 업로드 자체를 허용 않는것 권장한다함. 
									어떤 파일이든 포함될 수 있고, 가능한 공격방법이 매우 많아서? 
						ㄴ 대용량 파일 업로드로 Ddos 
							ㄴ 대응 
								ㄴ 웹 서버에 업로드 파일 크기 제한 설정. 
						ㄴ 파일 덮어씌우기 
							ㄴ 대응 
								ㄴ 업로드된 파일명을 그대로 저장하지 않고 고유한 파일명으로 변환하여 저장. 
						ㄴ 파일명 추측하여 파일 조회. 
							ㄴ 대응 
								ㄴ 파일을 웹 루트가 아닌곳에 저장하여 
						ㄴ 이중 파일 확장자 
							ㄴ ex ) ~~~.jpg.php, ~~~.php%00.jpg 
						ㄴ 파일명 유효성 
							ㄴ 파일명에 올 수 없는 문자가 포함되거나 길이가 너무 길거나 등. 
						ㄴ 파일 저장 위치 관련 
							ㄴ 권장사항 
								ㄴ 웹 서비스와 구분된 별도 호스트에 파일저장. 
								ㄴ 또는 웹 루트가 아닌곳에 저장. 
								ㄴ 또는 웹 루트인 경우, read권한 없이 저장. 
							ㄴ 파일저장에 database 이용 
								ㄴ 이점 ) 파일 백업, 파일시스템 관련 보안 해결. 
								ㄴ 단점 ) 성능 이슈, database의 저장소 용량 관련 이슈, sql injection 이슈 발생 가능. 
						ㄴ 대응 
							ㄴ 외부 저장소 서비스 사용시, 이런것들 중 일부 알아서 처리. 
								ㄴ ex ) AWS S3, 등 

					ㄴ 파일 다운로드 관련
						ㄴ 파일 다운 로직에서, 다운받을 파일 경로까지 입력 가능한 경우, 경로를 조작하여 서버의 중요한 파일을 다운받을 수 있는 경우.
					ㄴ 프론트로 넘어갔던 값을 다시 받아와 재사용하는 경우, 변조의 위험이 있다.
					ㄴ 보안상 중요한 프로세스인 경우, 2중 보안 장치 또는 인증 재확인을 추가하여 강화 가능.
						ㄴ 전화번호 인증 추가 또는 비번 재확인 등.
					ㄴ 관리자 페이지는 내부에서만 접근 가능하도록.
						ㄴ ip제한 등. 
					ㄴ clickjacking 
						ㄴ 악의적 사용자가 특정 클릭을 유도하는 방식이라하여 불리는 이름. 
							다른 일반적인 사이트인것처럼 페이지를 만들어두고, 특정 클릭을 유도하여 클릭하면 개인정보다 결재 등을 실행하는 방식. 
							페이지에 iframe으로 다른 사이트를 로드해놓고 투명한 버튼을 그위에 둚으로서 유도하는 등. 
					ㄴ 참조 
						ㄴ https://cheatsheetseries.owasp.org/index.html
				</pre>
				ㄴ 당연히, 무조건 엄격하게 적용해야함은 아님.
					보안이 강할수록 유저 편의성과 trade off인 경우가 있고, 서비스를 고려하여 적절히 결정 필요.

			</pre>

			ㅡ 프로그램에서 개인정보 암호화
				ㄴ 무슨 개인정보보호법에 의거하여,
					ㄴ 유저의 개인정보는 db저장시 암호화하여 저장해야 한다함.
						주민번호, 바이오정보, 비밀번호, 계좌번호, 주민번호, 여권번호, 카드번호, 운전면허번호 등
					ㄴ 비번은 일방향 암호화 해야한다함.
				ㄴ 암호화하여 저장하므로 db에 대한 like검색, 정렬 등은 기본적으로는 불가. 편법사용 필요?
		</pre>

		인코딩<button>펼치기</button>
		<pre>
			ㅡ 문자셋이란? )
				ㄴ 문자를 이진 숫자로 표현하기위해 문자코드표로 약속한게 UTF-8, EUC-KR 같은 문자셋.
				ㄴ A는 65를 나타내는 11011010...어쩌구로 표현하고 이런식으로 약속.
			ㅡ 인코딩,디코딩이란? )
				ㄴ 이 문자표대로 문자를 이진수로 만드는게 인코딩, 그 이진수를 다시 문자로 만드는게 디코딩.
				ㄴ 문자를 비트화하는걸 인코딩, 이를 다시 문자로 바꾸는게 디코딩.
			ㅡ 문자의 깨짐 현상 )
				ㄴ 인코딩은 UTF-8로했는데 디코딩은 ISO-8859-1로 하면 문자가 깨짐.
				ㄴ 이게 웹상에서 데이터를 주고받는 경우에 자주발생하는 문제. 인코딩과 디코딩의 문자셋이 다름.
			ㅡ 웹에서의 문자 인코딩 )
				ㄴ jsp페이지 지시자에서 pageEncoding은 해당 파일을(jsp페이지 같은) 저장하고 꺼내올때 어떤 charset으로 인코딩하고 디코딩할건지를 정해주는 부분.
				ㄴ contentType에서 charset지정하는게 해당 리소스를 보낼때 인코딩할 문자셋을 지정하는 부분.
					ㄴ '이 리소스를 보낼때 해당 문자셋으로 인코딩했다'는걸 알려주기도 하는 부분.
				ㄴ html의 < meta>태그에서 지정하는것도 동일함. contentType에서지정하는게 우선순위가 있는듯함.
				ㄴ ??? 리소스를 받는쪽(가령 브라우저)에서 항상 이 contentType에 나와있는 문자셋으로 디코딩할 것 같고 그게 상식적일것같지만, 실제로 그런지는 모르겠음.
				ㄴ 브라우저에서 해당 jsp파일에서 요청을 보내게되면 contentType에 나와있는 문자셋으로 요청을 인코딩하여 보낸다고함.
				ㄴ 서버에서는 들어온 요청을 어떤 문자셋으로 디코딩할지 정할 수 있으며, GET방식 요청과 POST방식 요청에 대한 디코딩 방식 설정 방법이 다르다. POST는 아래와 같다.
					ㄴ 톰캣같은경우 디폴트로 iso-8859-1?로 디코딩한다함.
					ㄴ 이를 명시적으로 지정하는게 request.setCharacterSet() 메소드이다.
						ㄴ 근데 왜인진모르겟으나 스프링에서 했을땐 안먹힘.계속 iso-8859-1로 디코딩함.
					ㄴ 또다른방법은 웹어플의 web.xml에 < filter>를 선언해주는 것.
						ㄴ ex)
							< filter>
								< filter-name>encodingFilter< /filter-name>
								< filter-class>org.springframework.web.filter.CharacterEncodingFilter< /filter-class>
								< init-param>
									< param-name>encoding< /param-name>
									< param-value>UTF-8< /param-value>
								< /init-param>
							< /filter>
							< filter-mapping>
								< filter-name>encodingFilter< /filter-name>
								< url-pattern>/*< /url-pattern>
							< /filter-mapping>
							ㄴ < filter-mapping>부분도 꼭해주어야한다.
					ㄴ get방식의 요청파라미터 디코딩은 server.xml에서 < Connector>의 속성값으로 URIEncoding= " (*문자셋*) "을 부여하면된다.
						ㄴ get방식은 url에 요청파라미터를 붙이므로 이부분의 문자셋을 지정함으로서 설정가능하다.
			ㅡ 이클립스에서 window - preference - encoding검색 을통해 파일들에 대해 기본 문자셋을 지정할 수 있다.
			ㅡ 다음은 문자가 깨질때 어떻게 깨지게 되었는지 확인할 수 있는 간단한 코드이다.
				ㄴ 이후에 나오는게 원래 어떤 문자셋으로 인코딩 되었었는지를 나태내고 앞서나오는게 그 문자를 다른 어떤 문자셋으로 디코딩해서 문자가 깨지게 되었느지를 나타낸다.
					String kor_str = "ìëíì¸ì";	//깨진문자.

					String[] ary = {"euc-kr","utf-8","iso-8859-1","ksc5601","x-windows-949"};
					for( int i =0 ; i < ary.length; i++){
						for(int j=0; j < ary.length ; j++){
							if( i != j){
							System.out.println( ary[i]+"=>"+ ary[j]+ " \r\n ==> " +new String(kor_str.getBytes(ary[i]),ary[j]));
							}
						}
					}
			ㅡ Base64
				ㄴ 바이너리와 텍스트 사이의 인코딩 방식.
					즉, 0, 1로 이루어진 이진 데이터를 문자기호로 인코딩 하는 것.
				ㄴ 이진 데이터를 6 bit씩 잘라서 문자와 매핑시켜 인코딩함.
					ㄴ 6bit로 표현 가능한 가지수가 64개. 하여 base64.
				ㄴ ex )
					이진데이터가 다음과 같을때,
					0	1	0	0	1	1	0	1	0	1	1	0	0	0	0	1	0	1	1	0	1	1	1	0
					6 bit씩 묶으면,
					010011	010110	000101	101110
					이를 base64의 문자와 매핑하여 인코딩하면
					TWFu
					즉, 이진데이터가 'TWFu'라는 문자로 인코딩된다.
				ㄴ 인코딩표 참조 : https://en.wikipedia.org/wiki/Base64

		</pre>

		자료구조, 알고리즘<button>펼치기</button>
		<pre>
			ㅇ 자료구조란 ?
				ㅡ 데이터에 대한 처리를 효율적으로 하기위해서, 데이터들의 조직화, 구조화한 방식을 말함.
			* 자료구조와 알고리즘은 강한 연관성을 가진다.

			ㅇ 알고리즘
				ㅡ 책 '종만북'에선, 알고리즘 문제 해결 단계가 다음과 같다고 한다
					1. 문제를 이해한다
						ㄴ 급한 마음에 대충 보지 말고 문제를 정확하게 이해하는 것이 중요. 시작 단추이기 때문에 잘못 됐을 때 대가가 크다.
					2. 문제를 익숙한 용어로 재정의한다
						ㄴ ???
					3. 어떻게 해결할지 계획을 세운다
						ㄴ 어떻게 해결할지, 어떤 알고리즘, 자료구조를 사용할지 등을 결정.
					4. 계획을 검증한다
						ㄴ 3번에서 생각한 방법이 문제의 조건을 모두 만족하는지 증명하고 시간과 메모리를 고려.
					5. 프로그램으로 구현한다
						ㄴ 고안한 알고리즘을 정확히 구현.
					6. 어떻게 풀었는지 돌아보고, 개선할 방법이 있는지 찾아본다.
						ㄴ 해당 문제엔 영향이 없지만 장기적으로 가장 중요하다함.
							풀때 당시의 사고 과정을 되돌하보며 피드백하거나 다시 풀어보는 것을 통해 배울 수 있는 것들이 많다.
							또는 타인의 코드를 보고 배울 수 있는 부분이 있다.
				ㅡ 문제 해결 방법 떠올리기
					ㄴ 해결할만한 문제의 경우 '직관'적으로 어떤 방식으로 풀어야 겠다는게 떠오른다.
					ㄴ 이게 아닌 어렵고 막막한 경우 다음의 질문들을 통해 방법을 떠올리는데 도움을 받을 수 있다
						ㄴ 비슷한 문제 푼적 있었는지
						ㄴ 단순한 방법으로 시작 가능한지
							ㄴ 이 질문을 통해, 단순하게 풀 수 있음에도 복잡하게 생각하여 막히는 경우를 해결할 수 있다.
							ㄴ 또는 해답 알고리즘이 근본적으로는 단순한 방법에 기반을 두고, 이 위에 최적화나 적절한 자료구조 선택 정도만
								필요로 하는 경우일 수 있다. (단순한 방법에서 점진적 개선하는 것)
							ㄴ 알고리즘 효율성의 기준선을 잡는데 도움을 줄 수 있다. 가장 단순한 방법이니 이를 효율성의 기준선으로 잡는 것.
						ㄴ ??? 문제를 푸는 과정을 수식화할 수 있을까?
						ㄴ 문제를 단순화시킬 수 있나?
							ㄴ 원래 문제를 좀 더 단순한 형태로 변경하여 풀어보고 이 단순화된 형태의 풀이 방식이 원래 문제 풀이법에 대한
								영감을 줄 수 있다.
							ㄴ 단순화를 어떤식으로 할지는 문제마다 잘 생각해 적용해 봐야 한다.
								조건을 일부 없애보거나 변수를 줄여보거나 다차원을 1차원으로 줄여보거나 표현을 단순화해보거나 등.
								좀 추상적이긴 하다.
						ㄴ 그림을 그려볼 수 있나
							ㄴ 문제와 관련된 내용을 그림으로 그려보아 직관을 얻을 수 있는 경우가 있다.
						ㄴ 수식으로 표현할 수 있나
							ㄴ 문제와 관련된 내용을 수학적 수식으로 표현해보아 직관을 얻을 수도 있다.
						ㄴ ??? 문제를 분해할 수 있나?
						ㄴ 뒤에서부터 생각해서 문제를 풀 수 있나?
							ㄴ ~~~
						ㄴ 순서를 강제할 수 있나?
							ㄴ ~~~
						ㄴ 특정 형태의 답만을 고려할 수 있나?
							ㄴ ~~~
				ㅡ 알고리즘 문제 풀이시, 코딩 팁
					ㄴ 코드를 간결하게
					ㄴ 중복되는 코드는 모듈화하여 재사용
					ㄴ 표준 라이브러리 사용
					ㄴ 명료한 변수명
					ㄴ 자료를 일관된 형태로 사용. ex ) 날짜는 iso로, 문자열은 utf-8 인코딩으로 등.
				ㅡ 알고리즘 문제 풀이시, 자주하는 실수
					ㄴ 산술 오버플로우. 변수의 표현 범위를 벗어나는 것.
					ㄴ 배열 out of index
					ㄴ 일관되지 않은 범위 표현 방식.
						ㄴ 가령 substring( 2, 6 ) 라치면, 잘려나오는 문자열의 인덱스는
							2 < i < 6 인지,
							2 <= i < 6 인지,
							2 <= i <= 6 인지 등.
						ㄴ 프로그램 내에서 이를 일관되게 표현하여야 헷갈리지 않아 buggy하지 않다.
						ㄴ 선택에 팁을 주자면..
							첫번째 방식은 처음과 마지막 idx를 포함시키려면 idx범위를 벗어나는 가상의 idx를 범위값으로 사용해야한다는 단점.
							ex ) len(arr)=10인 arr의 idx 0~9까지를 표현하려면, -1 < idx < 10 으로 표현해야함.
							세번째 방식은 공집합 표현이 어렵다는 단점.
							ex ) len(arr)=10인 arr에 대해 범위로 공집합을 표현이 어렵. 0 <= idx <= 0 이라 쳐도 0이 포함되므로.
							두번째 방식 추천?
					ㄴ off-by-one 오류?
						ㄴ 계산에서 하나를 빼먹거나 하나를 잘못 추가하는 경우.
							ex ) arr[i] ~ arr[j] 사이의 평균값 구한다칠때, 몇으로 나누나? j-i 가 아닌 j-i+1
								길이 100미터인 담장에 10미터 간격으로 기둥 박을 때 필요한 기둥 개수? 10개 아닌 11개.
					ㄴ 상수 오타
						ㄴ 문자열 잘못 쓰거나, 사용되는 상수 숫자를 잘못 입력하거나.
					ㄴ 스택 오버플로우
					ㄴ 다차원 배열 인덱스 실수
					ㄴ ??? 잘못된 비교 함수 작성
					ㄴ 최대, 최소 범위에서의 예외 케이스 놓침.
					ㄴ 연산자 우선순위 실수.
					ㄴ 느린 입출력 방식 사용.
					ㄴ 변수 초기화 안함.
					ㄴ ~~~

				ㅡ 수행 시간 측정
					ㄴ 같은 알고리즘이어도 입력값에 따라 환경에 따라 수행시간이 다름을 고려해야함.
						ㄴ 시간복잡도 O()는 최고차항을 제외한 나머지를 모두 제거한 것이므로 실제 수행시간은 제거된 항들도 모두 고려해야함
						ㄴ 반복문 내부가 복잡한 경우, 수행시간이 생각보다 늘어남
						ㄴ 메모리 사용 패턴???
						ㄴ 언어와 컴파일러 차이
						ㄴ 구형 컴퓨터
					ㄴ 대략 좀 보수적으로, O() 시간복잡도가 1억을 넘으면 실패한다고 본다고함.

				ㅡ P, NP, NP-완비 ???
					ㄴ ~~~

				ㅡ 정당성 증명 )
					ㄴ ~~~

				ㅡ 패러다임 
					ㄴ ??? 알고리즘, 즉, 문제를 해결하는 방법의 기저에 깔린 큰 틀에서의 전략, 패턴, 틀? 
						즉 문제를 해결하기 위한 방법(알고리즘)들이 특징적?으로 어떤 방식의 전략을 사용하는지를 분류하고 모델링한 것? 
						어떤 한 문제 해결 방식이 본질적으로 모든 케이스를 다 시도해보고 정답을 찾는 방식이더라(brute-force), 
						어떤 문제해결 방식들이 본질적으로 문제를 더 쉽게 해결할 수 있는 작은 단위의 문제들로 끊임없이 분리하고 이를 해결한 뒤 다시 합쳐서 
						최종 문제를 해결하는 방식이더라(divide-and-conquer) 등등. 이런식..? 
						문제해결 방식들을 추상적으로 분류한 느낌? 디자인 패턴처럼? 
						ㄴ ??? 알고리즘이 정확히 어느 패러다임에 속하는지는 중요하지 않다? 
							그냥 틀이기 때문에 이 틀을 사용하여 문제를 해결하는 알고리즘을 생각해내는게 중요하다? 
					ㄴ 종류 
						ㄴ 무식하게 풀기 
							ㄴ 경우를 일일이 나열하면서 답을 찾는 방식. '완전탐색' 이라고도 불림.
							ㄴ 가장 단순한 해결책으로 컴퓨터의 속도가 빠르다는 것으로 문제를 푸는 것.
							ㄴ 재귀 호출 
								ㄴ 기본 내용은 아는 그 재귀함수.
								ㄴ 내용에 더이상 쪼개지지 않는 최소 단위 작업 존재. (기저 사례, base case)
									n = 1인 경우 처리 등.
								ㄴ 반복문처럼 같은 로직을 반복하는 것이라 볼 수 있다. 이를 자기 자신을 호출하는 형태로 수행할뿐.
									경우에 따라 반복문보다 깔끔한 방식으로 로직 반복하는 코드 작성이 가능.
								ㄴ 완전 탐색 구현에 효과적.
								ㄴ 완전탐색이므로 시간복잡도는 가능한 모든 케이스의 최대값.
							ㄴ 최적화 문제에서의 완전탐색 
								ㄴ 최적화 문제란
									ㄴ 답이 하나가 아닌 여러개이고, 그 중 특정 기준에 따라 가장 '좋은' 답을 찾는 문제를 말함.
								ㄴ 완전탐색으로 최적화 문제를 풀 수있다. 모든 케이스를 확인하여 가장 '좋은' 것을 선택하면 되기 때문.
									물론, 시간복잡도는 따져보아야함.
							ㄴ 자주 나오는 패턴
								ㄴ 다음은 코딩 문제에서 완전탐색과 관련하여 자주 나오는 패턴이다.
									문제의 직접적 해결책은 아니더라도 부분문제로서도 자주 나온다 한다.
								ㄴ 모든 순열 만들기.
									ㄴ 주어진 원소를 가지고 가능한 모든 순열을 생성하여 풀 수 있는 문제.
								ㄴ 모든 조합 만들기
									ㄴ 주어진 원소를 가지고 서로 다른 모든 조합을 생성하여 풀 수 있는 문제.
						ㄴ 분할 정복 
							ㄴ 문제를 더 작은 단위의 문제로 나누고, 이 나누어진 문제를 해결한 뒤, 다시 합쳐서 원래의 문제를 해결하는 방식. 
							ㄴ ex )
								ㄴ 
							ㄴ 나누어진 문제가 중복되지 않는지 유의 필요. 
								중복되는 경우, 같은 값을 여러번 계산하므로 성능상 이슈 등 이슈가 될수 있다. 
								ㄴ ex ) 
							ㄴ 알고리즘 종류 
								ㄴ 병합 정렬
								ㄴ 퀵정렬 
								ㄴ 카라츠바 
									ㄴ 매우 큰 두 정수의 곱을 구하는 알고리즘. 
									ㄴ ??? ~~~ 이해안감. 
									ㄴ 일반적으론, 두 정수 곱할때, 초딩때 배운것처럼 각 자릿수를 한자리씩 밀어서 곱셈계산 후 모두 더하는식으로 계산하는 방식을
										알고리즘으로 사용하는데 시간복잡도가 O(n^2) 
										하여 나온게 카라츠바 알고리즘. 
										두 정수의 곱을 할때, 각 정수를 자릿수기준으로 둘로 나눈 뒤, (1234 * 5678이라하면, 1234를 자릿수 기준 둘로 나누면 
										12 * 10^2 와 34 로 나뉨. 5678도 마찬가지)
										이 나눈 두 정수를 곱하고 식을 정리하면, 
										1234 * 5678 = (12*10^2+34) * (56*10^2+78) = 12*56*10^4 + (12*78+34*56)*10^2 + 34*78 
										즉, 나뉜 자릿수들이 서로 4번 곱해지는 식으로 분할됨. 이런식으로 분할정복법 적용하여 계산하는게 알고리즘의 바탕이되는 방식
										이렇게 그냥 계산하면 시간복잡도는 동일하게 O(n^2). 
										카라츠바 알고리즘은 여기서 한 특징을 발견하고 이를 적용하여 시간복잡도를 이보다 작게함. 
										발견한 특징이란, ~~~???  



			ㅇ 복잡도
				ㅡ 시간복잡도 : 프로그램이 실행될때 필요한 실행문의 실행횟수.
					ㄴ 실행문마다 실행시간이 다르므로 정확하게 예측하기가 어려움. 그래서 나온게 대락적인 수행시간을 예측하는 '점근 표기법'
					ㄴ 점근 표기법 )
						ㄴ 실행문의 수행시간을 정확하게 예측하는것이 아니라 대략적인 예측만 하는 방법.
						ㄴ '빅오', '오메가', '세타' 방식이 잇다.
						ㄴ 빅오 표기법 ) 실행시간의 최악의 경우. 즉 가장 오래걸리는 경우를 측정하는 방법. ex) O(n), O(logn)
						ㄴ 오메가 ) 실행시간이 가장 적게 걸리는 경우를 측정. ex) Ω(n)
						ㄴ 세타 ) 실행시간이 어떤 범위안에 있는지를 측정. ex) Θ(n)
					ㄴ 빅오 표기법 )
						ㄴ 가장 많이 쓰이는 점근표기법.
						ㄴ 대표적 빅오 함수와 이들의 실행시간 차이)
							ㄴ O(1) > O(log n) > O(n) > O(n^2) > O(n^3) > O(2^n)
				ㅡ 공간복잡도 : 필요한 공간의 크기.
			ㅇ 성능 평가
				ㅡ 성능 분석 : 사전예측. 시간복잡도와 공간복잡도가 있다.
				ㅡ 성능 측정 : 사후검사.
			ㅇ ADT, 추상 자료형
				ㅡ 일종의 수학적, 논리적 모델이다.
				ㅡ 이 자료형이 어떻게 동작하는지, 의미적인, 기능적인 측면에서 정의된다. 구체적인 구현방법이 아니라.
				ㅡ 스텍, 큐, 트리, 등등을 말한다.
				ㅡ data structure와 비교된다.
					ㄴ data structure은 자료구조란 의미니까 일반적으론 스텍, 큐 등의 ADT까지 다 포함해서 사용하고있기는 한데
					ㄴ 배열, 연결리스트, 객체 등과 같이 실제로 데이터를 저장하는 구현체를 말하고
					ㄴ 이것들을 기반으로 ADT가 구현된다.
			ㅇ 스택
				ㅡ 한쪽 끝에서 삽입과 삭제가 일어나는 리스트.
			ㅇ 큐
				ㅡ 한쪽끝에서 삽입, 다른쪽 끝에서 삭제가 일어나는 리스트.
				ㅡ 구현 )
					ㄴ 선형인 '단순큐'는 끝에 도달하면 더이상 사용이 안되므로 '원형큐'를 사용한다.
					ㄴ 배열로 구현할경우, 배열의 최대 인덱스에 도달하면 다시 처음인덱스로 설정해줌으로서 원형큐구현.
			ㅇ 연결 리스트, 배열<button>more</button>
			<pre>
				ㅡ 연결리스트
					ㅡ 포인터를 사용하여 리스트를 표현한것.
					ㅡ 노드가 데이터와 다음 노드를 가리키는 포인터로 이루어져있다.
					ㅡ 시간복잡도 )
						ㄴ 삽입과 삭제가 포인터의 값만 변경해주면 되므로 상수시간복잡도가 걸린다.
						ㄴ 임의 노드 접근시 배열과 같이 인덱스가 없고 순차접근해야 하므로 O(n)을 가진다.
							ㄴ 따라서 맨 끝 노드 뒤에 노드 삽입 등의 경우, 맨 끝 노드 접근에 O(n), 삽입에 O(1)이 걸리는셈.
					ㅡ 구현 )
						ㄴ 노드를 나타내는 클래스가 있고, 첫번째 노드클래스를 가리키는 포인터를 가지는 클래스를 만들면 이게 연결리스트 클래스가 된다.
							ㄴ ex)
								class Node{
									char data;
									Node *nextNode;
								}
								class LinkedList{
									Node *firstNode;
									~~~	=>연결리스트 조작 메소드들
								}
								ㄴ 마지막을 가리키는 포인터를 추가하여 삽입등의 리스트 조작이 용이하게한다.
				ㅡ 배열
					ㄴ ~~~
					ㄴ 시간복잡도 )
						ㄴ 삽입,삭제시, 삽입,삭제하려는 위치가 맨 끝이고 공간이 남아있다면 O(1)
							맨 끝이 아니라면 원소를 한칸씩 움직여야하므로 O(n)
						ㄴ 임의 노드 접근은 인덱스가 있으므로 O(1)
				ㅡ 배열 vs 연결리스트 )
					ㄴ 시간복잡도로부터 성능상
						삽입, 삭제가 빈번하면 연결리스트, 원소 접근이 빈번하면 배열이 유리함을 알 수 있다.
			</pre>

			ㅇ 그래프 graph<button>펼치기</button>
			<pre>
				ㅡ 일반적인 그래프 <button>펼치기</button>
				<pre>
					ㅡ 개요 )
						ㄴ 한 노드와 이 노드와 연결된 간선으로 이루어진 자료구조.
						ㄴ 연결돼있는 객체간의 관계를 표현 할수있는 자료구조이다.
						ㄴ 정점(vertex)와 간선(edge)들의 유한집합.
					ㅡ 무방향 그래프, 방향 그래프
						ㄴ 간선이 방향을 가지고있는걸 방향그래프, 없는걸 무방향 그래프라고 한다.
						ㄴ 표현 )
							ㄴ 무방향 그래프의 간선 : ex) (0,1), (1,2)		=>정점 0과1을 잇는 간선, 정점 1과2를 잇는 간선
							ㄴ 방향 그래프의 간선 : ex) <0,1>, <1,0>	=>정점 0에서1로의 방향인 간선, 정점 1에서 0으로의 방향인 간선.
					ㅡ 일반적으로 그래프는 자기자신과연결된 간선이나 두 정점 사이의 여러개의 중복된 간선의 경우는 다루지 않는다.
					ㅡ n개의 정점을 갖는 무방향 그래프에서 간선의 최대개수 : n(n-1)/2
					ㅡ 완전그래프 : 최대개수의 간선을 가지는 그래프.
					ㅡ 인접과 부속 )
						ㄴ 간선 (u,v)가 있으면, u와 v는 '인접한다(adjacent)'라고 하며, 간선 (u,v)는 정점 u,v에 '부속된다(incidnet)'고 한다.
						ㄴ 방향그래프의 경우, < u,v>일때, u는 v에 인접한다고하고 v는 u로부터 인접한다고 한다. 부속된다는 동일.
					ㅡ 부분그래프 )
						ㄴ 어떤 그래프의 간선과 정점들 중 일부로 이루어진 그래프.
							ㄴ 부분 그래프의 정점과 간선이 원래 그래프 안에 포함되기만 하면 된다.
						ㄴ <img src="image/부분그래프.png" height="300px" width="auto"/>
					ㅡ 경로 Path )
						ㄴ 그래프상에 정점들을 잇는 간선들이 쭉연결되어있을때 이 간선들을 하나의 '경로'라고 한다.
						ㄴ 종류 )
							ㄴ 단순 경로 : 처음과 마지막 정점을 제외한 정점들이 서로 다른 경로.
								(간단히, 처음과 마지막을 제외하고는 한번갔던 정점을 다시 안가는 경로)
							ㄴ 싸이클 : '단순 경로' 중 처음과 마지막이 같은 경로
					ㅡ 연결 그래프 )
						ㄴ '무방향 그래프'에서 정점 u로부터 v까지의 '경로'가 있으면, u와 v는 '연결되었다'고 한다.
						ㄴ 그래프가 임의의 두 정점 사이에 '경로'가 존재하면 이 그래프를 '연결그래프'라 한다.
							(간단히 말해, 모든 정점이 연결되어있는 그래프)
					ㅡ 연결 요소 : '무방향 그래프'에서 최대로 연결된 '부분 그래프'
					ㅡ 강력 연결 : '방향 그래프'에서 두 정점 u,v에 대해 < u,v>, < v,u> 경로가 모두 있으면 u와 v는 '강력 연결되었다'고 한다.
					ㅡ 강력 연결 그래프 : '방향 그래프'에서 임의의 두 정점이 '강력연결'되어있다면 이 그래프를 '강력 연결 그래프'라 한다.
					ㅡ 강력 연결 요소 : '방향그래프'에서 최대로 '강력 연결된' '부분 그래프'
					ㅡ 정점의 차수 )
						ㄴ 정점에 '부속'한 간선들의 수
						ㄴ '방향 그래프'에서는 '진입차수(indegree)'와 '진출 차수(outdegree)'로 부름.
						ㄴ 총 간선의 수를 e라 할때, '모든 정점의 차수의 합'은 2*e이다.
					ㅡ 그래프 표현법 )
						ㄴ 인접행렬 )
							ㄴ 그래프를 n x n의 이차원 배열로 나타내는 방식.
							ㄴ <img src="image/자료구조_그래프_인접행렬.png" height="326"/>
								ㄴ 행과 열 각각은 정점들을 나타내며, 두 정점 사이에 간선이 있으면 배열의 값을 1로 표현, 없으면 0으로 표현하는 식.
							ㄴ 무방향 그래프는 대각선을 기준으로 대칭을 띄게됨.
							ㄴ 방향 그래프에선 arr[i][j] 라 하면, i가 출발정점, j가 도착정점을 나타낸다.
							ㄴ 무방향 그래프에서, 한 행 또는 열의 값을 모두 더한건 그 행 또는 열에 해당하는 정점의 차수를 의미한다.
							ㄴ 방향 그래프에선 한 행의 값을 모두 더한건 그 행에 해당하는 정점의 진출차수, 한 열의 값을 모두 더한건 그 열에 해당하는 정점의 진입차수를
								의미한다.
						ㄴ 인접 리스트 )
							ㄴ 연결 리스트를 이용해 표현하는 방식.
							<img src="image/자료구조_그래프_인접리스트.jpeg" height="300px" width="auto"/>
								ㄴ 정점이 n개면 n크기의 리스트 배열을 만들고 각 정점에 연결된 정점들을 리스트에 추가하는 식.
								ㄴ 한 정점에 연결된 정점들을 리스트에 추가할때 순서는 상관 없다.
								ㄴ 인접행렬과 달리 간선이 없는 경우에 대해 공간을 낭비하지 않음.
							ㄴ 무방향 그래프일 경우 추가된 노드의 개수는 2*e개이다. (e는 간선의 개수)
						ㄴ 비교 )
							ㄴ 인접행렬을 사용하게되면 행렬 내의 n^2-n개의 모든 항들을 조사해야하므로 O(n^2)이다.
							ㄴ 인접리스트의 경우 n개의 헤드노드와 2e개의 리스트노드를 조사하므로 O(n+e)이다. (e는 간선 수)
					ㅡ  가중치 그래프
						ㄴ 간선에 '비용이나 가중치'를 부여한 '그래프'
						ㄴ 표현 방법 )
							ㄴ 인접행렬 : 배열의 값에 1대신 '가중치' 값을 사용하므로서 표현.
							ㄴ 인접 리스트 : 각 노드에 '가중치'를 나타내는 프로퍼티 추가.
					ㅡ 그래프의 탐색 )<button>펼치기</button>
					<pre>
						ㄴ '연결 그래프'에 대해 모든 정점을 조회하며 탐색하는 방법으로, 대표적으로 DFS, BFS가 있다.
						ㄴ 깊이 우선 탐색, DFS, Depth first search )
							ㄴ 개요 )
								ㄴ 인접한 정점 중 방문이 안된 정점으로 계속 방문하며 깊게 들어감. 모든 인접한 정점이 방문되어 있으면 되돌아감.
									이를 반복하다가 출발정점으로 되돌아가게되면 모두 방문한것.
							ㄴ 구현 )
								ㄴ 정점이 방문되었는지 아닌지를 확인해주는데 쓰이는 방문확인배열을 하나 두고,
								ㄴ DFS함수를 한 정점을 인자로 넘겨 호출하면, 그 정점을 방문확인배열에서 방문함으로 변경하고, 그 정점의 인접한 정점들에 대해
									방문이 안되어있으면 재귀함수(DFS함수)를 호출.
								ㄴ 그러면 인접정점들중 방문 안된 정점으로 가서 거기서 또 방문안된 정점으로 들어가는 식으로 깊게들어가며 탐색을 함. 방문안된
									인접정점이  없으면 그 정점에 대한 DFS재귀함수가 종료되며 다음 인접정점중 방문안된 정점으로 DFS해서 들어감.
									이렇게 계속하다가 처음 시작한 정점에 대한 DFS함수가 종료되면 깊이우선탐색이 끝난것.
								ㄴ ex)
									void Graph::DFS(){
										visited = new bool[n];

										for(int i=0; i< n; i++){
											DFS(0);
											delete[] visited;
										}
									}
									void Graph::DFS(const int v){
										visited[v]=true;
										for(v에 인접한 각 정점w에 대해){
											if(!visited[w]) DFS(w);
										}
									}
							ㄴ 시간복잡도 )
								ㄴ 인접리스트 사용시 : ('정점'이 아닌) '리스트 노드'를 한번씩 조사해야하고, 리스트 노드의 수는 2*e이므로 O(e)
								ㄴ 인접행렬 사용시 : 한 정점에 대한 인접정점들 조사를 위해서 O(n)이 필요하므로 전체 정점에 대해 조사하면 O(n^2)가 된다.
						ㄴ 너비 우선 탐색, BFS, Breadth First Search
							ㄴ 정점하나 방문하고 그 정점과 인접한 정점들 중 방문이 안된 것 모두 방문. 그리고 모두 큐에 삽입. 그 다음 큐에서 하나 삭제한 후
								삭제된 정점에 대해 같은 과정을 반복. 방문 안된 인접정점이 없으면 그냥 삭제. 큐가 비게되면 탐색 종료.
							ㄴ 구현 )
								ㄴ 정점이 방문되었는지를 확인하는 방문확인배열을 만들고
								ㄴ ~~~
							ㄴ 시간복잡도 )
								ㄴ DFS와 동일.
					</pre>
					ㅡ 탐색을 이용한 연결 요소 찾기)
						ㄴ DFS나 BFS는 연결된 정점들을 따라서 탐색하므로 이를 사용하여 '연결요소'들을 찾는것.
						ㄴ 연결요소 찾는 알고리즘 )
							ㄴ 그래프의 모든 정점에 반복, 그 정점이 방문이 안되었으면 DFS나 BFS를 호출.
							ㄴ 시간복잡도 )
								ㄴ 인접 리스트 사용시 : 탐색에서 모든 노드를 한번씩 방문하므로 O(e),
									거기다가 모든 정점에 대해 반복하므로 O(n)을 더하여 O(n+e)
								ㄴ 인접 행렬 사용시 : O(n^2)
					ㅡ 신장 트리 )<button>펼치기</button>
					<pre>
						ㄴ 개요)
							ㄴ '연결 그래프' 중에서 '모든 정점을 포함'하면서, '트리'인 '부분 그래프'
							<img src="image/자료구조_그래프_신장트리.png" height="300px" width="auto"/>
							ㄴ DFS또는  BFS로 탐색하는 '과정 중에서', 정점v에서 인접하며 방문되지 않은 정점w가 있을때,
								간선(v,w)의 집합이 신장트리의 경로이다.
								ㄴ 따라서 DFS를 이용한 신장트리와 BFS를 이용한 신장트리가 따로잇다.
							ㄴ 사용 )
								ㄴ 최단 경로 탐색, 최소 가중치 경로 탐색, 싸이클 없는 경로 탐색 등.
						ㄴ 최소비용 신장 트리, MST, minimum cost spanning tree )<button>more</button>
						<pre>
							ㄴ 개요 )
								ㄴ '가중치 무방향 그래프'에서 '신장트리의 비용'은 신장 트리에 포함된 '간선들의 비용의 총합'이며,
									'최소비용 신장 트리'는
									최소의 '신장트리의 비용'을 가지는 신장트리이다.
								ㄴ 그래프 내의 간선들만 사용해야 한다.
								ㄴ n-1개의 간선만을 포함해야 한다.
								ㄴ '사이클'을 포함하지 않는다. (트리이기때문)
							ㄴ MST를 구하는 알고리즘 )
								ㄴ Kruskal, Prim, Sollin 알고리즘이 있다.
								ㄴ 증명은 패쓰. 똑똑하신분들이 귀납적으로 증명하여 이 알고리즘을 사용하면 MST가 나온다고 알려주심.
								ㄴ Kruskal 알고리즘 (크루스칼)
									ㄴ 방법 )
										ㄴ 그래프의 모든 간선들 중에서 가장 비용이 작은 간선순서로 선택. 그 선택된 간선이 이미 저장된 간선들과
											'사이클'을 형성하지 않으면 저장, 형성하면 버리고 다음 간선 선택.
										ㄴ 위 과정을 더이상 선택할 간선이 없어질때까지나, 저장된 간선의 수가 n-1개이면 break.(n은 노드수)
										ㄴ MST완성.
									ㄴ 위키에 나온 수도 코드 )
										algorithm Kruskal(G) is
											F:= ∅
											for each v ∈ G.V do  // 모든 정점에 대해, 각 정점을 set으로서 만듦.
												MAKE-SET(v)
											for each (u, v) in G.E ordered by weight(u, v), increasing do  // 모든 간선에 대해,
												// 간선 양 끝 정점이 속한 set을 찾고, 이들이 같은 set임을 확인(싸이클을 형성하는지 확인하는 것)
												if FIND-SET(u) ≠ FIND-SET(v) then
													// 같은 set에 속하지 않다면 두 set을 합집합. (해당 간선을 MST에 포함시키는 것)
													F:= F ∪ {(u, v)} ∪ {(v, u)}
													UNION(FIND-SET(u), FIND-SET(v))
											return F
									ㄴ ??? 시간 복잡도 )
										ㄴ 간선 수 E, 정점 수 V라 할 때.
										ㄴ 일단 간선들을 가중치에 따라 정렬. O(E*logE)
										ㄴ 정점들을 각각의 set으로 만듦. O(V)
										ㄴ ??? 모든 간선들에 대해 set 탐색 연산 및 합집합 연산.
										ㄴ 결과적으로, O(E*logE) 또는 O(E*logV)

								ㄴ Prim 알고리즘 (프림) )
									ㄴ 방법 )
										ㄴ 크루스칼과 비교하면, 프림알고리즘은 처음 선택할때부터 '사이클'을 형성하지 않는 것들만 선택하는 방식.
										ㄴ 그래프의 간선들중에서 이미 저장된 간선들과 '사이클'을 형성하지 않으면서, 가장 비용이 작은 간선을 저장.
											ㄴ 저장된 간선들의 정점 집합을 하나 두어서, 어떤 간선
										ㄴ 위 과정을 n-1개의 간선이 저장될 때까지 반복.
									ㄴ 시간 복잡도 )
										ㄴ 그래프에 사용되는 데이터 구조와 간선 가중치 정렬에 사용되는 데이터 구조에 따라 달라진다.
										ㄴ 위키에 따르면..
											ㄴ 인접행렬, 단순 선형 탐색 사용시, O(v^2)
											ㄴ 인접리스트, binary heap 사용시, O(E*logV)
											ㄴ 인접리스트, 피보나치 힙 사용시, O(E + V*logV)
										ㄴ ???
						</pre>
					</pre>

					ㅡ 최단 경로 )<button>펼치기</button>
					<pre>
						ㄴ 가중치 그래프, 방향 그래프인 경우에 한 정점에서 다른 정점으로 가는 경로의 가중치가 최소로 되는 경로를 말함.
						ㄴ 두가지 유형이 있다.
							ㄴ 단일 출발점으로부터 모든 종점까지의 최단경로를 구하는 것. (단, 간선의 길이가 '양수'이어야 한다)
							ㄴ 모든 정점쌍의 최단경로를 다 구하는 것.
								ㄴ 첫번째 유형구하는 방식으로도 구할 수 있으나 다른 더 효율적인 방법이 있다.
						ㄴ 단일 출발점, 모든 종점 )
							ㄴ Dijkstra 알고리즘 )
								ㄴ 개요 )
									ㄴ '방향 그래프'이면서, '가중치'가 양수인 '가중치 그래프'에서 단일 출발정점으로부터 모든 종점까지의
										최단경로 비용을 구하는 알고리즘.
								ㄴ 구현 )
									ㄴ1. '방향 그래프'를 인접행렬로 나타낸다. 경로가 없는 경우는 '무한대'를 의미하는 충분히 큰값으로 나타낸다.
										자기자신과의 경로부분은 0으로 나타낸다.
									ㄴ2. 출발정점v로부터 모든 정점 사이의 최단거리비용을 나타내는 배열 dist[]를 만든다.
										dist[w]는 v로부터 w로 가는 최단거리 비용을 나타낸다.
									ㄴ3. 출발정점v로부터의 최단경로 비용을 구한 정점의 집합 S를 만든다.
										S에 속하는 정점은 v로부터 해당정점까지의 최단거리 비용을 구한 정점이다.
									ㄴ4. 맨 처음 dist[]의 값은 출발정점v에서 각 정점과 연결된 경로들의 가중치이다.
									ㄴ5. 그다음 dist[]에서 가장 작은 값을 선택하고 그에 해당하는 정점(u라 가정)을 S에 넣는다.
										(v와 u사이의 최단 경로 비용을 확정지음)
									ㄴ6. dist[]의 나머지 값들을 갱신한다.
										ㄴ S에 속하지 않은 정점(x라 가정)들에 대해, '기존 dist[x]값'과 'v->u 가중치 + u->x 가중치'를
											비교하여 더 작은 값으로 dist[x]를 갱신.
									ㄴ7. S에 모든 정점이 포함될 때까지 5,6번을 반복.
								ㄴ 최단 경로 구하기 )
									ㄴ path[]을 하나 만들어서, 위 6단계에서 dist[]를 갱신시마다, dist[x]에 u값을 넣는다.
									ㄴ path[]를 역추적하여 정점a->b로 가는 최단경로를 구한다.
										ㄴ ex ) 정점 0 -> 1 의 최단경로
												path[] = 0, 4, 0, 0, 3, 0 이라 하면,
												우선 최단경로에 1 추가,
												path[1] = 4, 최단경로에 4 추가,
												path[4] = 3, 최단경로에 3 추가,
												path[3] = 0  최단경로에 0 추가, 최단경로에 추가된 값들은 1 4 3 0. 이를 역순을 하면
																최단경로가 된다. 0 -> 3 -> 4 -> 1
								ㄴ 시간복잡도 )
									ㄴ 위 과정에서,
										5,6번 반복이 n-1번 반복,
										5번에서 dist[]에서 가장 작은 값 탐색이 최대 n + 6번에서 정점들에 대해 가중치 비교 및 갱신이 최대 n
										따라서 O( (n-1) * (n + n) ) = O(n^2)

						ㄴ 모든 쌍들의 최단경로 )
							ㄴ 일단 방법 2가지 존재
								ㄴ Dijkstra를 모든 정점에 대해 적용(n번 적용)
								ㄴ Ford 알고리즘
							ㄴ 둘다 O(n^3)
								단, 실제론 Ford가 훨씬 빠르다함.
							ㄴ Ford 알고리즘 )
								ㄴ 기본 원리
									ㄴ 그래프상에서 임의의 i, j정점에 대해,
										i, j 사이의 최단경로가 있다하면, 그 최단 경로 위에 있는 정점 k에 대해,
										최단경로의 i에서 k까지의 경로와 k에서 j까지의 경로도 마찬가지로 최단경로이어야 한다는 것.
										아니라면 i,j최단경로는 최단경로가 아닐 것이기 때문에.
								ㄴ ??? ~~~
					</pre>

				</pre>

				ㅡ 트리<button>펼치기</button>
				<pre>
					<img src="image/자료구조_트리.jpeg" height="300px" width="auto"/>
					ㅡ 개요 )
						ㄴ '그래프'의 일종.
						ㄴ 정의, 특징 )
							ㄴ 그래프에서, 임의의 두 정점이 딱 하나의 간선에 의해서만 연결된 그래프.
							ㄴ 즉, 연결 그래프이면서 싸이클을 형성하지 않는 그래프
							ㄴ 배열, 리스트, 스택 등의 선형 자료구조가 아닌 '비선형' 자료구조이다.
							ㄴ '싸이클'이 있어선 안된다.
							ㄴ 부모 노드가 2개 이상이어선 안된다. 즉, 여러노드가 한노드를 가리킬 수 없다.
							ㄴ 노드들이 모두연결되어 있어야 한다.
						ㄴ 보통 계층적인 관계의 자료를 표현할 때 많이 쓰인다.
					ㅡ 용어 )
						ㄴ 서브트리 : 트리 내부에 있는 트리. 그림에서 E,K,L로 이루어진 트리는 전체 트리의 서브트리라고 할 수 있다.
						ㄴ 노드의 차수 : 어떤 노드의 서브트리의 수. 그림에서 A의 차수는 A바로아래로 서브트리가 B,C,D로 세개있으므로 3이된다.
						ㄴ 단말노드, leaf : 차수가 0인 노드. 맨끝에있는 노드. 그림에서 K,L,F,G..등
						ㄴ 비단말노드 : 단말노드가 아닌것들
						ㄴ 부모,자식,조상,자손
						ㄴ 레벨 : root노드의 레벨이 1, 그아래로 갈수록 레벨이 1씩 높아진다.
						ㄴ 트리의 깊이, 높이 : 트리에 속한 노드들 중 가장 높은 레벨.

					ㅡ 이진 트리 )
						ㄴ 모든 노드의 차수가 2이하인 트리.
						ㄴ 종류 )
							ㄴ 편향 트리 : 모든 노드들이 왼쪽자식노드로 이루어져있거나 오른쪽자식노드로 이루어진 트리.
									왼쪽 또는 오른쪽으로 일렬로 되어있는 형태.
							ㄴ 완전이진트리 : 마지막 레벨을 제외하고는 모든 레벨에서 최대노드개수를 가져야하며 마지막 레벨은 왼쪽부터 차곡차곡 차있어야함.
							ㄴ 포화이진트리 : 모든 레벨이 최대노드개수를 가지는 트리.
						ㄴ 성질 )
							ㄴ 레벨당 최대 노드 개수 : 레벨이 i일때, 2^(i-1)개  (i>=1)
							ㄴ 깊이가 k인 이진트리의 총 최대 노드 개수 : 2^k - 1 (k>=1)
								ㄴ n레벨에서의 최대노드개수를 1레벨부터 k레벨까지 더한것. (시그마)
							ㄴ 모든 노드의 개수가 n, 차수가 0인 노드의 개수가 n0, 차수가 1인게 n1, 2인게 n2라고할때,
								n = n0 + n1 + n2
								n = B + 1 (B는 총 가지의 수. 루트노드를 제외한 모든 노드는 가지를 하나씩 가지므로)
								B = n1 + 2*n2
								위를 종합해, n0 = n2 + 1
							ㄴ 완전 이진트리의 높이 : 'log2 (n+1)'의 소수점 올림  (2는 밑)
						ㄴ 완전이진트리 <button>펼치기</button>
						<pre>
							ㄴ 표현 )
								ㄴ 배열 표현 )
									ㄴ n개의 노드를 가지는 트리에 대하여, 부모의 index가 i이면 왼쪽 자식은 2*i, 오른쪽 자식은 2*i+1
									ㄴ i=1은 루트노드, 0은 사용안함
									ㄴ 2*n, 2*n+1은 n보다 작아야함.
								ㄴ 링크 표현 )
									ㄴ 객체로 만들며, 내부에 데이터값과 왼쪽자식노드, 오른쪽 자식노드를 가리키는 포인터를 프로퍼티로 가진다.
							ㄴ 순회 )
								ㄴ 트리에 있는 모든 노드를 한번씩 방문하는 방법을 말함.
								ㄴ 중위, 전위, 후위 순회가 있다.
									ㄴ 전위 순회 : root, 왼쪽서브트리, 오른쪽 서브트리 순서로 순회
									ㄴ 중위 순회 : 왼쪽 서브트리, root, 오른쪽 서브트리 순서로 순회
									ㄴ 후위 순회 : 왼쪽 서브트리, 오른쪽 서브트리, root순서로 순회.
								ㄴ 구현 )
									ㄴ 재귀함수 이용 )
										ㄴ 순회함수를 재귀함수로 사용하여 구현
										ㄴ ex) 중위순회 함수 예
											void inorder(Node *currentNode){
												if(currentNode){
													inorder(currentNode->leftChild);	=>중위순회는 왼쪽 서브트리,root,오른쪽서브트리 순서이므로 왼쪽
													cout<< currentNode->data;			서브트리에 대해서 함수를 재귀적으로 호출
													inorder(currentNode->rightChild);
												}
											}
									ㄴ 스택 이용 )
										ㄴ
										ㄴ 복잡도 )
											ㄴ 시간복잡도 : 모든 노드에 대해 삽입,삭제가 한번씩 일어나므로 노드수 n이라하면 O(2n)이니까 시간복잡도는 O(n).
											ㄴ 공간복잡도 : 스텍의 크기와 일치하며, 노드수가n일때 최악의 경우로 편향트리일경우 공간복잡도는 O(n)
							ㅇ 히프, heap<button>펼치기</button>
							<pre>
								* 우선순위 큐 : 삽입은 일반적인 큐와 같으나 삭제시 가장 우선순위가 높은 것이 먼저 삭제되는 큐.
								ㅡ 최대,최소 히프 )
									ㄴ 알아두어야할것 )
										ㄴ 최대 트리 : 각 노드의 키값이 그 자식의 키값보다 작지 않은 트리. 부모쪽이 더큰거.
										ㄴ 최소 트리 : 그 반대
										ㄴ 최대 히프 : 최대 트리이면서 완전이진트리.
										ㄴ 최소 히프 : 그 반대.
										ㄴ 최대,최소 히프는 최대,최소 우선순위 큐를 구현하는데 쓰인다.
								ㅡ 개요 )
									ㄴ 최대값과 최소값을 빠르게 찾기 위해 고안된 완전이진트리 형태의 자료구조.
									ㄴ 부모자식간에만 대소가 적용되고 형제간에는 적용되지 않는다.
								ㅡ 구현 )
									ㄴ 완전이진트리이므로 배열을 사용.
									ㄴ 여기선 우선 최대 히프를 구현한다.
									ㄴ 삽입 )
										ㄴ 개념 : 이진트리의 맨끝에 삽입 노드를 추가해주고, 부모 노드와 값을 비교하여 부모의 값이 더 클때까지 부모노드와 위치를 바꿔가며
												계속 올라간다. 부모노드의 값이 더 크거나, 루트노드에 도달하면 그곳이 삽입된 노드의 위치가된다.
										ㄴ 시간복잡도 : 최악의 경우 트리의 높이만큼 반복하므로, 이진트리의 높이인 log(2) (n+1) (2는 밑)을 사용하여 O(log(2) n) 이다.
									ㄴ 삭제 )
										ㄴ 루트노드위치에 항상 가장 큰 값을가지느 노드가 있으므로 이를 삭제해주고 최대 히프를 유지해주는 로직이 들어간다.
										ㄴ 루트 노드를 삭제하고 맨 마지막 노드를 루트노드위치로 올리고 두 자식노드와 비교해서 자식노드보다 값이 클때까지 위치를 바꿔주며 내려보낸다.
										ㄴ 시간복잡도 : 삽입과 마찬가지.
							</pre>
						</pre>
						ㄴ 이진 탐색 트리 <button>펼치기</button>
						<pre>
							ㄴ 개요 )
								ㄴ '이진 탐색'과 '이진트리'를 결합한 자료구조
								ㄴ 이진탐색의 효율적인 탐색과 빈번한 입력과 삭제에 용이함.
								* 이진 탐색
									ㅡ 한번 서치할때마다 탐색범위가 절반으로 줄어드는 탐색기법.
									ㅡ 정렬된 데이터를 대상으로한다.
									ㅡ 중간값을 확인하여 찾는값인지 확인하고 아닐경우 찾는값이 중간값보다 작으면 중간값의 왼쪽을 탐색하고 반대면 오른쪽을 탐색하는 기법.
							ㄴ 정의 )
								ㄴ 모든 원소는 키를 가지며, 동일한 키가 없다.
								ㄴ 키값의 크기 : (*왼쪽 서브트리의 노드들의 키값*) < (*루트의 키값*) < (*오른쪽 서브트리의 노드들의 키값*)
								ㄴ 왼쪽, 오른쪽 서브트리도 이진 탐색 트리이다.
							ㄴ 임의의 한 노드를 삽입, 삭제, 탐색하는데 용이하다.
							ㄴ 이진탐색트리의 높이 )
								ㄴ 이진탐색트리는 완전이진트리가 아니기때문에, 삽입, 삭제시의 값에 따라 트리의 모양이 바뀌며 높이도 계속 바뀐다.
								ㄴ 최악의 경우 '편향 트리'로서, 왼쪽 자식만 쭉 있거나, 오른쪽 자식만 쭉 있는 형태.
								ㄴ 평균적인 경우, O(log n)
								ㄴ 균형 탐색 트리(balanced search tree)
									ㄴ 왼쪽, 오른쪽의 서브트리 사이의 높이차를 1로 맞춤으로서 최악의 경우가 나오지 않게 하는 이진탐색트리.
							ㄴ 탐색 )
								ㄴ 찾는 키값을 루트값과 비교하여 같으면 찾은것, 루트값이 더 크면 왼쪽 서브트리 서치, 더 작으면 오른쪽서브트리 서치하는 방식.
								ㄴ 방식 )
									루트부터 시작해서,
									1. 찾는 키값과 루트의 키값이 같으면 탐색 완료,
									2. 찾는 키값이 루트보다 작으면 왼쪽 서브트리 탐색,
									3. 찾는 키값이 루트보다 크면면 오른쪽 서브트리 탐색,
									위 세 단계를 반복.
									왼쪽 또는 오른쪽 서브트리를 탐색하려는데 없어서 null이면 해당 키값은 없는 것.
							ㄴ 삽입 )
								ㄴ 동일한 키값을 가지는 원소가 있는지 확인하고, 없으면 이진탐색트리 규칙에 따라 맞는 위치에 삽입시켜준다.
								ㄴ 방식 )
									ㄴ '탐색'과 유사한 방식.
									ㄴ 루트부터 시작해서,
										1. 삽입할 값과 루트의 키값이 같으면, 이미 값이 존재하므로 false반환.
										2. 삽입할 값이 루트의 키값보다 작으면 왼쪽 서브트리로 이동, 크면 오른쪽 서브트리로 이동.
										위를 반복하다가 말단노드 위치에 오면 해당 위치에 값 삽입.
							ㄴ 삭제 )
								ㄴ 똑같은 방식으로 찾고 찾은 해당노드에 대해 세가지 경우로 나누어 처리. (자식노드가 없는경우, 하나인경우, 두개인 경우)
									ㄴ 자식노드가 없는경우 : 그 삭제하려는 노드의 부모노드의 자식필드 값을 0으로 만듦.
									ㄴ 하나인 경우 : 삭제하려는노드와 자식노드의 위치를 바꿈.
									ㄴ 두개인 경우 : 삭제하려는 노드의 왼쪽 서브트리에서 가장 큰 노드와 위치를 바꾸거나 오른쪽 서브트리에서 가장 작은 노드와 위치를 바꿈.
										ㄴ 왼쪽 서브트리에서 가장 큰 노드는 왼쪽 서브트리에서 오른쪽 자식쪽으로만 쭉내려가다가 오른쪽 자식노드가 없는 노드이다.
										ㄴ 오른쪽 서브트리에서 가장 작은 노드는 오른쪽 서브트리에서 왼쪽 자식쪽으로만 쭉내려가다가 왼쪽 자식노드가 없는 노드이다.
							ㄴ 시간복잡도 : 삽입, 삭제, 탐색의 시간복잡도는 트리의 높이를 h라 할때, O(h)
								ㄴ 이진탐색트리가 편향트리이 가까울수록 h는 최대인 n(노드수)에 가까워지며 효율이 안좋아진다.

							ㄴ 최적 이진 탐색 트리, Optimal binary search tree, OBST
								ㄴ 가중치 또는 확률이 있는 '이진 탐색 트리'에서 '탐색'을 하는 경우, '평균'적으로 가장 탐색하는 시간이 짧은 이진탐색트리를
									'최적 이진 탐색 트리'라고 한다.
								ㄴ ~~~~~~~~~~~~~~~~~~~~~~~~~~
								ㄴ 이러이러하면 결과적으로
									ㄴ 모든 노드가 확률이 동일할 경우, 트리가 '완전 이진 트리'에 가까울 수록 OBST에 가까워진다.
									ㄴ 각 노드의 확률이 다를 경우, 확률이 큰 노드가 루트에 가가울수록 OBST에 가까워진다.

							ㄴ AVL 트리
								ㄴ '이진 탐색 트리'가 삽입과 삭제가 일어나는 데이터셋을 표현하는데 쓰일경우, 입력되거나 삭제되는 데이터의 순서에 따라 모양이 달라지며,
									이에따라 동작에 평균 시간이 달라진다.
								ㄴ '이진 탐색 트리'의 삽입, 삭제, 탐색이 모두 O(log n)이다.
								ㄴ 정의 ) 트리 안에 어떤 노드를 기준으로 하든, 그 노드의 왼쪽 서브트리와 오른쪽 서브트리의 높이차가 1이하이면 AVL트리이다.
									(높이차가 1이하인것을 높이균형을 이루었다고함)
								ㄴ AVL의 삽입, 삭제, 탐색 )
									ㄴ 탐색 ) '이진탐색트리'와 동일하다.
									ㄴ 삽입, 삭제 )
										ㄴ 이진탐색트리의 삽입, 삭제와 동일한 방법인데 거기에다가, 삽입,삭제 이후에 '높이 불균형'이 일어나면 4가지 형태의 '회전'을
											실시하여 높이균형을 유지함.
										ㄴ LL
										ㄴ RR
										ㄴ LR
										ㄴ RL
						</pre>

				</pre>

			</pre>

			ㅇ 정렬 <button>펼치기</button>
			<pre>
				ㅡ 탐색 )
					ㄴ 순차탐색 )
						ㄴ 맨끝부터 다른쪽 맨끝까지 순서대로 쭉 탐색하는 방법. (배열 0부터 n까지 확인하듯이)
						ㄴ 탐색대상이 정렬되어있을 필요가 없다.
						ㄴ 시간복잡도 O(n)
					ㄴ 이진탐색 )
						ㄴ 탐색 대상이 순서에 따라 정렬되어 있어야함.
						ㄴ 탐색 대상의 중간을 확인해, 찾는값이 확인한 중간값보다 크면 중간의 오른쪽을, 작으면 중간의 왼쪽으로 범위를
							좁혀서 탐색해 나가는 방법.
						ㄴ 구현 )
							ㄴ 탐색 대상 범위를 나타내는 left, right를 두고 범위가 좁혀질때마다 left에 중간값+1을 하던지
								right에 중간값-1을 하다가, left>right되는 시점이 탐색끝났을때.
						ㄴ 시간복잡도 O(log n)
				ㅡ 정렬 )
					ㄴ 일련의 데이터들을 크기순(오름차순또는 내림차순)으로 정렬하는 것.
					ㄴ 삽입정렬 )
						ㄴ 개요 )
							ㄴ 일련의 데이터들을 앞에서부터 차례대로 알맞은 위치에 삽입시키는 정렬.
							ㄴ 앞쪽에서부터 하나씩 선택하여 그 원소를 삽입정렬하며, 선택한 원소기준으로 앞쪽을 정렬된곳,
								뒤쪽을 아직 정렬 안된곳으로 분류.
							ㄴ 선택한 원소를 앞쪽 정렬된 부분 안에서, 한쪽에서부터 하나씩 크기비교를 해가며 알맞은 위치를 찾고 그 위치에 삽입시킴.
						ㄴ 시간복잡도 )
							ㄴ 하나의 원소를 선택하고 이를 알맞은 위치에 삽입하는 과정의 시간복잡도는,
								이 원소가 i번째 원소라 할떄(즉, i-1개가 정렬된상태), 최악의 경우 약 i번 비교한다.
							ㄴ 위와같은 삽입작업이 i가 1일때부터 n-1일때까지 더해지므로 시그마 i=1부터 n-1까지 (i+1)해서 계산하면 O(n^2)
					ㄴ 퀵정렬 )
						ㄴ 방법 )
							1. 일련의 데이터 중 맨 앞의 값을 'pivot'이라고 정한다.
							2. pivot 바로 다음 부분을 'left', 반대편 맨끝을 'right'으로 정한다.
							3. left를 한칸씩 오른쪽으로 이동시키며 pivot보다 큰값이 있을때 멈춘다. 마찬가지로 right를 한칸씩 왼쪽으로 이동시키며
								pivot보다 작은값을 만나면 멈춘다.
							4. left,right가 둘다 멈추면 두 값을 서로 바꿔준다. (단, 멈췄을때 left< right이어야 한다.
								즉, left,right가 한칸씩움직이다 서로 교차하면 반복을 멈춘다)
							5. left, right가 교차할때까지 3,4번을 반복한다.
							6. 반복이 끝나면 right와 pivot의 값을 바꿔준다. 이렇게되면 pivot을 기준으로 오른쪽은 pivot보다 큰값,
								왼쪽은 pivot보다 작은값이 오게된다.
							7. 재귀함수를 이용해 pivot을 기준으로 오른쪽부분, 왼쪽부분에 대해 1~6번 과정을 반복해준다.
								각 부분의 원소가 2개 이상이어야 진행한다.
						ㄴ 시간복잡도 )
							ㄴ 데이터들이 이미 정렬되어 있는 경우가 최악의 경우이며 O(n^2)
								ㄴ 맨 왼쪽을 pivot으로 잡고 시작시 이미 정렬되어 있으므로 left는 첫번째에서 멈추고
									right는 pivot보다 큰 값을 찾지 못해 맨 오른쪽에서 끝까지옴(n번)
								ㄴ 다음 pivot은 이전 pivot바로 오른쪽이 되고 위 과정을 반복. n-1번
								ㄴ 이렇게 n, n-1, n-2, ..., 1 번 반복하여 O(n^2)
							ㄴ 하지만 평균적으로는 O(n*log n)이 나온다고 한다.
							ㄴ 최악의 경우를 피하는 방법으로 pivot을 선택할때, 무조건 맨앞의 값이 아닌 적절하게 중간값을 선택하는 방법이 있다.
								ㄴ 일련의 데이터에서 맨앞, 중간, 마지막 값중에 중간크기의 값을 pivot으로 선택하여 맨 앞으로 보내고 정렬하는 것.
					ㄴ 합병 정렬 )<button>more</button>
					<pre>
						ㄴ 기본 작업 단계 : 합병 )
							ㄴ 이미 정렬된 2개의 리스트를 1개의 정렬된 리스트로 만드는 것.
							ㄴ 방법 ) i1, i2를 각 리스트의 맨 처음에 두고 값 비교. 더 작은 값을 iResult에 복사.(iResult는 합친결과 리스트)
								더작은 값에 해당하는 i1또는 i2를 1증가. i1,i2가 각각 끝지점인 m,n을 넘어서지 않을때까지 반복.
								한쪽이 넘어서 반복이 끝나면 다른 한쪽 리스트의 나머지부분을 다 복사해서 iResult에 넣음.
							ㄴ 시간복잡도 : 합병하려는 원소들을 한번씩 복사하는 과정이므로 합병 대상 원소 수만큼의 시간복잡도가 걸린다.
						ㄴ 반복 합병 정렬 )
							<img src="image/합병정렬.png"/>
							ㄴ 위의 기본 작업단계 '합병'을 이용하여 데이터를 정렬하는 방법.
							ㄴ 방법 )
								ㄴ 일련의 데이터에서 데이터 각각을 정렬이 된 하나짜리 리스트 취급하여 이 하나짜리들을 옆에것과 '합병'.
									ㄴ 그 다음 합쳐진 두개짜리들을 옆에것과 '합병'
								ㄴ 이런식으로 length=1부터 시작하여 특정 길이 length 단위로 배열을 나누어 각각 '합병' 진행.
								ㄴ 해당 단계의 길이로 리스트 짝들을 묶은 뒤, 짝이 안 맞는 남는 것들은 그냥 복사.
								ㄴ 하나로 합쳐질때까지 반복.
						ㄴ 시간복잡도 )
							ㄴ 기본 작업 단계 '합병'의 경우, 결과적으로 모든 원소 한번씩 확인하여 복사하므로 원소 개수 O(n).
							ㄴ 특정 length 단위로 합병 진행시에도 결과적으로 모든 원소를 한번씩 확인하고 복사하므로 O(n).
							ㄴ 이를 배열이 하나로 합쳐질 때까지 반복.
								ㄴ length는 특정 길이 length에 대해 합병단계를 진행하는 횟수를 i라 할때,
									2^(i-1)를 따르고, length는 배열의 길이 n을 넘으면 안되므로 2^(i-1) < n
									양변에 log를 취하면 i-1 < log(2) n (밑이 2인 로그)
									하여 진행해야할 합병단계 최대 횟수는 log(2) n
								ㄴ O(n) * O(log(2) n) 이므로, 시간복잡도는 O(n*log(2) n)
							ㄴ 정렬하려는 길이n인 배열이 있을 때, 이런 '합병' 단계를 특정 길이 length로 나누어 합병해도
								모든 원소에 대해 한번씩 확인하고 복사하므로 O(n)
							ㄴ 즉, O(n) * (**)
					</pre>
					ㄴ 히프 정렬 )<button>more</button>
					<pre>
						ㄴ 개요)
							ㄴ '최대 또는 최소 히프'를 이용해 정렬하는 방법.
							ㄴ 최대 히프에서 가장 큰값인 root를 빼서 result에 저장하는 방식을 반복함으로서 정렬한다.
						ㄴ 방식 )
							ㄴ 정렬할 원소들이 있는 배열 arr을 논리적으로 완전이진트리로 바라보고 진행.
							1. arr을 최대(최소)힙으로 만듦.
								1.1 가장 마지막 노드의 부모 노드부터 루트 노트까지의 노드에 대해 '조정'
									'조정'이란, 특정 부분트리를 최대 히프로 만드는 과정.
									1.1.0 부분트리의 왼쪽, 오른쪽 서브트리가 최대히프 상태라는 전제하에,
									1.1.1 루트 노드의 두 자식노드 중 큰 것을 선택,
									1.1.2 하나이거나 없다면 종료.
									1.1.3 있다면 이 더 큰 노드보다 루트 노드가 더 크면 종료.
									1.1.4 작으면 자리를 바꿔준다.
									1.1.5 자리가 바뀌어 내려간 루트 노드에 대해 위 과정(1.1.1~1.1.4)을 반복해준다.
							2. 마지막 노드와 루트 노드의 자리를 바꿈. 루트노드가 내려간 마지막 자리는 배열에서 없는 것으로 취급.
								(이 부분은 정렬된 것으로 취급)
							3. 마지막 노드 이전 노드부터 루트 노드까지에 대해 '조정' 수행.
							4. 2,3번을 n-1번 반복.
							ㄴ arr에 원소들이 정렬된 상태가 된다.
						ㄴ 시간복잡도 )
							ㄴ 초기 배열을 완전이진트리로 보고 최대(최소)힙으로 만드는 과정 )
								idx n/2부터 1번까지 '조정'을 수행. '조정'은 최악의 경우 트리의 높이만큼 연산하므로 O(log n)
								따라서 O(n * log n)
								ㄴ ??? 더 정확히는 O(n)이라함.
							ㄴ 최대(최소)힙에 대해 히프정렬 과정 )
								n-1번 반복, 각 반복마다 '조정' 한번씩 수행하므로
								O(n * log n)
							ㄴ 시간복잡도는 O(n * log n)

						ㄴ 구현 )
							ㄴ 정렬된 데이터를 저장할 result를 따로만들고
							ㄴ 맨처음 일련의 데이터들을 최대히프로 만들어준다.
							ㄴ 최대히프에서 root값을 빼서 result에 저장, 이후 뺀값을 최대히프에서 삭제.
							ㄴ 최대히프에서 가장 마지막노드를 root자리에 위치시키고 최대히프구조를 유지시키기위해 정렬.
								(최대히프에서 삭제연산과 방식이 비슷하다)
								ㄴ 왼쪽과 오른쪽 자식중 큰값을 찾아서 이를 자신과 비교하고 자신이 더 크면 거기에 위치시키고 더 작으면
									그 자식과 자리를 바꾸고 이를 반복.
							ㄴ 최대히프가 빌때까지 반복.
						ㄴ ??? 여러 키에 의한 정렬?
						ㄴ ??? 기수정렬?
					</pre>
			</pre>

			ㅇ 해시, hash <button>펼치기</button>
			<pre>
				ㅡ 임의의 길이의 데이터를 고정된 길이의 데이터로 매핑하는 함수.
				ㅡ 해시 함수에 의해 반환된 값을 '해시값', '해시', '해시코드' 등으로 부른다.
				ㅡ 해시값은 '해시 테이블'이라는 고정된 크기의 테이블을 인덱싱하는데 사용된다.
					이렇게 해시테이블 인덱싱에 해시함수를 사용하는 것을 '해싱', 'scatter storage addressing' 라고 부른다.
				ㅡ 데이터 저장과 검색에 쓰인다. 검색시 거의 상수 시간 안에 검색이 가능하다.
				ㅡ 실제 데이터의 크기보다 약간 큰 정도의 저장공간을 필요로한다.
				ㅡ ??? 해싱은 정렬되거나 정렬되지 않은 리스트나 구조화된 트리에 대한 상수 접근을 가능케하는 저장소 공간 효율적인 데이터 접근 형태이다.
				ㅡ ??? ~~~
				ㅡ 해시함수는 checksum, check digit, fingerprint, lossy compression, randomization,
					error-correcting code, cipher 등과 관련이 깊다.
					ㄴ 겹치는 부분이 많긴 하지만,
						??? 이들은 각각의 요구사항과 사용방식이 있고,
				ㅡ ~~~~~~
				ㅡ 해쉬함수 정의 방법 )
					ㄴ 자릿수 선택 )
						ㄴ 키값에서 보통 중복이 많이 되는 부분을 제외한 나머지 부분들로 해쉬값을 만드는 것. 당연한 방법이다.
						ㄴ 비트 추출 방법
					ㄴ 자릿수 폴딩 )
						ㄴ 자릿수를 '접는다'는 뜻으로,
						ㄴ 키 값을 자릿수기준으로 일정하기 분할한다음, 그 나눠진 수들을 가지고 더하든지 XOR연산을 하든지해서 해쉬값을 만드는 방식이다.
						ㄴ ex)	273419라는 키값이 있을때, 이를 삼등분하여 27, 34, 19로 나누고 이들을 더한 80을 해쉬값으로 만드는 것.
					ㄴ 키를 제곱하여 이 중 일부를 추출
					ㄴ 등등 다양하다.
				ㅡ 충돌 문제 해결책 )
					ㄴ '열린 어드레싱 방법(open addressing method)'와 '닫힌 어드레싱 방법(closed addressing method)'가 있다.
					ㄴ '열린 어드레싱 방법 )
						ㄴ '충돌'이 발생하면 그 지점이 아닌 다른 지점에 저장하는 방식.
						ㄴ '선형 조사법'과 '이차 조사법'이 있다.
						ㄴ 선형 조사법 )
							ㄴ 간단히 말해, '충돌'이 발생하면 한칸 옆에있는 자리를 보고 비어잇으면 그곳에 저장한다.
							ㄴ 한칸 옆자리도 비어있지않으면 그 옆칸을 확인한다.
							ㄴ 이런식으로 '충돌'이 일어난 지점으로부터 'n칸' 옆자리를 확인하여 비어있으면 이곳에 저장하는 방식이다.
						ㄴ 이차 조사법 )
							ㄴ '선형 조사법'과 달리 충돌지점으로부터 n칸 옆자리가 아닌 'n^2'칸 옆자리를 확인하여 비어잇으면 저장하는 방식이다.
							ㄴ '선형조사법'은 '충돌'의 횟수가 증가함에 따라 데이터가 특정 지점에 몰리는 문제점이 있다. 이를 '클러스터(cluster) 현상'이라고 한다.
							ㄴ 이를 해결하기 위해 n에 제곱을 한만큼 떨어진 곳을 확인하여 비어잇을때 저장하는 방법을 쓰는것.
							ㄴ ex)	1^2=1칸 옆자리를 확인, 데이터가 들어있으면 2^2=4칸 옆자리를 확인, 데이터가 들어있으면 3^2=9칸 옆자리를 확인...
						ㄴ 이중 해쉬 )
							ㄴ 이차조사법 역시 문제점이 있다. 해쉬값이 같은 경우, 충돌 발생시 빈슬롯을 찾기위해 접근하는 위치가 늘 동일하여 이들을 주위로
								클러스터 현상이 발생한다는 것.
							ㄴ 이를 해결하기 위해, 충돌발생시 '이차 조사법'처럼 늘 같은 방식으로 빈 슬롯을 찾는게 아니라 매번 다른 방식으로 찾는 방식이 '이중 해쉬'이다.
							ㄴ 방법 ) '1차 해쉬 함수'와 '2차 해쉬 함수'를 두어서, 1차는 해쉬값을 만드는데 사용하고, 2차는 충돌발생시 얼만큼 떨어진 위치에서
								빈슬롯을 찾을지를 결정하는데 사용한다. '충돌' 발생시, 2차 해쉬함수에서 나온 값만큼 건너뛰면서 빈 슬롯을 찾게된다.
							ㄴ ex)
								1차 해쉬함수 : h1(k) = k%15 ,    2차 해쉬 함수 : h2(k) = 1+(k%7)
							ㄴ 2차 해쉬함수 형식 )
								ㄴ 필수는 아니지만 일반적으로 쓰이는 2차해쉬함수 형식이 있다고 한다.
								ㄴ h2(k) = 1 + (k%c)
									ㄴ 1을 더하는 이유는 2차 해쉬함수가 충돌발생시 몇칸 떨어진 위치에서 빈슬롯을 찾을지를 결정하는 함수인데 0이 나와버리면
										'0칸 떨어진곳에서 빈슬롯을 찾는다'와 같은 결과가 나오므로 이를방지하기 위해 1을 더한다.
									ㄴ c는 1차 해쉬함수에서 나오는 값의 범위보다 작으면서 '소수'를 선택한다.
										ㄴ 1차 해쉬함수에서 나오는 값의 범위보다 작아야 하는 이유는 이보다 클경우, 빈 슬롯을 찾으로 해쉬테이블을
											몇바퀴 돌아야하는데 이를 방지하기 위해서.
										ㄴ '소수'를 선택하는 이유는 통계적으로 '소수'를 선택해야 클러스터 현상의 발생확률이 줄어든다고 한다.
					ㄴ 닫힌 어드레싱 방법 )
						ㄴ '충돌'이 발생해도 그 지점에 무조건 저장하는 방식.
						ㄴ 해당 해쉬값 지점에 공간을 여러개 만드는  방식으로 구현한다.
						ㄴ 배열과 리스트로 가능하다, 배열은 충돌발생이 안될경우 메모리 낭비가 심해, 일반적으로는 리스트를 말한다.
						ㄴ '체이닝' )
							ㄴ 각 해쉬값 지점들을 리스트로 만들어 '충돌'발생시 그 리스트에 쭉이어서 추가하는 방식을 '체이닝'이라 한다.

				ㅡ 해쉬테이블의 슬롯 상태정보 )
					ㄴ 해쉬테이블의 각 슬롯마다 '상태정보'를 별도로 저장해 관리해야한다.
					ㄴ 상태는 보통 'EMPTY', 'DELETED', 'INUSE' 가 있다.
						ㄴ empty : 슬롯이 단한번도 채워진적이 없음.
						ㄴ deleted : 슬롯이 채워져있었으나 삭제됨.
						ㄴ inuse : 슬롯에 현재 값이 채워져있음.
					ㄴ 상태정보가 필요한 이유 )
						ㄴ '충돌'이 발생하여 데이터가 '선형 조사법'이나 '이차 조사법'에 의해 다른 곳에 저장되어있는경우
						ㄴ ???????????????????????????????///
			</pre>

			ㅇ 분할정복법<button>more</button>
			<pre>
				ㅡ 주어진 문제를 n개의 부분 문제들로 분할하고 각 부분 문제들을 해결하여 원래 문제의 해답으로 결합하는 방식.
				ㅡ 부분 문제들이 원래 문제와 크기 차이만 있는 동일한 문제이어야 한다.
				ㅡ ??? 대략 방식?
					재귀함수 사용.
					함수 내에서, 문제가 충분히 작다면 문제를 해결하여 반환,
					충분히 작지 않다면, 문제를 부분 문제로 분할후, 각 부분에 대해 재귀함수 호출.
					재귀함수들이 끝나면 부분문제들을 결함.
				ㅡ 장점
					ㄴ 어려운 문제를 간단해질 때까지 잘게 나누어 풂으로서 쉽게 해결할 수 있다
					ㄴ 병렬진행이 가능하다
					ㄴ
				ㅡ 재귀적으로 구현될 수도, 분할한 sub problem의 해를 따로 저장하는 식으로 구현될 수 있다.
				ㅡ 하나의 subproblem으로 분할하는 경우, 'divide and conquer'보단 'decrease and conquer'로 보는게 더 적절하다함.
				ㅡ ??? constant factor에 의해 탐색공간이 감소되면(가지치기 되면?)?
				ㅡ base case의 선택
					ㄴ base case란, 분할정복 알고리즘에서 가장 잘게 나누어지는 단위를 말함. 알고리즘에서 어떤 경우를 가장 작은 단위로
						보고 풀이를 할 것인지를 의미.
						ㄴ ex ) 합병정렬의 경우, 보통 나누어진 배열의 길이가 1인 경우를 가장 작은 단위로 보고 알고리즘 풀이가 진행됨. 
				ㅡ 유의사항 
					ㄴ 나눠져 계산되는 케이스가 중복되어 여러번 계산되는 일이 없도록 주의. 성능저하의 원인이됨. 
				ㅡ 동적 계획법과의 차이
					ㄴ 원문제가 'overlapping subproblem'이 아닌 하위 문제들의 해를 통해 구해질 수 있으면
						분할정복법이라함.
			</pre>

			ㅇ 그리디 알고리즘, Greedy<button>more</button>
			<pre>
				ㅡ ??? 매번 각 단계에서 지역적인 최선의 선택을 하는 휴리스틱 문제해결법을 따르는 모든 알고리즘을 지칭?
				ㅡ 정확한 최적해가 아닌 '적당한' 해를 구하기 위해 사용된다.
					ㄴ '적당한' 해란, 합리적인 시간 안에 최대한 최적해에 근접한 해.
				ㅡ 정확한 최적해를 구하기 위해 필요한 복잡하고 많은 풀이 단계를 생략해주어 시간이 많이 걸리지 않는 경우가 많다.
				ㅡ 그리디 알고리즘을 적용할 수 있는 문제 성질 )
					ㄴ greddy choice 속성
						ㄴ ???그리디 알고리즘에 의해 선택된 선택들은 알고리즘 안에서의 과거 선탹에 의존하여 결정될 순 있지만
							미래 선탹이나 subproblem에 의존하여 결정되지는 않는다?
					ㄴ optimal substructure
						ㄴ 동적 계획법에 나오는 것과 동일.
				ㅡ ??? 탐색, 'branch-and-bound' 문제에서 우선하는 것을 선택할 때 사용되는 알고리즘.
				ㅡ 그리디 알고리즘이 최적해를 산출해 낸다는 것이 증명만 된다면 이 알고리즘은 문제해결을 위한 선택함수로 사용된다.


			</pre>

			ㅇ 동적 계획법<button>more</button>
			<pre>
				ㅡ 최적화 알고리즘 중 하나.
				ㅡ 어떤 문제가 'optimal substructure'와 'overlapping subproblem'에 해당되면 동적 프로그래밍을 적용할 수 있다.
					ㄴ 'optimal substructure', 'overlapping subproblem'은 문제가 가지는 속성을 말함.
						문제가 이러한 속성을 가지면 동적 계획법을 적용할 수 있다는 말.
					ㄴ 'optimal substructure'이지만 'non-overlapping subproblem'이면 '분할 정복법'을 적용 대상이다.
					ㄴ '최적 하부구조(optimal substructure)'
						ㄴ 원문제를 하위 문제로 쪼갰을 때, 하위 문제에 대한 최적해를 통해 원문제에 대한 최적해를 구할 수 있을 때
							최적 하부구조를 가진다고 한다.???
						ㄴ 보통 재귀함수를 통해 표현된다.
						ㄴ ex ) 최단경로. a->b로 가는 최단경로 path1이 있다면,
							a와 b사이 임의의 c에 대해, a->c 경로가 path1-1, c->b경로가 paht1-2라하면 path1-1, path1-2도
							마찬가지로 최단경로이다.
					ㄴ 겹치는 하위 문제(overlapping sub-problem)
						ㄴ 원문제가 여러번 재사용되는 하위 문제로 분해될 수 있거나, 원문제를 재귀함수로 풀 때, 그 재귀풀이가 동일한
							하위문제를 반복적으로 푸는 경우, '겹치는 하위 문제'를 가진다고 한다.
						ㄴ ex ) 피보나치 수열.
							f(i) = f(i-1) + f(i-2)
							f(5)를 구한다할 때, 재귀로 구하는 과정에서 f(2) 등은 계속해서 구해지고, 이 f(2)를 전체 과정 안에서
							재사용해 사용할 수 있으므로 overlapping subproblem을 가진다.
				ㅡ ??? 큰 문제를 작은 문제로 중첩 재귀로서 표현할 수 있으면 동적 계획법을 적용할 수 있다?
					ㄴ ??? 이럴 때, 원래 문제와 sub문제 사이에 'Bellman equation'이란 관계가 있다?
				ㅡ ??? '최적 하부구조'를 만족하도록, 즉, 하위 문제를 통해 전체문제의 최적해를 풀 수 있도록 하위문제를 적절히 정의하는 것이
					중요?
					전체 문제의 최적해를 하위 문제들을 통하여 풀 수 있는 알고리즘을 생각해내는게 중요?
			</pre>

			ㅇ Backtracking, 백트래킹<button>more</button>
			<pre>
				ㅡ ??? 'partial candidate solution'이 적용되고, 해가 될 수 있는지 빠른 판단이 가능한 문제에 적용 가능하다?
				ㅡ '가능한 케이스'들을 나열한다.
					이 '가능한 케이스'들은 최종적으로 해의 일부('완벽한 케이스')가 될 수 있는 케이스들이며,
					알고리즘의 단계들을 거치면서 점진적으로 '완벽한 케이스'가 되어간다.
					이를 '트리' 구조로서 표현이 가능하다. 케이스들을 트리의 노드로 바라보고, 루트로부터 트리를 탐색해 나가며,
					노드가 '가능한 케이스'이면 그 노드의 서브트리 노드들을 나열하고 아닌 경우 나열하지 않고 탐색하지 않는다.
			</pre>

			ㅇ 알고리즘 문제풀이 팁<button>more</button>
			<pre>
				ㄴ 생각하고 있는 로직에서 사용하는 메모리량이 제한을 넘기거나 시간복잡도가 대략 1억을 넘기는지 고려. 
				ㄴ 코테 문제로서는 정답은 있을지 몰라도, 알고리즘 문제는 푸는 방법이 딱하나로 정해져 있다기보단, 
					문제를 푸는 여러 알고리즘들이 가능한데 그 중 어떤 조건(시간, 메모리, 스레딩 환경 등)에 따라 최적의 알고리즘이 있는 것? 
					한 문제를 brute-force로 풀 수도 있고, 분할정복으로도 풀 수 있는 것. 
					단지, brute-force로 풀면 시간복잡도가 몇이고, 메모리는 몇을 쓰게되고, 또 분할정복으로 풀면 시간복잡도는 얼마고 메모리는 얼마를 쓰게되고... 이런 것들이 다를뿐. 
					항상 어떤 패러다임이나 알고리즘을 이용한 풀이가 다른 것들보다 최적인건 아님. (항상 동적계획법이 brute-force보다 빠르지 않은식. 문제마다 다름) 
					어떤게 더 적절할지 알기 위해서 여러 패러다임이나 구현된 알고리즘들을 적용해 시도해보는 것. 
					각 패러다임, 알고리즘을 쓰면 어떻게 왜 더 좋아지는지, 어떤 원리로 돌아가는지, 장단이 뭔지 등은 알고리즘에 대해 공부 필요. 
				ㄴ 분할정복법 쓰면 빨라지는 이유 
					ㄴ ??? 큰 사이즈에 대해 문제를 쪼개어 작은 단위에 대해 풀면 큰 사이즈에 대해 한번에 계산하는 것보다 적게 걸리고, 그렇게 적게 걸리는 것들을 합치는 비용이 
						전체 사이즈에 대해 한번에 계산하느 ㄴ것보다 빠른 경우가 많아서? 
					ㄴ 당연히, 항상은 아니고 문제마다 다름. 더 느릴수도 있다? 
			</pre>

		</pre>

		FireBase<button>펼치기</button>
		<pre>
			ㅡ 간단 개요 )
				ㄴ 앱, 웹을 개발하는데 사용되는 주요한 여러 기능들(로그인처리, 메세지, 알림, 데이터베이스 등)을 손쉽게 구현할 수 있도록
					도와주는 도구들이 있는 플랫폼..? 툴 박스 같은것..?
			ㅡ FCM ( Firebase Cloud Message)
				ㄴ 크로스 플랫폼(iOS, android, 웹, 등)간 메세지 전송을 가능하게 해주는 솔루션.
				ㄴ 아키텍쳐?
					ㄴ firebase 콘솔, trusted environment(어플의 서버 등)
						ㄴ 메세지 전송 요청을 하는 곳.
					ㄴ firebase 서버
						ㄴ 받은 메세지 요청을 firebase 내부에서 처리하는 곳.
					ㄴ platform-level 메세지 transport
						ㄴ firebase 서버에서 처리 후, APN, ATL, 웹 푸쉬 프로토콜 등을 통하여 푸쉬 전송.
					ㄴ 클라이언트(안드로이드 앱, ios 앱, 웹 등)
						ㄴ 클라이언트단의 FCM SDK가 푸쉬를 받음. 어플 로직에 따라 처리.
				ㄴ 흐름
					ㄴ 클라이언트가 메세지를 수신할 수 있도록 FCM에 등록하고, 클라이언트를 유일하게 식별하는 등록토큰 발급.
					ㄴ FCM 콘솔/신뢰할 수 있는 환경(웹 서버 등)에서 대상을 타겟팅하여 메세지 작성, 전송.
						ㄴ firebase admin SDK, HTTP 프로토콜, XMPP 프로토콜 등 이용. (XMPP는 기기->서버 방향으로 메세지 보낼때 사용)
					ㄴ 메세지가 FCM 서버로 전달.
					ㄴ FCM 서버가 메세지의 데이터를 보고 처리. 플랫폼별 전송 레이어로 메세지 전달.
					ㄴ 플랫폼별 전송 레이러를 통해 메세지가 기기에 전달.
				ㄴ 서버 환경에서 메세지 작성
					ㄴ 인증
						ㄴ 서버 환경에서 FCM으로의 메세지 전송 요청은 '인증'이 필요.
						ㄴ 방식
							ㄴ 구글 서비스 내의 환경?(Compute Engine, Google Kubernetes Engine, App Engine, Cloud Function 등)에서
								인증하려는 경우
								ㄴ ??? ADC (어플리케이션 기본 사용자 인증) 사용?
							ㄴ 구글 서비스 환경 이외의 환경인 경우
								ㄴ '서비스 계정' 키 파일 필요
									ㄴ firebase console에서 '서비스 계정'의 비공개 키 생성으로 확보. 이 키파일의 데이터로 인증을 하게됨.
								ㄴ Firebase admin SDK 사용하는 경우
									ㄴ 키 파일 저장 후, 파일 경로를 'GOOGLE_APPLICATION_CREDENTIALS' 환경변수에 저장.
										ㄴ ex ) in linux
											export GOOGLE_APPLICATION_CREDENTIALS="/home/user/Downloads/service-account-file.json"
									ㄴ SDK의 인증함수 실행시, 이 환경변수의 경로에서 키 파일을 찾아 인증 진행.
										ㄴ ex ) in python...
											(*firebase admin SDK*).initialize_app()
								ㄴ SDK를 사용하지 않는 경우
									ㄴ FCM http v1 API 사용하는 경우
										ㄴ 각 언어들의 '구글 인증 라이브러리'를 사용하여 엑세스 토큰을 발급받아 reqeust header에 설정해야함.
											ㄴ 구글 인증 라이브러리 : https://github.com/googleapis?q=auth
										ㄴ ex )	https://github.com/googleapis/google-auth-library-python 라이브러리 사용하는 경우..
											credentials = service_account.Credentials.from_service_account_file(
												'(*service 계정 키파일 경로*)', scopes=(*인증 scope?*))
											request = google.auth.transport.requests.Request()
											credentials.refresh(request)
											token = credentials.token
											ㄴ from_service_account_file()에 명시적으로 키파일 경로를 넘겨야함.
											ㄴ '인증 scope'에는 FCM을 사용하려는 경우
												'https://www.googleapis.com/auth/firebase.messaging' 입력.
										ㄴ 위 토큰값을 request header에 다음과 같이 추가
											ex )
												headers = {
												'Authorization': 'Bearer ' + "(* 토큰 *)",
												'Content-Type': 'application/json; UTF-8',
												}
									ㄴ 기존 http 사용하는 경우
										ㄴ ~~~
					ㄴ 작성
						ㄴ Firebase Admin SDK 사용
							ㄴ ~~~
						ㄴ FCM http v1 API 사용
							ㄴ 특정 하나의 기기 전송
								ㄴ requet 형식 ex )
									POST https://fcm.googleapis.com/v1/projects/myproject-b5ae1/messages:send // HTTP/1.1

									Content-Type: application/json
									Authorization: Bearer ya29.ElqKBGN2Ri_Uz...HnS_uNreA

									{
									"message":{
										"token":"bk3RNwTe3H0:CI2k_HHwgIpoDKCIZvvDMExUdFQ3P1...",
										"notification":{
											"body":"This is an FCM notification message!",
											"title":"FCM Message"
										}
									}
									}
								ㄴ body는 적절히 dump 필요. ex ) python의 json.dumps( { ~~~ } ) ???
							ㄴ 여러 기기 전송
								ㄴ request 형시 ㄱex )
									--subrequest_boundary
									Content-Type: application/http
									Content-Transfer-Encoding: binary

									POST /v1/projects/myproject-b5ae1/messages:send
									Content-Type: application/json
									accept: application/json

									{
									"message":{
										"token":"bk3RNwTe3H0:CI2k_HHwgIpoDKCIZvvDMExUdFQ3P1...",
										"notification":{
										"title":"FCM Message",
										"body":"This is an FCM notification message!"
										}
									}
									}

									...

									--subrequest_boundary
									Content-Type: application/http
									Content-Transfer-Encoding: binary

									POST /v1/projects/myproject-b5ae1/messages:send
									Content-Type: application/json
									accept: application/json

									{
									"message":{
										"token":"cR1rjyj4_Kc:APA91bGusqbypSuMdsh7jSNrW4nzsM...",
										"notification":{
										"title":"FCM Message",
										"body":"This is an FCM notification message!"
										}
									}
									}
									--subrequest_boundary--
						ㄴ 기존 http 방식 사용
							ㄴ ~~~
					ㄴ upstream
						ㄴ ~~~
					ㄴ topic
						ㄴ ~~~
					ㄴ ~~~
				ㄴ 클라이언트
				ㄴ
		</pre>

		기타 외부 api<button>펼치기</button>
		<pre>
			ㄴ 유튜브 api<button>펼치기</button>
			<pre>
				ㄴ ~~~~~
				ㄴ api 리소스 유형
					ㄴ api를 통해 여러 작업(조회,삭제,수정,삽입)을 할 수 있는 리소스의 유형.
					ㄴ video, thumbnail, playlist, channel, search result 등.
				ㄴ api 작업 유형
					ㄴ list, insert, update, delete 를 제공.
					ㄴ 리소스 유형별로 가능한 작업이 다르다.
				ㄴ part, fields
					ㄴ api 요청시, 'part', 'fields' 파라미터를 추가하여, api에서 반환하는 데이터에서 일부만을 받을 수 있다.
						api의 결과로 반환받을 여러 데이터들이 있는데, 'part'가 이들의 상위 그룹 역할이고, 'fields'가 각 'part'의
						하위 요소 취급이다. ex) part=snippet 하위에 fields=title,position 등.
						각 api 요청에 이 part, fields 매개변수를 넘겨, 딱 필요한 데이터들만 받을 수 있도록 하는 것.
						ㄴ https://www.googleapis.com/youtube/v3/search?key=(*api키*)&maxResults=10&q=동화약품
							위와 같은 api요청에 쿼리파라미터로 'part', 'fields'를 추가하는 것.
						ㄴ 각 api요청마나 가능한 'part'들 존재. 문서 참고.
							ex) 키워드 검색api인 https://www.googleapis.com/youtube/v3/search 에는 'id', 'snippet' part 존재.
						ㄴ api의 응답 데이터(json)에 대해, json의 키값으로 'fields' 작성 가능.
							ㄴ 동일 계층 키워드면 컴마(,)로 나열, 하위 계층 키워드면 상위 계층 키워드 뒤에 소괄호()로 나열.
							ㄴ 아래 예제 참고.
						ㄴ ex)<button>more</button>
						<pre>
							ㄴ https://www.googleapis.com/youtube/v3/search?key=AIzaSyByUMQzcO6cH_OLQ6iukmS4bTTWHFatPY8&part=id,snippet&maxResults=10&q=%EB%8F%99%ED%99%94%EC%95%BD%ED%92%88%20000020&type=video
								위와 같이 요청시, ('part'파라미터만 지정) 아래와 같이 결과.
								id, snippet 'part'에 해당하는 모든 데이터 반환.
							{
							"kind": "youtube#searchListResponse",
							"etag": "jqqvVuUsOjLEbnAoS29pl3s-uYQ",
							"nextPageToken": "CAoQAA",
							"regionCode": "KR",
							"pageInfo": {
								"totalResults": 4091,
								"resultsPerPage": 10
							},
							"items": [
								{
								"kind": "youtube#searchResult",
								"etag": "FVO4D-RAOhujM4onwxFNLL3zYYs",
								"id": {
									"kind": "youtube#video",
									"videoId": "70DLk9gay8w"
								},
								"snippet": {
									"publishedAt": "2021-12-15T06:18:44Z",
									"channelId": "UC8Sv6O3Ux8ePVqorx8aOBMg",
									"title": "동화약품(000020)_종목 상담_주식 챔피언 쇼 (20211215)",
									"description": "종목 상담: #동화약품(000020) #주식 #김두호 #종목 #상담 이데일리TV ✓주식·부동산 전문 재테크 채널 ▷이데일리TV 채널 구독하기 ...",
									"thumbnails": {
									"default": {
										"url": "https://i.ytimg.com/vi/70DLk9gay8w/default.jpg",
										"width": 120,
										"height": 90
									},
									"medium": {
										"url": "https://i.ytimg.com/vi/70DLk9gay8w/mqdefault.jpg",
										"width": 320,
										"height": 180
									},
									"high": {
										"url": "https://i.ytimg.com/vi/70DLk9gay8w/hqdefault.jpg",
										"width": 480,
										"height": 360
									}
									},
									"channelTitle": "이데일리TV",
									"liveBroadcastContent": "none",
									"publishTime": "2021-12-15T06:18:44Z"
								}
								},
								...
							]
							}

							ㄴ https://www.googleapis.com/youtube/v3/search?key=AIzaSyByUMQzcO6cH_OLQ6iukmS4bTTWHFatPY8&part=id,snippet&maxResults=10&q=%EB%8F%99%ED%99%94%EC%95%BD%ED%92%88%20000020&type=video&fields=kind,etag,nextPageToken,regionCode,pageInfo,items(kind,etag,id(videoId),snippet(publishedAt,title,thumbnails(default(url)),channelTitle))
								위와 같이 요청시, ('fields'파라미터 추가) 아래와 같이 결과.
								id 'part'의 'videoId' field만, snippet 'part'의 publishedAt,title,thumbnails.. 등등 field만 반환.
							{
							"kind": "youtube#searchListResponse",
							"etag": "9g9dM56dyGW-Lf8NFbqCJZVQL2E",
							"nextPageToken": "CAoQAA",
							"regionCode": "KR",
							"pageInfo": {
								"totalResults": 4030,
								"resultsPerPage": 10
							},
							"items": [
								{
								"kind": "youtube#searchResult",
								"etag": "FVO4D-RAOhujM4onwxFNLL3zYYs",
								"id": {
									"videoId": "70DLk9gay8w"
								},
								"snippet": {
									"publishedAt": "2021-12-15T06:18:44Z",
									"title": "동화약품(000020)_종목 상담_주식 챔피언 쇼 (20211215)",
									"thumbnails": {
									"default": {
										"url": "https://i.ytimg.com/vi/70DLk9gay8w/default.jpg"
									}
									},
									"channelTitle": "이데일리TV"
								}
								},
								...
							]
							}

						</pre>

				ㄴ 할당량<button>more</button>
				<pre>
					ㄴ api요청시마다 할당량이 소모.
						요청하는 api종류마다 할당량이 다름 ex) 영상 하나에 대한 정보 조회는 1, 키워드 검색 요청은 100 등
						한 api 종류 안에서도 'part'의 개수만큼 할당량 추가.
					ㄴ api 종류별 할당량
						ㄴ https://developers.google.com/youtube/v3/determine_quota_cost
						ㄴ ex) 키워드 검색 api인 https://www.googleapis.com/youtube/v3/search의 경우 한번 요청으로 최소 할당량 100이 소모.
					ㄴ 할당량 늘리기
						ㄴ googl cloud platform > youtube data api 관리 콘솔에서 할당량 추가 요청을 구글에 보내어 허락받아야함.
						ㄴ 할당량 요청 api 로직에 할당량 최적화 개선 여지가 있는지 메일로 주고받는 과정이 있다 하고, 오래 걸린다 함.
				</pre>

				ㄴ 라이브러리<button>more</button>
				<pre>
					ㄴ api요청을 편리하게 할
				</pre>

			</pre>

			ㄴ 애플 <button>펼치기</button>
			<pre>
				ㄴ 로그인 연동<button>펼치기</button>
					<pre>
						ㄴ 문서가 영어로 되어있고 이해하기가 어려워 블로그에서 찾은 구현된코드만 기록해둔다. OAuth방식이라 대충 어떻게 동작하는지
							알수는 있을것이다.
							ㄴ 블로그 주소 : https://whitepaek.tistory.com/61
						ㄴ 처음 로그인 요청 부분. js 코드 )
							< body >
							< div id="appleid-signin" data-color="black" data-border="true" data-type="sign in" style="height: 50px; width: 100%;">< /div>
							< script type="text/javascript" src="https://appleid.cdn-apple.com/appleauth/static/jsapi/appleid/1/en_US/appleid.auth.js">< /script>
							< script type="text/javascript">
								AppleID.auth.init({
									clientId : '[[${client_id}]]',	//애플에서 certificate & identifier?등록시 나오는 서비스id.
									scope : 'name email',
									redirectURI : '[[${redirect_uri}]]',	//애플에서 앱등록시 설정하는 redirect url.
									state : 'test',
									nonce : '[[${nonce}]]',	//잘모르겠음. 크게상관없는 임의의 값이거나 api로부터 반환받은값 검증에 쓰이는듯함.
									usePopup : false
								});
							< /script>
							ㄴ 이렇게 만들고 실행하면 앱 로그인 버튼이 뜨며, 클릭후 로그인하면 정보가 redirect url로 넘어감.
						ㄴ 응답받는 컨트롤러 메소드 )
							@ApiOperation(value = "애플 로그인 리다이렉트 메소드",notes = "")
							@PostMapping("/appleAuthCode")
							public void getAppleAuthCode(
									AppleAuthCodeDto request,
									HttpServletResponse response
							) throws NoSuchAlgorithmException, InvalidKeyException, IOException, InvalidAlgorithmParameterException, NoSuchPaddingException, BadPaddingException, ParseException, IllegalBlockSizeException {
								System.out.println("in /v2/api/appleAuthCode");
								SnsLoginResponseDto dto = memberService.snsLoginForApple(request.getId_token());
							}
							ㄴ AppleAuthCodeDto에는 state,code,id_token,user가 들어있으며, id_token안에 로그인한 사용자 정보가 들어있다.
								이중 sub가 로그인 사용자의 고유 식별자이다.
							ㄴ id_token은 암호화되어 있고 다음은 이를 decode하는 코드이다. JWT를 사용하였다.
								SignedJWT signedJWT = SignedJWT.parse(idToken);
								ReadOnlyJWTClaimsSet getPayload = signedJWT.getJWTClaimsSet();
								ObjectMapper objectMapper = new ObjectMapper();
								AppleLoginPayLoadDto payload = objectMapper.readValue(getPayload.toJSONObject().toJSONString(), AppleLoginPayLoadDto.class);
								String usrId = payload.getSub();

					</pre>

			</pre>

			ㄴ 구글 api<button>more</button>
			<pre>
				ㄴ 구글 로그인 
					ㄴ 
				ㄴ Google Cloud 
					ㄴ Vertex AI <button>more</button>
					<pre>
						ㄴ 구글 클라우드 기능 중 하나로, ai관련 여러 기능을 제공하는 플랫폼 의미. 
							ㄴ 모델학습, 기존 모델 파인튜닝, 평가, 배포 등을 여기서 제공하는 모듈 또는 페이지에서 할수있게해줌. 
							ㄴ 여러 기능들이 있고 각 기능들이 어떻게 동작하고 어디까지 가능하고 어떻게 사용하는지 등은 각각 확인 필요. 
						ㄴ 모델 training 
							ㄴ ~~~ 
							ㄴ 방법 
								ㄴ AutoML 
									ㄴ ??? 개요 
										ㄴ vertex ai에서 제공하는 ui로 학습시키는 방법? 
											vertex ai에서 제공하는 옵션 내에서 데이터셋 준비하여 ui상에서 클릭클릭으로 세팅 뒤, 학습시키면 
											일정시간 후 학습된 모델이 완성디ㅗ는 식. 
										ㄴ 학습시킬 수 있는 데이터 형태 정해져 있음. 
											ㄴ text, image, tabular, video 
										ㄴ 학습시킬 데이터 형태별로, 가능한 모델의 학습목표가 정해져있음. 
											ㄴ 이미지는 classification, object detection 
											ㄴ text는 classification, entity extraction, sentiment analysis 등 
											ㄴ 등 
										ㄴ 
											ㄴ Tabular data 
												ㄴ 이진 분류, multi-class 분류, regression, forecasting 
								ㄴ custom training 
									ㄴ ??? 코드로 직접 모델을 학습시키는 방법? 
									ㄴ ??? 학습 코드를 직접 vertex ai에 넘기면 vertex ai내에서 도커 컨테이너를 생성해 넘긴 코드를 실행하여 
										학습을 진행하는식? 
										넘길 학습코드는 단일 파이썬 코드, 파이썬 패키지, 별도 컨테이너가 가능? 
								ㄴ 비교 
									ㄴ AutoML이 당연히 더 간단 & 제한 많음. 
										ㄴ 학습 목표, 학습 시간, 파라미터 커스텀, 데이터 크기 등. 
									ㄴ 대신 세부 지식이나 코딩 덜 필요. 
						ㄴ prediction 
							ㄴ 그냥 학습된 모델이 인풋에 대해 내놓는 결과물 의미? 
						ㄴ 모델 평가 및 반복 
							ㄴ 학습시킨 모델을 평가하고, 조정 뒤 재학습을 반복. 
						ㄴ 모델 deploy 
						ㄴ 모델 monitoring 
						ㄴ MLOps (Machine Learning operations)
							ㄴ 머신러닝 시스템에 대한 CI/CD와 CT(continuous training)을 자동화하게 해주는 도구. 
							ㄴ 소프트웨어의 DevOps 처럼 머신러닝 시스템에도 DevOps같은것을 적용하는 기능이라보면됨? 
						ㄴ generative AI 
							ㄴ 
						ㄴ 참고 
							ㄴ https://cloud.google.com/vertex-ai/docs

					</pre>
			</pre>

			ㄴ 카카오<button>more</button>
			<pre>
				ㄴ ~~~
				ㄴ 카카오 채널
					ㄴ ??? 카카오 개발페이지에서 해당 앱을 '비즈니스' 앱으로 등록 후, 카카오톡 채널 추가?
						'카카오 비즈니스'에서 동일한 정보로 등록된 비즈니스 채널과 연결 가능
					ㄴ 항상하는 여러 설정들 있고,
						rest api에선 다른 기능들 제공하고 주요 기능들(채널 추가, 채팅창 열기 등)은 android, ios, javascript sdk로 제공되는듯.


			</pre>

			ㄴ Google Analytics <button>more</button>
			<pre>
				ㄴ 웹사이트, 앱에서 데이터를 수집하여 인사이트를 제공하는 구글의 웹 분석 서비스. 
				ㄴ google analytics의 account, property, stream
					ㄴ 다음의 형태 
						조직(선택)
						ㄴ account 1
							ㄴ property 1 
								ㄴ data stream 1
								ㄴ data stream 2 
								ㄴ ~~~
							ㄴ property 2
							ㄴ ~~~
						ㄴ account 2
						ㄴ ~~~
				ㄴ account 
					ㄴ 
				ㄴ property 
					ㄴ 하나의 앱, 웹 등 논리적인 어플리케이션을 나타냄. 데이터를 수집할 논리적인 대상 단위? 
				ㄴ data stream 
					ㄴ 유저가 직접적으로 접촉하는 부분으로부터 오는 데이터 흐름을 의미. 
					ㄴ data stream 생성시, 일종의 code snippet이 생성되고 이를 해당 웹이나 앱에 추가하면 
						이 코드를 통해 데이터가 수집되어 google analytics의 report 생성에 사용됨. 
					ㄴ 하나의 어플이 여러 플랫폼(웹, ios, android)에서 서비스되는 경우, 각각에 대해 data stream 생성 가능. 
					ㄴ 삭제시, 과거 데이터 보존. 
				ㄴ event 
					ㄴ 웹, 앱에서의 특정 상호작용 또는 특정 발생하는 케이스에 대해 측정할 수 있게해주는
					ㄴ 페이지 로드, 링크 클릭, 구매 완료, 앱 충돌 등 측정 가능. 
					ㄴ 유형
						ㄴ 자동 수집 이벤트 
							ㄴ 다음은 자동으로 수집되는 이벤트 목록. 
							ㄴ automatically collected event 
								ㄴ 웹, 앱에 analytics 세팅시, 디폴트로 자동 수집되는 이벤트들. 
									ㄴ 'the Google Analytics for Firebase SDK'나 'gtag.js'를 사용하면 자동으로 수집됨. 
								ㄴ 목록 
									ㄴ ~~~ 
									ㄴ 페이지 로딩, 스크롤, 파일 다운 등등.. 
							ㄴ enhanced measurement event 
								ㄴ 웹, 앱에 analytics 세팅하고, enhanced measurement를 enable 할시 수집되는 이벤트. 
								ㄴ 목록 
									ㄴ ~~~ 
						ㄴ 구현 필요한 이벤트 
							ㄴ 다음은 수집을 위해선 구현이 필요한 이벤트 목록 
							ㄴ recommended event 
								ㄴ Google Analytics에서 사용하기를 추천하는 이벤트들. 어플 카테고리에 따라 추천하는 이벤트 목록들 있음. 
								ㄴ 추가적인 데이터를 인자로 받아야하여 수동으로 구현을 해줘야하는 이벤트들. 
								ㄴ 정해진 이벤트 파라미터들을 받도록 구현해야함. 
								ㄴ ??? 이 이벤트를 통하여 수집된 데이터들은 미리 정의된 dimensions, metrics들에 자동으로 업데이트된다? 
								ㄴ 목록 
									ㄴ 공통 추천 이벤트 목록 
										ㄴ ad_impression 
										ㄴ earn_virtual_currency 
										ㄴ ~~~ 
									ㄴ 온라인 판매 관련 추천 이벤트 목록 
										ㄴ add_payment_info 
										ㄴ ~~~ 
									ㄴ ~~~ 
									ㄴ 참고 
										ㄴ https://support.google.com/analytics/answer/9267735?dark=1&sjid=8796730725648071821-AP
								ㄴ 각 이벤트들의 파라미터 및 상세 내용은 레퍼런스 참고. 
									https://developers.google.com/analytics/devguides/collection/ga4/reference/events?client_type=gtag#earn_virtual_currency
							ㄴ custom event 
								ㄴ 사용자가 직접 정의하는 이벤트. 
								ㄴ 이벤트명은 조건 충족 필요. 
									ㄴ case sensitive 
									ㄴ 예약된 이벤트명 사용 불가. 
									ㄴ ~~~ 
									ㄴ https://support.google.com/analytics/answer/13316687#zippy=%2Cweb
								ㄴ 개수 제한	
									ㄴ web은 없음. 
									ㄴ 앱은 500개.
					ㄴ event parameter 
						ㄴ 이벤트에 전달되는 웹, 앱상에서의 유저 상호작용에 대한 추가적인 데이터. 
						ㄴ 이점 
							ㄴ 이벤트에 더 상세한 추가정보를 함께 전달함으로써 유저 행동에 대해 더 정밀한 모니터링 가능. 
						ㄴ automatically collected event 등에 파라미터를 설정할 필요는 없음. 
						ㄴ recommended event 추가시 각 이벤트가 받아야하는 파라미터 설정 필요. 
						ㄴ custom event에 파라미터 추가 가능. 
						ㄴ 파라미터 추가 방법 
							ㄴ key-value pair 형식으로 
						ㄴ ??? 처음 커스텀 파라미터 추가시, 24시간동안 리포트에서 파라미터가 '(not-set)'으로 보인다? 
							커스텀 이벤트의 파라메어를 커스텀 dimension, metric로 등록한 뒤, 이에 대한 report생성해도 값이 바로 나오지 않기는함. 하루 뒤에 나옴. 
					
					ㄴ 이벤트 발생 
						ㄴ 당연히 automatically collected event, enhanced measurement event는 자동으로 발생. 임의로 발생시킬 필요 없다. 
							recommended event, custom event를 발생시키는 방법에 대한 것. 
						ㄴ Google tag (gtag.js) 이용 
							ㄴ 라이브러리의 gtag() 메소드를 적절한 파라미터와 함께 호출하여 이벤트를 발생시킴. 
							ㄴ 당연히 해당 페이지에 gtag 라이브러리 로드 필요. 
								ㄴ ex ) < script async src="https://www.googletagmanager.com/gtag/js?id=G-58SS9231TR">< /script>
							ㄴ 형식 
								gtag('event', (*이벤트명*), (*이벤트 파라미터*))
								ㄴ (*이벤트 파라미터*)는 옵션. 
								ㄴ (*이벤트 파라미터*) 형식은 키-값 쌍 dict. 
							ㄴ ex ) 
								// custom event 발생. 
								gtag('event', "testEvent", {
									"param1": "Hello", 
									"param2": 123,
								})

								// recommended event인 'refund'이벤트 발생. 
								gtag('event', "refund", {
									"currency": "USD", 
									"transaction_id": 123, 
									value: 1000, 
									shipping: 1.1, 
								})

					ㄴ 발생한 이벤트 확인 
						ㄴ 발생한 이벤트들은 report 페이지에서 확인 가능. 

					ㄴ key event 
						ㄴ 좀 중요한 action (어플리케이션, 비즈니스에 있어서 중요한)을 측정하는 이벤트. 
						ㄴ 수집하는 이벤트들 중에 어떤 이벤트든 key event로 설정 가능. 
							특정 actiono에 대한 이벤트를 먼저 만든 뒤, key event로 'mark'하면됨. 
						ㄴ ??? Attribute credit to touchpoints
						In the Advertising section, you can use the Pathing and Attribution reports to attribute credit to different touchpoints along a user's path to triggering key events and see how different attribution models distribute credit differently to those touchpoints. Learn more about advertising reports
						ㄴ ??? Google Ads conversions ? 
							ㄴ ~~~ 

					ㄴ event group 
						ㄴ 웹, 앱상에서 발생한 이벤트는 발생 즉시 analytics로 전송되지 않음. 
							group끼리 묶이거나 batch형식으로 전송. 
						ㄴ 예외 
							ㄴ key event는 즉시 전송. ??? batch의 일부더라도? 
							ㄴ ??? debug mode에서 로드된 컨테이너는 batch전송을 하지 않음? 
							ㄴ ??? Events that are held by your device are sent when a user leaves a page
							ㄴ 'fetch API'를 지원하지 않는 브라우저 환경에서는 즉시 전송. 
					
					ㄴ 유저단에서 네트워크가 끊기거나 하여 offline이 되는 경우, 이벤트 데이터는 device에 저장되었다가 
						다시 연결시 전송됨. 
					ㄴ analytics는 발생한 뒤 72시간이 지난 이벤트는 무시함. 

				ㄴ Dimension, Metric 
					ㄴ 둘 다 google analytics에서 수집하는 데이터를 지칭하는 단어. 
						성격이 다른 것. metric는 항상 숫자로 표현 가능한 수치형 데이터, dimension은 대부분 문자열로 표현가능한 데이터. 
					ㄴ event parameter의 데이터를 가지고 생성. 
					ㄴ ??? 
					ㄴ custom dimensions, metrics 
						ㄴ 커스텀 dimension, metrics 생성 가능. 
						ㄴ 유형 
							ㄴ user-scoped custom dimension 
								ㄴ 
							ㄴ event-scoped custom dimension 
								ㄴ 
							ㄴ item-scoped custom dimension 
							ㄴ custom metrics
							ㄴ calculated metrics
						ㄴ report 페이지에서 custom dimension, metric 값들이 다른 것들보다 늦게 반영되는듯. 24시간? 

				ㄴ report 
					ㄴ realtime report 
						ㄴ analytics에 등록된 웹이나 앱을 사용자가 사용시 이에 대해 실시간으로 데이터를 수집해 보여주는 리포트. 
						ㄴ 최근 30분 동안의 데이터. 
						ㄴ ??? 'comparisons' 사용 가능? 
						ㄴ 'View user snapshot' 사용 가능? 

					ㄴ DebugView report
						ㄴ ??? 브라우저나 모바일 장치에서의 이벤트를 모니터링? 
						ㄴ 사용법 
							ㄴ gtag.js 에서 다음코드로 debug모드 on
								ㄴ gtag('config', 'G-58SS9231TR', {"debug_mode": true}); 
							ㄴ google analytics페이지의 admin페이지 > Data display > Debug View 에서 확인 가능. 
					ㄴ report collection 
						ㄴ 리포트 페이지에서 좌측 메뉴에서 'Reports snapshot', 'Realtime' 항목 하위에 있는 목록들을 'report collection'이라함. 
						ㄴ 설정에 따라 보여지는 목록이 바뀜. 
						ㄴ custom 가능. 
						ㄴ 목록 
							ㄴ App developer 
							ㄴ Business objectives
							ㄴ Games reporting
							ㄴ Life cycle 
							ㄴ User 
					ㄴ Library 
						ㄴ ??? 커스텀 리포트 생성? 
				ㄴ Google Ads와의 연결 
					ㄴ ~~~ 
				ㄴ Advertising 
					ㄴ ~~~ ??? 

				ㄴ Analytics 화면 사용법 
					ㄴ account, property, view 전환 
						ㄴ home에서 왼쪽 상단에 전환 가능한 네이게이션바 존재. 
					ㄴ search 
						ㄴ 그냥 통합검색창 같은거. 
					ㄴ 오른쪽 상단 사각형 형태 점4개. 
						ㄴ google Marketing Platfor의 다른 서비스들로 이동 가능.
					ㄴ 오른쪽 상단 물음표
						ㄴ 현재 페이지에 대한 도움말. 

				ㄴ 실무 
					ㄴ 어떤 데이터를 수집할지 결정하고 이를 수집하는 기본항목이 있는지, 어떻게 관리창에서 볼 수 있는지, 없으면 어떻게 수집할지 등 
						수집할 항목을 먼저 정하고 각 항목에 대해 어떻게 수집할지 검토하여 구현해야 하는 듯. 
						GA가 수집하는 각 항목들이 어떤 기준으로 어떻게 수집되는지, 구체적으로 어떤 데이터인지 등도 문서에서 확인 필요. 
					ㄴ 기본적으로 있는 report collection에서도 충분히 많은 데이터 제공. 
					ㄴ 이 기본적 항목들이 어떤건지 하나하나 확인하거나, 데이터를 확인해보거나, 추가적으로 어떤 데이터를 수집할지 결정하는 것 등은 
						개발이라기보다 데이터 분석, 기획. 대충어떤건지 알고, 기술적으로 세팅 및 구현하는 것까지가 개발일듯. 
				ㄴ 참조 
					ㄴ https://developers.google.com/analytics/devguides/collection/ga4/events?client_type=gtag
					ㄴ https://support.google.com/analytics/topic/13367566?hl=en&dark=1&sjid=8796730725648071821-AP
					ㄴ https://support.google.com/analytics/answer/13947485?hl=en&dark=1&sjid=17703095413670925090-AP&visit_id=638563430394112530-1179398679&ref_topic=13948007&rd=1#
					ㄴ https://support.google.com/analytics/answer/9212670?hl=en&sjid=17703095413670925090-AP&visit_id=638563430394112530-1179398679&ref_topic=13818299&rd=1#
						
			</pre>

			ㄴ Telegram API <button>more</button>
			<pre>
				ㄴ 
				ㄴ 텔레그램 서비스 관련 내용 <button>more</button>
				<pre>
					ㄴ Telegram bot 
						ㄴ 텔레그램 계정의 일종으로 취급. 
						ㄴ 전화번호 필요치 않음. 
						ㄴ 일반 유저 계정과의 차이점. 
							ㄴ 'last seen', 온라인 상태값 없음. 'bot'이라고만 표시. 
							ㄴ 할당된 클라우드 저장소 작음. 오래된 메세지 금방 사라짐. 
							ㄴ 일반 유저에게 먼저 대화 시작 불가. 
								일반 유저에 의해 그룹으로 초대되거나, 일반 유저가 봇에게 먼저 대화를 시작해야 가능. 
							ㄴ 디폴트로, 그룹 내에 존재하는 봇은 '관련된 메세지'만 볼 수 있음.  
						ㄴ 그룹에 봇을 등록시키려면, 그룹의 관리자가 봇을 추가해야함. 
						ㄴ 채널에는 봇을 관리자로서 밖에 추가 못함. 당연히 관리자가 봇을 추가해 줘야함. 
						ㄴ Privacy Mode 
							ㄴ 봇별로, privacy mode설정값이 존재. 
							ㄴ privacy mode에서 봇은 인식할 수 잇는 정보 제한됨. 
								ㄴ ??? 해당 봇에게 명시적으로 전달된 명령어. 
								ㄴ ??? 일반 명령어? 
								ㄴ ???inline 메세지?
								ㄴ 서비스 메세지
								ㄴ private chat의 메세지 
								ㄴ 봇이 멤버로 있는 채널의메세지. 
							ㄴ 해제 방법 
								ㄴ @BotFather 채팅에서 /setprivacy 명령어 입력. 
								ㄴ 해제하려는 봇선택 & 해제. 
					ㄴ 채널 설정 
						ㄴ 채널 타입 
							ㄴ 채널을 초대되노 사람만 들어올수 있는지 아무나 가능한지 여부 설정. 
						ㄴ content protection 
							ㄴ 채널의 내용을 subscriber가 복사, 저장, 포워딩 가능한지 여부 설정. 
							ㄴ ?? 어느 정도 범위까지 되는지 확인 필요? api로도 당연히 안되겠지? 
					ㄴ 그룹 
						ㄴ ??? 컨텐츠 보호 따로 없음? 

				</pre>

				ㄴ Bot API <button>more</button>
				<pre>
					ㄴ 개요 <button>more</button>
					<pre>
						ㄴ HTTP 기반 interface. 
						ㄴ http요청을 통하여 봇 관련 다양한 동작 가능. 
						ㄴ ??? 'https://api.telegram.org/bot< token>/METHOD_NAME' 와 같은 형식으로 요청을 보내면, 
							이를 ??? 봇 서버?가 받아 내부적으로 요청에 맞는 로직을 실행하여 동작. 
						ㄴ 요청을 받을 봇 서버?를 직접 로컬에 세팅 가능. 
							ㄴ 로컬에 Bot api 요청을 받을 서버를 설치하고 위의 url이 아닌 이 로컬 서버로 요청을 보내면, 
								위 url에 보냈을 때처럼 똑같이 동작하는 식. 
							ㄴ 이점 
								ㄴ Download files without a size limit.
								ㄴ Upload files up to 2000 MB.
								ㄴ Upload files using their local path and the file URI scheme.
								ㄴ Use an HTTP URL for the webhook.
								ㄴ Use any local IP address for the webhook.
								ㄴ Use any port for the webhook.
								ㄴ Set max_webhook_connections up to 100000.
								ㄴ Receive the absolute local path as a value of the file_path field without the need to 
									download the file after a getFile request. 
						ㄴ 대략적 가능한 기능 목록 
							ㄴ 참고 ) https://core.telegram.org/bots/features#keyboards
					</pre> 

					ㄴ 기본 사용법 <button>more</button>
					<pre>
						ㄴ 봇 생성 
							ㄴ 텔레그램 앱에서 @BotFather 과 채팅 생성. 
								ㄴ 'BotFather'로 검색하면 나옴. 
							ㄴ botfather 채팅에서 '/newbot' 입력. (명령어) 
							ㄴ 시키는대로 진행. 
							ㄴ 생성 후, 마지막에 나오는 봇의 api token 확보. 
						ㄴ 그룹에 봇 등록. 
							ㄴ 그룹 클릭 후, 옆 메뉴에서 걍 등록. 
							ㄴ 등록된 봇은 이제 해당 그룹에 대한 동작 가능(메세지 전송 등) 

					</pre>

					ㄴ Update <button>more</button>
					<pre>
						ㄴ 텔레그램 봇과 관련된 변경사항을 나타내는 개념으로, 
							봇과 관련된 변경사항이란 
							봇이 있는 그룹에서의 새로운 메세지, 봇이 있는 그룹에서의 멤버 변경, 
							봇이 있는 채널에서의 게시물 추가 등, 다양. 
							ㄴ 참조 ) https://core.telegram.org/bots/api#getting-updates
						ㄴ object로서 표현 <button>more</button>
						<pre>
							ㄴ 구성  
								ㄴ 'Update'에 대한 고유 식별값 키와 변경사항이 어떤 것인지에 대한 키값으로 구성. 
								ㄴ update 객체당 변경사항에 대한 키값은 단 하나 존재. 
								ㄴ 변경사항에 대한 키값의 내용은 변경사항 종류에 따라 각각 다름.  
								ㄴ ex )  
									// message에 대한 변경사항 object. 
									{ 
										updated_id : 1234566,  // update 고유 식별값. 
										message: {  // message에 대한 변경사항. 
											message_id: 2, 
											chat: {
												id: ~~~, 
												title: ~~~, 
												~~~
											}, 
											from: {
												id: 12314421, 
												is_bot: false, 
												~~~ 
											},
											new_chat_memger: {~~~}, 
											~~~
										}
									}
								ㄴ 참조 ) https://core.telegram.org/bots/api#getting-updates
						</pre>
						ㄴ BOT API로부터 update 받아오기 <button>more</button>
						<pre>
							ㄴ BOT API를 사용하여 텔레그램 앱상에서 발생한 봇과 관련된 Update를 받아올 수 있다. 
							ㄴ ??? 새로 생긴 'Update'는 BOT API서버에? 저장되며 24시간동안 유지된다? 
							ㄴ JSON 형태의 Update object를 받게됨. 
							ㄴ 받는 방법 
								ㄴ BOT API의 getUpdates 메소드
									ㄴ ex ) 
										https://api.telegram.org/bot7940244695:AAFsSnah4hgRUsZ9d3dgPsKKAiwUKcEcY_k/getUpdates
									ㄴ 참조 ) https://core.telegram.org/bots/api#getupdates
								ㄴ Bot API의 setWebhook 메소드 
									ㄴ 임의의 URL을 정하고 Update가 생성될 때마다 Bot api서버가 이 URL로 해당 Update객체를 전송하도록 설정. 
									ㄴ 실패하는 경우, 몇번 재시도 해보고 안되면 무시된다함. 
									ㄴ 참조 ) https://core.telegram.org/bots/api#setwebhook
									ㄴ secret_token 파라미터 
										ㄴ 이 파라미터에  임의의 문자열을 넣어 webhook을 설정하면, 이때 설정된 웹훅에 의해 요청이 
											전송될 때마다 해당 request header의 'X-Telegram-Bot-Api-Secret-Token'필드에 
											이 secret_token값이 들어가 있게됨. 
										ㄴ 이를 통해 들어오는 request가 어떤 웹훅에 의해 전송된것인지 특정 가능. 
						</pre>

					</pre>

					ㄴ method 목록 <button>more</button>
					<pre>
						ㄴ 참고 ) https://core.telegram.org/bots/api#available-methods
						ㄴ api url 'https://api.telegram.org/bot< token>/(*method*)' 형식에서 (*method*)에 들어갈 메소드명들임. 
						ㄴ sendMessage 
							ㄴ 특정 채널 또는 그룹에 메세지를 전송. 
							ㄴ ~~~ 
						ㄴ ~~~ 

					</pre>
 
					ㄴ 라이브러리 
						ㄴ telegram Bot API를 사용하기 쉽게 구현해놓은 라이브러리들. 
						ㄴ 아주 간단한 기능들이면 http방식 사용해도 충분하지만 그게 아니거나 확장성을 위해선 
							라이브러리 사용하는게 좋다함. 
						ㄴ 목록 
							ㄴ python 
								ㄴ https://github.com/python-telegram-bot/python-telegram-bot
								ㄴ ~~~ 
							ㄴ java 
								ㄴ ~~~
							ㄴ ~~~ 

					ㄴ Bot Payments API 
						ㄴ 텔레그램 유저로부터 결제를 받을 수 있게 해주는 기능. 
						ㄴ 수수료 없음. 
						ㄴ ~~~
				</pre>

				ㄴ Telegram API 
					ㄴ ??? 

				ㄴ TDLib (Telegram Database Library) <button>more</button>
				<pre>
					ㄴ ??? 텔레그램의 주요 기능들을 구현하여 개발자가 라이브러리로서 사용 가능한 클라이언트 프로그램? 
						이를 빌드하여 개발자의 플젝에 포함시켜 텔레그램의 주요 기능들을 이 라이브러리를 사용함으로서 구현 가능하고 
						이를통해 텔레그램 기능을 가진 커스텀 앱을 쉽게 만들 수 있게 해줌? 
					ㄴ ??? 텔레그램 클라이언트 프로그램을 유저가 따로 개발 할 수 있도록 도와주는 라이브러리? 
						서버단 동작은 텔레그램을 그대로 사용? 
					ㄴ ??? 텔레그램 앱과 동일한 텔레그램 서버를 통하여 동작하므로 
						텔레그램 앱과도 통신 가능? 
					ㄴ build 
						ㄴ 문서에선 특정 사이트보고 그대로 하면 된다함. 
							ㄴ https://tdlib.github.io/td/build.html
						ㄴ tdlib을 사용할 때 사용할 언어, os 등에 따라 어떻게 빌드해야 하는지 상세히 나옴. 
							ㄴ 대략, tdlib 빌드 및 실행에 필요한 의존성 프로그램들 설치해주고 
								(페이지에 나옴. os에 맞는 프로그램명 찾아 dnf 등으로 설치하면됨)
								명령어 따라해주면됨.  
					ㄴ ???api id ? 
						ㄴ https://my.telegram.org/ 에서 api_id, api_hash 등 확보 가능. 
					ㄴ 기본 개념? 
						ㄴ 'message'는 'chat'에 속함. 
						ㄴ 'chat'내에서 각 'message'는 고유의 식별번호를 부여받음. 
						ㄴ 'chat'내에서 'message'는 식별번호순으로 정렬. 
						ㄴ 'message' 유형 다양. 텍스트, 포토 등. 
						ㄴ 텔레그램 유저는 'user' 라 불림. 
						ㄴ 'user'는 필수로 'first name'을 가짐. 
						ㄴ 'user'는 옵션으로 'last name', 'username', 'porfile photo'를 가짐. 
						ㄴ 텔레그램 봇은 'user'의 특별한 유형. 
						ㄴ 'chat'은 'member'를 가짐. 
							ㄴ 'user' 등. 
						ㄴ 'chat' 내의 'member'들은 6가지 종류의 상태값 가짐. 
							ㄴ 'chat의 owner'부터 'banned된 유저' 등. 
						ㄴ 'chat' 유형 
							ㄴ private chat 
								ㄴ 1:1 'chat'
							ㄴ basic group 
								ㄴ 0~200명의 member를 가지는 basic group. 
								ㄴ member별로 각각의 message history 가짐. 
									ㄴ 따라서 새로 들어온 멤버는 들어오기 이전 history없을 수 있음. 
							ㄴ supergroup 
								ㄴ 20만명까지 member 가능한 group. 
								ㄴ 모든 member가 하나의 message history 공유. 
									ㄴ 따라서 새로 들어온 멤버도 기존멤버들과 동일한 history 볼 수 있음. 
								ㄴ 'broadcast', 'channel'
									ㄴ supergroup의 특별한 종류. 
									ㄴ 제한된 수의 멤버. 
									ㄴ chat 생성자 또는 관리자만 메세지 작성 가능. 
									ㄴ 그 외 멤버들은 메세지 읽기만 가능. 
							ㄴ secret chat 
								ㄴ??? end-to-end 암호화 1:1 chat? 
								ㄴ??? 이 'chat'을 초기화하거나 받아들인 기기에서만 ㅣ용ㅇ 가능?> 
						ㄴ 'chat'은 '고유 식별자' 값과 '제목'값을 필수로 가짐. 
						ㄴ 'chat'목록은 각 'chat'은 채팅의 최신 활성 시간에 따라 정렬되어 유저에게 리스팅됨. 
						ㄴ ??? The correct order of chats in chat lists is maintained by TDLib, so the Application only needs to listen to updates that change the chat.positions field and sort all chats by the pair (position.order, chat.id) in a given position.list.
						ㄴ 
					ㄴ interface 
						ㄴ 
					ㄴ Update 
						ㄴ tdlib으로 telegram의 'update'가 전달되는 방식 
							ㄴ ~~~??? 
						ㄴ 각 언어의 tdlib wrapper 모듈 사용하면 간단하게 받을 수 있음. 
						ㄴ update 객체 목록 
							ㄴ updateNewMessage 
								ㄴ telegram의 'message' 객체 포함. 
							ㄴ ~~~ 
					ㄴ api 
						ㄴ 메소드 <button>more</button>
						<pre>
							ㄴ getChatHistory <button>more</button>
							<pre>
								ㄴ getChatHistory(	
										int53 	chat_id_,
										int53 	from_message_id_,
										int32 	offset_,
										int32 	limit_,
										bool 	only_local_ 
									)		
								ㄴ chat에서 메세지목록을 시간 역순으로 가져와 반환하는 메소드. 
									가장 최신 메세지가 먼저오고 오래될수록 뒤에 오는식. 
								ㄴ 인자 
									ㄴ chat_id : chat식별자값. 
									ㄴ from_message_id : 가져올 메세지 목록의 시작 메세지 식별값. 즉, 이 식별값의 메세지부터 시간역순으로 
										가져오게됨. 
										0 설정시, 가장 최신 메세지부터 가져옴. 
									ㄴ offset 
										ㄴ from_message_id에서 설정한 메세지로부터 offset값만큼 떨어진 메세지부터 가져오기 시작. 
										ㄴ 음수값으로 설정하며, 음수값이 클수록 from_message_id가 나타내는 메세지보다 나중에(시간적으로 이후에)
											생성된 메세지를 가리키게됨. 
											ㄴ ex ) 
												메세지가 A, B, C, D, E, F 가 순서대로 생성됐다치면, 
												from_message_id를 C로 지정하고 offset을 -2로 지정하면, 
												가져오는 메세지 목록은 C에서 2개 뒤의 메세지인 E부터 시작하게됨. 
												E, D, C, B, A 이런식으로. 
										ㄴ 0 설정시, 당연히 from_message_id에서 지정한 메세지부터 가져오기 시작. 
									ㄴ limit 
										ㄴ 반환받을 메세지 최대 개수. 
										ㄴ ??? 설정은 하지만, 성능상의 이유로, 반환받을 메세지 개수는 TDLib에 의해 결정된다? 
											따라서, 설정한 값보다 작을 수 있다? 
									ㄴ ??? only_local 
							</pre>
							ㄴ createNewBasicGroupChat 
								ㄴ 새 'basic group' 생성. 
							ㄴ createNewSupergroupChat 
								ㄴ 새 'supergroup' 또는 'channel' 생성. 
								ㄴ 제목, 채널 여부, 포럼 여부 등만 생성과함께 설정 가능하ㅗㄱ 
									채널타입, 권한 등은 별도 메소드로 설정해야하는 듯. 관련 설정값 없음. 
							ㄴ addChatMembers 
								ㄴ chat에 멤버 추가. 
							ㄴ setChatMemberStatus 
								ㄴ chat 멤버의 설정값 설정. 
								ㄴ 특정 봇이 채널에 들어가있지 않아도(원래 채널엔 봇은 일반 멤버로 못들어오긴함) 
									이걸로 관리자로 설정하면 채널에 추가되는듯. 
							ㄴ searchPublicChats 
								ㄴ ??? username, title에 대한 쿼리 인자값으로 public chat 검색? 
							ㄴ setChatPhoto 
								ㄴ chat의 프로필 이미지 변경? 
								ㄴ basic group, supergoup, channel에만 적용. 
							ㄴ sendMessage 
							ㄴ forwardMessages
								ㄴ chat의 메세지를 다른 chat으로 포워딩. 
								ㄴ 해당 채널이 'restrict saving content' 설정이 돼있으면 불가. 
							ㄴ setChatMemberStatus
							ㄴ ~~~

						</pre>
						ㄴ 참고 
							ㄴ https://core.telegram.org/tdlib/docs/classtd_1_1td__api_1_1_function.html
					ㄴ class 
						ㄴ message 
							ㄴ 
						ㄴ 참고 
							ㄴ https://core.telegram.org/tdlib/docs/classtd_1_1td__api_1_1update_new_message.html
					ㄴ python-telegram module <button>more</button>
					<pre> 
						ㄴ https://github.com/alexander-akhmetov/python-telegram?tab=readme-ov-file
						ㄴ tdlib의 json interface를 python으로 사용할 수 있게하는 wrapper 프로그램. 
							내부적으로 tdlib의 인터페이스 중 하나인 TDJson을 호출하는식으로 동작. 
						ㄴ 조건 
							ㄴ python 3.9이상, 
							ㄴ linux, macos. (윈도우 안됨) 
						ㄴ 기본 사용법 
							ㄴ ~~~ 
							ㄴ telegram.client의 Telegram 인스턴스 생성. 
								ㄴ ex ) 
									from telegram.client import Telegram, AuthorizationState

									tg = Telegram(
										api_id='api_id',
										api_hash='api_hash',
										phone='+31611111111',
										database_encryption_key='changeme1234',  # ??? 암거나 넣어도 동작은함. 
									) 
							ㄴ Telegram인스턴스에서 call_method( (*tdlib의 메소드명*), (*메소드에 전달할 인자*), (*block여부*) ) 호출하여 
								tdlib의 메소드 호출시킴. 
								ㄴ telegram.utils.AsyncResult 반환. tdlib method의 반환값이 이 객체안으로 반환됨. 
								ㄴ (*block*) true시, 메소드가 동기식으로 동작. 즉, 결과 반환받을 때까지 실행흐름 멈춤. 
									false이면 이후 결과 도착시 AsyncResult으로 결과가 들어옴. 
							ㄴ 메소드 반환값의 update속성에 결과 확인. 
							ㄴ 반환될때까지 기다리리면 반환값의 wait() 호출. 
							ㄴ 메소드와 메소드에 필요한 인자는 docs참고. (https://core.telegram.org/tdlib/docs/classtd_1_1td__api_1_1_function.html) 
								ㄴ 인자는 dict형태로 전달 가능. 
								ㄴ 인자가 특정 클래스 인스턴스인 경우, 중첩 dict형태로 전달 가능. 
						ㄴ ex ) 
							tg = Telegram(
								api_id='api_id',
								api_hash='api_hash',
								phone='+31611111111',
								database_encryption_key='changeme1234',  # ??? 암거나 넣어도 동작은함. 
							)
							tg.login() 

							result = tg.cal_method("searchPublicChats", {"query": "stock", }) 
							result.update 
							
						ㄴ ~~~
						ㄴ 참고 
							ㄴ https://python-telegram.readthedocs.io/main/non_blocking_login.html
					</pre>

					ㄴ ~~~ 
					ㄴ 실무 
						ㄴ python-telegram module을 통한 TDLib 사용시 
							'libssl.so.1.1: cannot open shared object file: No such file or directory' 오류 발생 이슈. 
							ㄴ python-telegram의 Telegram 인스턴스 생성시 발생. 
							ㄴ 추측 원인 
								ㄴ tdlib이 openssl 1.1.1버전을 필요로 하는 듯. 
									ㄴ 구글링해보니 대부분 openssl 1.1.1을 설치함으로서 해결했다고 나옴. 
									ㄴ https://stackoverflow.com/questions/72133316/libssl-so-1-1-cannot-open-shared-object-file-no-such-file-or-directory
							ㄴ 해결 
								ㄴ 구글링에 나오는 openssl 1.1.1 설치 방법에 따라 openssl 설치. 
									ㄴ 참조 
										ㄴ https://docs.openiam.com/docs-4.2.1.3/appendix/2-openssl
										ㄴ https://gist.github.com/Bill-tran/5e2ab062a9028bf693c934146249e68c
										ㄴ https://velog.io/@mimic1995/rocky9-openssl-%EA%B5%AC-%EB%B2%84%EC%A0%84-%EC%86%8C%EC%8A%A4-%EC%84%A4%EC%B9%98
									ㄴ 환경변수 추가 
										ㄴ PATH의 앞부분에 새로 설치한 openssl bin경로 추가. 
											ㄴ PATH=/usr/local/openssl/bin:$PATH 
										ㄴ 환경변수 LD_LIBRARY_PATH 추가. 새로설치한 openssl의 lib 경로 가리키도록. 
											ㄴ export LD_LIBRARY_PATH=/usr/local/openssl/lib 
											ㄴ 안할경우, libssl.so.1.1 못찾겟단 오류. 
									ㄴ 이슈 
										ㄴ openssl make시, 
											'Can't locate File/Compare.pm in @INC (you may need to install the File::Compare module)' 오류 
											ㄴ File/Compare.pm 뿐 아니라, Pod/Html.pm 등 여러가지로 발생. 
											ㄴ 해결 
												ㄴ 필요한 프로그램들 설치. 
													ㄴ dnf install perl-IPC-Cmd, dnf install '*/Compare.pm'
														dnf install '*/Copy.pm' 
														dnf install perl-Pod-Html 등. 
						ㄴ getChat 등의 메소드 사용시, 본인이 생성한 private채널을 검색한 경우, chat not found 오류 뜰때 있음. 
							ㄴ 정확한 이유 모르겠으나, getChats() 에 limit 크게 주어 한번 전체 채널 로딩하고나면 정상적으로 채널 찾아짐. 
						ㄴ ~~~

					ㄴ 참고 
						ㄴ https://core.telegram.org/tdlib
						ㄴ https://core.telegram.org/tdlib/getting-started

				</pre>

				ㄴ Gateway API 
					ㄴ 텔레그램을 통해 인증코드를 보내고, 텔레그램 상에서 받게 해주는 기능. 
					ㄴ SMS를 통한 인증번호 대체 가능. 
					ㄴ 더 보안이 좋고 빠르고 저비용이라함. 
					ㄴ ~~~ 

				ㄴ Telegram Widgets 

				ㄴ source code 
					ㄴ 

			</pre>

			ㄴ LLM 서비스 관련 
				ㄴ openai <button>more</button>
				<pre>
					ㄴ ~~~ 
					ㄴ 주요 개념 
						ㄴ 명령 권한 레벨 
							ㄴ 어떤 명령을 우선적으로 고려하여 응답할지 설정 가능한 기능. 
							ㄴ authority의 level 목록 
								ㄴ platform 
									ㄴ llm이 수행하면 안되는 것들에 대한 금지 명령으로 주로 구성. 비윤리적, 불법적 등. 
									ㄴ 다른 level에서 override불가. 
								ㄴ developer 
								ㄴ user 
				</pre>
				ㄴ gemini 
				ㄴ Claude api <button>more</button>
				<pre>
					ㄴ 클로드 챗과 api 별도. 
					ㄴ 크레딧을 선불 구매 & 보유한 크레딧 소모하여 api 또는 Workbench 사용 가능. 
					ㄴ anthropic 콘솔에서 크레딧 구매, 사용량 확인, 사용량에 따른 이메일 알림 기능 가능. 
					ㄴ sdk 
						ㄴ python 
							ㄴ https://github.com/anthropics/anthropic-sdk-python
				</pre>
				ㄴ 비교 
					ㄴ api지원여부, context길이 제한, 비용 등 명확히 구분되는 기능을 제외한 응답 품질은 약간씩 차이점이 있는 정도같다. 

		</pre>

		IDE<button>펼치기</button>
		<pre>
			ㄴ Intellij

			ㄴ Visual Studio Code <button>more</button>
			<pre>
				ㄴ 단축키
					ㄴ 단축키 설정 : 컨트롤 + k, ctrl + s
					ㄴ 터미널 창 : ctrl + `
					ㄴ 사이드바 창 : ctrl + b
					ㄴ 행삭제 : ctrl + shift + k
					ㄴ 아래에 행 삽입 : ctrl + enter
					ㄴ 행복사 : shift + alt + up, shift + alt + down
					ㄴ 에디터
						ㄴ 코드 접기
							ㄴ 코드 fold, unfold : ctrl + shift + [ (접기) , ctrl + shift + ] (펼치기)
							ㄴ 전체 접기 : ctrl + k, ctrl + 0
							ㄴ 전체 펼치기 : ctrl + k, ctrl + j
							ㄴ 현재 커서 속한 영역 recursive 접기 : ctrl + k, ctrl + [
							ㄴ 현재 커서 속한 영역 recursive 펼치기 : ctrl + k, ctrl + ]
							ㄴ n 단계 접기 : ctrl + k, ctrl + (*숫자n*) 
					ㄴ 편집기 왼쪽, 오른쪽 이동 : ctrl + shift + pageup, pagedown
					ㄴ 전체 검색 : ctrl + shift + f
					ㄴ 디버그 시작 : f5
					ㄴ 일반 시작 : ctrl + f5
				ㄴ launch.json
					ㄴ 디버깅 설정 파일. 디버깅 및 파일 실행 관련 여러 설정들 명시. 
					ㄴ 생성 방법
						ㄴ 플젝 루트 하위에 .vscode 폴더 안에 launch.json 파일 생성. 
						ㄴ 또는 좌측 '실행 및 디버그' 에서 launch.json 파일 생성하고
							이 파일에서 '구성 추가' 버튼 클릭하여 디버깅 설정 하나 추가.
					ㄴ ex ) launch.json 파일 예시. 구성 하나 추가할 때마다 configurations의 요소 하나 추가.
						{
							// IntelliSense를 사용하여 가능한 특성에 대해 알아보세요.
							// 기존 특성에 대한 설명을 보려면 가리킵니다.
							// 자세한 내용을 보려면 https://go.microsoft.com/fwlink/?linkid=830387을(를) 방문하세요.
							"version": "0.2.0",
							"configurations": [
								{  // 파이선 파일 모듈로 실행. 
									"name": "공시데이터",
									"type": "debugpy",
									"request": "launch",
									"cwd": "${workspaceFolder}/..",  // workingDirectory 상위 폴더로 설정. 모듈로 실행하는거라 플젝 루트로 하면 모듈 못찾음? 
									"python": "${workspaceFolder}/venv/Scripts/python.exe",
									"module": "scraping.noname.dart_and_daishin.getOriginalFile"  // 모듈명. 
								},
								{
									"name": "Python 디버거: 현재 파일",  // vscode상에 표시되는 이름.
									"type": "debugpy",
									"request": "launch",  // 디버깅 시작할 모드? 설정. launch시, 'program'에 명시된 파일으로 디버깅 시작.
									"program": "${file}",
									"console": "integratedTerminal"
								},
								{
									"name": "Python 디버거: 프로세스 ID를 사용하여 연결",
									"type": "debugpy",
									"request": "attach",
									"processId": "${command:pickProcess}"
								},
								{
									"name": "Python 디버거: Django",
									"type": "debugpy",
									"request": "launch",
									"args": [
										"runserver"
									],
									"django": true,
									"python": "C:\\Users\\tony7\\PycharmProjects\\venv\\Qsee_venv\\Scripts\\python.exe",  // 실행할 interpreter.
									"autoStartBrowser": false,
									"program": "${workspaceFolder}\\manage.py"
								}
							]
						}
					ㄴ launch.json에서 사용가능한 변수 목록
						ㄴ https://code.visualstudio.com/docs/editor/variables-reference
						
					ㄴ python Debugging
						ㄴ python을 디버깅하고자 하면 'python debugger' extension 설치 필요.
					
				ㄴ extension <button>more</button>
				<pre>
					ㄴ copilot X  <button>more</button>
					<pre>
						ㄴ 사용법
							ㄴ 코파일럿 구독 및 extension 설치. 
							ㄴ 코드 제안
								ㄴ 함수 정의 부분 작성시, 또는 코드 작성시, 
									함수 몸체나 이후에 올 내용을 제안함. 
								ㄴ tab키로 수용. 또는 alt + [, alt + ] 키로 다른 제안 확인 가능. 
								ㄴ ctrl + 오른쪽 화살표 로 한 단어씩 수용 가능. 
								ㄴ cntl + enter 로 editor 새 창 띄우고 전체 제안 목록 볼 수 있음. 
							ㄴ chat 
								ㄴ extesion 설치	
								ㄴ chat 창에서 chatgpt처럼 사용 가능. 
								ㄴ prompt 내용에 '#editor' 와 같은 식으로 사전 정의된 키워드 사용 가능. 
									ㄴ #editor : 현재 활성화된 editor 탭을 가리킴. 
									ㄴ #selection : 현재 선택된 텍스트를 가리킴. 블럭씌운거. 
									ㄴ #file : 입력시마다 파일 하나를 지칭 가능. 
								ㄴ 그 외 '/help' 입력하여 추가 사용법 확인 가능. 
						ㄴ 참조
							ㄴ https://docs.github.com/ko/copilot
					</pre>
					ㄴ git graph 
				</pre>
				
				ㄴ 참조
					ㄴ https://code.visualstudio.com/docs
			</pre>

		</pre>

		통계<button>more</button>
		<pre>
			ㅡ ~~~~~
			ㅡ 중앙값 : 데이터 항목들 중 인덱스 가운데 위치한 항목의 값??
			ㅡ 확률 변수 : 특정 확률로 일어나는 각 사건의 결과들을 임의의 수치값으로 표현한 변수.
				ㄴ 가령, 동전 두개를 던지는 경우를 봤을 때, 모든 사건의 경우에 대해서 나오는 앞면의 개수를 실수로 표현하면 0,1,2가 되며
					이걸 사건의 결과들을 임의의 수치값으로 표현하였다고 볼 수 있다.
				ㄴ 종류 )
					ㄴ 이산확률 변수 : 확률변수가 가질 수 있는 값이 '가산 개'인 것. 자연수같이 셀 수 있다고.
					ㄴ 연속확률 변수 : 확률변수가 가질 수 있는 값이 어떤 범위에 속하는 모든 실수값인 경우.
			ㅡ 상태공간, 확률 변수가 취하는 모든 실수들의 집합.
				ㄴ 이 상태공간 안의 특정 값이 나올 가능성은 확률로 계산될 수 있다.
			ㅡ 확률 분포, 확률 함수
				ㄴ 확률 함수란, 확률 변수에서 특정한 값을 입력하면 그 값이 발생할 확률을 나타내는 함수.
					ㄴ 가령 동전두개 던지기에서, 앞면의 개수를 확률변수로 수치화했다면, 앞면의 개수가 2개(확률변수의값이 2)나올 확률은 1/4가 된다.
				ㄴ 확률 분포란, 이런 확률 함수에서 확률 변수의 값과 그 확률을 분포로 나타낸 것. 정규분포 등.
			ㅡ 기댓값
				ㄴ 확률변수의 기댓값. 그 확률변수의 사건들에 대한 확률변수 값의 평균이라고 생각하면 된다.
				ㄴ 모든 사건들에 대해 (*확률변수의 값*) * (*그 값에 해당하는 확률*) 을 모두 더한 값이다.
			ㅡ 사분편차
				ㄴ 전체 분포에서 1/4에 해당하는 값부터 3/4에 해당하는 값의 차를 절반으로 나눈 것.
					ㄴ 즉, 전체 분포를 4등분하여 중간 두개의 쿼터 중 하나를 나타낸다.
			ㅡ 편차
				ㄴ 개별 항목의 값과 평균의 차이. (*개별값*) - (*평균*) 으로 계산
				ㄴ 분산 : 데이터의 분포에서 편차가 얼마나 되는지를 알기 위해 편차의 제곱을 모두 더해 총 항목의 개수로 나누어준 값.
					ㄴ 전체 분포에서 얼마나 퍼져있는지를 알고 싶은데, 이를 편차를 모두 더해 평균내서 계산하자니 편차의 합이 0이 되기때문에
						생각한 방법이라함.
				ㄴ 표준편차 : 분산에 제곱근을 취해준 값.
					ㄴ 분산을 이용해 분포가 얼마나 퍼져있는지 확인할 수 있지만, 제곱을 하였기 때문에 단위가 다름. 해서 제곱근을 취해줌.
			ㅡ 정규분포
				ㄴ 확률 분포의 종류 중 하나? 그냥 확률 분포가 이런 형태를 따르는게 많다고하며 이런 정규 분포가 가지는 특징들이 있다.
				ㄴ 표준 정규분포 : 많은 데이터들의 분포가 정규분포를 따르지만, 이들끼리 비교하기가 여럽다. 하여 평균과 표준편차를 0, 1로 맞추어
								비교하기가 쉽게 만든 정규분포이다.
			ㅡ 공분산
				ㄴ 확률 변수가 두 가지일때, 두 변수 사이의 상관관계를 확인할 수 있는 값.
					ㄴ 양수이면, x증가시 y도 증가한다 말할 수 있다.
				ㄴ 이를 이용하여 '상관계수'를 구한다.
				ㄴ ?????
		</pre>

		코드<button>more</button>
		<pre>
			ㅡ 클린 코드의 필요성
				ㄴ 코드 작성 후, 평생 다시 볼일이 없으면 상관 없지만,
					이후 다시 보거나 수정이 필요하거나 재사용을 하게 될 시,
					코드가 잘 정리되지 않고 지저분할 수록 파악 및 수정 작업이 더 buggy하고 오래 걸린다.
				ㄴ 무조건은 아니지만 프로그램에 수정은 한번 쓰고 버릴 프로그램이 아니라면 있을 확률이 크다.
				ㄴ 개인적인 경험으로는, 개발 완료 후 수정할 때 뿐만 아니라 개발 중에도 조금 코드가 길어지면 비슷한 현상을 겪는 것같다.
					코드가 길고 복잡하여 파악이 어렵고 오래걸리고 수정이 어렵고 buggy하다.
			ㅡ 클린 코드에 있어서 주요한 요소 )
				ㄴ 가독성 )
					ㄴ 변수명이 난해하거나 로직이 단순명쾌하지 않은 것.
					ㄴ 시작 단계인 코드 파악이 어려워 오래걸리고 실수를 유발함.
				ㄴ 정돈, 묶여 있지 않고 여기저기 흩어져 있거나 중복된 경우 )
					ㄴ 높은 buggy. 흩어진 코드 중 놓치는 경우가 생겨 오류 발생.
					ㄴ 가독성에도 좋지 않음.
				ㄴ 의존성
					ㄴ 의존성이 많을 수록 수정시 연달아 수정이 필요한 부분이 많고, 버그 발생시 연달아 문제가 생기는 부분이 많다.
				ㄴ 등등.. 딱 어떤게 어떤점을 유발해서 문제가 된다기보단
					이런 여러 요인들이 복합적으로 수정에 있어서 악영향을 끼치는 것.
					해서, 이런 요인들에 유의하면 되겠다.
			ㅡ 아름다울 필요까지는 없을 것 같다. 그정도로 중요도가 높거나 영향력이 크지는 않을 것 같다.
				단지, 지저분해서 문제가 생길 정도는 아니어야 한다.
			ㅡ 중복, 변수명, 적절한 크기 및 단일책임 묶음(함수 또는 클래스), 의존성, 

			ㅡ 책 "클린 코드"<button>more</button>
			<pre>
				ㄴ 1. 깨끗한 코드<button>more</button>
				<pre>
					ㄴ 나쁜 코드의 문제점 : 단기적으로는 모르겠지만, 장기적으로 보았을 때
						깔끔하지 않고 지저분한 코드 때문에, 코드 파악, 수정에 많은 비용이 들고 후에는, 버그를 감당할 수 없어진다?
						ㄴ 지금 당장 그 부분을 개발하는 데에는 빠를지 몰라도, 이후 이 지저분한 부분과 조금이라도 연관이 있는
							부분을 하게 된다면 바로 역효과가 나타날 것.
						ㄴ 따라서, 시간이 조금 더 걸리더라도 좋은 코드를 작성해야 한다. 장기적으로 볼 때 그 조금 더 든 시간 보다
							많은 시간을 아껴줄테니.
					ㄴ 좋은 코드에 대한 대가들의 생각
						ㄴ 적은 의존성, 깔끔하고 명쾌한 논리
						ㄴ 글처럼 잘 읽히는, 깨끗한 코드, 단순명료한 로직.
						ㄴ 중복을 피해라, 한 가지 기능만 해라.
					ㄴ 이 책은 책을 집필한 사람들이 생각하는 '좋은 코드'에 관한 내용이다. 즉, 절대적인 기준이 아니다.
				</pre>
				ㄴ 2. 의미 있는 이름<button>more</button>
				<pre>
					ㄴ 명확하게 이름으로 대상을 파악할 수 있게 해라.
					ㄴ 가까운 범위 안에 유사한 이름을 사용하지 마라.
					ㄴ 이름에서 불필요한 정보를 제공하는 부분은 제외하라.
					ㄴ 클래스 이름은 명사, 함수 이름은 동사.
					ㄴ 같은 개념에 일관성 있는 단어를 사용하라. (가져온다는 함수 이름으로 get, retrieve, fetch 등을 이것 저것 쓰지 말란 것)
				</pre>
				ㄴ 3. 함수<button>more</button>
				<pre>
					ㄴ '의미 있는 이름'으로 무슨 일을 하는지 파악할 수 있어야 한다.
					ㄴ 한 가지 일을 해야 한다.
						ㄴ 이름으로 파악할 수 없는 다른 일을 수행하면 안 된다.
						ㄴ 오류 처리도 '한 가지 일'에 해당된다. 따라서 try/catch문으로 가독성을 떨어뜨리지 말고 오류 처리 또한 새로운
							함수로 빼내어야 한다.
					ㄴ 명확하고 쉽게 읽히기 위해 함수는 '짧아'야 한다.
						ㄴ 무조건 작을 수록 좋다고 한다. 10줄 이내, 4,5줄..?
					ㄴ 들여쓰기, 즉, 중첩구조를 사용할 수록 안 좋다. 파악하기 어렵다. 1,2단을 넘어가선 안된다.
					ㄴ 함수를 적절히 분리하고 적절한 이름을 짓는다면 함수들을 이용해 줄일 수 있다.
					ㄴ 추상화의 수준이 같아야 한다.?????
						ㄴ
					ㄴ 인수가 적을 수록 좋다?????
						ㄴ 인수는 코드를 이해하기 어렵게 만든다?????
							ㄴ 순서
							ㄴ 출력인수(인자로 받은 값을 반환하는 것)는 함수를 이해하는 데 어려움을 준다.
						ㄴ 인수가 많을 수록 테스트 하기 어렵다.
						ㄴ 최대한 인수를 줄이거나 객체를 만들어 넘기거나
					ㄴ 반복하지 마라.
						ㄴ 코드가 길어져 이해하기 어려워지고, 똑같은 것을 여러번 고쳐야 하므로 수정에 드는 시간과 버그 가능성이 늘어난다.
					ㄴ 일단 코딩하고 리펙토링 하는 것..?????
					ㄴ 예제 최종 수정본(목록3-7)
						ㄴ 길게 늘여쓸 코드를 이런식으로 위 원칙들대로 함수화하여 코딩하는 것.
						ㄴ 확실히, 길게 늘여쓰고 추상화의 단계가 뒤섞여 있는 것보다는 로직을 파악하기 쉬울 것 같다.
						ㄴ 함수들이 너무 많은 게 개인적으로 불편하긴 하다.
						ㄴ 오로지 가독성을 위해서 이렇게까지 해야 하나 싶기도 하다. 재사용성도 한두개 얻어 걸릴 수는 있어도 딱히 좋을 것
							같지는 않다.
							가독성만을 위해 길게 늘여쓸 코드들을 부분 부분 떼어내어 함수로 만들고 이름을 붙인 느낌이다. 물론, 가독성
							측면에서는 좋은 것 같다.
							ㄴ 의존성 측면에서는?
								ㄴ 그 수행하는 한가지 일을 담당하는 부분만 수정하면 되므로 더 좋은가..??
							ㄴ 재사용하지 않을 함수가 저렇게 쭉 나열되어 있으면 가독성이 오히려 더 떨어질 것 같은데, 이함수 저함수
								돌아다니며 로직을 파악해야 하고.
								차라리 단순명료한 로직과 변수명에 신경써서 한눈에 볼 수 있게 하는 게 낫지 않을까.
							ㄴ 재사용성, 모듈화에 딱히 좋을 것 같지가 않다..?

				</pre>
				ㄴ 주석 <button>more</button>
				<pre>
					ㄴ 주석은 코드를 제대로 작성을 못 했을 때, 이를 보완하기 위해 쓰게 되는 것.
						즉, 코드가 알아먹기 어렵고 지저분해서 설명을 덧붙이는 것이고, 따라서 지양해야 하는 것이라고 한다.
						주석을 달 바에 코드를 다시 짜라고 한다.
					ㄴ 주석은 유지보수하기가 힘들다. 개발자가 주석까지 유지보수를 할 것이라 기대하기는 어렵다.
						따라서, 시간이 지날 수록 주석은 해당 코드와 동떨어지게 된다.
					ㄴ ~~~~~
				</pre>
				ㄴ 형식 맞추기
					ㄴ ~~~~~
				ㄴ 객체와 자료구조<button>more</button>
				<pre>
					ㄴ
				</pre>
				ㄴ 오류 처리<button>more</button>
				<pre>
					ㄴ ~~~~~
					ㄴ null을 반환하지 마라
						ㄴ null 체크가 필요해지고 이는 코드를 지저분하게 만든다.
				</pre>
				ㄴ 단위 테스트<button>more</button>
				<pre>
					ㄴ
				</pre>
				ㄴ 클래스<button>more</button>
				<pre>
					ㄴ 객체지향에 대해 더 공부하고 보는 게 좋을 것 같다.
				</pre>
				ㄴ 시스템<button>more</button>
				<pre>
					ㄴ 프로그램의 전체적인 시스템 수준에서도 깨끗한 코드를 유지하는 것에 관해 다룬다.
					ㄴ 시스템 제작과 사용을 분리하라
						ㄴ 시스템 제작이란 프로그램에서 사용될 객체들의 생성과 초기화?를 말 하는 듯하고
							시스템 사용이란 이러한 객체들을 사용하여 프로그램의 로직이 실제로 돌아가는 것을 말하는 듯 하다.
						ㄴ ex)
							public Service getSerivce(){
								if(service==null){
									service = new ServiceImpl( ~~~~~ );
								}
								return service
							ㄴ 위와 같이 함수 안에 객체 생성 로직(시스템 제작 로직)과 service를 반환하는 로직(시스템 사용 로직)이 섞이게 하지 말라함.
						ㄴ 이를 분리하기 위한 방법 : main 분리
							ㄴ main이나 main에서 호출하는 곳에서 시스템 제작과 관련한 로직을 모두 처리하는 것.
								ㄴ 즉, main부분에서 사용할 객체들을 모두 생성해 놓고 런타임 로직에서는 이를 사용하기만 하는 것.
						ㄴ 분리하기 위한 방법2 : 추상 팩토리 패턴?????
							ㄴ
						ㄴ 분리하기 위한 방법3 : 의존성 주입?????

				</pre>
			</pre>

			ㅡ 리책터링 2판, 마틴 파울러<button>more</button>
			<pre>
				ㄴ 리펙터링이란 )
					ㄴ '설계를 하고 코딩'을 하는 것이 아닌,
						'코딩을 하고 설계를 개선하는 것'을 말함.
					ㄴ 프로그램 동작은 그대로 유지하면서 코드를 더 이해하고 수정하기 쉽게 바꾸는 것. 
				ㄴ 리팩터링 첫 단계는 테스트 코드 준비. 
					기능은 그대로 두고 구조만 변경하는 리팩토링을 진행한 후, 코드 수정으로 인한 기능상의 문제가 생기지 않았는지 확인 필요하므로. 
				ㄴ 리팩토링과 성능 
					ㄴ 리팩토링으로 인해 성능 이슈가 발생할 수 있으나, 
						드문 경우이고, 대게 성능보다 코드가 깔끔하게 정돈되어 있는게 나은 경우가 많다. 
						일단, 리팩토링을 먼저 진행 후, 성능 이슈가 나타나면 그때 최적화를 하는게 권장 순서. 
				ㄴ 문제가 되는 코드 목록 ('악취 코드' 목록) <button>more</button>
				<pre>
					ㄴ 기이한 이름
					ㄴ 중복 코드 
						ㄴ 같은 기능을 하는 코드가 여러곳에 중복되어 있는 경우, 이 기능을 수정하려면 
							이 중복되는 코드들을 모두 여러번 수정해야 하고, 다른점이 없는지 확인해야함. 이 과정에서 버그가 유발. 
					ㄴ 긴 함수 
						ㄴ 함수 본문이 길어지면 그 함수가 무슨일을 하는지 파악하기 어려워짐. 
						ㄴ 짧은 본문과 하는 일에 대한 명확한 함수명으로 함수가 하는 일을 파악하기 쉽게 해야함. 
					ㄴ 많은 매개변수 
						ㄴ 다른 변수에서 값을 얻을 수 있는 데이터는 질의함수로 대체, 객체 통째로 넘기기, 등으로 처리
					ㄴ 전역 데이터. 
						ㄴ 어디서든 접근, 수정이 가능해 버그가 발생하기 쉽고 찾기도 어렵다. 
					ㄴ 가변 데이터???
					ㄴ 듸엉킨 변경. 
						ㄴ 한 모듈이 여러가지 이유에 의해 변경이 필요한 경우를 말함. 
						ㄴ 단일책임 원칙이 지켜지지 않아 발생. 
					ㄴ 산탄총 수술. 
						ㄴ 하나의 변경사항을 위해 여러 부분이 변경이 필요한 경유. 
					ㄴ 기능 편애. 
						ㄴ 컴포넌트가 적당한 영역을 기준으로 영역 내부의 캄포넌트보다 외부와 상호작용이 더 많은 경우. 
						ㄴ 뭐가 문제인지 잘 모르겠다. 
					ㄴ 데이터 뭉치. 
						ㄴ 관련있는 대이터들이 항상 뭉쳐서 변수로서 사용되는 경우. 이들을 묶어서 사용. 
					ㄴ 기본형 집착. 
						ㄴ 프로그램에서 사용할 더 적절하고 편리한 자료형을 만들지 않고 무조건 원시타입으로만 사용하려는 경우. 
						ㄴ swich문???
						ㄴ 반복문???
					ㄴ 성의없는 요소. 
						ㄴ 굳이 하는일 없이 필요없는 클래스, 함수, 인터페이스 등이 그대로 있는 경우. 
					ㄴ 추측성 일반화. 
						ㄴ 막연하게 '나중에 필요할 거야'란 생각으로 작성된 경우. 
					ㄴ ??? 임시 필드. 
					ㄴ ??? 메시지 체인. 
					ㄴ ~~~
				</pre>
				
				ㄴ 테스트 구축하기 
					ㄴ 

				ㄴ 리팩토링 방법 목록 <button>more</button>
				<pre>
					ㄴ 함수 추출하기 
						ㄴ 함수 본문을 보고 무슨일을 하는지 파악하기 어렵다면, 해당 코드를 함수로 추출하고 적절한 함수명을 붙여 
							무슨일을 하는지 파악하기 쉽도록 함. 
						ㄴ '하는 일'에 대한 책임 분리도 됨. 
					ㄴ 함수 인라인하기 
						ㄴ 코드에서 표현식이 너무 길게 늘여져서 사용되는 경우, 그 표현식 자체나 그 중간값을 적절한 이름의 지역변수로 만들어서 사용. 
						ㄴ 그 표현식이 함수 안에서만 의미를 가지면 변수로 만들 수 있고 함수 밖에서도 똑같이 의미있게 사용되면 함수로서 추출할 수도 있다. 
					ㄴ 변수 추출하기 
						ㄴ 코드에서 표현식이 너무 길게 늘여져서 사용되는 경우, 그 표현식 자체나 그 중간값을 적절한 이름의 지역변수로 만들어서 사용. 
						ㄴ 그 표현식이 함수 안에서만 의미를 가지면 변수로 만들 수 있고 함수 밖에서도 똑같이 의미있게 사용되면 함수로서 추출할 수도 있다. 
					ㄴ 변수 인라인하기 
						ㄴ 변수 추출하기의 반대
						ㄴ 표현식을 변수로 나타내는게 아무 의미 없을 때, 변수를 표현식으로 풀어서 사용. 
						ㄴ 변수명과 표현식 사이의 유의미한 차이가 벼로 없을 때 등. 객체의 name속성을 name이란 변수로 사용한다거나. 
					ㄴ 함수 선언 바꾸기 
						ㄴ 함수명이나 매개변수가 적ㅈㄹ하지 않은 경우 이를 수정하는 것. 
						ㄴ 함수명은 함수가 하는 일을 적절히 표현해야 하고
						ㄴ 매개변수가 어떤게 적절할지는 케바케가 심해 대략적인 일반론은 없고, 그때마다 잘 고려해야한다함. 
							ㄴ 가령, 객체를 통째로 받으면 함수와 객체가 묶이게 되지만 객체 내의 여러 속성들을 사용할 수 있다는 장점이 있다. 
								한편, 딱 필요한 값들만 받으면 객체의 다른 속성들을 사용하지 못해 로직이 약간 복잡해질지라도 객체 변경에 대한 의존성은 없다는 장점. 
								호출하는 부분에서 객체를 넘기려면 불필요하게 해당 객체를 생성해야 할 수도 있고 반대의 경우 객체 내의 데이터를 꺼대 
								반환하는 작업이 필요할 수도 있다. 
							ㄴ 이렇기 때문에 매개변수를 적절하게 수정하는건 너무 완벽하게 하려 과투자 하지 말자? 
						ㄴ 방법
							ㄴ 함수 선언을 바꾸려면 함수가 정의된 부분과 그 함슈를 사용하는 곳을 바꿔줘야함. 바꿀곳이 간단하고 몇개 없으면 그냥 선언문과 사용하는곳 동시에 바꿔주먄됨.
							ㄴ 수정할곳이 너무 많아 한번에ㅜ어려운 경우, 점진적으로 수정하기 위해 ‘마이그레이션‘ 방법 사용. (챡에서만 나오는 단어?) 먼저 새 함수 정의하여 수정할 함수 본문을 그대로 옮김. 이 새함수에서 원하는대로 함수선언을 변경. 기존 수정할 함수 본문에서 이 새ㅜ함수를 호출하도록함. 그럼 기존 함수는 그저 동일한 동작을 하는 새 함수를 호출허기만함. 이 상태에서 기존함수 사용처들을 차례처례 ‘함수 인라인 시키면됨’
						ㄴ 이런부분에서 가성비에 대해 의문이 듦. 이렇게 바꾸는게 적지 않은 비용이 들텐데 이름하나 바꾸자고 이렇게까지하는게 적절한가?
					ㄴ 변수 캡슐화하기 
						ㄴ 변수에 직접 접근하지 않고, 변수에 직접 접근하는 함수를 만들고 이를 통해서만 접근하도록 하는 것. 
							getter, setter 함수 같은 것. 
							직접 접근보다 이렇게 함수를 통하여 접근하도록 해두면, 관리 및 수정에 용이. 
					ㄴ 변수 이름바꾸기
						ㄴ 변수의 범위가 넓을수록 신중하게 지어야함.
						ㄴ 그냥 바꾸먄 되고 함수 선언 바꾸기에서처럼 한번에 바꾸기 어럅다면 새별수를 만들고 바꿀 변수를 대입한다음 점진적으로 바꿔도 됨.
					ㄴ 매개변수 겍체만들기
						ㄴ 서로 관련잇는 여러 데이터들이 매개변수로서 이리저리 뭉쳐다니는 걍우 이를 객체화히여 사용하면 매개변수 수가 줄어 깔끔해지고 이 묶은 객체를 로직상의 객체로서 개념적으로ㅠ정의히고 사용하루수도 있다. 관련 로직을 객체 내로 함수화 시킨다거나.
					ㄴ 여러 함수 클래스로 묶기
						ㄴ 서로 관련 있는 여러 함수들을 한 클래스로 묶어 사용할 수 있다.
					ㄴ 여러함수를 변환함수로 묶기
						ㄴ 데이터를 뱐환하거나 계산하는 로직이 여러곳에서 중복되거나 단계가 흩어져 있다면 하나의 함수로 묶어낼 수 있다.
					ㄴ 단계 쪼개기
						ㄴ 뒤섞여 있는 로직을 명확히 분리된 단계로 나눌 수 있다면 로직을 단계별로 나누어지도록 분리.

				</pre>

				ㄴ 무제 <button>more</button>
				<pre>
					ㄴ 리팩터링의 첫 단계는 코드를 수정한 뒤에도 동작에 이상이 없음을 보장해 줄 테스트 코드들 작성.
						ㄴ 테스트를 작성하는 데 시간이 할애되지만 크만큼 디버깅 시간이 줄어든다.
						ㄴ 한가지 수정시마다 테스트하면, 변경 폭이 작아 문제를 찾고 해결하기 쉽다.
						ㄴ 이렇게 조금씩 변경하고, 매번 테스트 하는 것.
					ㄴ 함수로 추출하여 리펙토링 할 때, 클래스의 멤버 변수가 아닌데도, 해당 범위에서 접근 가능한 지역 변수들을
						함수 내에서 멤버 변수처럼 접근하여 사용하고 수정하는 방식은 buggy한 것 같다.
						ㄴ 해당 범위 어디서나 접근하고 수정할 수 있는 지역 변수가 함수의 반환값 대입 같은 것도 안 했는데 갑자기
							바뀌어 버려 예측하기 어렵다.
					ㄴ 리펙토링 과정에서 반복문 등과 관련된 부분을 수정하며 성능에 문제가 될까 염려하는 경우.
						ㄴ 미미한 부분들은 큰 영향이 없으니 그냥 가독성을 우선하는 게 좋다.
						ㄴ 성능 이슈가 나오더라도, 리펙토링이 되어 있어야 수정하기 쉽다.
				</pre>
 
			</pre>

			ㅡ 대표적 요소들. 
				ㄴ 이를이 안 좋을 수록 코드가 파악하기 어렵고, 수정하기 어렵고, 버그에 취약해짐. 
				ㄴ 목록 
					ㄴ 가독성 
						ㄴ 코드를 읽었을 때 뭔 코드인지 쉽게 파악이 되어야함. 
					ㄴ 의존성 
						ㄴ 특정 코드 단위가 그 단위가 관심을 가지고 잇는 부분 이외의 다른 어떤 대상의 변화에 영향을 받고 따라서 수정이 필요한 것. 
						ㄴ 특정 객체에 대한 의존성, 데이터 형식에 대한 의존성, 시간에 대한 의존성, 등. 
						ㄴ 아예 없을 수는 없으나, 최대한 없어야함. 
					ㄴ buggy한 코드 
						ㄴ 코드가 개발자가 쉽게 파악하기 어려운 버그의 소지가 있는 부분이 있어서는 안된다. 

			ㅡ 무제 <button>more</button>
			<pre>
				ㄴ 주석도 필요 없을 정도로, 보면 이해 할 수 있는 로직과 모양새가 깔끔하고 단순한 코드?
					ㄴ 이를 위해선 변수 명이 보면 바로 이해가 가야 한다.
					ㄴ 적절한 값을 적절한 네이밍으로 변수화가 필요하기도 하다.
				ㄴ 중복되는 로직, 한 부분에서 코드가 너무 길어지는 경우 등은 모듈화.
				ㄴ 약어를 지양하라.
					ㄴ 이름 길어지는 게 싫기는 하겠지만, 의미 전달이 어렵다.
					ㄴ 당장 작성할 때야 알겠지만 나중에 쉽게 알 수 있을까?
				ㄴ 코드에 신경써야 하는 이유는.. 가독성, buggy, 수정 때문?
					ㄴ 가독성은 buggy와 수정에서 중요한 요소이고?
				ㄴ 겹치는 부분들이 있기는 하지만 코드에 신경써야 하는 이유는 세 가지 정도 있는 것 같다.
					코드 파악, 수정에 용이, buggy 
					ㄴ 변수명, 깔끔하고 명쾌한 로직, 함수화, 중복 제거 등은 코드를 쉽게 파악하기 위해서
					ㄴ 의존성, 즉, 코드들을 잘 분리해 두는 것은 수정에 용이하기 위해서
					ㄴ 위 두가지가 모두 buggy한 것과 관련이 있고,
				ㄴ 충분한 고려 없이 그냥 막, 돌아가게만 만든 코드와 그렇지 않은 코드.
				ㄴ 기본적인 배경 지식이 있다고 가정하고 내용을 진행해 나가는 것 같다. TDD나 몇 가지 디자인 패턴이나, 객체지향, 등등.
			</pre>
		</pre>

		소프트웨어 테스트<button>more</button>
		<pre>
			ㄴ ~~~~~

			ㄴ test case
				ㄴ 하나의 테스트를 정의하는 명세. 입력값, 조건, 테스트 절차, 예상 결과값 등을 포함.

			ㄴ 방법<button>more</button>
			<pre>
				ㄴ ~~~
				ㄴ test automation (테스트 자동화)<button>more</button>
				<pre>
					ㄴ 테스트 대상 소프트웨어와 분리된 다른 소프트웨어를 사용하여
						테스트를 진행을 제어하고 테스트 결과를 예상 결과와 비교하는 것.
					ㄴ 반복적이고 필수적인 테스트를 자동화 할 수 있다.
					ㄴ 수작업으로 하기 어려운 테스트를 수행할 수 있다.
					ㄴ 결국, 가장 큰 장점은 빠르고 힘 안들이고 테스트를 할 수 있다는 것?
						ㄴ 테스트할게 많고 자주 할수록 효과 큼?
						ㄴ 소프트웨어가 크고 복잡할 수록 수정에 따라 어떤 부분에 영향이 있을지 확인할게 많으므로 효과 큼?
						ㄴ 개발 시간 증가라는 확실하고 작지 않은 단점이 있으므로 효과를 고려해서 가성비를 따져봐야함?
						ㄴ 생각보다 두세번만 테스트해도 일일이 테스트하는 것보다 테스트 코드 작성하는 시간이 더 적게 걸린다?
							아주 단순한 로직이 아니면 여러 케이스에 대해 테스트할게 꽤많으므로.
							관련된 부분이 많으면 더더욱?
							문서화하고 읽고 테스트하는 것도 성가신 일?
					ㄴ 'Continuous delivery(CD)'와 'continuout testing'에 있어서 필수적이다.
						ㄴ Continuous delivery란
							ㄴ 짧은 소프트웨어 싸이클로 소프트웨어가 항상 안정적으로 릴리즈 가능하도록 하는 소프트웨어 엔지니어링 방식.
							ㄴ 빠른 속도와 짧은 주기로 빌드, 테스트, 릴리스하는 소프트웨어를 지향.
							ㄴ 변경사항 릴리즈의 비용, 시간, 리스크를 줄여 프로덕션 프로그램에 더 많은 업데이트를 가능하게 한다.
							ㄴ Continuous deployment
								ㄴ continuous delivery와 유사한 개념.
								ㄴ 동일하게 소프트웨어를 언제든지 릴리즈 가능하도록 하는 엔지니어링 방식이지만,
									continuous delivery와 다르게 continuous deployment는 자동화된 배포를 통하여 프로덕션에 릴리즈.
									continuous delivery는 수동으로 릴리즈.
								ㄴ continuous deployment를 위해선 continuous delivery가 우선 필요하다 할 수 있다.
						ㄴ Continuous testing
							ㄴ
					ㄴ 방법들 )
						ㄴ 테스트 자동화를 하기 위한 여러가지 접근법 존재.
						ㄴ graphical user interface testing
							ㄴ 테스트 프레임워크를 사용하여 사용자 인터페이스에서의 이벤트를 발생시키고,
								사용자 인터페이스 상에서의 변화를 확인하여 테스트하는 방식.
							ㄴ 액션을 기록하고 반복하여 자동 재생함으로서 테스트하는 방식.
							ㄴ 소프트웨어 개발이 거의 필요치 않다.
							ㄴ GUI를 가지는 어떤 프로그램이라도 적용될 수 있다.
							ㄴ 안정성, 유지보수 관점에서의 문제.
								ㄴ GUI상의 변경시 기록 재설정 필요.
								ㄴ 관련없거나 잘못된 기록 및 재생 동작.
							ㄴ ex ) auto-hotkey
							ㄴ web testing에 있어서 변형 도구 )
								ㄴ web 페이지를 테스트하는 경우를 위한 GUI testing의 변형판 도구들이 있다.
								ㄴ 이 경우 interface란 web page가 되며.
								ㄴ ??? html과 DOM event를 활용하기 때문에 기술적으로 약간 다르다?
								ㄴ ex ) Headless browsers, Selenium Web Driver
							ㄴ 모바일 어플에 대한 변형 도구도 존재.
								ㄴ 모바일에서의 다양한 해상도, 크기, os에 대해 테스트하기 유용하다.
						ㄴ API driven testing
							ㄴ ???유저 인터페이스가 아닌 프로그램 상에서의 인터페이스를 사용하여 테스트.
								프로그램상에서의 인터페이스란
							ㄴ GUI 구현체와 독립적으로 수행될 수 있다.
								ㄴ GUI 구현체가 준비가 안 되어 있어도 개발단계에서 실행할 수 있는 장점.
								ㄴ 코드가 좀 더 클린하게 되는 경향이 있다.
							ㄴ API가 프로그램 로직의 주요 인터페이스인 경우 특히 더 중요하게 여겨진다.
					ㄴ ??? 중요한 결정 사항들?
					ㄴ unit test의 테스트 자동화는 TDD로 알려진 'extreme programming', 'agile software development'의 핵심이다.
					ㄴ 장기간 유지보수되는 제품에 대한 회귀테스트에 효과가 좋다.
						ㄴ 아무리 작은 변경사항이라도 이전에 동작하던 기능에 문제를 일으킬 수 있으므로.
					ㄴ 자동화된 테스트를 많이 쓸수록 그 가치가 커진다 할 수 있다.
						ㄴ 따라서, 프로그램에서 항상 쓰이는 공통적인 부분에 대해 자동화 테스트를 작성하는 것이 효율이 좋다.
					ㄴ 테스트 레벨별 자동화할 테스트 숫자 결정
						ㄴ test automation pyramid에 따라 테스트 레벨별로 자동화할 테스트의 숫자가 결정된다함.
							<img src="image/test_automation_pyramid.png"/>
						ㄴ unit test를 가장 많이 자동화하고 ui test를 가장 적게 만든다.
							ui의 경우 자동화 테스트 적용이 더 어렵기 때문. 작은 변화에도 많은 자동화 테스트가 수정이 필요하여 유지보수 비용 큼.
					ㄴ ~~~
				</pre>

				ㄴ ~~~

			</pre>

			ㄴ Unit test<button>more</button>
			<pre>
				ㄴ 프로그램의 특정 부분(unit)이 의도된 설계대로 동작하는지 확인하기 위해 개발자에 의해 작성된 'test automation'를 의미.
				ㄴ ~~~
				ㄴ 장점 )
					ㄴ 빠른 버그 확인.
						ㄴ 코드를 실행한 뒤에 버그를 확인하고 찾고 고치는 비용보다
							개발 단계에서 정확히 어떤 케이스가 문제가 있는지 확인하여 고치는 비용이 훨씬 싸다.
					ㄴ 버그에 대한 보험.
						ㄴ 개발단계에서 유닛 단위로 테스트를 진행함으로서 실서비스 단계에서의 버그 발생을 줄여주는 보험이 된다.
						ㄴ 또한 당연히 유저단에서 버그가 확인되는 것은 단순히 픽스 비용 문제보다 큰 문제이다.
					ㄴ 일종의 문서로서의 역할 가능.
						ㄴ 단위 테스트를 보면서 unit의 대략적인 기능, 사용법 등 확인 가능.
				ㄴ 한계 및 단점 )
					ㄴ 유닛 단위로 테스트 되기 위하여 개발시 코드 구조에 신경써야 한다.
					ㄴ 'unit' 단위로 인한 한계점
						ㄴ unit단위에 대해선 테스트 되지만, 시스템 전체에 대해 오류가 없음을 보장하지 않음.
							다른 unit들과 함께 동작해야하는 통합 테스트나 성능 테스트에 대해 제약.
					ㄴ 테스트 코드로 테스트하기 어려운 문제들 존재.
						ㄴ ex ) '비결정적 알고리즘'에 대한 테스트, 멀티 스레드 관련 테스트 등.
							ㄴ '비결정적 알고리즘'(nondeterministic)이란, 같은 인풋값에 대해서 매번 실행시마다 실행 내용이 달라지는 알고리즘?
					ㄴ 개발 시간 증가.
						ㄴ 하나의 동작에 대한 케이스별 테스트 코드 작성을 위해 2배 이상의 코드 작성이 필요한 경우 많음.
					ㄴ 테스트 코드 자체 버그 가능성.
						ㄴ 코드의 버그를 테스트하기 위한 테스트 코드 작성 중에도 버그가 있을 수 있기 때문에
							완벽하게 장담하기 힘들다.
					ㄴ ??? 테스트할 명확한 조건들 필요?
						ㄴ 이러한 조건들이 없으면 테스트 코드가 실질적으로 도움되지 않을 것.
					ㄴ ??? 적용을 위한 개발 과정에서의 엄격한 절차 필요
						ㄴ 수행된 테스트, 소스 코드에 대한 변경사항 기록 필요.
						ㄴ 버전컨트롤 시스템 사용 필요. 테스트 실패시 버전컨트롤 시스템의 히스토리를 통하여 변경점 확인.
					ㄴ 단순히 인풋, 아웃풋이 있는 유닛이면 테스트하기 쉬우나, 외부 프로그램과 상호작용하는 경우 테스트 코드 작성이
						까다로울 수 있음.
						ㄴ ex ) http request 요청에 대한 테스트, db와 상호작용하는 테스트.
			</pre>

			ㄴ Integration testing (통합 테스트)
				ㄴ

			ㄴ 웹 서버 성능 테스트 
				ㄴ ??? 많은 트래픽, 많은 동시 유저 등을 실제환경과 동일하게 시뮬레이션하여 
					응답속도, 리소스 사용량, 오류 등을 테스트하는 것. 
				ㄴ Apache JMeter <button>more</button>
				<pre>
					ㄴ 개요 
						ㄴ 웹어플의 기능테스트 및 성능측정을 위해 만들어진 어플. 
							현재는 웹 어플뿐 아니라 다양한 대상  테스트 가능. 
						ㄴ 100% Java로 구현
						ㄴ 오픈소스.  
						ㄴ 다양한 어플리케이션, 서버, 프로토콜에 대한 테스트 가능. 
							ㄴ Http, HTTPS, SOAP/REST, FTP, JDBC를 통한 DB, ...
						ㄴ CLI mode 지원. 
						ㄴ ??? Full featured Test IDE that allows fast Test Plan recording (from Browsers or native applications), building and debugging.
						ㄴ 결과를 html형태의 report로 산출가능. 
						ㄴ ~~~
					ㄴ 요구사항 
						ㄴ 자바 8 이상 필요. 
						ㄴ 100% 자바로 만들어졌으므로, JVM과 호환되는 os면 동작. 
					ㄴ 설치 
						ㄴ 블로그보고 따라서. 
						ㄴ JRE/JDK 설치 필요, JAVA_HOME 환경변수 설정 필요, directory path에 공백 존재시 오류 발생 가능. 
					ㄴ 실행 
						ㄴ Window ) bin/jmeter.bat 실행. 
						ㄴ Unix ) bin/jmeter 실행. 
						ㄴ 실행 관련 설정 변경 
							ㄴ ~~~ 
						ㄴ JMeter의 경로 관련 
					ㄴ ??? GUI모드는 test script에, CLI 모드는 load testing에 사용되야한다? 
					ㄴ test tree의 scope (element의 계층, 순서)
						ㄴ test tree 에는 element들의 계층 구조, 순서가 존재하며, element에 따라 적용되는 영향이 다름. 
							ㄴ 가령, controller는 순서에 영향을 받아 test tree상의 controller 순서 그대로 실행되고,  
								assertion은 부모가 request이면 해당 request에, controller이면 해당 controller가 생성하는 모든 request에 적용되는 식. 
					ㄴ test plan building 
						ㄴ test plan 
							ㄴ 테스트에서 실행할 일련의 단계들 의미. 
							ㄴ 하나 이상의 'element'로 구성.
								Thread Groups, logic controller, sample generating controller, listener, timer, assertion, configuration element로 구성? 
								ㄴ ??? A minimal test will consist of the Test Plan, a Thread Group and one or more Samplers.
							ㄴ element 
								ㄴ 
								ㄴ 목록 
									ㄴ Test Plan 
										ㄴ ???~~~
									ㄴ thread group 
										ㄴ JMeter가 테스트를 수행하는데 사용할 스레드들을 관리하는 element. 
										ㄴ ??? test plan의 시작점?
										ㄴ ??? 'controller', 'sampler' element는 'thread group'하위에 있어야함? 
										ㄴ 스레드 개수, 실행 횟수, ramp-up period 설정 가능
										ㄴ ramp-up period 
											ㄴ 여러 스레드들이 모두 실행을 시작하는데 걸리는 시간. 
											ㄴ 그룹 내 스레드들이 ramp-up period 시간 내에 균일한 텀으로 시작됨. 
											ㄴ ex ) ramp-up period = 100s, 스레드 개수 = 10 이면, 
													그룹 내 스레드가 순서대로 10초 간격으로 시작됨. 
										ㄴ ??? 각 스레드가 테스트를 독립적으로 실행? 
										ㄴ 그룹 내 element들 실행 반복? 
											ㄴ 디폴트로 한번 반복. 
										ㄴ thread lifetime 설정 
											ㄴ 스레드 그룹에 대해 duration, startup delay 설정 가능. 
											ㄴ duration : ??? 스레드가 실행될 시간. 이 시간동안만 스레드 실행? ???실습필요
											ㄴ startup delay : 시작 전 이 시간만큼 대기 후 시작. 
									ㄴ controller 
										ㄴ 테스트 진행을 관리하는 element. 
										ㄴ 유형 
											ㄴ sampler
												ㄴ JMeter가 테스트 서버로 request를 보내고 response를 기다리도록함. 
												ㄴ 
												ㄴ test tree 상의 순서대로 실행. 
												ㄴ ??? 반복횟수 설정 가능 
												ㄴ 목록  
													ㄴ HTTP request
														ㄴ http, https request를 웹서버로 보내는 sampler. 
														ㄴ??? html file을 image로 파싱 가능
														ㄴ??? embedded resource들에 대한 요청도 가능. 
														ㄴ ??? 디폴트 parser는 'org.apache.jmeter.protocol.http.parser.LagartoBasedHtmlParser'
															ㄴ 'htmlparser.className' property로 변경 가능. 
														ㄴ ??? HTTP request의 구현체는 'java', 'HTTPClient4' 중 하나 선택 가능? 
													ㄴ FTP request
													ㄴ JDBC request
													ㄴ Java object request
													ㄴ JMS request
													ㄴ JUnit Test request 
													ㄴ LDAP request 
													ㄴ Mail request
													ㄴ OS Process request
													ㄴ TCP request
												ㄴ sampler별 설정값 존재 
												ㄴ ??? test plan에 대한 Configuration element 추가를 통해 추가 설정 가능. 
												ㄴ ??? 같은 서버에 같은 유형의 request를 여러개 전송하는 경우, Default Configuration element 검토? 
												ㄴ ??? 결과를 보거나 저장하려면 test plan에 Listener 추가 필요
												ㄴ ??? 응답에 대한 validation을 수행하려면 sampler에 Assertion 추가? 
													ㄴ 응답은 정상적으로 왔으나 내용에 오류가 있는 등에 사용. 
											ㄴ logical controller 
												ㄴ JMeter가 언제 request를 보낼지 결정하는 로직을 커스텀 할 수 있는 conroller. 
													각 logical controller별로 하위 request 의 실행 순서를 결정하는 로직들이 있고 이를 적절히 사용. 
												ㄴ 목록 
													ㄴ Once only controller 
														ㄴ 테스트 반복 중 맨 처음 한번만 사용되는 controller. 
													ㄴ ~~~ 
										ㄴ test fragment 
											ㄴ ??? controller 중 하나이지만 thread group 내가 아닌 같은 레벨에 위치하는 controller. 
											ㄴ ???~~~ 
									ㄴ listener 
										ㄴ JMeter가 테스트에 대해 수집한 정보를 보여주는 element.
										ㄴ 데이터를 파일로 저장하는 기능 존재. 
										ㄴ test tree에서 하위 레벨에서 오는 데이터들을 수집. 
										ㄴ ??? Note that Listeners are processed at the end of the scope in which they are found.
										ㄴ 목록 
											ㄴ Graph result 
												ㄴ 그래프로 결과를 보여줌.
												ㄴ load test시 사용하지 않는 것 권장한다함. 리소스 소모량 많아서. 
												ㄴ ~~~
											ㄴ View Results Tree 
												ㄴ ~~~
												ㄴ 마찬가지로 load test시 사용하지 않는 것 권장한다함.
												ㄴ 각 sample에 대한 응답의 tree 보여줌. 
												ㄴ 응답 시간, 응답 코드, 
												ㄴ renderer 
													ㄴ 각 request에 대한 결과를 어떤형식으로 볼지 결정 가능. 
											ㄴ ~~~ 
									ㄴ timer 
										ㄴ timer의 'scope' 내에 있는 'sampler'들이 실행되기 전에 JMeter가 일정시간 대기하도록 하는 element.
										ㄴ timer를 설정하지 않을시, JMeter는 request를 딜레이없이 바로 보내기 때문에 서버 부하 가능 있으므로 권장함. 
										ㄴ thread group에 여려 timer 설정시, 대기시간의 합만큼 대기. 
									ㄴ assertion 
										ㄴ response를 테스트하게 해주는 element. 
										ㄴ ex ) 
											응답에 특정 문자열이 포함되어 있는지 등 확인 가능. 
										ㄴ ??? sampler에 부착 가능? ???sampler만? 
										ㄴ main sample, sub sample 적용 옵션 선택 
											ㄴ main sample, sub sample 중 어느곳에 assertion을 적용할지 또는 둘 다 적용할지 설정 가능. 
											ㄴ main sample, sub sample 
												ㄴ main sample : request시 이에 대한 직접적인 응답. 
												ㄴ sub sample : request시 css, js 등 embedded된 응답. 
											ㄴ main 성공하고 sub 실패시, 실패 취급. 
										ㄴ ??? 결과보기 위해선 thread group에 assert listener 등록 필요? 
									ㄴ configuration 
										ㄴ 
										ㄴ 적용 범위 
											ㄴ test tree상에서, configuration element의 부모를 root로 하는 sub tree에서만 접근 가능. 
												즉, 형제 노드들 및 그들의 하위 범위에서만 접근 가능. 
											ㄴ ??? 여러개의 configuration이 가능한 경우, 
									ㄴ pre-processor 
									ㄴ post-processor
								ㄴ element들 실행 순서 
									0. configuration
									1. pre-processor (적용할게 있는 경우)
									2. timer (적용할게 있는 경우)
									3. sampler (sampler, logic controller가 이들의 순서 규칙에 따라)
									4. post-processor (적용할게 있는 경우)
									5. assertion (적용할게 있는 경우)
									6. listener 

							ㄴ element 추가 삭제
								ㄴ JMeter 프로그램에서 좌측 test tree > 우클릭시 나오는 옵션 선택으로 가능. 
							ㄴ test tree에서 각 element 클릭시 해당 element에 대한 창이 오른쪽에 뜸. 
						ㄴ element save, load 
							ㄴ ~~~
							ㄴ test plan을 파일로 저장해두는걸 권장한다함. 
							ㄴ test plan tree 전체 또는 일부만 파일로 저장 가능. 
								ㄴ??? 일부만 저장 ) test tree에서 특정 element클릭 후 파일로 저장하면 해당 element를 root로하는 subtree만 저장? ???실습 필요. 
						ㄴ 
					ㄴ load test running 
						ㄴ 
					ㄴ 사용 팁 
						ㄴ JMeter 최신 버전 유지 권장. 
							ㄴ 성능개선 위해. 
							ㄴ 최신 버전으로부터 3개 버전 이전 버전은 절대 사용하지 말라함. 
						ㄴ ~~~???
					ㄴ 서버 모드 테스트
					ㄴ CLI 모드 
					ㄴ 로깅 
					ㄴ JMeter configuring 
						ㄴ ??? /bin/user.properties 파일 수정 | jmeter.properties 생성 후 command에 옵션으로 전달. 
						ㄴ 파라미터 
							ㄴ ~~~ 
						ㄴ 설정값 적용 우선순위 
							1. -p propfile
							2. jmeter.properties (or the file from the -p option) is then loaded
							3. -j logfile
							4. Logging is initialised
							5. user.properties is loaded
							6. system.properties is loaded
							7. all other command-line options are processed
						ㄴ ??? property는 jmeter에서 global하게 접근 가능. 
						ㄴ ~~~ 
					ㄴ CSRF 를 사용하는 페이지 로그인 
						ㄴ 
					
					ㄴ ~~~
				
				</pre>

			ㄴ TDD, 켄트 벡<button>more</button>
			<pre>
				ㄴ ~~~~~
				ㄴ TDD란? 개요 )
					ㄴ TDD, Test-Driven Development
						방식이 (자동화된) 테스트를 중심으로 개발을 해 나가는 방법이어서 이렇게 이름 붙었다.
					ㄴ 대략적인 방식은,
						자동화된 테스트를 작성하고,
						이 테스트를 통과하도록 코드를 작성하고,
						작성한 코드로 테스트 통과 후 리펙토링을 하는 것.
						위 세 단계가 한 싸이클로, 이를 반복하면서 개발해 나가는 방식이다.

				ㄴ 무제<button>more</button>
				<pre>
					ㄴ 모든 작업을 작은 단위로 나눈다.
						해당 작업에 대한 적절한 자동화된 테스트를 준비한다.
						개발
						테스트
						리펙토링
					ㄴ TDD도 배우지만, 테스트 코드에 대한 것들도 배우고 사실상 이게 주된 목적이다.
					ㄴ 자동화된 테스트의 장점
						ㄴ 테스트가 수월해져, 수정이 수월해 진다.
					ㄴ 테스트는 서로 독립적인 게 좋다.
						ㄴ 다른 테스트에 영향을 받을 시 당연히 해당 기능을 제대로 테스트 할 수 없다.
					ㄴ 단위 테스트 위주로 개발하면 생기는 장점.
						ㄴ 테스트 단위로 적절하기 구성하기 위해, 작성하는 코드가 응집도가 높아지고 의존성이 낮아진다.
					ㄴ 모든 해야 하는 기능에 대한 테스트 케이스를 적고 이에 대한 리펙토링을 적는다.
						개발 중간에 생각난 테스트 케이스나 리펙토링도 할 일 목록에 추가한다.
					ㄴ 테스트 작성시, assert를 먼저 작성하라.
						ㄴ 시스템 개발시, 그 시스템이 어떨 것이라는 것부터 만들고 시작하고,
							특정 기능 개발시, 그 기능이 완료되면 통과할 테스트부터 작성하듯이,
							테스트 개발시, 완료되면 통과할 assert부터 작성하라고 한다.

				</pre>
			</pre>

		</pre>
 
		모니터링, Mornitoring <button>more</button>
		<pre>
			ㄴ ~~~
			ㄴ ??? 필요성 ?
				ㄴ 시스템, 프로그램 상태에 대한 이해를 더 잘 하게 해줌. 
					가령 어플이 특정 시간대에 느리다면, 그 시점에 request 수가 어땠는지, 요청당 완료 시간은 어땟는지, 쿼리 속도는 어땠는지 
					등을 확인하여 문제를 파악할 수 있음. 
			ㄴ 모니터링 대상 
				ㄴ ??? 어플리케이션 ? 
					ㄴ 어플에 대한 전반적 모니터링? 
					ㄴ APM tool 이란걸 이용하여 가능? 
				ㄴ 리소스 
					ㄴ CPU 사용량, disk 용량, 메모리 사용량 등. 
					ㄴ Prometheus + Grafana, Nagios, Zabbix, AWS Cloud Watch
				ㄴ DB 
				ㄴ 로그 
					ㄴ ELK stack, graylog, splunk 
				ㄴ 프로세스 
					ㄴ Celery Flower, Kafka 
				ㄴ 보안 
					ㄴ SIEM tool들
				ㄴ 배포, CI/CD 프로세스 
				ㄴ 등등.. 딱 정해진건 아니고, 대충 이런것들을 모니터링 한다~ 정도. 
			ㄴ Push vs Pull 
				ㄴ 모니터링 방법에 대한 큰 분류. 
					push방식은 모니터링 돼야하는 타겟이 모니터링 시스템에게 직접 데이터를 push하는 방식. 
					pull방식은 모니터링 시스템이 모니터링 돼야하는 타겟에 접근하여 데이터를 pull해오는 방식. 
				ㄴ push 방식 
					ㄴ 보통 agent(모니터링 돼야하는 타겟)들에 모니터링용 프로그램 등이 설치. 
					ㄴ 모니터링 시스템으로 데이터를 보내야 하므로 모니터링 시스템의 end-point ip를 알아야함? 
					ㄴ ??? metric 정보가 변경될 때마다 재배포해야함? 
				ㄴ pull 방식 
					ㄴ agent들은 모니터링 시스템에 대한 인지가 없다
					ㄴ ??? exporter 등 들이 metrics를 노출시키고 모니터링 시스템이 이를 수집해가는식. 

			ㄴ 로깅, Logging <button>more</button>
			<pre>
				ㄴ ~~~
				ㄴ 로그 데이터를 다른 외부 서비스로 보내더라도 일단 로컬에 저장하는 것이 좋다. 
					ㄴ 네트워크 이슈, 외부 서비스의 이슈 등 발생시 로그 소실 가능성 존재. 
					ㄴ 로그 저장과 전송을 분리. 
				ㄴ 로그 파일 디스크 용량 이슈 
					ㄴ 로그 파일이 꾸준히 쌓이면서 필연적으로 디스크 용량이 찰 수 밖에 없다. 
						이를 처리해줘야함. 

				ㄴ logrotate <button>more</button>
				<pre>
					ㄴ 개요 )
						대량으로 발생되는 로그파일을 쉽게 관리하게 도와주는 프로그램. 
						로그 파일 자동 로테이션, 압축, 삭제, 메일링 기능 제공. 
						일별, 주간별, 월간별 또는 너무 커졌을 때 처리 될 수 있는 기능 제공. 

					ㄴ 리눅스, 우분투에 기본적으로 설치되어 있는 데몬 프로그램. 
					ㄴ daily cron job을 이용하여 돌아간다함. 
					ㄴ --force 옵션으로 강제로 실행되거나, ??? logrotate가 하루에 여러번 실행되거나, 
						로그 사이즈 기준의 설정이 없다면 logrotate는 하루에 여러번 로그파일을 수정하는 일이 없다. 
						
					ㄴ 버전 확인 
						ㄴ logrotate --version 
					ㄴ 설정 
						ㄴ 설정 파일 내에 여러 지시자들로 로그 로테이션 동작이 어떻게 될지를 정의하는 방식. 
						ㄴ ex ) <button>more</button>
						<pre>
							# see "man logrotate" for details

							# global options do not affect preceding include directives
							
							# rotate log files weekly
							weekly
							
							# use the adm group by default, since this is the owning group
							# of /var/log/syslog.
							su root adm
							
							# keep 4 weeks worth of backlogs
							rotate 4
							
							# create new (empty) log files after rotating old ones
							create
							
							# use date as a suffix of the rotated file
							#dateext
							
							# uncomment this if you want your log files compressed
							#compress
							
							# packages drop log rotation information into this directory
							include /etc/logrotate.d
							
							# system-specific logs may also be configured here.

							ㄴ 분리된 파일  
								in /etc/logrotate.d/qstock_calculator ... 

								/home/qstock_calculator/logs/*.log {
									create 644 root root
									daily
									ifempty
									dateext
									dateformat %Y-%m-%d
									compress
									maxage 180 
								}
						</pre>

						ㄴ ??? 섹션? 
							ㄴ 설정 파일 내에서 파일 경로를 나타내는 표현 뒤에 대괄호를 쓰고 그 안에 설정값들을 나열하면 
								파일 경로 표현에 해당하는 파일들에 대해 대괄호 내의 설정값대로 log rotation이 수행됨. 
							ㄴ 물론 대괄호 밖 글로벌범위의 설정값들은 상속됨. 

						ㄴ directives <button>more</button>
						<pre>
							ㄴ weekly (또는 'hourly', 'daily', 'monthly', 'yearly')
								ㄴ rotation 주기. 
								ㄴ ??? 기본적으로 logrotate가 하루 한번 실행되므로 주기를 하루보다 짧게 하려면 추가 설정 필요
							ㄴ ??? su root adm 
								ㄴ log rotation이 기본적으로 root user, admin group 으로 실행됨? 
									이 지시자로 로테이션된 로그파일이 어느 유저, 그룹에 속할지 설정 가능. 
							ㄴ rotate (*카운트*)
								ㄴ 오래된 로그 파일이 삭제되거나 메일로 보내지기 전 발생하는 로테이션 카운트. 
									즉, 해당 카운트만큼의 로테이션 후에는 오래된 로그파일이 삭제되거나 메일로 전송됨. 
								ㄴ 0인 경우, 로테이션시 이전 파일은 바로 삭제됨. 
								ㄴ ??? -1 인 경우, 'maxage' 지시자에 의한게 아니면 삭제되지 않음. ? 
							ㄴ create 
								ㄴ 파일이 로테이션 된 후, 해당 파일과 동일한 이름의 로그 파일을 바로 생성. 
								ㄴ 뒤에 chmod, owner, group을 명시하여 생성될 로그 파일의 모드, 소유자 그룹을 설정 가능. 
									ㄴ ex ) create 655 noname_user noname_group 
							ㄴ dateext 
								ㄴ 파일 로테이션시, 로테이션된 파일의 파일명 끝에 날짜형식 확장자를 추가함. 
									디폴트는 number가 붙음. logname.YYYYMMDD 이런식으로. 
							ㄴ dateformat 
								ㄴ dateext 를 명시하여 로테이션된 파일에 확장자를 붙일 때, 어던 형식으로 붙일지 설정. 
								ㄴ %Y, %m, %d, %s만 가능하다함. 
								ㄴ 디폴트는 %Y%m%d 
							ㄴ compress 
								ㄴ 오래된 로그파일이 압출될지 설정. 
								ㄴ 디폴트로 gzip 사용. 
								ㄴ 디폴트는 off. 
							ㄴ delaycompress 
								ㄴ??? compress 지시자 사용시, 로테이션된 파일을 바로 압축하지만, delaycompress 지시자 존재시 
									다음 로테이션시 압축함. 즉, 압축이 한싸이클 미뤄지는 것. 
								ㄴ 로깅을 하는 프로세스가 해당 로그파일이 로테이션되었음을 인지하지 못하는 경우 유용하다함. 
							ㄴ ifempty 
								ㄴ 로그파일이 비어있어도 해당 파일을 로테이션. 
							ㄴ notifempty 
								ㄴ 로그파일이 비어있는 경우, 로테이션 안함. 
							ㄴ maxage (*days*)
								ㄴ 로그파일이 해당 날짜 이상으로 오래 되었으면 삭제.
								ㄴ ??? 로테이션이 될 때만 체크한다? 
								ㄴ 'maillast', 'mail' 지시자 설정시, 파일을 ㅡ메일로 보냄. 
								ㄴ rotate 지시자에서 설정한 최대 보유할 로그파일 수와 동시에 적용되는 듯. 
									rotate 지시자값을 0으로 두면 maxage 안넘어도 바로 삭제됨. 
							ㄴ size (*사이즈*)
								ㄴ 로그파일이 명시된 크기보다 커지면 로테이션
								ㄴ 단위 ) 없으면 바이트, 'k'는 킬로바이트, 'M'은 메가바이트, 'G'는 기가바이트. 
									ㄴ ex ) size 100  / size 100k  / size 100G 
								ㄴ ??? 시간주기 로테이션 지시자(daily, weekly 등)과 배타적이다? 
									ㄴ ??? 마지막에 온 지시자가 적용된다? 
							ㄴ minsize (*사이즈*)
								ㄴ??? size 지시자와 유사하게, 명시된 크기보다 커지면 로테이션되지만, 
									시간주기 로테이션 지시자(daily, weekly 등)가 명시한 주기 이전에는 로테이션되지 않는다? 
									? 시간주기 지시자가 명시한 주기마다 사이즈 체크해서 이상인 경우만 로테이션하는식인가? 
							ㄴ include (*파일 또는 폴더*)
								ㄴ 추가적인 설정파일 또는 snippet을 포함시키는 지시자. 
								ㄴ 파일인 경우, 해당 include 지시자 위치에 해당 파일의 내용이 있는 것처럼 해당 파일을 읽어들임. 
								ㄴ 폴더인 경우, 해당 폴더 내의 파일들이 알파벳순으로 읽힘. 
									ㄴ 폴더나 named pipe 같은 regular file이 아닌 경우와 'tabooext' extension인 경우 무시됨. 
								ㄴ 설정을 모듈화하는데 유용하게 사용. 
								ㄴ 보통 /etc/logrotate.d 위치에 파일별 설정파일들을 추가하고 include 지시자로 이 폴더를 포함시킴. 
									ex ) include /etc/logrotate.d 
							ㄴ prerotate (*명령어 또는 스크립트*) endscripts
								ㄴ 로테이션이 실행되기 직전에 실행될 명령어 또는 스크립트를 명시. 
							ㄴ postrotate (*명령어 또는 스크립트*) endscripts 
								ㄴ 로테이션이 실행된 직후에 실행될 명령어 또는 스크립트 명시. 
							ㄴ ~~~
						</pre>

						ㄴ create mode, copytruncate mode 
							ㄴ create mode 
								ㄴ 로테이션시, 대상 파일의 이름을 변경 후, 새 파일을 생성하는 방식. 
							ㄴ copytruncate mode 
								ㄴ 로테이션시, 대상 파일을 새 이름으로 복사하여 새로 생성하고, 대상 파일은 내용을 비우고 그대로 둠. 
								ㄴ ??? 로그를 남기는 프로세스나 어플리케이션이 새로 생성된 로그 파일로의 전환이 여의치 않는 경우 유용? 
								ㄴ 로깅을 하고 있는 프로세스가 파일이 로테이션되어 새 파일에 로깅을 해야함을 인지하지 못하여 
									이미 로테이션된 이전 로그파일에 계속 작성을 하는 경우 등에 유용. 
								ㄴ 기존 파일을 복제한 뒤, truncate하는 시점 사이의 약간의 갭이 존재하여 일부 로그가 유실될 수 있음. 

						ㄴ 디폴트 설정 파일 
							ㄴ /etc/logrotate.conf 
								ㄴ 글로벌 설정 파일. 
							ㄴ /etc/logrotate.d 
								ㄴ ~~~ 

						ㄴ ??? 로테이션 주기를 1시간 단위로 변경하기 
							ㄴ logrotate는 기본적으로 하루 한번 실행되므로 로테이션 주기를 시간단위로 변경하는건 추가적인 설정 필요. 
							ㄴ ??? 우분투에서만 가능? 

					ㄴ 'logrotate' command 
						ㄴ logrotate [-dv] [-f|--force] [-s|--state file] config_file ..
						ㄴ 여러개의 설정파일을 인자로 받을 수 있음. 
							ㄴ 여러개 오는 경우, 후순위 설정파일이 이전 설정파일의 설정값을 덮어씀. 
							ㄴ ??? 폴더를 넘기면 폴더 내의 설정파일들이 사용됨. 
						ㄴ 옵션 
							ㄴ --debug : 디버그 모드로 실행. 로그파일이나 ???logrotate 상태파일에 대한 변경은 전혀 없다. 
							ㄴ --force : 바로 로테이션을 실행시킴. 
						ㄴ 오류 발생시, non-zero 상태값과 함께 exit. 

				</pre>

				ㄴ 로그 분석 솔루션 간단 비교<button>more</button>
				<pre>
					ㄴ ELK stack 
						ㄴ ~~~
						ㄴ 비용 
							ㄴ 일부 기능은 구독해야 제공 
								ㄴ 알림, ~~~ 
						ㄴ 로그분석툴은 처음이니 어정쩡하게 아는 상태로 툴 선정하느니 안정빵으로 가장 많이 사용되는거 하는게 낫고, 
							많이 사용된다 하여 레퍼런스나 한계를 처리하기 위한 추가 라이브러리도 많을 것이고, 
							괜찮은 선택지 같다. 
							어정쩡하게 아는 장점들을 나열해보면, 
							로그 분석 관련 왠만한 기능은 있고 
							일부 기능 유료지만, 무료 기능들만 해도 왠만한건 있고 
							알림은 유료지만 다른 라이브러리로 무료로 구현 가능할듯함. 

							
					ㄴ graylog
					ㄴ Rollbar 
						ㄴ 

				</pre>

			</pre>
			ㄴ 툴 비교
				ㄴ Prometheus 
					ㄴ 모니터링할 데이터 수집 및 처리 라이브러리. 
					ㄴ 오픈소스라 무료 
					ㄴ 쿠버네티스에서 사용하기 용이하다함. 나중에ㅓ 사용하게되면 장점
					ㄴ 가장 많이 사용하는 툴 중 하나
					ㄴ 당연히 왠만한 수집 기능은 다 있음.  
				ㄴ Grafana 
					ㄴ prometheus 와 함께 사용하는 시각화 툴. 
				ㄴ ~~~
			ㄴ 툴 목록 
				ㄴ Prometheus <button>more</button>
				<pre>
					ㄴ 개요 
						ㄴ 오픈소스 시스템 모니터링 및 노티 툴. 
							ㄴ 시스템, 프로그램, 리소스 등을 모니터링 할 수 있게 해주는 프로그램. 
						ㄴ SoundCloud에서 시작. 
						ㄴ metric들을 time series 형태로 수집 및 저장. 
							ㄴ Metrics 란? 
								ㄴ 일종의 수학적 측정치를 나타내는 말. 
								ㄴ 프로메테우스에선 대략 수집하는 데이터 항목들을 지칭하는 단어. 
									ㄴ 측정된 총 http 요청 수, cpu 사용시간, 디스크 여유 사이즈 등을 각각 metric라고 부를 수 있음. 
						ㄴ Go 언어로 개발. 
							ㄴ ??? static binary로의 빌드 및 배포를 원활히 하기 위하여 선정되었다함. 
					ㄴ 아키텍쳐 <button>more</button>
					<pre>
						<img src="image/prometheus_architecture.png" />
						ㄴ prometheus 서버 
							ㄴ time series 데이터를 수집 및 저장하는 컴포넌트. 
						ㄴ 클라이언트 라이브러리
							ㄴ ???어플 코드에 대한 모니터링시 사용되는 요소인듯?
							ㄴ ‘instrumenting’ 이란 기능?
						ㄴ push gateway
							ㄴ ??? 일시적 작업? 이나 batch job은 프로메테우스 서버가 스크랩할때까지 오래 존재하지 않으므로 
								그들의 metric를 프로메테우스 서버로 보낼수있게하기 위해 pushgateway에 일단 넣어두고 
								나중에 프로메테우스 서보가 pushgateway를 스크랩해가는 기능?
						ㄴ 특수 목적 exporter 들
							ㄴ ???거의 모든 어플리케이션(MySQL, Elastic, Kafka, Redis 등)이 프로메테우스에서 사용 가능한 메트릭 정보를 제공?
						ㄴ alertmanager
						ㄴ 그 외 기타 추가 지원 툴들  
					</pre>
					ㄴ 프로메테우스가 사용하기 적합한 경우
						ㄴ 시계열 숫자 데이터를 저장하는 경우.
						ㄴ ???머신집중적 모니터링과 동적인 서비스 중심적인 하키텍쳐에도 잘 맞는다?
						ㄴ ???In a world of microservices, its support for multi-dimensional data collection and querying is a particular strength?
					ㄴ 잘 맞지 않는 경우
						ㄴ 통계적 데이터를 다루기때문에 데이터 하나하나에 대한 정확하고 상세한 정보를 수집해야 하는 경우 적절하지 않다.
					ㄴ 프로메테우스 서버는 standalone. 다른 네트워크 저장소나 remote 서버에 의존하지 않는다.
					ㄴ 다른 대안 툴들과의 비교
						ㄴ ~~~
					ㄴ 데이터 모델
						ㄴ 기본적으로 모든 데이터를 time series(시계열 데이터)로 저장한다.
						ㄴ ??? streams of timestamped values belonging to the same metric and the same set of labeled dimensions. Besides stored time series, Prometheus may generate temporary derived time series as the result of queries.
					ㄴ Metric name, label 
						ㄴ metric name 
							ㄴ 측정되는 대상을 명시. 
							ㄴ ex ) http_requests_total (받은 http request 총 개수를 나타내는 metric의 이름)
							ㄴ 아스키코드, digit, underscore, colon 포함 가능. 
								ㄴ ??? colon은 'user defined recording rule'에서 사용되도록 예약되어 있음. 
									exporter, direct instrumentation에서 사용해선 안됨. 
						ㄴ label 
							ㄴ 같은 메트릭 이름을 거진 데이터들을 여러 label 조합으로 식별할 수 있게 해주는 요소.
							ㄴ 대략, 한 메트릭 시계열 데이터 각각에 라벨값이 붙고 이 러벨값으로 추가 필터링이나 집계 등을 하게 해줌?
							ㄴ ???라벨을 추거하거나 제거하는 등의 러벨값의 변화는 새 시계열 데이터를 생성하게된다?
							ㄴ 라벨명 규칙
								ㄴ 숫자, 아스키, 언더스코어로 구성
								ㄴ 연속 두개의 언더스코어는 내부동작에서 사용을 위해 예약되어있음.
							ㄴ 비어있는 라벨은 러벨이 없는것으로 취급.
							
					ㄴ Sample 
						ㄴ 실제 time series 데이터를 의미. 
						ㄴ millisecond timestamp 값과 float64 값으로 구성. 
					ㄴ Notation  
						ㄴ 메투릭스명과 라벨명으로 시계열 대이터를 식별하는 것을 notation이라 하는듯?  
						ㄴ < metric name>{< label name>=< label value>, ...}
						ㄴ ex ) api_http_requests_total{method="POST", handler="/messages"}
					ㄴ Metric type 
						ㄴ 4가지 metric 데이터 유형 존재. 
						ㄴ ??? 클라이언트 라이브러리에서만 타입이 구분됨? prometheus 서버는 현재 이런 유형을 구분
						ㄴ 목록 
							ㄴ Counter 
								ㄴ 값이 증가하거나 리셋될 수 밖에 없는 유형. 
									즉, 0 등으로 초기화 되는게 아니면 증가밖에 하지 않는 유형의 값. 
								ㄴ ex ) request 횟수, 에러 횟수 등. 
							ㄴ Gauge 
								ㄴ 증감할 수 있는 유형. 
								ㄴ ex ) queue에 들은 이벤트 개수 등. 
							ㄴ Histogram
								ㄴ ??? 어떤 범위내의 관측데이터의 카운트와 합계를 나타내는 값 타입?
								ㄴ ex ) 요청 지연시간, 응답 사이즈 등의 메트릭스에 사용? 
								ㄴ ??? metric 값에 대해 특정 범위(bucket)들을 정의하고 이 bucket에 속하는 카운트를 집계? 
								ㄴ ex ) 
									request의 처리 시간이라면, 
									처리시간에 대해 0ms ~ 0.1ms,  0~0.5ms, 0~1ms 등의 bucket들을 정의하고 
									request마다 처리시간을 측정하여 해당 bucket에 속하는 카운트를 집계. 
							ㄴ Summary 
								ㄴ ~~~???
					ㄴ job, instance 
						ㄴ ??? prometheus에서 스크랩 되는 endpoint를 'instance'라 호칭. 
							ㄴ ??? 일반적으로 하나의 프로세스? 
						ㄴ 같은 목적을 위한 instance들의 집합을 'job'이라 호칭. 
							ㄴ 
					ㄴ 프로메테유스서버는 target으로부터 시계열 데이터 수집시 자동으로 몇가지 label들을 붙임.
						ㄴ job : target이 속한 job이름.
						ㄴ instance : 터겟의 ‘호스트명:포트’ 값.
						ㄴ ???이 데이터가 이미 존재한다면, ‘honor_labels’ 설정값에 따라 동작.
						ㄴ ???인스턴스 그크랩시 다음 sample을 저장한다?
							? 스크랩시 자동 수집하는 데이터인건 알겟는데 하나의 스칼라같은 값이라는건지 시계열이란건지?
							ㄴ up{~~~
							ㄴ ~~~
					ㄴ 기본 사용법 <button>more</button>
					<pre>
						ㄴ 설치 
							ㄴ ~~~ 
						ㄴ Prometheus 서버 실행 
							ㄴ 설치한 위치에서 'prometheus.exe' 실행하면 서버가 실행되고 
								설정파일에서 설정된대로 데이터를 수집하기 시작. 
						ㄴ prometheus 대시보드 
							ㄴ 설정에 따라 다ㅡㄹ지만 디폴트로 localhost:9090를 통해 로컬에서 돌아가는 프로메테우스 대시보드 접속 가능. 
							ㄴ 프로메테우스 쿼리 사용 가능. 쿼리 결과를 table 또는 기본적 그래프 형식으로 볼 수 있음. 
						ㄴ exporter 
							ㄴ 모니터링 타겟(즉, 시스템, 리소스 등 여러 데이터를 수집하려는 타겟)쪽에 prometheus의 exporter라는 프로그램 설치하여 
								이 프로그램이 데이터를 수집하여 특정 포인트에 수집한 데이터들을 노출시키도록함. 
							ㄴ 프로메테우스 서버는 이 포인트로부터 데이터를 읽어와 서버에 저장하는 식으로 수집. 
							ㄴ 데이터를 노출시키는 이 포인트는 일반적으로 (*해당 타겟 host*):(*노출port*)/metrics 
								ㄴ ex ) 192.168.0.184:8091/metrics 
								ㄴ 해당 포인트로 접속시 exporter가 수집한 여러 데이터들이 출력됨.  
					</pre>
					
					ㄴ node_exporter <button>more</button>
					<pre>
						ㄴ https://github.com/prometheus/node_exporter?tab=readme-ov-file
						ㄴ *NIX kernel이 제공하는 하드웨어, OS관련 metric들 전용 Prometheus exporter. 
						ㄴ GO 언어로 개발. 
						ㄴ 디폴트로 9100 port로 HTTP를 listen. 
						ㄴ 데이터 수집할 타겟에 node exporter 설치. 
						ㄴ 이 exporter를 프로메테우스 서버가 수집하도록 설정. 
						ㄴ 리눅스에 설치 
							ㄴ 프로메테우스 다운 페이지에서 알맞은 node_exporter를 wget명령어로 다운하고 tar로 압축해제. 
							ㄴ ex ) 
								wget https://github.com/prometheus/node_exporter/releases/download/v(*버전*)/node_exporter-(*버전*).(*os*)-(*아키텍쳐*).tar.gz
								tar xvfz node_exporter-*.*-amd64.tar.gz 
							ㄴ 이후 설치된 node_exporter 실행하면 exporter가 실행. 
								metric를 노출시키게 되고 프로메테우스가 데이터를 수집해갈 수 ㅣㅇㅆ음. 
						ㄴ 도커에 설치하는 경우 
							ㄴ ~~~ 
						ㄴ 윈도우용 node_exporter <button>more</button>
						<pre>
							ㄴ 별도 페이지에서 다운 및 설치. 
								ㄴ https://github.com/prometheus-community/windows_exporter?tab=readme-ov-file
							ㄴ 기본 사용법 
								ㄴ 설치 후, 대략 C드라이브/Program Files 위치즈음에 window_exporter 폴더 존재. 
									그 안의 window_exporter 실행파일 실행시 실행됨. cmd로 실행하는것 추천. 
								ㄴ 명령어에서 옵션 넘겨 동작 설정 가능. 
								ㄴ 윈도우의 해당 port는 열어주어야함. 
							ㄴ 옵션 
								ㄴ ~~~ 
								ㄴ --collectors.enabled "(*collector명*),(*collector명*), ..." 
									ㄴ 사용할 collector 명시. 
									ㄴ 디폴트값은 '[defaults]' 라는 문자열로, 
										디폴트로 사용되기로 되어있는 collector들이 포함됨. 
										디폴트 컬렉터 목록은 문서 참고. 
						</pre>
						ㄴ Collectors 
							ㄴ exporter에서 데이터를 수집하는 객체 같은 것? 
							ㄴ 컬렉터마다 특정 영역의 데이터들을 수집? 
							ㄴ 디폴트로 사용되는 컬렉터 존재. 
							ㄴ exporter 실행 명령어에 옵션으로 어떤 컬렉터 사용할지 명시 가능. 
							ㄴ 컬렉터 목록 
								ㄴ ~~~ 
						ㄴ ??? exporter 실행시 listen-address에서 주소를 지정하지 않아야 다른 서버에서 접속하여 데이터 가져갈 수 있는 듯. 
							ㄴ 즉, ./node_exporter --web.listen-address 127.0.0.1:8093   // 이런식으로 하면 프로메테우스 서버에서 접속을 
								못하고, 
								./node_exporter --web.listen-address :8093  // 이런식으로 해야 접속 가능? 
					</pre>
					ㄴ prometheus 서버 자체도 스크랩 대상이 될 수 있음. 
						ㄴ 하여 설정 파일에 localhost:9090 등으로 스크랩 대상을 포함시키면 
							프로메테우스 서버의 metrics들을 스크랩함. 
						ㄴ ??? 프로메테우스 서버로부터 스크랩되는 metric 목록은 다음 url에서 확인 가능? 
							localhost:9090/metrics 
					ㄴ??? expose하고 있는 metric는 해당 서버의 /metrics url에서 확인 가능? 
						ㄴ ex ) 192.168.0.183:9081/metrics 
						ㄴ 수집된 metric들의 값 목록이 나온다. 
					ㄴ endpoint를 묶어 '그룹'으로 만들 수 있음. 
						'그룹'들을 하나의 'job'에 추가할 수 있음. 
						'그룹'에 'label'을 붙일 수 있음. 
						ㄴ 설정파일을 통하여 가능. 
					ㄴ rule? 
						ㄴ 
					ㄴ 프로메테우스 재시작 없이 설정값 적용
						ㄴ 프로그램을 재시작 할 필요 없이, 'SIGHUP' signal을 통하여 설정값을 리로드 할 수 있다. 
						ㄴ 리눅스의 경우, 'kill -s SIGHUP (*pid*)' 명령어를 통해 가능. 
					ㄴ 프로메테우스 종료 방법
						ㄴ recovery 메커니즘이 있기는 하나, SIGTERM signal로 종료하는게 안전하다함. 
						ㄴ 리눅스에서, 'kill -s SIGTERM (*pid*)' 명령어로 가능. 

					ㄴ 설정 <button>more</button>
					<pre>
						ㄴ 명령어 인자 또는 설정 파일을 통하여 프로메테우스 설정 가능. 
						ㄴ --config.file 명령어 인자로 설정파일 명시 가능. 
						ㄴ 설정 파일 <button>more</button>
						<pre>
							ㄴ YAML 형식. 
							ㄴ 예제 
								ㄴ https://github.com/prometheus/prometheus/blob/release-2.54/config/testdata/conf.good.yml
								ㄴ ex ) 
									global:
										scrape_interval:     15s # By default, scrape targets every 15 seconds.
										evaluation_interval: 15s # Evaluate rules every 15 seconds.
									
										# Attach these labels to any time series or alerts when communicating with
										# external systems (federation, remote storage, Alertmanager).
										external_labels:
										monitor: 'codelab-monitor'
									
									rule_files:
										- 'prometheus.rules.yml'
										
									# A scrape configuration containing exactly one endpoint to scrape:
									# Here it's Prometheus itself.
									scrape_configs:
										# The job name is added as a label `job=< job_name>` to any timeseries scraped from this config.
										- job_name: 'prometheus'
									
										# Override the global default and scrape targets from this job every 5 seconds.
										scrape_interval: 5s
									
										static_configs:
											- targets: ['localhost:9090']
									
											- targets: ['192.168.0.183:8091', ]
											labels:
												group: 'production'
									
											- targets: ['192.168.0.184:8093']
											labels:
												group: 'canary'
									
											- targets: ['localhost:8094']
											labels:
												group: 'monitoring' 

							ㄴ 설정값 타입 
								ㄴ < boolean> : true 또는 false. 
								ㄴ < duration> : 정규식에 맞는 기간 표현. 
									ㄴ ex ) 1d, 1h30m, 10s, ... 
								ㄴ ~~~ 
								ㄴ 그 외도 존재. 이 경우, 각 설정값에서 설명. 
							ㄴ global 설정 
								ㄴ 설정파일에서 글로벌 범위로 설정되어 다른 설정파일들에 영향을 미치거나 디폴트값 취급되는 설정들. 
								ㄴ ex ) <button>more</button>
								<pre>
									global:
										# How frequently to scrape targets by default.
										[ scrape_interval: < duration> | default = 1m ]
									
										# How long until a scrape request times out.
										[ scrape_timeout: < duration> | default = 10s ]
									
										# The protocols to negotiate during a scrape with the client.
										# Supported values (case sensitive): PrometheusProto, OpenMetricsText0.0.1,
										# OpenMetricsText1.0.0, PrometheusText0.0.4.
										# The default value changes to [ PrometheusProto, OpenMetricsText1.0.0, OpenMetricsText0.0.1, PrometheusText0.0.4 ]
										# when native_histogram feature flag is set.
										[ scrape_protocols: [< string>, ...] | default = [ OpenMetricsText1.0.0, OpenMetricsText0.0.1, PrometheusText0.0.4 ] ]
									
										# How frequently to evaluate rules.
										[ evaluation_interval: < duration> | default = 1m ]
									
										# Offset the rule evaluation timestamp of this particular group by the specified duration into the past to ensure the underlying metrics have been received.
										# Metric availability delays are more likely to occur when Prometheus is running as a remote write target, but can also occur when there's anomalies with scraping.
										[ rule_query_offset: < duration> | default = 0s ]
									
										# The labels to add to any time series or alerts when communicating with
										# external systems (federation, remote storage, Alertmanager).
										external_labels:
										[ < labelname>: < labelvalue> ... ]
									
										# File to which PromQL queries are logged.
										# Reloading the configuration will reopen the file.
										[ query_log_file: < string> ]
									
										# An uncompressed response body larger than this many bytes will cause the
										# scrape to fail. 0 means no limit. Example: 100MB.
										# This is an experimental feature, this behaviour could
										# change or be removed in the future.
										[ body_size_limit: < size> | default = 0 ]
									
										# Per-scrape limit on number of scraped samples that will be accepted.
										# If more than this number of samples are present after metric relabeling
										# the entire scrape will be treated as failed. 0 means no limit.
										[ sample_limit: < int> | default = 0 ]
									
										# Per-scrape limit on number of labels that will be accepted for a sample. If
										# more than this number of labels are present post metric-relabeling, the
										# entire scrape will be treated as failed. 0 means no limit.
										[ label_limit: < int> | default = 0 ]
									
										# Per-scrape limit on length of labels name that will be accepted for a sample.
										# If a label name is longer than this number post metric-relabeling, the entire
										# scrape will be treated as failed. 0 means no limit.
										[ label_name_length_limit: < int> | default = 0 ]
									
										# Per-scrape limit on length of labels value that will be accepted for a sample.
										# If a label value is longer than this number post metric-relabeling, the
										# entire scrape will be treated as failed. 0 means no limit.
										[ label_value_length_limit: < int> | default = 0 ]
									
										# Per-scrape config limit on number of unique targets that will be
										# accepted. If more than this number of targets are present after target
										# relabeling, Prometheus will mark the targets as failed without scraping them.
										# 0 means no limit. This is an experimental feature, this behaviour could
										# change in the future.
										[ target_limit: < int> | default = 0 ]
									
										# Limit per scrape config on the number of targets dropped by relabeling
										# that will be kept in memory. 0 means no limit.
										[ keep_dropped_targets: < int> | default = 0 ]
									
									runtime:
										# Configure the Go garbage collector GOGC parameter
										# See: https://tip.golang.org/doc/gc-guide#GOGC
										# Lowering this number increases CPU usage.
										[ gogc: < int> | default = 75 ]
									
									# Rule files specifies a list of globs. Rules and alerts are read from
									# all matching files.
									rule_files:
										[ - < filepath_glob> ... ]
									
									# Scrape config files specifies a list of globs. Scrape configs are read from
									# all matching files and appended to the list of scrape configs.
									scrape_config_files:
										[ - < filepath_glob> ... ]
									
									# A list of scrape configurations.
									scrape_configs:
										[ - < scrape_config> ... ]
									
									# Alerting specifies settings related to the Alertmanager.
									alerting:
										alert_relabel_configs:
										[ - < relabel_config> ... ]
										alertmanagers:
										[ - < alertmanager_config> ... ]
									
									# Settings related to the remote write feature.
									remote_write:
										[ - < remote_write> ... ]
									
									# Settings related to the remote read feature.
									remote_read:
										[ - < remote_read> ... ]
									
									# Storage related settings that are runtime reloadable.
									storage:
										[ tsdb: < tsdb> ]
										[ exemplars: < exemplars> ]
									
									# Configures exporting traces.
									tracing:
										[ < tracing_config> ]
								</pre>
							ㄴ < scrape_config> 섹션 
								ㄴ 데이터를 수집할 타겟과 어떻게 수집할지에 대한 설정을 하는 섹션. 
								ㄴ ??? 일반적으로 하나의 섹션에 하나의 'job'이 온다? 
								ㄴ ??? target이 'static_configs' 값에 의해 설정 될 수도 있고, 
									service-discovery 매터니즘에 의해 동적으로 discover될 수도 있다? 
								ㄴ 구성 <button>more</button>
								<pre>
									# The job name assigned to scraped metrics by default.
									job_name: < job_name>

									# How frequently to scrape targets from this job.
									[ scrape_interval: < duration> | default = < global_config.scrape_interval> ]

									# Per-scrape timeout when scraping this job.
									[ scrape_timeout: < duration> | default = < global_config.scrape_timeout> ]

									# The protocols to negotiate during a scrape with the client.
									# Supported values (case sensitive): PrometheusProto, OpenMetricsText0.0.1,
									# OpenMetricsText1.0.0, PrometheusText0.0.4.
									[ scrape_protocols: [< string>, ...] | default = < global_config.scrape_protocols> ]

									# Whether to scrape a classic histogram that is also exposed as a native
									# histogram (has no effect without --enable-feature=native-histograms).
									[ scrape_classic_histograms: < boolean> | default = false ]

									# The HTTP resource path on which to fetch metrics from targets.
									[ metrics_path: < path> | default = /metrics ]

									# honor_labels controls how Prometheus handles conflicts between labels that are
									# already present in scraped data and labels that Prometheus would attach
									# server-side ("job" and "instance" labels, manually configured target
									# labels, and labels generated by service discovery implementations).
									#
									# If honor_labels is set to "true", label conflicts are resolved by keeping label
									# values from the scraped data and ignoring the conflicting server-side labels.
									#
									# If honor_labels is set to "false", label conflicts are resolved by renaming
									# conflicting labels in the scraped data to "exported_< original-label>" (for
									# example "exported_instance", "exported_job") and then attaching server-side
									# labels.
									#
									# Setting honor_labels to "true" is useful for use cases such as federation and
									# scraping the Pushgateway, where all labels specified in the target should be
									# preserved.
									#
									# Note that any globally configured "external_labels" are unaffected by this
									# setting. In communication with external systems, they are always applied only
									# when a time series does not have a given label yet and are ignored otherwise.
									[ honor_labels: < boolean> | default = false ]

									# honor_timestamps controls whether Prometheus respects the timestamps present
									# in scraped data.
									#
									# If honor_timestamps is set to "true", the timestamps of the metrics exposed
									# by the target will be used.
									#
									# If honor_timestamps is set to "false", the timestamps of the metrics exposed
									# by the target will be ignored.
									[ honor_timestamps: < boolean> | default = true ]

									# track_timestamps_staleness controls whether Prometheus tracks staleness of
									# the metrics that have an explicit timestamps present in scraped data.
									#
									# If track_timestamps_staleness is set to "true", a staleness marker will be
									# inserted in the TSDB when a metric is no longer present or the target
									# is down.
									[ track_timestamps_staleness: < boolean> | default = false ]

									# Configures the protocol scheme used for requests.
									[ scheme: < scheme> | default = http ]

									# Optional HTTP URL parameters.
									params:
									[ < string>: [< string>, ...] ]

									# If enable_compression is set to "false", Prometheus will request uncompressed
									# response from the scraped target.
									[ enable_compression: < boolean> | default = true ]

									# Sets the `Authorization` header on every scrape request with the
									# configured username and password.
									# password and password_file are mutually exclusive.
									basic_auth:
									[ username: < string> ]
									[ password: < secret> ]
									[ password_file: < string> ]

									# Sets the `Authorization` header on every scrape request with
									# the configured credentials.
									authorization:
									# Sets the authentication type of the request.
									[ type: < string> | default: Bearer ]
									# Sets the credentials of the request. It is mutually exclusive with
									# `credentials_file`.
									[ credentials: < secret> ]
									# Sets the credentials of the request with the credentials read from the
									# configured file. It is mutually exclusive with `credentials`.
									[ credentials_file: < filename> ]

									# Optional OAuth 2.0 configuration.
									# Cannot be used at the same time as basic_auth or authorization.
									oauth2:
									[ < oauth2> ]

									# Configure whether scrape requests follow HTTP 3xx redirects.
									[ follow_redirects: < boolean> | default = true ]

									# Whether to enable HTTP2.
									[ enable_http2: < boolean> | default: true ]

									# Configures the scrape request's TLS settings.
									tls_config:
									[ < tls_config> ]

									# Optional proxy URL.
									[ proxy_url: < string> ]
									# Comma-separated string that can contain IPs, CIDR notation, domain names
									# that should be excluded from proxying. IP and domain names can
									# contain port numbers.
									[ no_proxy: < string> ]
									# Use proxy URL indicated by environment variables (HTTP_PROXY, https_proxy, HTTPs_PROXY, https_proxy, and no_proxy)
									[ proxy_from_environment: < boolean> | default: false ]
									# Specifies headers to send to proxies during CONNECT requests.
									[ proxy_connect_header:
									[ < string>: [< secret>, ...] ] ]


									# List of Azure service discovery configurations.
									azure_sd_configs:
									[ - < azure_sd_config> ... ]

									# List of Consul service discovery configurations.
									consul_sd_configs:
									[ - < consul_sd_config> ... ]

									# List of DigitalOcean service discovery configurations.
									digitalocean_sd_configs:
									[ - < digitalocean_sd_config> ... ]

									# List of Docker service discovery configurations.
									docker_sd_configs:
									[ - < docker_sd_config> ... ]

									# List of Docker Swarm service discovery configurations.
									dockerswarm_sd_configs:
									[ - < dockerswarm_sd_config> ... ]

									# List of DNS service discovery configurations.
									dns_sd_configs:
									[ - < dns_sd_config> ... ]

									# List of EC2 service discovery configurations.
									ec2_sd_configs:
									[ - < ec2_sd_config> ... ]

									# List of Eureka service discovery configurations.
									eureka_sd_configs:
									[ - < eureka_sd_config> ... ]

									# List of file service discovery configurations.
									file_sd_configs:
									[ - < file_sd_config> ... ]

									# List of GCE service discovery configurations.
									gce_sd_configs:
									[ - < gce_sd_config> ... ]

									# List of Hetzner service discovery configurations.
									hetzner_sd_configs:
									[ - < hetzner_sd_config> ... ]

									# List of HTTP service discovery configurations.
									http_sd_configs:
									[ - < http_sd_config> ... ]


									# List of IONOS service discovery configurations.
									ionos_sd_configs:
									[ - < ionos_sd_config> ... ]

									# List of Kubernetes service discovery configurations.
									kubernetes_sd_configs:
									[ - < kubernetes_sd_config> ... ]

									# List of Kuma service discovery configurations.
									kuma_sd_configs:
									[ - < kuma_sd_config> ... ]

									# List of Lightsail service discovery configurations.
									lightsail_sd_configs:
									[ - < lightsail_sd_config> ... ]

									# List of Linode service discovery configurations.
									linode_sd_configs:
									[ - < linode_sd_config> ... ]

									# List of Marathon service discovery configurations.
									marathon_sd_configs:
									[ - < marathon_sd_config> ... ]

									# List of AirBnB's Nerve service discovery configurations.
									nerve_sd_configs:
									[ - < nerve_sd_config> ... ]

									# List of Nomad service discovery configurations.
									nomad_sd_configs:
									[ - < nomad_sd_config> ... ]

									# List of OpenStack service discovery configurations.
									openstack_sd_configs:
									[ - < openstack_sd_config> ... ]

									# List of OVHcloud service discovery configurations.
									ovhcloud_sd_configs:
									[ - < ovhcloud_sd_config> ... ]

									# List of PuppetDB service discovery configurations.
									puppetdb_sd_configs:
									[ - < puppetdb_sd_config> ... ]

									# List of Scaleway service discovery configurations.
									scaleway_sd_configs:
									[ - < scaleway_sd_config> ... ]

									# List of Zookeeper Serverset service discovery configurations.
									serverset_sd_configs:
									[ - < serverset_sd_config> ... ]

									# List of Triton service discovery configurations.
									triton_sd_configs:
									[ - < triton_sd_config> ... ]

									# List of Uyuni service discovery configurations.
									uyuni_sd_configs:
									[ - < uyuni_sd_config> ... ]

									# List of labeled statically configured targets for this job.
									static_configs:
									[ - < static_config> ... ]

									# List of target relabel configurations.
									relabel_configs:
									[ - < relabel_config> ... ]

									# List of metric relabel configurations.
									metric_relabel_configs:
									[ - < relabel_config> ... ]

									# An uncompressed response body larger than this many bytes will cause the
									# scrape to fail. 0 means no limit. Example: 100MB.
									# This is an experimental feature, this behaviour could
									# change or be removed in the future.
									[ body_size_limit: < size> | default = 0 ]

									# Per-scrape limit on number of scraped samples that will be accepted.
									# If more than this number of samples are present after metric relabeling
									# the entire scrape will be treated as failed. 0 means no limit.
									[ sample_limit: < int> | default = 0 ]

									# Per-scrape limit on number of labels that will be accepted for a sample. If
									# more than this number of labels are present post metric-relabeling, the
									# entire scrape will be treated as failed. 0 means no limit.
									[ label_limit: < int> | default = 0 ]

									# Per-scrape limit on length of labels name that will be accepted for a sample.
									# If a label name is longer than this number post metric-relabeling, the entire
									# scrape will be treated as failed. 0 means no limit.
									[ label_name_length_limit: < int> | default = 0 ]

									# Per-scrape limit on length of labels value that will be accepted for a sample.
									# If a label value is longer than this number post metric-relabeling, the
									# entire scrape will be treated as failed. 0 means no limit.
									[ label_value_length_limit: < int> | default = 0 ]

									# Per-scrape config limit on number of unique targets that will be
									# accepted. If more than this number of targets are present after target
									# relabeling, Prometheus will mark the targets as failed without scraping them.
									# 0 means no limit. This is an experimental feature, this behaviour could
									# change in the future.
									[ target_limit: < int> | default = 0 ]

									# Per-job limit on the number of targets dropped by relabeling
									# that will be kept in memory. 0 means no limit.
									[ keep_dropped_targets: < int> | default = 0 ]

									# Limit on total number of positive and negative buckets allowed in a single
									# native histogram. The resolution of a histogram with more buckets will be
									# reduced until the number of buckets is within the limit. If the limit cannot
									# be reached, the scrape will fail.
									# 0 means no limit.
									[ native_histogram_bucket_limit: < int> | default = 0 ]

									# Lower limit for the growth factor of one bucket to the next in each native
									# histogram. The resolution of a histogram with a lower growth factor will be
									# reduced as much as possible until it is within the limit.
									# To set an upper limit for the schema (equivalent to "scale" in OTel's
									# exponential histograms), use the following factor limits:
									# 
									# +----------------------------+----------------------------+
									# |        growth factor       | resulting schema AKA scale |
									# +----------------------------+----------------------------+
									# |          65536             |             -4             |
									# +----------------------------+----------------------------+
									# |            256             |             -3             |
									# +----------------------------+----------------------------+
									# |             16             |             -2             |
									# +----------------------------+----------------------------+
									# |              4             |             -1             |
									# +----------------------------+----------------------------+
									# |              2             |              0             |
									# +----------------------------+----------------------------+
									# |              1.4           |              1             |
									# +----------------------------+----------------------------+
									# |              1.1           |              2             |
									# +----------------------------+----------------------------+
									# |              1.09          |              3             |
									# +----------------------------+----------------------------+
									# |              1.04          |              4             |
									# +----------------------------+----------------------------+
									# |              1.02          |              5             |
									# +----------------------------+----------------------------+
									# |              1.01          |              6             |
									# +----------------------------+----------------------------+
									# |              1.005         |              7             |
									# +----------------------------+----------------------------+
									# |              1.002         |              8             |
									# +----------------------------+----------------------------+
									# 
									# 0 results in the smallest supported factor (which is currently ~1.0027 or
									# schema 8, but might change in the future).
									[ native_histogram_min_bucket_factor: < float> | default = 0 ]
								</pre>
							ㄴ < tls_config> 섹션 
								ㄴ TLS 연결에 대한 설정. 
								ㄴ ex ) 
									~~~ 
							ㄴ ~~~ 
						</pre>

						ㄴ Rule 
							ㄴ 
							ㄴ Recording rule <button>more</button>
							<pre>
								ㄴ 자주 사용하거나 계산 비용이 비싼 결과를 미리 계산해서 time series set으로 저장하게 해줌. 
									매번 표현식을 계산하는 것보다 빠르게됨. 
								ㄴ 대시보드 등에 유용. 
								ㄴ ~~~
							</pre>
							
							ㄴ Alerting rule <button>more</button>
							<pre>
								ㄴ ~~~
							</pre> 

						ㄴ Template 
							ㄴ ??? ~~~ 

						ㄴ Rule 에 대한 단위 테스트 
							ㄴ ~~~ ??? 
						
						ㄴ HTTPS and authentication 
							ㄴ 기본 인증과 TLS 기능 제공. 
							ㄴ 실험적 기능. 변경될 수 있음. 
					</pre>

					ㄴ 쿼리 <button>more</button>
					<pre>
						ㄴ PromQL (Prometheus Query Language)
							ㄴ 프로메테우스에서 제공하는 데이터를 실시간으로 time series형식으로 조회하거나 집계 가능한 쿼리언어. 
						ㄴ 프로메테우스 expression 브라우저에서 그래프 또는 테이블 형식으로 볼 수 있음.
							또는 HTTP API를 통해 사용할 수 있음. 
						ㄴ ??? 쿠ㅓ리 표현식의 결과 타입? 
							ㄴ 목록 
								ㄴ instant vector 
								ㄴ range vector 
								ㄴ scalar 
								ㄴ string 
							ㄴ ??? 쿼리 결과를 어떻게 사용하는지에 따라 유효한 결과 타입이 정해져 있다? 
								ㄴ ??? 가령, 결과 타입이 scalar인데 그결과를 그래프 렌더링에 사용하는건 타입이 유효하지 않다? 
									그래프를 그리기 위해선 instant vector 타입만 가능하므로? 
						
						ㄴ Literal 
							ㄴ String literal 
								ㄴ 작은따옴표, 쌍따엄표, 백틱으로 표현하는 상수값.
								ㄴ ??? Go 언어와 같은 escape 규칙 따름?
									ㄴ ??? 단, 백틱 사용시 escape 파싱하지 않음?
							ㄴ float liternal 
						ㄴ time series selector 
							ㄴ ???~~~ Time series selectors are responsible for selecting the times series and raw or inferred sample timestamps and values.
							ㄴ ??? 상위 개념인 'instant query', 'range query'와 혼동돼선 안된다? 
							ㄴ label 매칭 
								ㄴ 기호에 따라 매칭 방법 결정 
									ㄴ (*label명*) (*매칭기호*) (*값*)
									ㄴ ex ) group~="scraping" 
								ㄴ 목록 
									ㄴ = : 값으로 주어진 문자열과 동일한 label값으로 필터링. 
									ㄴ ~= : 값으로 주어진 문자열과 동일하지 않은 label값으로 필터링. 
									ㄴ =~ : 값으로 정규식이 오고, 이 정규식과 매칭되는 label값을 가진 time series를 필터링. 
									ㄴ !~ : =~의 반대. 매칭 안되는것 필터링. 
							ㄴ instant vector selector
								ㄴ 라벨값 매칭에서 라벨값이 빈 경우, 해당 라벨이 없는 시계열 데이터가 먀칭됨.
								ㄴ 라벨 여러개 명시하여 매칭하는 경우 각 라벨매칭을 모두 만족해야 매칭됨.
								ㄴ 매칭은 최소 하나의 이름을 명시하거나 빈 문자열에 해당하지 않는 라벨값을 명시해야함.
								ㄴ 메트릭이름 댜신 ‘__name__’ label값을 이용하여ㅜ매칭 가능. 모든 메트릭들이 이 라벨값을 가지고 있음.
									ㄴ ex) http_requests_total 메트릭은 ‘http_requests_total’이란 ’__name__’ 라벨값 가짐.
								ㄴ ???메트릭이름은 bool, on, ignoring, group_left, group_right가 될 수 없다.
									ㄴ ???이를 ‘__name__’ label을 이용해 우회가능하다?
							ㄴ range vector selector
								ㄴ instant vector selector와 거의 유사. 단지 전체시계열이 아닌 현재시점부터 과거로 일부 time duration에ㅜ대한 데이터만 select함.
								ㄴ instant selector뒤에 대괄호([])를 붙이고 그 안에 ‘time duration’을 넣어 사용 가능.
								ㄴ 범위는 닫힌범위.
								ㄴ ex )
									ㄴ `http_requests_total{job="prometheus"}[5m]`
							ㄴ time duration
								ㄴ 숫자와 단위를 나타내는 문자(또는 문자열)로 표현
									ㄴ ex ) 5m, 200ms, 3y
									ㄴ 단위모곡
										ㄴ ms, s, m, h, d, w, y
								ㄴ 결합가능
									ㄴ 당연히 큰단위가 먼저와야하고 각단위는 한번씩만 가능.
									ㄴ ex) 1h30m
							ㄴ offset
								ㄴ select할 대이터의 offset  살정 가능.
								ㄴ ex )
									ㄴ http_requests_total offset 5m
									ㄴ http_requests_total[5m] offset 5w
								ㄴ ???instant selector의 경우, offset시점에 햐당하는 데이터 반환?
								ㄴ ??? range selectir의 경우, 범위가 끝나는 지점 설정 가능?
								ㄴ selector 비로 뒤에 와야함.
								ㄴ @ modifier
									ㄴ offset과 유사한 기능. select하는 데이터의 시점을 명시.
									ㄴ 형식
										ㄴ (**selector*) @ (*modifier value**)
									ㄴ offset과 유사하게 selector 바로 뒤에 붙여서 사용.
									ㄴ unix timestamp 를 입력받아 그 시점에 해당하는 데이터를 조회.
									ㄴ ex )
										ㄴ http_requests_total @ 16038393
											ㄴ 160~~~값에 해당하는 시점에서의 총 요청수 조회.
									ㄴ offset과 함께 사용 가능.
										ㄴ modifier가 먼저 적용되고 그 시점으로부터 offset이 작용
										ㄴ selector 뒤에 입력하는 순서는 상관없음. offset이 먼저오던 modifier가 먼저오던.
									ㄴ modifier 값으로 start(), end() 함수 사용 가능.
						ㄴ subquery
							ㄴ ???  
						ㄴ 연산자 
							ㄴ prometheus에서 쿼리상에서 제공하는 연산자들. 
						ㄴ 함수 
							ㄴ prometheus에서 쿼리상에서 제공하는 함수들. 
							ㄴ ~~~ 
							ㄴ absent() 
								ㄴ ??? ~~~
								ㄴ 값을 하나라도 전달받으면 빈 값 반환. 하나도 받지 않으면 값 1을 가진 element 하나 반환. 
						ㄴ 주석 
							ㄴ '#'으로 시작하는 줄을 주석취급. 
						ㄴ 예제  
						ㄴ 실무 tip 
							ㄴ 특정 쿼리 표현식의 결과가 있을 땐 그 값을 쓰고 없는 경우 명시적으로 특정 값을 반환하고 싶은 경우. 
								쿼리 표현식 맨 뒤에 'OR on() vector( (*1또는 0*) )' 을 사용하면 앞부분 쿼리표현식의 결과가 없는 경우, 
								vector()에 명시한 값을 반환. 
								ㄴ 함수 absent()로 값이 없는 경우 확인 가능하지만, 위와 같이 값이 있기도 하고 없기도 할때 사용하기 애매. 
									그럴때 이 방법 쓰면 유용. 
					</pre>

					ㄴ Storage <button>more</button>
					<pre>
						ㄴ 프로메테우스는 local on-disk time series db 를 기본적으로 포함. 
						ㄴ 선택적으로 remote storage 사용 가능. 
						ㄴ ~~~ ???
					</pre> 
				
					ㄴ Federation 
						ㄴ ??? 한 프로메테우스 서버가 다른 프로메테우스 서버로부터 데이터를 수집하게 해주는 기능? 

					ㄴ 시각화 
						ㄴ expression browser 
							ㄴ prometheus 서버의 url /graph 페이지를 통해 기본적인 테이블, 그래프 시각화 가능. 
						ㄴ Grafana 
						ㄴ ??? console templates

				</pre> 
				
				ㄴ Grafana <button>more</button>
				<pre>
					ㄴ 개요 
						ㄴ ??? 쿼리, 시각화, 알림 기능을 해주는 소프트웨어? 
						ㄴ ??? time series db, logging tool, NoSQL db, SQL db, CI/CD tool 등에 대해 쿼리 가능

					ㄴ ??? 다른 상품들? 
						ㄴ Grafana Loki 
						ㄴ Grafana Tempo 
						ㄴ Grafana Mimir 
						ㄴ Grafana Oncal 
						ㄴ Grafana Cloud 
						ㄴ Grafana Enterprise 
							ㄴ Grafana 오픈소스에는 없는 기능 제공 및 관련 교육 제공하는 commercial edition.  
					
					ㄴ time series database, TSDB
						ㄴ 시계열 데이터 저장에 특화된 db를 지칭하는 말. (Grafana에서만 사용하는 단어 아님)
						ㄴ 값들의 차, 값들의 차의 차를 저장하는 형식으로 많은 공간 절약 가능.
						ㄴ ???‘tag’ 사용 가능?
							ㄴ 각 시계열 데이터에 탸그, 라벨 등을 붙여 그 데이터에 context 데이터를 부여하는 기능? 필터링에 서용?
						ㄴ ex ) Prometheus, InfluxDB
						ㄴ TSDB 데이터의 수집
							ㄴ 일반적으로 collector 컴포넌트가 따로 존재하여 이 개체둘이 시계열 데이터를 수집.
							ㄴ 수집대상은 기계, 인스턴스 등 뭐든 가능.
							ㄴ 일반적으로 collector는 특정 TSDB를 염두해두고 만들어진다함.
							ㄴ ex) Prometheus의 exporter, statsd
							ㄴ 컬렉터는 일반적으로 push, pull 방식중 하나 사용.

					ㄴ 기본 사용법 
						ㄴ 다운 
							ㄴ 공식 홈에서 버전, 에디션(Enterprise인지 오픈소스인지), os 선택하고 다운. 
						ㄴ 실행 
							ㄴ Grafana 폴더 /bin/grafana-server 실행. 
							ㄴ 디폴트로 3000 port에서 실행. 
							ㄴ localhost:3000 접속. 
							ㄴ 로그인. 디폴트 id, pw는 admin, admin 
						ㄴ alert 
							ㄴ 홈 좌측 > 'Alerting' 메뉴에서 알림 설정 가능.
							ㄴ alert rule 
								ㄴ Alert rule페이지
								ㄴ 'add new alert'
								ㄴ 쿼리, 알림 조건 설정 
									ㄴ 'Define query and alert condition'
										ㄴ 쿼리 입력하여 확인할 데이터 결정. 
									ㄴ expression 부분의 threshold에서 쿼리의 결과값이 어떨때 조건을 충족하는 것으로 취급할지 결정. 
									ㄴ expression 중 하나를 'set alert condition' 버튼을 통해 
										알림이 발송되는 기준으로 결정. 
										ㄴ 여러 쿼리들에 대해 여러 threshold expression들을 두고 이것들의 and | or 조건으로 알림조건을 설정하려면 
											expression 중 'Math' 타입을 두고, 식을 작성하여 기준 설정 ㅏ능 
											ㄴ ex ) 
												$A > 0 || $B > 0 || $C > 0 
								ㄴ pending period 설정 
									ㄴ 해당 조건이 얼마의 시간동안 충족되면 알림을 발송할지 설정. 
									ㄴ ex ) 
										1m 이면, 해당 조건이 1분동안 충족이되면 알림 발성. 
								ㄴ conact point 설젖ㅇ 
									ㄴ 어떤 알림을 어디로 보낼지 설정. 
									ㄴ msTeams, email 등. 
								ㄴ 알림 메세지 설정
									ㄴ summary, description 등. 

					ㄴ Dashboard 
						ㄴ 'panel'로 구성. 
						ㄴ 'panel'은 data source로부터의 데이터를 시각화 형태로 변환하는 컴포넌트에 의해 생성. 
							ㄴ 이 변환 과정은 'plugin', 'query', 'optional transformation'으로 구성. 
						ㄴ data source 
							ㄴ sql db부터 csv 파일까지 뭐든 가능. 
						ㄴ plugin 
							ㄴ Grafana에 추가할 수 있는 플러그인. 다양한 기능의 플러그인 존재. 
							ㄴ data source plugin 
								ㄴ 실행할 쿼리를 받고, 데이터 소스로부터 데이터를 받고, 받아온 데이터와 grafana dashboard 데이터 형식 사이의 
									차이를 조정하는 기능. 
								ㄴ 데이터 형식 차이는 'data frame'이라는 개념을 사용하여 수행. 
									data source의 데이터 형식이 무엇이든 'data frame'형식으로 변환하여 내보내는 형식. 
								ㄴ Query 
									ㄴ ??? 각 데이터 소스별로 쿼리변환 ui 제공하나? 
								ㄴ Transformation 
									ㄴ ??? 
								ㄴ panel 
									ㄴ 최종적으로 데이터가 전달되는 컴포넌트. 
									ㄴ 데이터를 어떤 모양으로 볼지 설정. bar 차트, line차트, 등. 
									ㄴ ??? 이 요소에도 쿼리 존재. panel로 받은 데이터에 대해 쿼리 처리 가능? 
						ㄴ 대시보드 빌딩은
							대시보드를 통하여 하고자하는게 무엇인지, 이를 위해 필요한 데이터 소스가 무엇인지 결정하는 것부터 시작. 
						ㄴ 생성 
							ㄴ ~~~ 
							ㄴ import  
								ㄴ 설정파일 json을 그대로 import하여 대시보드 구성 가능. 
								ㄴ ~~~
								ㄴ 유저가 생성한 대시보드 찾아볼 수 있는 곳 
									ㄴ 유저가 json으로 설정을 만들어 두어 그대로 가져가 쓰거나 참조 가능한 목록이 있는 곳. 
									ㄴ https://grafana.com/grafana/dashboards/
				</pre>


		</pre>

		Window<button>more</button>
		<pre>
			ㄴ 작업 스케줄러<button>more</button>
			<pre>
				ㄴ 작업 만들기<button>more</button>
				<pre>
					ㄴ ~~~~~
					ㄴ 트리거<button>more</button>
					<pre>
						ㄴ ~~~~~
						ㄴ 고급 설정<button>more</button>
						<pre>
							ㄴ 작업이 지연되는 최대 시간(임의지연) : 가령, 30분 설정 시, 시작 시간이 3:00이면, 3:00~3:30 사이에
																랜덤한 시간에 작업 시작.
							ㄴ
						</pre>

					</pre>

					ㄴ 조건<button>more</button>
					<pre>
						ㄴ 유휴 상태(Idle)
							ㄴ 유휴 상태란, 컴퓨터를 사용하고 있지 않아 아무 것도 안 하는 상태. screensaver가 동작 중이거나 cpu 사용량이
								0% 이하이면 해당.
							ㄴ 특정 시간 이상 유휴 상태일 때만 작업 실행하도록 설정.
						ㄴ 전원
							ㄴ AC전원 어쩌구는 노트북인 경우, 베터리, 전원 연결과 관련된 설정.
							ㄴ

					</pre>

					ㄴ 설정<button>more</button>
					<pre>
						ㄴ 요청 시 작업이 실행되도록 허용 : 작업 스케줄러 메인 창에서 우클릭-실행 클릭 시, 작업이 실행되게 할 건지 여부 설정.


					</pre>

				</pre>
			</pre>
			ㅡ
		</pre>

		software design (소프트웨어 설계) <button>more</button>
		<pre>
			ㄴ ???
			ㄴ ??? 개념화, 프레이밍, 구현, 위임, 시스템을 수정하는 것과 관련된 모든 활동?
				또는 요구사항을 따르거나 프로그래밍하기 전 양식화된 소프트웨어 엔지니어링 절차를 의미?
			ㄴ ???
			ㄴ ??? 하나 이상의 문제들에 대해 소프트웨어 솔루션을 구상하고 정의하는 과정?
			ㄴ 주요 설계 요소 중 하나는 '요구사항 분석'.
			ㄴ 분석과 설계 차이
				ㄴ ??? 분석의 결과는 해결해야할 작은 문제들로 구성되어 있다?
				ㄴ ??? 분석은 멤버나 그룹이 달라도 큰 차이가 없어야 한다?
				ㄴ ??? 설계는 같은 문제에 대해서도 여러개의 설계가 존재할 수 있다?
			ㄴ ~~~
			ㄴ design 개념
				ㄴ ??? 설계자가 더 정교한 방법을 적용할 수 있게 해주는 기반이 된다?
				ㄴ 목록 )
					ㄴ abstraction
						ㄴ
			ㄴ 설계시 고려사항
				ㄴ
			ㄴ 모델링 언어
				ㄴ
			ㄴ 디자인 패턴, design pattern
				ㄴ 과거 마주한적이 있거나 다른 사람들에 의해 해결된 설계시의 문제가 있다.
					이러한 흔한 문제에 대한 솔루션을 나타내는 템플릿 또는 패턴을 '디자인 패턴'이라 한다.
				ㄴ ??? 알고리즘의 패러다임처럼 아주 추상적이고 전반적인 틀에 대한 내용이고, 
					추상적인 특정 문제 상황을 해결하기 위한 추상적인 방식을 말하는 것? 
					실제 문제상황이 닥쳤을 때, 이 문제가 대략 어떤 특징을 보이는지 파악하고, 대략 어떤 디자인패턴을 이러저러하게 잘 적용시키면 
					해결할 수 있겠다는 식으로 사용?  
				ㄴ ~~~ 
				ㄴ 상속보다는 구성을 활용? 
					ㄴ 'IS A' 관계인 상속보다는 'HAS A' 관계인 구성 즉, 객체가 다른 객체를 내부적으로 포함하고 있는게 상황에 따라 더 적절할 수 있다. 
					ㄴ 무조건 상속만을 고려하지 말란 것. 
				ㄴ 목록  <button>more</button>
				<pre>
					ㄴ Strategy Pattern 
						ㄴ??? 알고리즘, 어떤 로직 등을 분리하고 캡슐화하여 이걸 교환해가면서 사용할 수 있게하는 패턴? 
						ㄴ 알고리즘을 사용하는 클라이언트와 독립적으로 알고리즘을 변경할 수 있다. 
					ㄴ Observer Pattern (옵저버 패턴)
						ㄴ 
					
				</pre>

			ㄴ architectural patter (architectural style)
				ㄴ 디자인 패턴과 거의 유사한 개념. 위키상에는 구분되어있기는 하나, 범위만 더 포괄적일뿐 거의 비슷한 개념이라고 하고있음.
				ㄴ 모두 특정 상황에서 발생하는 흔한 문제들에 대한 재사용가능한 솔루션.

			ㄴ 목록 <button>more</button>
			<pre>
				ㄴ 객체지향<button>more</button>
				<pre>
					ㄴ '객체지향의 사실과 오해' 책 참고
					ㄴ '객체지향이란 실세계를 모델링할 수 있는 패러다임'?
						ㄴ 객체지향에 대한 설명 중 실세계의 대상을 객체화 시켜서 사용한다는 것들이 있는데 이는 적합하지 않은 면이 있다고 한다.
							ㄴ 실제 실무에서 실세계의 대상과 연결지을만한 객체가 많지 않을 것이기 때문에.
						ㄴ 그러나 실용적인 부분에선 적합하지 않을지 몰라도 객체지향의 이론을 이해하는데는 효용성이 크다한다.
							ㄴ ~~~
					ㄴ 역할, 책임, 협력
						ㄴ ex ) 커피를 주문하고, 주문을 받고 커피를 만들고 고객에게 전달하는 과정.
								고객, 캐시어, 바리스타. 역할.
								각자가 해야 할 일을 수행. 책임.
								이들이 서로 '요청'과 응답을 하며 과정이 이루어진다. 협력.
						ㄴ 역할을 맡는 사람이 '객체', 이들 간의 요청이 '메시지', 이들의 책임 수행이 '메소드'에 해당.
						ㄴ ???여러 사람이 동일한 역할을 수행할 수 있다???
						ㄴ 역할은 대체 가능하다.
							ㄴ 그 사람이 필요한 역할을 맡고 있다면 누구라도 상관 없다는 것.
						ㄴ 책임 수행 방법은 자율 선택 가능하다
							ㄴ 요청을 받을 사람은 그 요청의 수행 방법을 자유롭게 선택 가능하다. 다형성.
						ㄴ 한 사람이 동시에 여러 역할 수행 가능.
							ㄴ
						ㄴ 객체
							ㄴ 필요 성질
								ㄴ 협력적
									ㄴ ???
								ㄴ 자율적
									ㄴ ???
									ㄴ 객체의 내부와 외부를 명확히 구분하는 것으로 결정된다???
							ㄴ 객체는 외부에서 그 객체가 '무엇을' 하는지는 알아도 '어떻게' 하는지는 모르게 해야한다.
						ㄴ 메시지
							ㄴ 한 객체가 다른 객체에게 요청을 하는 것을 메시지를 보낸다고한다.
						ㄴ ??? 왜 이런 패턴으로 프로그램을 구성하는가? 왜 객체지향 방식인가? 이점이 뭔가?
					ㄴ 객체지향으로 설계된 프로그램은 이런 객체들의 연쇄적인 요청과 응답을 통해 구성된다.?
					ㄴ 객체지향이란?
						ㄴ 시스템을 상호작용하는 자율적인 객체들의 공동체로 바라보고
					ㄴ 클래스 중심이 아닌 객체와 이들의 협력관계를 중심으로 객체지향을 생각해야 한다?
					ㄴ 객체지향은 인간이 기본적으로 세상을 인지하는 방식과 유사하기 떄문에 직관적이고 이해가 쉽다?


					ㄴ 객체지향과 ORM?
						ㄴ ORM의 객체들은 (가령 Entity) 데이터 조회라는 '행동'을 기본적으로 가지고 있다 할 수 있나?
							당연히 그 외 추가적인 행동의 책임이 있을 수 있고.
					ㄴ ??? 객체지향 원칙
						ㄴ 바뀌는 부분은 캡슐화
						ㄴ 상속보다는 구성. 'IS A'보다는 'HAS A'
						ㄴ 구현이 아닌 인터페이스에 맞춰 프로그래밍한다. 
				</pre>

				ㄴ REST <button>more</button>
				<pre>
					ㄴ Representational state transfer
					ㄴ ??? 웹과 같은 architecture of a distributed, internet-scale hypermedia system이 어떻게 작동해야하는지에 대한
						조건들을 정의.
						ㄴ 그 내용은 대략 ~~~한것들이 있다.
					ㄴ RESTful
						ㄴ 이 REST 설계 조건들을 따르는 어플을 'RESTful'하다고 지칭하지만,
							현대에선 ???

				</pre>
				
				ㄴ Repository pattern 
					ㄴ 데이터 접근과 관련된 로직을 분리 & 추상화. 
						데이터 조회, 관리, 변경 등의 로직을 repository가 구체적으로 구현하고 
						외부에서는 데이터 접근 관련 세부사항을 알 필요 없이 repository의 인터페이스를 통해 데이터 접근 관련 로직을 사용하는 식. 
					ㄴ ex ) 
						repository 인터페이스를 만들고, 이 인터페이스가 데이터 특정한 select, update, delete 동작을 하는 메소드들을 노출시킴. 
						각 메소드에서 특정 동작들을 db접근하여 구체적으로 구현하고 
						외부에서 데이터 접근 관련 로직(데이터 조회, 수정, 삭제 등)을 해야 할때, 이 인터페이스의 메소드들을 호출하여 사용하는식. 
					ㄴ 일반적으로 웹 어플에서 db접근하는 경우 많이 사용. 
						근본적으로는 db접근뿐 아니라 api호출 등 데이터 소스가 무엇이든 데이터 접근 로직을 추상화하는데 사용. 
					ㄴ 유의사항 
						ㄴ 

				ㄴ DAO (Data Access Object) pattern 
					ㄴ repository pattern과 유사하게 데이터 접근 로직을 분리 & 추상화한것. 
					ㄴ repository pattern과 미묘한 차이가 있다고 하나, 큰 의민느 없는 듯 하다. 
						사용방식도 똑같고, 데이터 접근 로직을 분리해낸다는 목적도 똑같다. 
						뭐 엄밀한 정의랄만한 정론?이 있다고 하는사람도 있는 듯한데, 수학이론도 아니고 
						디자인 패턴이 소프트웨어 개발에 있어서 발생하는 문제를 해결한다는 목적만 달성하면 되고, DAO나 repository나 같은 문제를 
						해결한다는 점에서 유의미하게 엄밀히 구분지을 필요 없을 듯. 
						ㄴ https://blog.sapiensworks.com/post/2012/11/01/Repository-vs-DAO.aspx
						ㄴ ??? 아주 엄밀히 차이가 있다면, 
							DAO가 더 낮은 레벨에 위치한다함. 
							더 db 접근에 가까운 레벨에서 db와 직접적으로 교류하고, 
							그 윗단에 repository가 있어 repository는 도메인 레벨에서의 db접근 로직을 처리하며 DAO도 사용하는 식? 

				ㄴ ??? Unit of Work (UoW) pattern 
					ㄴ db 연결과 트랜잭션을 한곳에서 관리하는 패턴이라는데  
						대충 클래스 안에 db연결, 롤백, close 등의 로직들을 몰아넣고 사용하는 식? 


			</pre>
			ㄴ 로직을 독립 라이브러리로 분리 vs 서비스 내에 포함시키기 
				ㄴ 	라이브러리로 분리						서비스 내부에 포함
					장점									장점
					- 코드 재사용성 증가					- 단일 서비스에 최적화된 설계 가능
					- 중앙 집중식 관리로 유지보수 용이			- 의존성 관리가 필요 없음
					- 여러 서비스에서 일관된 로직 사용 가능		- 변경 사항이 다른 서비스에 영향을 주지 않음
					단점									단점
					- 초기 설계 및 분리 작업에 시간 소요		- 코드 중복 발생 가능
					- 의존성 관리 필요						- 동일한 로직 수정 시 여러 서비스에서 수정 필요
					- 변경 시 다른 서비스에 영향 가능			- 표준화 및 일관성 부족 
				ㄴ 당연히, 서비스가 여러개에 걸쳐 있는 경우 의미. 단순 웹 어플 하나이면 그냥 웹 플젝 내에서 폴더를 따로 두던지하면됨. 
				ㄴ 암호화, 인증 로직 등은 분리가 좋은 경우. 
				ㄴ 실무 
					ㄴ cosmos chat agent 로직에 대해. 
						ㄴ langgraph 채팅 로직, milvus 세팅 및 초기 insert 로직, milvus 개별 insert 로직 등일텐데. 
							로직마다 사용처가 웹 또는 스크래퍼 또는 일회성이고 다른곳에서 재사용 여지가 별로 없다? 
		</pre>

		UML diagram <button>more</button>
		<pre>
			ㄴ software engineering에서, 시스템의 설계를 시각화하는 표준을 제공하기 위해 만들어진 범용, 개발 modeling language.
				즉, 소프트웨어 만들 때, 설계를 도식으로 만들어 눈으로 보기 좋게하는데, 이 도식화 방법에 대한 표준.
				ㄴ modeling language : 일관된 규칙대로 정보, 시스템 등을 표현하는데 사용되는 만들어진 인공 언어.
				ㄴ 당연히, 소프트웨어 설계에 대한 서로 다른 표기법, 접근법 등을 표준화하려고 등장했다.
			ㄴ 1997에 OMG(Object Management Group)에 의해 표준으로 채택되고 지금까지 계속 관리중.
				2005, ISO(International Organization for Standardization)에 의해 표준 채택 후 계속 관리 중.
			ㄴ 실무 사용
				ㄴ 대부분의 실무자들은 UML을 사용하지 않으나, 이와 유사한 그냥 손으로 그린 다이어그램을 사용한다.
				ㄴ 대충 시간이 없어 비스무리한 것을 그려놓거나 머릿 속에만 가지고 있거나,
					대규모 플젝 등 체계가 잡혀있는 곳에선 기획, 설계단에서 만든다?
			ㄴ ~~~
			ㄴ 분류 )
				ㄴ UML diagram은 여러 방식으로 시스템을 표현한다. 크게 두 분류로 나눌 수 있다.
				ㄴ 정적, 구조적 UML diagram (static, structural)
					ㄴ 시스템의 정적인 구조에 포커스를 둔 표현 방식.
					ㄴ ex ) Class diagram, Component diagram, Composite structure diagram,
						Deployment diagram, Object diagram, Package diagram, Profile diagram
				ㄴ 동적, 행위적 UML diagram (dynamic, behavioral)
					ㄴ 시스템의 동적인 행위에 포커스를 둔 표현 방식.
					ㄴ ex ) Activity diagram, Communication diagram, Interaction overview diagram,
						Sequence diagram, State diagram, Use case diagram, Timing diagram
					ㄴ Use case diagram )
						ㄴ 동적 모델링의 핵심 중 하나.
						ㄴ 시스템의 요구 사항, 즉, 시스템이 무엇을 해야 하는지를 표현하는데 사용된다.
						ㄴ ~~~
					ㄴ ~~~
			ㄴ ~~~
		</pre>

		ProtonVpn<button>more</button>
		<pre>
			ㄴ centos7에 protonvpn 설치
				ㄴ protonvpn-cli이용
				ㄴ ~~~
				ㄴ KeyError 'resolvconf_hash' 나는 경우
					ㄴ ~/.pvpn-cli/resolv.conf.backup 파일 삭제 후, protonvpn-cli 재설치, 실행.
				ㄴ domain leak protection이라 하여,
					ㄴ protonvpn설치히 사용하는 domainname 서버를 protonvpn에서 제공하는 서버로 변경한다.
						ㄴ /etc/resolv.conf 파일이 수정되며, protonvpn어쩌구하는 내용이 들어간다.
					ㄴ 문제는 이렇게 변경되면 google, naver 등을 도메인으로 들어가지지 않는다. 추가 설정이 필요한 것인지..
					ㄴ 일단 기존 domain name server로 수정해줌.
		</pre>

		AI<button>more</button>
		<pre>
			ㄴ ??? 인간의 지능으로 하는 것들(지각, 추론, 학습 등)을 컴퓨터도 할 수 있도록 하는 것?
			ㄴ ~~~
			ㄴ 강인공지능 (일반인공지능, artificial general intelligence)
				ㄴ 실제 사람처럼 생각하는 지능을 가진 인공지능. 사람과 똑같이 생각하므로 일반적인 경우에 모두 사용할 수 있는 인공지능. 

			ㄴ machine learning (=머신러닝, 기계학습)<button>more</button>
			<pre>
				ㄴ 개요 
					ㄴ 인간의 학습능력을 컴퓨터가 할 수 있도록 연구, 구현하는 분야. 
					ㄴ ex ) 
						ㄴ 아이에게 여러장의 고양이 사진을 보여주며, '이게 고양이야'라고 알려주면 
							아이가 이후 고양이를 보고 '저게 고양이다'라고 판단 할 수 있는 것처럼, 
							컴퓨터에게 여러 사진을 주고 이게 뭔지 '학습'하게 하고 이후 그 비슷한 사진을 보여줬을 때 그게 뭔지 판단할 수 있도록 하는 것. 
							(지도학습) 
						ㄴ 뜨거운 냄비를 만져 데이고 나서 다음부터는 만지지 않게 되듯이, 
							컴퓨터가 뭔가 알아서 해보게 한다음 그게 적절했는지 피드백을 주어 컴퓨터가 스스로 답을 찾아가도록 하는 것(강화학습) 
					ㄴ ??? 궁극적 목적? 
						ㄴ 뭐에 대해 학습을 했건, 머신에게 처음보는 새로운 데이터를 입력했을 때, 머신이 최적의 답을 내놓도록 하는 것? 
				ㄴ??? training 단계, testing 단계 
					ㄴ 머신러닝은 기본적으로 두가지 단계로 구성. 
						training단계, testing단계. 
					ㄴ training 단계 
						ㄴ 인풋데이터를 주고 '모델'이 이에 대해 답을 내면 그 답에 대해 피드백. 
							모델은 피드백 결과를 반영하며 '학습' 
					ㄴ tesing 단계 
						ㄴ 학습한적이 없는 새로운 데이터를 '모델'에게 주었을 때, 모델이 이 데이터에 대해 최적의 답을 내는지 테스트. 
				ㄴ ??? 지도학습
					ㄴ data set 
						ㄴ 학습에 사용될 데이터들 의미. 
						ㄴ training set, validation set, test set 
							ㄴ 머신러닝 모델링시, 데이터셋을 3가지 묶음으로 나누어야함. 
								??? 한번 결정하고 모델링에 사용시 중간에 절대 변경할 수 없음? 
							ㄴ training set 
								ㄴ ??? 모델 튜닝할 때 사용하는 데이터셋? 즉, training 단계에서 사용할 데이터셋. 
							ㄴ validation set 
								ㄴ 튜닝이 끝나고 testing 단계에서 테스트용으로 사용할 데이터셋. 
								ㄴ 이걸 사용하는 테스팅 단계를 진행한다는건 당연히 training단계에선 모델이 어느정도 최적의 답을 낸다는 것. 
									그래도 테스팅 단계에선 결과가 잘 안나올 수 있음. 튜닝단계에서 사용하지 않은 새로운 데이터셋을 쓰기 때문에. 
									잘 안나오는 경우, 다시 training단계로 돌아가 튜닝을 하고 다시 테스팅 단계를 진행하고를 반복. 
									validation set으로도 결과가 잘 나올 때까지. 
							ㄴ test set 
								ㄴ validation set과 유사하게 모델을 테스트하는데 사용하는 데이터셋이지만, 
									validation set으로 테스트 & 다시 training set으로 튜닝을 반복하다 최종적으로 테스트하는데 사용되는 데이터셋? 
									test set으로 테스트한 다음에는 더이상 이전단계로 돌아가 튜닝을 해선 안된다? 
								ㄴ??? 테스트 결과 정확도는 완전히 처음보는 데이터에 대해서 어느정도의 성능을 내느냐를 나타내므로 
									처음보는 test set에 대해 테스트를 하고 그 결과를 보고 다시 튜닝을 한다면 
									이 test set에 대해서도 학습이 반영되는 것이므로 튜닝 이후의 test set에 대한 결과는 완전 처음보는 
									데이터에 대한 결과가 아니라 최종 결과로서의 의미가 없어서? 
						ㄴ set분류시 유의사항 
							ㄴ ex ) 
								??? mri사진이 데이터셋이라 할때, 환자 10명에 대해 100장씩의 데이터가 있다하면, 
								총 1000장 중 무작위로 700, 100, 200장 이런식으로 묶으면 안됨. 
						ㄴ 데이터 수에 따른 성능 
							ㄴ 최근까지의 연구결과에선, 개수가 증가할 수록 성능도 증가했고 더이상 증가하지 않는 시점도 나온게 없다함. 
						ㄴ 데이터 비용 
							ㄴ 데이터가 많을 수록 좋은것에 비해, 데이터 확보에는 비용이 듦. 
							ㄴ 데이터 확보, 전처리, 데이터에 라벨링을 다는 과정, 
								등은 모두 비용이 듦. 
						ㄴ 데이터 퀄리티 이슈 
							ㄴ 어떤게 질 좋은 데이터인지에 대한 고려 필요. 
							ㄴ 편향되지 않은 데이터 
							ㄴ 데이터에 대한 라벨링의 정확도 이슈. 
								ㄴ 라벨링을 사람이 하는거다보니, 같은 데이터에 대해서도 사람마다 라벨링 결과가 다를 수 있음. 
								ㄴ ex ) 같은 환자에 대한 의사들의 진단결과 다름. 
							ㄴ 데이터 수 만큼이나 데이터의 퀄리티도 모델 성능에 영향을 크게 미치는 요인이라함. 
								ㄴ 데이터가 좀 적더라도 적절할 데이터로 학습시키면 성능이 괞찮아질 수 있다는 것. 
					ㄴ 
					ㄴ ~~~
				
				ㄴ ~~~
				ㄴ 방법
					ㄴ supervised learning : 이미 정제된 데이터들로 학습하는 머신러닝 방식.
						ㄴ ex ) 고양이 사진에 'cat' label, 강아지사진에 'dog' label들을 붙여 데이터를 주어 학습시킴.
						ㄴ
							ㄴ 일정 범위를 예측(regression), 이지선다 분류(binary classification), 여러 케이스 분류(multi-label classification)
					ㄴ unsupervised learning : 사전 정제 없이, 그냥 raw 데이터로 머신러닝하는 방식?
					ㄴ ~~~
				ㄴ 머신러닝 model 
					ㄴ ??? 훈련이 완료되고 나서, 머신 러닝의 목표(즉, 예측 또는 판단)를 수행할 때 사용되는 일종의 수학적 모델. 
					ㄴ 훈련이 진행되는 동안 이 model의 내부 파라미터들이 반복적으로 조정되는식. 
					ㄴ 또는 이 모델로 학습하여 튜닝이 끝난 결과를 통칭하는 단어? 
					ㄴ 목록 
						ㄴ ~~~
						ㄴ artificial neural network (=neural network, ANN) <button>more</button>
						<pre>
							ㄴ ~~~  
							ㄴ ??? 아주 대략적 원리? 
								ㄴ 여러 뉴런으로부터 입력값을 받음
								ㄴ 입력값에 각각의 '가중치'를 곱.
								ㄴ 그 결과들을 합 (결합함수?)
								ㄴ 그 합에 대하여 '임계값' 기준 어떤 판단을함. 0인지 1인지. (활성화함수?)
									ㄴ 결합함수 결과에 대해 임계값보다 큰지 작은지 판단해야 하는데, 임계값도 계속 변화하므로 수식이 복잡하다함.
										하여 (*결합함수 합*) > (*임계값*)에서 임계값을 좌변으로 넘겨 (*임계값*) + (*결합함수 합*) > 0 과 같이 0 기준으로
										크면 1, 작으면 0 이런식으로 간단하게 만들고,
										여러 뉴런으로부터 입력값 받아 가중치를 곱할 때, 하나의 입력을 추가하고 이를 (*임계값*)으로 취급. (이의 입력값은 1, 가중치는 계속변동)
										하여 이 추가된 입력값포함 입력값들을 가중치 곱하여 더하면 (*임계값*)+(*결합함수 합*)이 되도록.
								ㄴ 판단한 결과 값(0 또는 1)과 이 결과값에 대한 예측치와의 차이값으로 가중치 조절.
									ㄴ 차이값에 '학습률' 곱. (가중치 조절 과정에서 그냥 차이값 사용시 변동성이 커, 완화 위한 임의의 값)
									ㄴ 이 값을 기존 입력값에 각각 곱.
									ㄴ 이 값을 기존 가중치에 각각 합한 것이 조정된 가중치.
								ㄴ 이를 레이어 거치며 반복
								ㄴ 최종 결과 도출.
								ㄴ 정확한 결과를 도출하는 가중치와 임계값을 찾아내는 것이 관건. 이 과정을 학습이라함?
									이를 찾은게 모델이라함?
								ㄴ 이 과정이 기본적인 머신러닝 방식?
							ㄴ ~~~ 
						
							ㄴ LLM (large language model) <button>more</button>
							<pre>
								ㄴ 언어의 이해와 생성을 목표로 하는 언어 모델. 
								ㄴ 생성형 ai로 활용. 
									ㄴ 인풋에 대해 다음에 올 단어를 연속적으로 예측하는 방식으로. 
								ㄴ 문제점
									ㄴ 환각 (Hallucination)
										ㄴ 잘못된 정보를 답변으로 내놓는 것. 
										ㄴ 학습시 없는 데이터에 대해서는 답변할 수 없거나 정확하지 않은 답변을함. 
									ㄴ 답변의 근거를 제시할 수 없음. 출처 제시를 못하는 것. 
								ㄴ ??? model custom?
									ㄴ 범용으로 만들어진 주요 llm들을 특정 목적에 맞게 커스텀하는 방법 
									ㄴ RAG, fine-tuning 등 이용. 

								ㄴ 관련 도구, 라이브러리
									ㄴ Hugging Face 
										ㄴ ??? LLM관련 여러 서비스를 제공하는 플랫폼? 
											깃을 통한 트래이닝되어 완성된 여러 model들, llm관련 기능을 제공하는 라이브러리, 등 제공? 
											쓰기 복잡하다함? 
											서비스 기간이 길고 llm에선 중심적이라함. 
									ㄴ LangChain <button>more</button>
									<pre>
										ㄴ ??? llm관련 기능 개발 프레임워크? 마찬가지로 llm관련 기능들 제공? 
											상대적 최근 시작. 
										ㄴ Model I/O <button>more</button>
										<pre>
											ㄴ language model과 상호작용하는 컴포넌트. 
											ㄴ langchain에서의 language model 유형. 
												ㄴ LLM 
													ㄴ 순수한 text completion model을 의미. 
													ㄴ 문자열 하나를 입력받아 완성된 문자열을 결과로 내보냄. 
													ㄴ GPT-3 등. 
												ㄴ ChatModel
													ㄴ LLM을 기반으로 하지만, 대화를 위해 특별히 튜닝된 모델. 
													ㄴ ??? api가 pure text completion model과 다르다함. 
													ㄴ ??? 단 하나의 문자열이 아닌 채팅 메세지 리스트를 인풋으로 받는다함. 
													ㄴ GPT-4 등 
											ㄴ 각 모델마다 프롬프트 전략이 다름. 고려 필요. 
												ㄴ 어떤 모델은 json형식 프롬프트가 최적이고 다른건 xml이 최적이고 등. 
											ㄴ Prompt Template
												ㄴ llm application에게 넘길 프롬프트를 형식에 따라 적절히 변환하는 컴포넌트. 
												ㄴ ex ) 
													from langchain_core.prompts import PromptTemplate

													prompt = PromptTemplate.from_template("What is a good name for a company that makes {product}?")
													prompt.format(product="colorful socks")
												ㄴ ~~~ 
											ㄴ Output parser
												ㄴ llm이 반환한 응답을 적절하게 변환하는 컴포넌트. 
												ㄴ ~~~ 

										</pre> 

										ㄴ Tool calling <button>more</button>
										<pre>
											ㄴ model에게 함수 같은 'tool'을 건네주고, 이를 실행할지 말지, 어떤 tool을 실행해야 하는지 등을 판단하게
												하고 이를 실행시키는 기능. 
											ㄴ ??? model이 판단하는 방식? 
												ㄴ 명확한 문서내용은 찾지 못했으나, openai api문서 등을 참고해 볼때, 
													tool을 정의할 때, tool 이름, tool에 대한 설명, 필요한 인자 등을 신중히 결정하여 
													이 tool의 메타데이터를 model에게 넘겨주어 모델이 이 내용을 보고 판단하게 하는 듯. 
													model이 이를 보고 결정만 하면, 실행은 모델의 응답을 받는쪽에서 하는거니. 
												ㄴ 참고 
													ㄴ https://python.langchain.com/docs/concepts/tool_calling/#overview
													ㄴ https://platform.openai.com/docs/guides/function-calling?api-mode=chat 
											ㄴ custom tool 
												ㄴ 구성 요소 
													ㄴ name 
														ㄴ str 
														ㄴ ??? llm, agent에게 있어서 unique해야함? 기준이 구체적으로 어떻게? 
														ㄴ 잘 정의할수록 model이 적절하게 사용 가능. 
													ㄴ description 
														ㄴ str 
														ㄴ tool이 뭘하는지 설명. 
														ㄴ llm, agent가 참고하게됨. 
														ㄴ 잘 정의할수록 model이 적절하게 사용 가능. 
															ㄴ ex ) 성능부하나 input으로 들어갈 토큰 수 줄이기 위해 최소한의 결과만 
																반환되도록 사용하라거나 하는 내용도 llm이 알아먹고 적용함. 
													ㄴ args_schema 
														ㄴ ??? 
													ㄴ return_direct 
														ㄴ boolean 
														ㄴ agent인 경우에만 유효. 
															True인 경우, 해당 tool 실행 후, agent 진행이 멈추고 tool의 결과를 유저에게 return. 
												ㄴ 가능한 형태 
													ㄴ function 
														ㄴ 왠만하면 이걸로 충분하다함. 
														ㄴ '@tool' decorator로도 정의가능. 
														ㄴ @tool decorator 
															ㄴ 기본 동작 
																ㄴ 함수명이 tool name, 함수의 docs가 tool description이됨. 
																	ㄴ 따라서 함수 docs 필수. 
															ㄴ ??? typing.Annotated, nested schemas 등 지원? 
															ㄴ decorator에 인자를 넘겨 여러 설정 가능. (ref 참고)
															ㄴ ??? 'google style docstring' 자동 파싱도 가능? 
														ㄴ ??? langchain_core.tools.structured.StructuredTool의 from_function() 
															ㄴ 
													ㄴ Langchain 'Runnables' 
														ㄴ ~~~ 
													ㄴ BaseTool 상속 
														ㄴ ~~~ 
												ㄴ 예외 처리 
													ㄴ 방식 
														ㄴ 'langchain_core.tools.ToolException' throw & 'handle_tool_error' 라는 이름으로 핸들러 정의하여 예외 처리. 
														ㄴ handle_tool_error는 boolean, string, 함수일 수 있음. 
															ㄴ??? True인 경우, 그냥 예외의 컨텐츠 반환됨? 
															ㄴ string인 경우, 해당 문자열값이 tool반환값이됨. 
															ㄴ function인 경우, 'ToolException'을 인자로서 받아야 하며 return값이 있어야함. 
																return값이 tool의 반환값이됨.  
										</pre>

										ㄴ Retrieval <button>more</button>
										<pre>
											ㄴ 배경
												ㄴ llm은 기본적으로 모델 학습시 학습한 데이터에 기반하여 동작. 학습되지 못한 데이터는 응답에 사용 못함. 
													근데 user-specific data에 근거하여 동작하기를 바라는 수요 존재. 
													회사 고유의 데이터에 근거하여 질문에 답변하거나 등. 
											ㄴ llm application이 user-specific data 등 특정 데이터에 기반하여 동작할 수 있게 해주는 컴포넌트. 
												즉, RAG(Retrieval-Augmented Generation)를 가능하게 해주는 컴포넌트.

											ㄴ Document loader <button>more</button>
											<pre>
												ㄴ ??? 여러 소스들로부터 여러 형태의 document들을 로드해주는 컴포넌트? 
												ㄴ 다양한 소스로부터 데이터를 가져와 'Document' 객체에 저장. 
												ㄴ 관련 클래스 
													ㄴ Document 객체
														ㄴ text와 metadata로 구성. 
														ㄴ ~~~
													ㄴ BaseLoader 
														ㄴ Document loader들에 대한 인터페이스. 
														ㄴ ~~~
														ㄴ 메소드
															ㄴ __init__()
																ㄴ 모든 설정값들은 여기서 인자를 받아서 세팅되도록 해야함. 
															ㄴ load() 
																ㄴ 모든 document를 메모리로 즉시 로드. 
																ㄴ 개발중에만 편의를 위해 사용. production 환경에선 사용하지 않도록. 
																	document를 한번에 메모리로 로드하므로 메모리 여유가 있다고 무조건 가정하고 동작하므로. 
																ㄴ ??? 단순히 list(self.lazy_load())를 호출? 
															ㄴ aload() : ???
															ㄴ lazy_load()
																ㄴ document를 하나씩 lazy로 로드. 
																ㄴ prod에서 사용. 
																ㄴ ??? 인자를 받도록 구현해선 안됨. 
																ㄴ Iterator를 반환하도록 구현해야함. 
															ㄴ alazy_load()
																ㄴ 비동기로 lazy_load() 
																ㄴ ??? 인자를 받도록 구현해선 안됨. 
													ㄴ Blob 
														ㄴ lanchain상에서 바이너리 데이터를 나타내는 클래스 
													ㄴ BaseBlobParser
														ㄴ Blob을 파싱하여 Document를 반환하는 클래스. 
												ㄴ loader 목록 
													ㄴ Custom Document Loader 
														ㄴ BaseLoader를 상속하여 구현. 
														ㄴ ~~~
													ㄴ csv
													ㄴ directory
													ㄴ html
													ㄴ json
													ㄴ markdown
													ㄴ microsoft ofice
													ㄴ pdf 
														ㄴ PyPDFLoader
											</pre>

											ㄴ Text Splitting <button>more</button>
											<pre>
												ㄴ document를 적절히 작은 단위의 chunk들로 나누는 컴포넌트
												ㄴ ???대략 다음과 같이 split
													ㄴ text를 의미단위 chunk로 나눔. 
													ㄴ 이 chunk들을 설정한 크기가 될때까지 결합. 
													ㄴ 설정한 크기가 되면 다음 chunk들에 대해 이를 반복. 
												ㄴ??? 어떻게 text를 chunk로 나눌지, 타겟으로하는 
												ㄴ 방식 
													ㄴ 길이 기반 
														ㄴ 토큰 기반 
															ㄴ 토큰 수 기준으로 텍스트를 쪼갬. 
														ㄴ 문자수 기반 
															ㄴ 문자 수 기준으로 텍스트를 쪼갬. 
													ㄴ text 구조 기반 
														ㄴ text는 기본적으로 계층 형태로 나타낼 수 있ㄷ함. (문단, 문장, 단어... )

													ㄴ document 구조 기반 
														ㄴ html, markdown, json 같은 일부 document들은 계층형태를 가짐. 
															이런 문서들을 그 구조대로 쪼개는 방식. 
													ㄴ 의미 기반 
														ㄴ 실제 내용의 의미를 기반으로 쪼개는 방식. 
														ㄴ 구현 방법 
															ㄴ text 내용에 유의미한 의미변화가 있을때 쪼개는 방식. 
																ㄴ sliding window ??? 
																ㄴ 몇개의 문장들을 하나의 윈도우로 보고, 이들에 대해 embedding. 
																ㄴ 다음 몇개에 문장에 대해서도 반복한 뒤, embedding을 비교하여 의미차이가 있으면 쪼갬. 
														ㄴ 장점 
															ㄴ 쪼갠 내용에 대해 후속으로 retrieval나 요약 등의 작업시, 
																의미기반으로 이미 쪼개놨기 때문에 퀄리티가 올라간다함. 
												ㄴ test splitter 목록 
													ㄴ langchain-text-splitters 패키지에 존재. 
													ㄴ Recursive 
														ㄴ 사용자가 설정한 문자 기준으로 split. 
														ㄴ RecursiveCharacterTextSplitter, RecursiveJsonSplitter 
													ㄴ html 
														ㄴ html specific 문자 기준으로 split. 
														ㄴ??? chunk가 어디서 왔는지에 대한 메타 정보 저장. 
														ㄴ splitter 목록 
															ㄴ HTMLHeaderTextSplitter
																ㄴ html의 요소 레벨에서 text를 split. 
															ㄴ HTMLSectionSplitter
													ㄴ ~~~ 
												ㄴ text splitter 결과 확인 
													ㄴ 'Chunkviz'를 통해 text가 어떻게 split되었는지 확인 가능. 
													ㄴ https://chunkviz.up.railway.app/
											</pre>

											ㄴ Text embedding model <button>more</button>
											<pre>
												ㄴ 자연어처리(NLP)에서의 word embedding을 의미하며, 이 embeding을 해주는 model을 말함. 
												ㄴ langchain에서 embedding과 관련한 여러 provider, method들 제공. 
												ㄴ langchain의 Embedings class 
													ㄴ 여러 embedding model provider들이 제공하는 embedding model들과 통일된 방식으로 
														상호작용할 수 있게 해주는 클래스. 
													ㄴ ??? document를 embedding하는 메소드, query를 embedding하는 메소드로 구분? 
												ㄴ 임베딩 모델 목록
													ㄴ CohereEmbeddings
														ㄴ langchain_cohere.embeddings.CohereEmbeddings 
														ㄴ cohere 언어 모델을 사용하는 embedding 인터페이스를 구현. 
														ㄴ cohere관련 문서에서 자세한 내용 확인 가능. 
															ㄴ https://cohere.com/
															ㄴ https://huggingface.co/CohereForAI
															ㄴ https://docs.cohere.com/reference/embed
														ㄴ 사용하려면 cohere api키 필요. 
														ㄴ 메소드
															ㄴ ~~~
															ㄴ embed_documents(texts: list[str]) -> List[List[float]] 
																ㄴ str list를 받아 embedding하고 그 결과 반환. 
													ㄴ OpenAIEmbeddings 
														ㄴ pip install langchain-openai 
														ㄴ 마찬가지 문서에 상세한 설명은 없고, 오픈소스 보면서. 
														ㄴ __init__ 
															ㄴ ~~~ 
															ㄴ dimensions 
																ㄴ 결과 임베딩 벡터의 차원 수 지정. 
														ㄴ embed_documents() 
															ㄴ 문자열 리스트를 임베딩하여 벡터값을 반환. 
														ㄴ embed_query()
											</pre>

											ㄴ Vector store <button>more</button>
											<pre>
												ㄴ database의 한 종류인 'vector database'를 나타내는 컴포넌트. 
												ㄴ interface 
													ㄴ 마찬가지로, 랑체인에서 여러 vector store들에 대해 통일된 형식의 인터페이스 제공. 
													ㄴ 주요 메소드 
														ㄴ add_documents 
														ㄴ delete 
														ㄴ similarity_search 
													ㄴ 기본 사용법 
														ㄴ vector store 인스턴스 초기화. 
															ㄴ 일반적으로 생성자 인자로 embedding model을 필요로함. 
														ㄴ 'Document' 객체 리스트에 대해 add_documents로
												ㄴ search 
													ㄴ vector store에 query를 날리면 vector store는 쿼리에 대해 임베딩을 하고 
														저장된 모든 document들에 대해 이 쿼리 임베딩값과 유사성을 비교하여 가장 유사성이 높은 
														document를 찾음. 
													ㄴ 유사성 확인 
														ㄴ 두 임베딩값 사이의 유사성을 확인하는 방법. 
														ㄴ 벡터형태인 경우, 계산을 통해 유사성을 계산 가능. 
															ㄴ cosine similarity : 두 벡터 사이의 코사인 각도 측정을 통해. 
															ㄴ euclidean distance : 두 점 사이의 직선거리 측정을 통해. 
															ㄴ??? dot product : 한 벡터를 다른 벡터에 'projection'한 값 측정을 통해. 
														ㄴ 어떤 방식을 사용하는지는 vector store마다 다름. 확인 필요. 
													ㄴ store내 전체 document에 대한 서치 
														ㄴ 가장 유사성이 높은걸 찾으려면, 위의 유사성 확인 방법으로 모든 document에 대해 
															계산해봐야함. 이를 효율적으로 하는 알고리즘이 필요. 
														ㄴ 많은 vector store들이 'HNSW(Hierarchical Navigable Small World)'를 사용한다함. 
													ㄴ Metadata filtering 
														ㄴ 벡터값에 의해서만 쿼리하는게 아니라, 특정 metadata를 통해 검색 대상을 줄일 수도 있다.
														ㄴ vector store에 따라, 제공함. 
												ㄴ 여러 종류의 vectorstore 지원 가능. 
													ㄴ FAISS <button>more</button>
													<pre>
														ㄴ ~~~
														ㄴ 디폴트로 vector data를 RAM에 저장. 
															local disk에 저장도 가능. 
														ㄴ 메소드 
															ㄴ similarity_search(
																	query: str, k: int = 4, filter: Optional[Union[Callable, Dict[str, Any]]] = None, 
																	fetch_k: int = 20, **kwargs: Any
																) → List[Document]
																ㄴ (*query*)에 대해 유사성 검색을 하여 가장 유사한 상위 (*k*)개의 document를 반환. 
															ㄴ add_documents(documents: List[Document], **kwargs: Any) → List[str]
																ㄴ document들을 추가로 embedding하고 vectorstore에 추가. 
															ㄴ save_local(folder_path: str, index_name: str = 'index') → None
																ㄴ faiss 데이터를 저장. 
																ㄴ 내부적으로 python 'pickle' 모듈 사용하여 저장. 
															ㄴ load_local(folder_path: str, embeddings: Embeddings, index_name: str = 'index', *,
																allow_dangerous_deserialization: bool = False, **kwargs: Any) → FAISS
																ㄴ 로컬에 저장된 vector store을 가져옴. 
																ㄴ 저장된 vector store와 동일한 Embeddings을 넘겨야 동일하게 동작. 
																ㄴ pickle한 데이터를 역직렬화하기 때문에 파일에 악성코드가 있다면 위험할 수 있다. 
																	따라서 allow_dangerous_deserialization를 True로 명시적으로 설정해야 동작함. 
																	반드시, 신뢰할 수 있는 파일에 대해서만 사용해야함. 
													</pre>
													ㄴ Milvus <button>more</button>
													<pre>
														ㄴ pip install langchain_milvus 
														ㄴ Milvus class 
															ㄴ langchain에서의 milvus사용의 중심 클래스. 
																이 클래스를 중심으로 사용하여 milvus와 상호작용하게됨. 
																내부적으로는 당연히 'pymilvus'모듈의 MilvusClient를 이용하여 동작. 
															ㄴ 문서에 그닥 상세한 설명 없는듯. 오픈소스 보면서 진행하도록. 
															ㄴ __init__ 
																ㄴ 파라미턴 
																	ㄴ embedding_function 
																		ㄴ 임베딩 모델을 지정하는듯. 
																		ㄴ OpenAIEmbeddings 객체 등 넣으면, 내부적으로 임베딩하는데 사용됨. 
																	ㄴ connection_args 
																	ㄴ auto_id 
																		ㄴ entity 생성등 id와 관련된 동작을 할때, 이 값 여부에 따라 동작이 바뀜. 
																		ㄴ True일시, entity삽입할때 id자동생성. 
																	ㄴ vector_field 
																		ㄴ 정확하진 않지만, 설정한 컬렉션에서 벡터 데이터가 저장될 필드명을 명시하는 듯. 
																			해당 컬렉션이나 이 필드에 대한 인덱스가 정의되어있지 않은 경우, 이 필드명으로 컬렉션이나 인덱스를 정의하거나 
																			db insert시 벡터데이터를 이 필드에 저장하는식으로 동작. 
																			지정하지 않으면 constant.py에 있는 이상한 디폴트 문자열 사용하는데, 이럴경우, 그 필드명의 인덱스 없다고 인덱스 
																			생성하다 오류남. 
																	ㄴ text_field 
																		ㄴ vector_field파라미터와 유사. 벡터화될 데이터의 본문을 저장할 필드맵.
															ㄴ add_texts
																ㄴ 문서 리스트를 받아 임베딩 및 db insert를 수행. 
																ㄴ 옵션으로 metadata list를 받으며, 이 배열의 인덱스가 문서 리스트의 인덱스와 
																	일치해야함. 
																	각 metadata는 db insert시, 컬렉션의 필드에 삽입될 데이터로서 넘어감. 
																ㄴ ex ) 
																	pdf_loader = PyPDFLoader(f"https://pro.stockcosmos.kr/media/{file_path}")
																	splitted_content_list = text_splitter.split_documents(pdf_loader.load())  
																	splitted_content_list = [doc.page_content for doc in splitted_content_list]
																	# 이 key들이 컬렉션의 필드명과 매핑되고, value들이 필드값으로서 insert됨. 
																	metadata_list = [
																		{
																			"stock_code": report["stock_id"],
																			"title": report["title"], 
																			"date": report["date"].strftime("%Y-%m-%d"), 
																			"fin_corp": report["fin_corp"], 
																			"writer": ", ".join(report["writer_list"]), 
																			"file_path": file_path, 
																		} for _ in splitted_content_list
																	] 
													
																	vector_db.add_texts(splitted_content_list, metadata_list)
															ㄴ as_retriever() 
																ㄴ langchain vectorstore면 기본적으로 모두 가지고 있는 함수로서, 
																	VectorStoreRetriever를 반환. 
																ㄴ VectorStoreRetriever
																	ㄴ vector store를 retriever로서 사용할수 있게 해주는 wrapper클래스. 
																	ㄴ retriever의 기본 메소드인 invoke()호출시 vector db로부터 유서성 검색을 하고 결과를 반환. 
															ㄴ ex ) 
																embedding = OpenAIEmbeddings(
																	model="text-embedding-3-large", dimensions=1536,
																) 

																stock_notice_vector_db = Milvus(
																	embedding,
																	connection_args={
																		"uri": "http://192.168.0.149:19530", 
																		"token": "root:Milvus", 
																		"db_name": "stock_cosmos",
																	},
																	collection_name="stock_notice", 
																	auto_id=True, 
																	vector_field=["vector_val"], 
																	text_field="content",
																) 

																stock_notice_retriever = stock_notice_vector_db.as_retriever() 
																stock_notice_retriever_tool = create_retriever_tool(
																	stock_notice_retriever, 
																	"stock_notice_retriever", 
																	"search most relevant stock notice data for query", 
																	response_format="content_and_artifact",
																)
													</pre>
												ㄴ ~~~
											</pre>

											ㄴ Retriever <button>mroe</button>
											<pre>
												ㄴ ??? retrieval ? 
													ㄴ retriever과 구분? 
													ㄴ 사용자 인풋으로부터 적절한 쿼리를 결정하는 요소?   
													ㄴ 2가지 단계 
														ㄴ query analysis 
															ㄴ 사용자 인풋에 대해 model이 적절한 쿼리를 생성하는 과정. 
															ㄴ ???방법? 명확히 분류된거? 뭔기준인지 뭔차인지 모르겟음. 
																ㄴ query re-writing 
																	ㄴ 사용자 입력 프롬프트를 적절하게 다시 작성. 
																		즉, 사용자 입력 자연어를 같은 의미의 다른 형태의 자연어 질문으로 변환하는 것. 
																	ㄴ 주로 llm model을 사용하여 수행한다함. 이점이 있어서. 
																		ㄴ 이점 
																			ㄴ 인풋에서 단순히 키워드를 추출하는게 아니라, 의미를 이해하고 숨어있는 키워드를 
																				추출하는것도 가능. 
																			ㄴ 유저 인풋에서의 모호한 단어 등을 문맥을 이해하여 명확하게 조정 가능. 
																	ㄴ 방식 
																		ㄴ Multi-query 
																			ㄴ 사용자 입력 질문을 여러개의 다른 질문으로 작성하는 방식. 
																		ㄴ Decomposition 
																			ㄴ 사용자의 질문을 여러개의 하위 문제, 질문으로 분해하는 방식. 
																		ㄴ Step-back 
																		ㄴ HyDE 
																ㄴ query construction 
																	ㄴ 자연어 쿼리를 특정한 쿼리언어나 필터로 변환하는 것? 
																		structured 데이터나 semi-structured 데이터를 저장하고 있는 db와 
																		함께 쓰일때 유용. 
																	ㄴ 방식 
																		ㄴ Text-to-SQL 
																			ㄴ 자연어를 RDB를 위한 SQL로 변환. 
																		ㄴ ???Text-to-Cypher 
																			ㄴ 자연어를 graph db를 위한 Cypher로 변환? 
																		ㄴ Self Query 
																			ㄴ ???
														ㄴ information retrieval 
															ㄴ 모델이 생성한 쿼리로 시스템(vector db, rdb 등)으로부터 데이터를 패치해오는 과정. 
													ㄴ 여러 알고리즘 존재. 
													ㄴ langchain에서 제공하는 알고리즘 중 하나 선택하여 사용 가능. 
													ㄴ langchain상에서 retriever는 동일한 인터페이스를 가짐. 
												ㄴ retrieval system 
													ㄴ langchain상에서 vector db, graph db, rdb 등 데이터를 저장하고 패치해올 수 있는 시스템을 지칭할때 쓰는듯. 
												ㄴ retriever interface 
													ㄴ langchain에선 여러 retrieval system들에 대해 동일한형태의 인터페이스를 제공. 
													ㄴ 모두 'query'를 인풋으로 받아 list[Document]를 반환. 
														ㄴ 'Document'는 langchain_core.documents.base.Document 
													ㄴ 인터페이스는 langchain_core.retrievers.BaseRetriever를 기본으로하며 
														_get_relevant_documents()를 필수로 구형해야 하며, 
														이 메소드는 쿼리를 받아 어떤 Document를 반환할지 결정하고 Document들을 반환해야함. 
													ㄴ ??? langchain상에선 그냥 llm이 참고할 수 있게 어떤형태든 데이터를 가져와주는 컴포넌트 의미? 
														ㄴ Text-to_SQL로 자연어 프롬프트로부터 sql을 실행하여 데이터를 가져오든 
															vectorstore로 의미적으로 관련깊은 문서를 가져오든? 
												ㄴ ??? db로부터 embedding관련 데이터를 가져오는 컴포넌트? 
												ㄴ 많은 retrieval 알고리즘 제공? 
												ㄴ unstructured query를 받아 document를 반환하는 인터페이스 컴포넌트. 
													??? vector store와 유사하지만 더 큰 범위이다? vector store를 기반으로하는 retriever도 있지만, 
													꼭 vector store를 기반으로 하지 않는 retriever도 존재. 
												ㄴ retrieval 종류
													ㄴ Vectorstore 
														ㄴ vector store을 이용하여 document를 가져오는 retriever. 
														ㄴ vector store class의 lightweight wrapper. 
														ㄴ vector store가 구현하는 search method를 사용. similarity search, MMR 등. 
														ㄴ 가장 단순하고 사용하기 쉬움. 
														ㄴ ex ) 
															from langchain_community.vectorstores import FAISS
															from langchain_openai import OpenAIEmbeddings
															from langchain_text_splitters import CharacterTextSplitter
															
															documents = loader.load()
															text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
															texts = text_splitter.split_documents(documents)
															embeddings = OpenAIEmbeddings()
															db = FAISS.from_documents(texts, embeddings)
															retriever = db.as_retriever()  # FAISS vector store로부터 초기화된 'VectorStoreRetriever' 반환. 
															docs = retriever.invoke("what did he say about ketanji brown jackson")
														ㄴ ??? Maximum marginal relevance retrieval ? 
														ㄴ ??? Similarity score threshold retrieval?
														ㄴ ??? Specifying top k ?
													ㄴ Multi-Query Retriever 
														ㄴ ??? llm과 함께 객체를 생성하고, 
															사용자가 입력한 쿼리에 대해 이 llm으로 적당히 튜닝하여 여러개의 쿼리를 만들고 
															이 생성된 쿼리들에 대해 document를 받아오고 
															이 document들의 union을 반환하는 방식. 
														ㄴ ??? 거리 기반 벡터 db의 경우, 쿼리에 포함된 단어의 미묘한 차이 여부, 
															쿼리에 포함된 단어의 적절한 의미 임베딩 여부에 따라 retrieval가 반환하는 결과가 
															달라지는 경우가 있고 이를 개선하는데 사용된다함. 
														ㄴ ex ) 
															from langchain.retrievers.multi_query import MultiQueryRetriever

															retriever_from_llm = MultiQueryRetriever.from_llm(
																retriever=(*retrieval*), llm=(*쿼리 생성에 사용될 llm*)
															)

															unique_docs = retriever_from_llm.invoke( (*쿼리*) )
														ㄴ ~~~
													ㄴ ~~~ 
											</pre> 

											ㄴ Indexing <button>more</button>
											<pre>
												ㄴ 개요 
													ㄴ ??? langchain에서 document에 대한 인덱싱 기능을 의미? 
														indexing API를 통하여 이루어짐. 
														document가 document의 소스와 vector store 사이에서 동기적으로 유지되도록 해줌? 
														vector store에 중복된 내용 저장을 피하고 
														변경사항 없는 내용을 rewrite하는걸 피하고
														변경사항 없는 내용에 대한 embedding 재계산을 피하게 해줌? 
														이를 통하여 시간, 비용 절약 및 검색 결과 개선? 
												ㄴ ??? document source로부터 vector store로 데이터를 로드하고 동기화 상태를 유지하게 해준다? 
													vector store에 컨텐츠를 중복저장하는걸 방지, 
													변경사항이 없는 컨텐츠를 다시 write하는 것 방지, 
													변경사항이 없는 컨텐츠의 embedding을 다시 계산하는 것 방지. 
												ㄴ ??? document가 transformation단계를 거쳐 변형되었더라도 동작한다? 
												ㄴ??? 동작 방식? 
													ㄴ 'record manager'를 이용? 
													ㄴ 컨텐츠 indexing할 때 다음 수행. 
														ㄴ document의 hash 계산. (??? 컨텐츠와 메타데이터를 합친것의 hash?)
														ㄴ document의 hash값, write time, source id를 record manager에 저장. 
															ㄴ ??? source id? 
												ㄴ deletion mode 
													ㄴ 
											</pre>

											ㄴ 실무 
												ㄴ 똑같이 llm에 요청을 하는건데, 같이 제공한 컨텍스트를 자동으로 선정하여 제공하는데 의미가 있는 기능? 
													얼마나 관련있는 컨텍스트들이 선정되도록 할지가 신경쓸부분? 그 후 이 컨텍스트를 가지고 
													llm이 응답하는건 llm성능에 달림? 
													ㄴ 어떤 컨텍스트에 기반하여 응답해야하는지가 정해져있다면 굳이 필요 없다? 
														그냥 llm요청시 그 컨텍스트를 같이 넘겨주면 되니까? 
												ㄴ 간단하게 만들어도, 관련있는 문서를 찾아서 이에 기반한 응답은 잘 되는편. llm성능에 따라 당연히 다르겠지만. 
										</pre>

										ㄴ LangChain Expression Language (LCEL) <button>more</button>
										<pre>
											ㄴ ??? chain을 선언적 방법으로 손쉽게 구성할 수 있는 도구? 
												??? 코드변경 없이 production에 프로토타입을 추가할 수 있게 해줌? 
											ㄴ 이점
												ㄴ ??? first-class streaming support? 
													ㄴ chain을 통과하여 결과가 빠르게 나온다? 
												ㄴ 비동기 지원
													ㄴ LCEL을 통해 만든 chain은 동기 또는 비동기로 실행 가능. 
												ㄴ optimized parallel execution
													ㄴ LCEL chain 중에 parallel하게 실행할 수 있는 부분이 있으면 자동으로 parallel하게 수행되며, 
														이는 비동기, 동기 방식에 상관없이 수행된다. 
												ㄴ retries and fallback
													ㄴ LCEL chain에서 재시도, fallback 기능을 넣을 수 있다. 
												ㄴ chian의 중간단계 접근 가능. 
													ㄴ chain이 최종적으로 끝나기 전에 중간단계의 결과를 볼 수 있다. 
												ㄴ ??? input and output schemas
												ㄴ ??? LangSmith를 통한 chain 내 동작 로깅. 
												ㄴ ??? LangServe 를 통한 손쉬운 배포? 

											ㄴ 사용법  
												ㄴ ex ) 
													from langchain_cohere import ChatCohere

													model = ChatCohere(cohere_api_key="~~~")  # llm 모델 생성. 
													prompt = ChatPromptTemplate.from_template("~~~")  # prompt 탬플릿 생성. 
													output_parser = StrOutputParser()  # output parser 생성.

													chain = prompt | model | output_parser  # chain 생성. prompt, model, parser를 결합. 
													chain.invoke(~~~)  # chain 실행. 

												ㄴ 컴포넌트 사이에 '|' 키워드를 붙여 컴포넌트를 chain으로 연결하는 식. 
													ㄴ '|'는 unix command 쉘에서 사용하는 |와 유사. 이전에서 나온 결과를 다음요소의 인풋값으로 넘기는식. 
											ㄴ ~~~

										</pre> 

										ㄴ Providers 
											ㄴ ??? 개요  
												ㄴ langchian과 호환되어 사용 가능한 여러 standalone 모듈들? 
													랑체인의 기본 컴포넌트인 chat model, vector store, document loader 등에 사용될 수 있는
													모듈들부터, 기타 추가 기능을 제공하는 모듈들 존재? 
												ㄴ ex ) 
													랑체인에서 chain 구성시, 컴포넌트 중 하나인 chat model에 
													providers중 하나인 openai에서 제공하는 ChatOpenAI 모듈을 사용하는식. 
											ㄴ 목록 
												ㄴ ~~~ 

											ㄴ https://python.langchain.com/v0.1/docs/integrations/platforms/

										ㄴ LangSmith <button>more</button>
										<pre>
											ㄴ 개요 
												ㄴ llm 어플리케이션에 대한 모니터링, 성능 평가 기능 등을 제공하는 플랫폼. 
													langsmith 모듈로 어플 코드를 어플에 추가하면 langsmith 페이지상에서 어플 모니터링 및 평가 등이 가능. 
												ㄴ Observability, Evaluation, Prompt Engineering으로 구성
											ㄴ Observability <button>more</button>
											<pre>
												ㄴ 기본 사용법 
													ㄴ pip install langsmith 
													ㄴ 환경변수 세팅 
														// true이면 추적, 아니면 추적데이터 수집 안함. 
														// 'RunTree', API를 사용하는 경우, 영향 없다함. 
														LANGSMITH_TRACING=true  
														LANGSMITH_API_KEY=~~~  # 페이지에서 발급 가능. 
														LANGSMITH_ENDPOINT=https://api.smith.langchian.com
														// langsmith 모니터링 페이지에 있는 플젝명. 기본 플젝명은 'default' 
														// 여기 명시했는데 langsmith모니터링 페이지에 없으면 자동 생성한다함. 
														LANGSMITH_PROJECT=(*project name*)  
													ㄴ 어플리케이션 코드에 tracing 코드 추가 
														ㄴ langsmith.wrappers.wrap_openai 같은 wrapper 사용하여 객체들을 감싸거나 
														ㄴ langsmith.traceable 같은 decorator를 함수에 붙이거나. 
															ㄴ ex ) 
																@traceable( )
																def chatbot(state: State):
																	return {"messages": [llm_with_tools.invoke(state["messages"])]}
													ㄴ langsmith 페이지를 통해 접속 가능한 모니터링 페이지에 
														tracing하고 있는 데이터가 업로드되어 표시됨. 
												ㄴ ??? 피드벡 기능? 
													ㄴ 그냥 어플 로직상에서 chain실행 하나(run)에 대해 id를 기억하고 그 run id에 대해 점수 등을 
														langsmith 함수로 보내어 langsmith모니터링 페이지상에서 볼수잇게하는 기능? 
												ㄴ??? 메타데이터 기록 기능 
													ㄴ ??? langsmith에 기록될 log에 메타데이터를 명시 가능? 
													ㄴ ???방법 
														ㄴ traceable decorator에 'metadata' 속성 추가하고 값으로 dict. 
															ㄴ ex ) 
																@traceable(metadata={"key": "value"})
																def chatbot(state: State):
																	return {"messages": [llm_with_tools.invoke(state["messages"])]}
														ㄴ traceable decorator가 붙은 함수 호출시, 'langsmith_extra'속성 추가하고 
															여기에 'metadata'키값 추가하고 value로 dict.
															ㄴ ex ) 
																@traceable
																def chatbot(state: State):
																	return {"messages": [llm_with_tools.invoke(state["messages"])]}
																	
																chatbot(state, langsmith_extra={"metadata": {"key": "value"}}) 
													ㄴ 모니터링페이지에 metadata가 표시. 
												ㄴ 모니터링 탭? 
												ㄴ traceable decorator 
													ㄴ 인자 
														ㄴ project_name 
															ㄴ tracing데이터를 보낼 langsmith 프로젝트 이름. 
																langsmith 페이지의 해당 플젝에 tracing데이터가 업로드됨. 
													ㄴ 함수 호출시 'langsmith_extra' 매개변수 
														ㄴ 데코레이터가 붙은 함수 호출시, 'langsmith_extra'란 키워드 매개변수에 dict를 넘기면 
															이 dict의 키와 값들이, traceable decorator의 인자로 들어감. 
														ㄴ ex ) 
															@traceable 
															def chatbot(state: State):
																return {"messages": [llm_with_tools.invoke(state["messages"])]}
															
															# @traceable(project_name="my_project")와 같음. 
															chatbot(state, langsmith_extra={"project_name": "my_project"}) 
													ㄴ ??? trace context manager 
													ㄴ ??? 뭐 정확히 어케 돌아가는지, 인자 뭐가 있는지 등 자세한 설명 없다? 소스보면서 하란건지. 

												ㄴ ??? lamgsmith.wrappers 
													ㄴ llm client를 wrap하여 자동으로 tracing이 되게하는 wrapper들? 
													ㄴ openai 등 몇개만 되는듯? 
													ㄴ ??? 뭐 정확히 어케 돌아가는지, 인자 뭐가 있는지 등 자세한 설명 없다? 소스보면서 하란건지. 
												ㄴ ??? RunTree API 
													ㄴ 코드로 명시적으로 tracing데이터를 하나하나 보내는 API 
													ㄴ 오류 가능성이 높아 권장 않는다함. 
													ㄴ ??? 뭐 정확히 어케 돌아가는지, 인자 뭐가 있는지 등 자세한 설명 없다? 소스보면서 하란건지. 
												ㄴ tracing 데이터 업로드 전 종료 이슈 
													ㄴ langsmith의 tracing은 background thread에서 수행된다함. 
														하여, tracing데이터 전송 완료 전 어플 종료시, tracing데이터가 누락될 수 있음. 
													ㄴ 해결책 
														ㄴ langsmith.Client의 flush() 
															ㄴ 어플 메인로직의 finally 문 같은 곳에 명시적으로 client.flush()를 호출하여 데이터가 
																마저 전송되도록. 
														ㄴ langchain_core.tracers.langchain.wait_for_all_tracers() 
															ㄴ 위 client.flush()와 마찬가지 기능을 langchain에서 제공하는 것.  
											</pre>
											ㄴ ??? Evaluation 
												ㄴ graph의 반환 결과에 대해 성능 평가를 하는 기능? 
											ㄴ ???Prompt Engineering
												ㄴ ???UI로 프롬프트 입력하게 해주는 기능?  
											ㄴ 참고 
												ㄴ https://docs.smith.langchain.com/ 
										</pre>
										ㄴ LangGraph 
											ㄴ 'AI agent'항목 참고.   
										ㄴ LangServer

										ㄴ Security 
											ㄴ ~~~ 

										ㄴ 참고 
											ㄴ https://python.langchain.com/v0.1/docs/get_started/introduction/

										ㄴ 실무 
											ㄴ 아주 기초적 수준으로, embedding, llm 등에 대한 이해 없이 구현은 가능. 
												근데 langchain을 사용해서 예제코드수준으로 간단하게 구현한거지, 	
												명세에 따라, 어떤 loader를 사용할지, 어떤 splitter, embedding model, retriever, vector store가 적합할지, 
												그 사용하는 것들에 대한 이해, 이 기능 관련한 아키텍쳐는 어떻게 구성할지(장고 앱 안에 넣을지, 따로 어플을 나눌지, 
												데이터는 어디에 저장할지, 소스document들은 어떻게 가져올지 등)  등 고려할게 많다. 
										
									</pre>
									ㄴ OpenAI Platform 
										ㄴ ??? openai에서 제공하는 llm관련 인테페이스? 
											openai API및 기타 여러 기능들을 API를 통해 구현 가능. rag, agent 등의 기능들 포함. 
											??? openai 모델만 사용가능한듯?  
										ㄴ ~~~ 
										ㄴ OpenAI Agents SDK 
											ㄴ 'AI Agent'항목 참고. 

								ㄴ ~~~
							</pre>
						
						</pre>
						ㄴ Decision trees 
						ㄴ Genetic algorithms 

				ㄴ deep learning (딥러닝) 
					ㄴ 머신러닝의 일부 분야로서, 
						'neural network'를 활용하여 ???classification, regression, representation learning 등의 작업을 수행. 

			</pre>

			ㄴ ai 활용 
				ㄴ 생성형 ai (Generative artificial intelligence) <button>more</button>
				<pre>
					ㄴ ai의 활용분야 중 하나. text, image, video 등을 생성함. 
					ㄴ ~~~
					ㄴ prompt engineering 
						ㄴ prompt를 생성형 ai가 이해할 수 있는 방식으로 명령어를 구성하는 것을 의미. (prompt는 자연어)
						ㄴ ~~~
						ㄴ RAG (Retrieval-Augmented Generation)
							ㄴ LLM과 관련한 prompt engineering의 한 방법. LLM의 단점, 한계를 보완.
							ㄴ 단순 LLM만으로 하는 답변은 모델 생성시 학습된 데이터를 기반으로 답변을 생성해내는데 반해, 
								RAG를 이용하면 
							ㄴ 아주, 대략적, 추상적 동작 방식
								ㄴ LLM이 프롬프트에 대해 바로 답변하는게 아니라, 
									일종의 데이터 저장소와 여기서 데이터를 추출하는 컴포넌트를 두고, 프롬프트에 대해 이 데이터 저장소에서 먼저 
									데이터를 추출하고 데이터가 있으면 이것에 기반하여 LLM이 답변하도록 하고, 없으면 답변하지 않도록 하는 방식. 
							ㄴ 장점 
								ㄴ fine tuning을 하지 않아도 최신 데이터에 기반한 답변 가능. 데이터 저장소를 적절히 업데이트만 하면 됨. 
								ㄴ 명확하게 제공된 데이터에 근거하여 답변하므로 상대적으로 정확한 답변 가능. 
								ㄴ 데이터가 없는 경우 잘못된 정보 제공이 아닌 답변하지 않음으로서 LLM의 hallucination 문제 해결. 
								ㄴ 명확한 근거가 되는 출처 제공 가능. 
				</pre>

				ㄴ AI Agent <button>more</button>
				<pre>
					ㄴ 개요 
						ㄴ 추상적 개념? 
						ㄴ 위키 정의 (intelligent agent)
							ㄴ 'machine perception'을 하고, 설정된 임의의 목표 달성을 위해 필요한 동작을 자율적으로 수행하는 agent를 의미? 
								추가적으로 머신러닝 등을 하여 아웃풋을 개선하는 agent? 
							ㄴ 광범위하게, 정의에 부합하는 무엇이든 AI Agent라고 할 수 있다함. 온도계, 제어시스템, 국가, 인류 등. 
							ㄴ '목표 지향적 행동'이 핵심이라함. 
						ㄴ ??? 이를 llm을 사용하는 소프트웨어를 개발하여 만든 무언가 쯤으로 생각하면 될듯? 
					ㄴ ex ) 
						ㄴ chatGPT Deep Research 
						ㄴ manus ai 
						ㄴ openmanus (https://github.com/openmanus-ai/openmanus) 
							ㄴ 이름은 manus이긴하나, manus를 보고 3시간만에 대충 따라서 만든 ai agent라함. 
							ㄴ 오픈소스. 
							ㄴ 코드보니 대략, 
								openai를 이용, 프롬프트 입력받아 llm한테 넘기고, 인터넷 서칭, 명령어 실행 등의 'tool'들을 직접 구현하고 
								이것들을 openai ref에 맞게 llm한테 넘겨 llm이 프롬프트에 대해 알아서 이중에 필요한 것들을 선택하게하고 
								선택된것들을 실행, 이를 여러단계 반복하는식. 
					ㄴ 개발 프레임워크 
						ㄴ OpenAI SWARM (OpenAI Agents SDK)
							ㄴ openai에서제공하는 multi-agent 어플 개발을 위한 프레임워크. 
							ㄴ openai의 실험적 라이브러리였던 'Swarm'을 업그레이드한것. 
							ㄴ 다른 ai agent 프레임워크들에 비해 가볍고 사용하기 쉽다함. 
								그만큼 제한이 많음? 
						ㄴ AutoGen 
						ㄴ CrewAI 
						ㄴ LangGraph <button>more</button>
						<pre>
							ㄴ 개요 
								ㄴ ??? LLM을 사용하는 stateful, multi-actor 어플 개발에 사용되는 라이브러리? 
								ㄴ ??? 주요 기능
								ㄴ RAG, 프롬프트 최적화, 응답 template화 등 같이 
									LLM과 상호작용하는 과정에서 거치는 일련의 전/후처리들을 보통 '체인'이라 부름. 
									이 '체인'을 스스로 적절히 선택하여 동작하는 LLM프로그램을 만들고자 하는게 배경. 
									ㄴ 이를 AI Agent라고 할 수 있음. 
								ㄴ 'cognitive architecture'
									ㄴ LLM application의 자율성의 레벨?
										ㄴ 랑체인 내 개념에 따르면, llm어플리케이션은 자율성 정도에 따라 몇가지 레벨로 구분가능하다함.
										ㄴ <img src="image/langchain_llm_app_level_of_autonomy.png"/>
										ㄴ??? 마지막 완전 자율 단계는 어떤 작업을 수행해야 하는지까지 llm이 결정?  
										ㄴ 참고 ) https://blog.langchain.dev/what-is-a-cognitive-architecture/
									ㄴ router 
										ㄴ 다음에 어떤 작업을 수행해야 하는지를 llm이 결정. 
									ㄴ structured output 
										ㄴ llm의 응답이 구조화된 형태가 되도록 하는 것. 
											이를 통해, 안정적으로 llm의 응답을 해석하여 라우팅 등의 처리 가능. 
									ㄴ 프로그램 구조를 어떻게 가져가는지에 따라 분류하는 듯. 
										정해진 로직흐름이 있고 그 안에 llm이 사용되는 정도인지, 
										정해진 로직 흐름 중, llm의 결정에 따라 흐름이 분기되는 정도인지, 
										정해진 로직 흐름도 없고, llm이 로직 진행을 처음부터 끝까지 결정하는식인지 등. 
									ㄴ 정해진 우열은 없다함. 케이스에 따라 적합한 방식만 있을뿐. 
								ㄴ llm에 더 많은 자율성을 부여할 수록 결과의 신뢰성은 낮아진다. 
									llm의 결정에 오류가 있을수 있으므로. 
									ㄴ langgraph에선, llm에 더 많은 자율성을 주면서도 결과의 신뢰성을 커버할 수 있는 기능들을 제공. 
										ㄴ controllability
										ㄴ Persistence
										ㄴ Human-in-the-Loop
										ㄴ Streaming 
							ㄴ  
							ㄴ 주요 개념 
								ㄴ state 
									ㄴ 일종의 데이터 덩어리. 
									ㄴ 어떤 python type도 가능하나, 일반적으로 TypedDict | Pydantic의 BaseModel
									ㄴ 그래프 정의시 가장 먼저 정의. 
									ㄴ schema 
										ㄴ state의 schema는 모든 node, edge의 input의 schema가 된다. 
										ㄴ ??? 그래프는 디폴트로 인풋, 아웃풋의 schema가 동일. 
											명시적으로 정할 수도 있음. 
										ㄴ multiple schema 
											ㄴ 일반적으로 모든 노드는 하나의 스키마로 통신하지만 이것으로 부족한 케이스들 있을 수 있음. 
												ㄴ 노드 중 일부가 그래프의 인풋, 아웃풋에 포함되지 않은 정보를 전달해야하거나
													ㄴ 'PrivateState'로 해결 가능. 
												ㄴ 그래프의 인풋, 아웃풋이 서로 달라야 하는 경우 등. 
													ㄴ 모든 키를 포함하는 'internal' schema를 정의하고 
														이 키들 중 일부를 포함하는 'input', 'output' schema를 정의하여 사용함으로서 해결 가능. 
										ㄴ 그래프 정의시, 그래프 인스턴스 초기화할 때 schema에 해당하는 클래스를 인자로 넘겨 스키마 설정. 
											ㄴ ex ) <button>more</button>
											<pre>
												class InputState(TypedDict):
													user_input: str

												class OutputState(TypedDict):
													graph_output: str

												class OverallState(TypedDict):
													foo: str
													user_input: str
													graph_output: str

												class PrivateState(TypedDict):
													bar: str

												def node_1(state: InputState) -> OverallState:
													# Write to OverallState
													return {"foo": state["user_input"] + " name"}

												def node_2(state: OverallState) -> PrivateState:
													# Read from OverallState, write to PrivateState
													return {"bar": state["foo"] + " is"}

												def node_3(state: PrivateState) -> OutputState:
													# Read from PrivateState, write to OutputState
													return {"graph_output": state["bar"] + " Lance"}

												builder = StateGraph(OverallState,input=InputState,output=OutputState)
												builder.add_node("node_1", node_1)
												builder.add_node("node_2", node_2)
												builder.add_node("node_3", node_3)
												builder.add_edge(START, "node_1")
												builder.add_edge("node_1", "node_2")
												builder.add_edge("node_2", "node_3")
												builder.add_edge("node_3", END)

												graph = builder.compile()
												graph.invoke({"user_input":"My"})
												{'graph_output': 'My name is Lance'}
											</pre> 
											ㄴ ??? 그래프 인스턴스 생성시 schema 클래스를 인자로 넘기지 않았더라도, 
												schema class가 정의만 되어있다면 node가 이 스키마를 반환할 수 있음. 
									ㄴ reducer 
										ㄴ node가 반환한 값('update')을 'state'에 어떻게 반영할지를 결정하는 컴포넌트. 
										ㄴ 'state' schema의 key별로 각각의 'reducer'를 가짐. 
										ㄴ 'update'에 특정 key가 있으면, 그 key의 reducer가 호출되어 이 reducer의 로직에 따라 
											값이 'state'에 반영. 
										ㄴ key에 대해 아무 reducer가 정의되지 않으면, 그냥 값을 override 처리. 
										ㄴ ??? typing.Annotated 등으로 reducer 설정? 
									ㄴ ??? Messages ? 
										ㄴ ~~~???
									ㄴ??? 각 'graph'마다 'state'를 생성. 
									ㄴ ???state는 graph내 node들이 실행될때마다 node들에게 전달됨. 
									ㄴ ???node들은 실행을 마친 뒤 결과값으로 state 값을 업데이트. 
									ㄴ ???state가 어떻게 업데이트될지는 graph종류 및 custom function에 따라 결정. 

								ㄴ Node 
									ㄴ agent의 로직이 들어있는 파이선 함수. 
										ㄴ 인자 
											ㄴ 첫번쨰 positional 인자로 'state'를 필수로 가짐. 
											ㄴ 두번째 positional 인자로 여러 설정파라미터를 나타내는 'config'를 옵션으로 가짐. 
									ㄴ input으로 'state'를 받고, 작업 수행 후, 업데이트된 'state'반환. 
									ㄴ add_node() 
										ㄴ node를 graph에 추가. 
										ㄴ ??? 인자로 받은 함수는 'RunnableLamdas'로 변환됨? 
									ㄴ special 사전 정의 Node 
										ㄴ 'langgraph.graph.START' node 
											ㄴ 가장 처음 시작하는 노드. 유저 인풋을 그래프에게 전달. 
											ㄴ 처음 실행되야할 노드 결정을 위해 사용. 
											ㄴ ex ) graph.add_edge(START, "(*임의 node명*)") 
										ㄴ 'langgraph.graph.END' node 
											ㄴ 마지막 노드를 나타내는 노드. 
											ㄴ 어떤 노드 다음에 아무 액션이 없도록 설정하기 위해 사용. 
											ㄴ ex ) graph.add_edge("(*임의 node명*)", END) 
									ㄴ??? 'state'에서 일부 key만 구성하여 반환하면, 그 key들에 대해서만 state가 업데이트됨. 

								ㄴ Edge
									ㄴ 현재 'state'에 따라 다음 수행해야할 'node'가 뭔지 결정하는 파이선 함수. 
									ㄴ 조건에 따라 분기될 수도, 정해진 다음단계로 전달만 할 수도 있음. 
									ㄴ 유형 
										ㄴ normal edge 
											ㄴ 하나의 노드에서 바로 다음 노드로 이동하는 엣지. 
											ㄴ add_edge() 이용하여 설정 가능. 
										ㄴ conditional edge 
											ㄴ 다음에 어떤 노드로 이동할지 결정하는 함수를 호출하여 다음 노드를 결정하는 엣지. 
											ㄴ add_conditional_edges( (*이전노드*), (*다음노드결정함수*) ) 이용하여 설정 가능. 
												ㄴ (*다음노드결정함수*) 
													ㄴ 'state'를 인자로 받음. 
													ㄴ 디폴트로 node 이름 반환. 해당 노드가 다음에 실행됨. 
													ㄴ??? 노드 이름 list가 반환될 수도 있으며, 이 경우, 다음 'super step'에서 이 노드들이 병렬로 동시 실행. 
													ㄴ 노드명이 아닌 임의값 반환하고, add_conditional_edges()의 추가인자에서 
														임의반환값에 따른 다음 노드 설정 가능. 
										ㄴ entry point 
											ㄴ 유저 인풋 도착시 처음 호출되어야할 엣지. 
											ㄴ add_edge()와 START node로 설정 가능. 
												ㄴ ex ) add_edge(START, "(*임의노두명*)" )
										ㄴ conditional entry point 
											ㄴ 유저 인풋 도착시 어떤 노드가 처음 호출돼야하는지 결정하는 함수 호출하여 
												처음시작 노드를 결정하는 엣지. 
											ㄴ add_conditional_edges()와 START 노드로 설정가능. 
												ㄴ add_conditional_edges(START, (*함수*))
								ㄴ ???Send 
									ㄴ ~~~??? 
								ㄴ Command 
									ㄴ ??? node기능과 edge기능을 한 node내에서 수행하고 싶을때 사용.
									ㄴ node에서 'Command' 객체에 state update내역과 다음 노드명 설정하여 반환시, 
										그 내용으로 state가 업데이트된 후 해당 노드명으로 이동됨. 
									ㄴ ex ) 
										def my_node(state: State) -> Command[Literal["my_other_node"]]:
											if state["foo"] == "bar":
												return Command(update={"foo": "baz"}, goto="my_other_node")
									ㄴ 예제와 같이 node 함수에서 return type 어노테이션에 Command로 갈 가능성이 있는 
										노드명 명시해야함. 
									ㄴ 사용 케이스 
										ㄴ ??? tool 안에서의 사용 
											ㄴ ??? ~~~ 
										ㄴ ??? Humman-in-the-loop 안에서의 사용. 
											ㄴ ~~~???
								
								ㄴ ???Persistence 
									ㄴ ??? 'checkpointer'를 이용하여 각 'superstep'마다 state의 스냅샷 저장? 
										이를 통해, 재개가 가능하고 여러 다른 기능들 가능? 
										ㄴ ??? 체크포인트는 'thread'에 저장되고, thread를 통해 그래프의 실행 후에도 그래프의 
											state에 접근이 가능하여, 여러가지 기능을 가능하게 한다? 
											human-in-the-loop, memory, time travel, fault-tolerance 등? 
									ㄴ graph생성시, 그래프를 'checkpointer'와 함께 컴파일하는것을 통해 세팅 가능. 
									ㄴ checkpointer 사용시, graph의 'configurable'로서 'thread_id'를 반드시 넘겨야함. 
									ㄴ thread가 실제 스레드를 구현상에 사용하는지는 모르겠으나, 그냥 thread_id만을 기준으로 저장되는 데이터가 구분됨. 
									ㄴ checkpoint 
										ㄴ ??? 각 super-step별로 저장된 graph의 state의 스냅샷? 
										ㄴ 'StateSnapshot'
											ㄴ checkpoint를 나타내는 객체. 
											ㄴ 속성 
												ㄴ config 
												ㄴ metadata 
												ㄴ values 
												ㄴ next 
												ㄴ tasks 
								ㄴ Memory 
									ㄴ ~~~ 
									ㄴ 분류 
										ㄴ short-term memory 
											ㄴ langgraph에서 사용하는 개념적 용어로서, 
												??? 하나의 'thread'(langgraph의 thread) 내에서의 내용 기억을 의미? 
											ㄴ langgraph에선, 'state', 'checkpoint'로 이를 구현. 
												??? state로 그래프 흐름 내에 있어서 정보들을 기억하고, 
												checkpoint로 하나의 thread_id에 대해 이전의 내용들을 기억? 
											ㄴ 대표적 사용 예 : 대화 history 
											ㄴ 대화 history가 길어지는 경우 대처 
												ㄴ chatbot같은 경우, 대화가 길어져 저장해야할 대화 기록이 많아지는 경우, 
													이 히스토리들이 llm에 context에 모두 들어가거나 하면 성능, 비용 이슈가 있으니 
													이를 적절히 줄이기를 원할 수 있음. 
												ㄴ 방법 
													ㄴ 메세지 목록 중 일부 제거 
													ㄴ 이전 메세지 내용 요약 
												ㄴ 유의사항 
													ㄴ 메세지 목록 중 일부를 제거하려는 경우, 
														chat model에 따라 메세지목록이 특정 형식이나 순서에 대한 조건을 필요로 할 수 있다는 점 
														유의 필요. 
														가령, 어떤 모델은 메세지 목록에서 AIMessage가 아닌 HumanInputMessage가 가장 앞에 
														와야 한다거나 등. 
										ㄴ long-term memory 
											ㄴ ??? langgraph에서 사용하는 개념적 용어로서, 
												여러 'thread'들 간의 정보 공유를 의미? 

								ㄴ ???Thread 
									ㄴ langgraph내에서 thread는 개별 세션 또는 그래프와 유저사이의 대화를 의미. 
									ㄴ 'thread id'에 의해 langgraph thread가 특정됨. 
								ㄴ ??? Storage 
									ㄴ??? langgraph에서 제공한느 built-in document 저장소? 
									ㄴ langgraph thread에 상관없이 공통적으로 사용. 
									ㄴ custom namespace 방식 사용하여 데이터 저장. 
								ㄴ ??? graph Migration 
								ㄴ Configuration 
									ㄴ ~~~ 
									ㄴ recursion limit 
										ㄴ 그래프에서, 한번의 그래프 실행시 수행 가능한 최대 'superstep'의 횟수가 제한. 
										ㄴ 디폴트 25회. 
								ㄴ interrupt 
									ㄴ ???interrupt()함수를 통해, 그래프 동작을 중단시킬 수 있다. 
									ㄴ 중단시키고 유저가 입력하는 정보를 받거나 하는데 사용. 
								ㄴ Breakpoint 
									ㄴ??? 그래프의 동작을 중단시키고, 한단계씩 진행되는 것을 가능하게함. 
									ㄴ langgraph 'persistence'를 통하여 동작함. 
								ㄴ SubGraph 
								ㄴ Visualization 
								ㄴ Streaming 
									ㄴ ??? 결과가 완료되지 않았어도 생성중인 결과를 실시간으로 표시하여 UX를 개선할수 있는 기능. 
								ㄴ Tool calling 
								ㄴ Action takings
								ㄴ Memory 
								ㄴ Planning 
							ㄴ 'node'와 'edge'를 구성함으로서 여러 복잡한 기능을 하는 langgraph application을 만드는 것.
							ㄴ??? message passing 방식?
							ㄴ ???'super-step' 
								ㄴ 노드 실행 싸이클 같은 것? 
									동시에 실행되는 노드들은 같은 super-step 안에 속한것이고 
									연달아 수행되는 노드들은 각각 다른 super-step에 속한것? 
							ㄴ 처음 graph 시작시 모든 node는 'inactive'. 
								새 메세지(state)를 받은 노드는 'active'. 노드의 동작을 수행하고 update를 반환. 
								'super-step'종료시, 인풋 message가 없는 노드는 다시 'inactive'. 
								모든 노드가 'inactive'이고 이동중인 메세지가 없으면 그래프 종료. 
							ㄴ ??? graph 유형? 
								ㄴ StateGraph 
								ㄴ MessageGraph 
							ㄴ graph compiling 
								ㄴ graph를 빌드하려면, state, node, edge 등을 정의한 뒤, 그래프를 'compile'해야함. 
								ㄴ 그래프를 'compile'하는 것이란, 정의한 그래프가 문제가 없는지 몇가지 체크를 하는 과정을 
									langgraph 내에서 지칭하는 용어로, langgraph 내 컴파일 함수 호출을 통해 이루어짐. 
									ㄴ ex ) graph = graph_builder.compile(~~~)
							ㄴ 사용법 
								ㄴ 대략 
									ㄴ 'state', 'node', 'edge' 등 정의하고
										node들에 어떤 동작할지 정의하고, edge와 node들 연결하여 어떤 노드 다음에 어떤 노드 실행할지 등 정의하고 
										컴파일 후 실행시키면, 정의한 구조(graph)에 따라 프로그램이 동작. 
										ㄴ 형식은 이렇게 단순하고 구조를 어떻게 가져가는지에 따라 자유롭게 구성 가능. 
									ㄴ 이게 기본 구성이고, 추가적으로 agent개발에 도움이 될법한 여러 툴들 제공하는식인듯. 
										메모리, stream 등. 
									ㄴ 메모리 설정 
										ㄴ ??? 대략, 
											langgraph 컴파일시 'checkpointer'를 넘기고, 그래프 실행시 thread id를 넘기면, 
											langgraph가 이 thread id별로 그래프의 step마다에서의 state값을 저장 & 
											동일한 thread id로 그래프 재시작시, 저장된 state를 불러와 채팅 이어가기 가능? 
											또한 step별 저장된 state를 checkpointer로서 이 지점부터 재시작 가능? 
								ㄴ ex ) <button>more</button>
								<pre>
									import json
									from typing import Annotated

									from typing_extensions import TypedDict

									from langchain_cohere import ChatCohere
									from langchain_core.messages import ToolMessage


									from langgraph.graph import StateGraph, START, END
									from langgraph.graph.message import add_messages


									class State(TypedDict):
										# Messages have the type "list". The `add_messages` function
										# in the annotation defines how this state key should be updated
										# (in this case, it appends messages to the list, rather than overwriting them)
										messages: Annotated[list, add_messages]


									graph_builder = StateGraph(State)
									
									cohere_chat_api_key = "~~~"
									llm = ChatCohere(cohere_api_key=cohere_chat_api_key)

									from langchain_community.tools.tavily_search import TavilySearchResults

									tool = TavilySearchResults(max_results=2)
									tools = [tool]
									# tool.invoke("What's a 'node' in LangGraph?")

									llm_with_tools = llm.bind_tools(tools)

									def chatbot(state: State):
										return {"messages": [llm_with_tools.invoke(state["messages"])]}


									# The first argument is the unique node name
									# The second argument is the function or object that will be called whenever
									# the node is used.
									graph_builder.add_node("chatbot", chatbot)



									class BasicToolNode:
										"""A node that runs the tools requested in the last AIMessage."""

										def __init__(self, tools: list) -> None:
											self.tools_by_name = {tool.name: tool for tool in tools}

										def __call__(self, inputs: dict):
											if messages := inputs.get("messages", []):
												message = messages[-1]
											else:
												raise ValueError("No message found in input")
											outputs = []
											for tool_call in message.tool_calls:
												tool_result = self.tools_by_name[tool_call["name"]].invoke(
													tool_call["args"]
												)
												outputs.append(
													ToolMessage(
														content=json.dumps(tool_result),
														name=tool_call["name"],
														tool_call_id=tool_call["id"],
													)
												)
											return {"messages": outputs}

									tool_node = BasicToolNode(tools=[tool])
									graph_builder.add_node("tools", tool_node)

									def route_tools(
										state: State,
									):
										"""
										Use in the conditional_edge to route to the ToolNode if the last message
										has tool calls. Otherwise, route to the end.
										"""
										if isinstance(state, list):
											ai_message = state[-1]
										elif messages := state.get("messages", []):
											ai_message = messages[-1]
										else:
											raise ValueError(f"No messages found in input state to tool_edge: {state}")
										if hasattr(ai_message, "tool_calls") and len(ai_message.tool_calls) > 0:
											return "tools"
										return END
									graph_builder.add_conditional_edges(
										"chatbot",
										route_tools, 
										{"tools": "tools", END: END},
									)

									graph_builder.add_edge("tools", "chatbot")
									graph_builder.add_edge(START, "chatbot")
									# graph_builder.add_edge("chatbot", END)

									graph = graph_builder.compile()


									def stream_graph_updates(user_input: str):
										for event in graph.stream({"messages": [{"role": "user", "content": user_input}]}):
											for value in event.values():
												print("Assistant:", value["messages"][-1].content)


									while True:
										try:
											user_input = input("User: ")
											if user_input.lower() in ["quit", "exit", "q"]:
												print("Goodbye!")
												break

											stream_graph_updates(user_input)
										except:
											# fallback if input() is not available
											user_input = "What do you know about LangGraph?"
											print("User: " + user_input)
											stream_graph_updates(user_input)
											break


									# from IPython.display import Image, display

									# try:
									#     display(Image(graph.get_graph().draw_mermaid_png()))
									# except Exception:
									#     # This requires some extra dependencies and is optional
									#     pass








								</pre> 
							ㄴ LangGraph Studio 
								ㄴ langgraph 어플을 시각화, 디버깅 할 수 있는 IDE. 
							ㄴ LangGraph Platform <button>more</button>
							<pre> 
								ㄴ langgraph 어플 배포 기능 포함.  
									여러 컴포넌트들로 구성 
								ㄴ 컴포넌트 목록 
									ㄴ langgraph server 
										ㄴ ??? graph로직만 만들면, langgraph를 이용하여 구현가능한 여러 기능들이 포함된 langgraph application을 
											자동으로 만들어주는 기능? 
										ㄴ ??? 플젝 구성하고 명령어등 사용하면 자동 생성? 도커파일 같은거. 
										ㄴ postgresql을 이용한 persistence, redis를 이용한 task queue, 스트리밍 등등의 기능 포함? 
										ㄴ cloud용 로컬 standalone형 등 구분? 이에따라 방법 다름? 
										ㄴ langgraph server api 
											ㄴ 
									ㄴ 
								ㄴ depolyment 
									ㄴ ??? langgraph application 구조 세팅 & 배포 단계로 구성? 
										app구조 세팅은 그냥 langgraph에서 정해진대로 프로젝트 코드를 구성하는 것 의미? 
										배포는 cloud에 할지, local standalone에 할지 등 가능? 
									ㄴ standalone 
										ㄴ 도커에 컨테이너로서 세팅하는 듯하고 
										ㄴ langgraph CLI를 이용해 도커파일을 자동생성하는 듯. 
											ㄴ langgraph build 
										ㄴ 이를 통해만든 langgraph server는 redis, postgresql, langsmith을 기본적으로 사용되도록
											사전정의되어있는듯함. 
									ㄴ??? 얘네가 제공하는 방법 아니더라도 그냥 알아서 배포해도되나? 
										FASTAPI등으로 요청받고, 로컬 langgraph가 돌아가는식으로? 
							</pre> 
							ㄴ deployment 
								ㄴ ??? langgraph platform을 이용하는 방법만 나와있음? 
								ㄴ platform 안쓰고 하려면 FastAPI나 django 등으로 요청 받아 반환하도록? 
							ㄴ ~~~ 
							ㄴ 참고 
								ㄴ https://langchain-ai.github.io/langgraph/
								ㄴ https://langchain-ai.github.io/langgraph/concepts/
								ㄴ https://langchain-ai.github.io/langgraph/tutorials/
								ㄴ https://langchain-ai.github.io/langgraph/how-tos/
								ㄴ https://langchain-ai.github.io/langgraph/reference/
						</pre>
						ㄴ 비교 
							ㄴ langgraph가 커스텀이 좋긴하나 러닝커브가 높고 보일러코드가 많다함. 
					ㄴ 상용 
					ㄴ 참고 
						ㄴ 

				</pre>

			ㄴ 무제 )
				ㄴ ChatGPT<button>more</button>
				<pre>
					ㄴ 사용 후기 
						ㄴ 컴퓨터, 기술적인 지식, 자주하는 시행착오 등은 그냥 물어보면 더 잘 서칭, 효과적.
							여러 조건들이 섞인 로직을 구현하는건 잘 알아듣게 정교한? 상세한 명령 필요? 그리 간단하진 않은 것 같다.
							전체 프로그램을 요구사항 분석, 명세 추출 등은 당연히 안되고, 설계도 아직까지는 안되는 듯 하다.
							ㄴ 그리고 영어가 확실히 나은 듯 하다. 언어 자료들을 학습하여 만들기 때문에 자료가 많은 영어가 더 성능이 좋다함.
						ㄴ 다음 단어 예측
						ㄴ masked 단어 예측
						ㄴ 문장의 정확한 의미를 파악하지 못하여 예측이 틀리는 경우?


				</pre> 
				ㄴ 김성훈 머신러닝 유튭 강의 정리<button>more</button>
				<pre>
					ㄴ explicit programming : 케이스들을 일일히 명시적으로 프로그래밍적으로 처리하는 방식?
						ㄴ ex ) 이런 케이스엔 저렇게 동작하고, 이런 패턴이면 스팸으로 처리하고, 등.
						ㄴ 케이스가 너무 많은 문제.
						ㄴ 이런 케이스를 일일히 명시하여 처리하지 말고 프로그램이 알아서 학습하여 처리하도록 하는게 머신러닝? 처음 생각.
					ㄴ supervised learning : 이미 정제된 데이터들로 학습하는 머신러닝 방식.
						ㄴ ex ) 고양이 사진에 'cat' label, 강아지사진에 'dog' label들을 붙여 데이터를 주어 학습시킴.
						ㄴ
							ㄴ 일정 범위를 예측(regression), 이지선다 분류(binary classification), 여러 케이스 분류(multi-label classification)
					ㄴ unsupervised learning : 사전 정제 없이, 그냥 raw 데이터로 머신러닝하는 방식? 

				</pre>
				
				ㄴ 약인공지능 : 특정한 조건, 환경, 기능에 대해서만 동작하는 인공지능. 
					
		</pre>

		자연어 처리 (NLP, Natural Language Processing)<button>more</button>
		<pre>
			ㄴ ~~~
			ㄴ word embedding 
				ㄴ 단어를 특정한 방식으로 표현하는 것을 말함. 
					보통 단어의 의미를 인코딩하여 실수 vector로 표현하며, 
					유사한 의미를 가지는 단어들이 vector 공간상에 가까이 위치하도록 값이 인코딩된다. 

		</pre>

		봇<button>more</button>
		<pre>
			ㄴ ~~~
			ㄴ 무제 )
				ㄴ 스크래핑 프로그램같이 컴퓨터상에서 사람인 것처럼 동작하는 프로그램?
				ㄴ 좋은? 기능을 하는 봇이 있고 악용되는 봇이 있다.
					ㄴ 전자의 예 ) 검색엔진의 크롤링 봇?
					ㄴ 후자의 예 ) 민감한 데이터 스크래핑, 디도스 공격용 봇, 계정 탈취 등.
				ㄴ 봇 탐지 )
					ㄴ 해킹과 보안처럼 창고 방패마냥, 봇을 동작시키려는 사람들과 막으려는 사람들이 갖은 방법을 사용.
					ㄴ 가장 기본적인 봇 동작은 selenium, 매크로 등으로 동작하는 것들?
					ㄴ 가장 기본적인 봇 탐지 & 방지는 봇 위험이 많다 판단되는 특정 ip영역대를 차단하는 것?
					ㄴ ip 평판 이용 )
						ㄴ 알려진 vpn 공급자에 속한 ip 등은 평판이 나쁨.
					ㄴ http request header확인.
					ㄴ tls 지문???
					ㄴ ~~~
					ㄴ 머신러닝을 통해 일반유저의 패턴을 학습하여 봇 탐지?

				ㄴ 매크로를 만들법한 프로그램?
					ㄴ autohotkey
					ㄴ autoit
					ㄴ PyAutoGui

				ㄴ google의 reCAPTCHA v3
					ㄴ 구글의 봇탐지 프로그램.
					ㄴ js단에서 클라이언트가 봇인지 아닌지를 판별하는 점수(0~1점. 0은 봇, 1은 사람)를 계산.
					ㄴ ??? 판별은 휴리스틱 ai를 이용하여 액션 패턴을 파악한다함?
						한 ip에서 너무 많은 요청 등.
					ㄴ ??? ai를 이용해 만든 봇으로 파훼는 현재 가능하다 한다.

		</pre> 

		실무? <button>more</button>
		<pre>
			ㄴ 공공기관 외주 방식? 
				ㄴ 대부분 내부 상주 개발직 없음? 
					필요한 프로그램은 외주 처리(SI) & 유지보수 맡김(SM) 
				ㄴ 보안상 원격 여는 것 지양함. 
					하여 개발은 업체에서 하더라도 설치는 직접 와서하거나 아예 파견형태로 개발. 
					외주업체 내에서 할시 동일환경에서의 테스트 필요. 

			ㄴ ~~~
			ㄴ 회사 플젝 <button>more</button>
			<pre> 
				ㄴ cosmos <button>more</button>
				<pre>
					ㄴ ~~~ 
					ㄴ 
				</pre>

			</pre>

		</pre>


	</pre>

	<br>기타<button>더보기</button>
	<pre>
		기타<button>더보기</button>
		<pre>
			ㄴ 소프트웨어 release에서, 'deprecated' vs 'removed' 
				ㄴ deprecated
					ㄴ 지원이 중단된 기능임을 의미. 더이상 개발, 관리하지 않는 기능이고 따라서 안전하지 않음. 
					ㄴ 사용은 가능함. 보통 경고 출력이 따라옴. 
					ㄴ 이전버전과의 호환 및 사용자단에서 버전업을 할 시간을 주기 위한 상태. 
					ㄴ 보통 다음 버전에서 removed됨. 
				ㄴ removed 
					ㄴ 기능이 완전히 제거된 것. 사용 자체 불가. 
			ㄴ markdown 
				ㄴ https://daringfireball.net/projects/markdown/
				ㄴ 특정한 문법에 맞는 텍스트를 html 등으로 변환하는 언어, 규칙 같은 것? 
				ㄴ ex ) 
					## 블라블라~~~  => html h2태그로 변환. 
					~~~ 
				ㄴ 사용 예 ) llm 응답 형태. 
				ㄴ 라이브러리 
					ㄴ python의 markdown 

			ㄴ ???etcd 
				ㄴ ???개요 
					ㄴ 일종의 데이터 저장 프로그램 
					ㄴ 분산시스템 환경에서 데이터가 일관되게 저장될 수 있는 기능 제공. 
						즉, 여러 분산된 머신 등에서 접근을 해도 데이터가 항상 일관되도록 저장하는듯. 
					ㄴ key-value형태로 데이터를 저장. 
			ㄴ UTC 형태 
				ㄴ ex ) Aisa/Seoul 타임존의 datetime값, 2024-08-12 16:40:35.395 +0900 
					ㄴ 앞의 datetime형태가 해당 타임존의 datetime값. 8월12일 16시 40분 35초. 
					ㄴ 맨 뒤 붙은 +0900 (혹은 -0900) 같은게 utc offset. 
						ㄴ 해당 타임존의 시간값이 UTC 시간으로부터 얼마나 차이가 나는지 나타냄. 
						ㄴ +인 경우, UTC보다 해당 타임존의 시간이 얼마만큼 '빠른'지 나타내고 
							-인 경우 '느릱'지 나타냄. 
							즉, +0900이면, 서울타임존의 시간이 UTC보내 9시간 '빠름' 즉, UTC시간에서 9시간을 더한게 서울타임존시간. 
			ㄴ thread-safe 
				ㄴ 함수 또는 코드가 여러 스레드들이 동시에 접근하여 실행되어도 
					예상되는 결과를 받지 못하거나, race condition이 발생하거나, 데이터 충돌이 일어나지 않는 것을 읨. 
				ㄴ 문제상황 예시 
					ㄴ 스레드 A,B,C와 객체의 멤버 변수의값을 1 증가시키는 메소드가 있다고 할 때, 
						스레드A가 아닌 다른 여러 스레드들이 이 메소드를 호출하여 값을 업데이트해버리면 
						스레드 A에서 예기치 못한 잘못된 변수값을 사용하게됨. 
				ㄴ 구현 
					ㄴ ??? Re-entrancy? 
					ㄴ Thread-local storage 
					ㄴ Immutable object 
					ㄴ Mutual exclusion 
					ㄴ Atomic operation 
					ㄴ java에서
						ㄴ 여러 스레드가 동시접근하여 문제가 될만한 코드에 'lock'을 걸어, 한번에 하나의 스레드만 실행이 가능하도록. 
							ㄴ lock은 프로그래밍 언어별로 기능이 있다? java의 'synchronized' 키워드 처럼. 
			ㄴ 웹 서비스 성능 개선 
				ㄴ 웹 서비스 성능 개선을 위한 일반적인 방법들.
				ㄴ 목록 
					ㄴ ??? data store sharding (데이터 저장소 샤딩)
					ㄴ load balancing 
						ㄴ 서버를 여러개 두고 로드밸런서로 트래픽을 분산. 
					ㄴ CDN 
					ㄴ db replication을 통한 db로의 트래픽 분산. 
						ㄴ db를 write node, read node로 분리하고 sql 트래픽을 분산하는 식. 
					ㄴ 각 프로그램 설정값 튜닝 
						ㄴ db 설정값, 서버 설정값 등을 최적화. 
					ㄴ 하드웨어 교체. 
						ㄴ 더 성능 좋은 cpu, 메모리, 디스크 등으로 교체. 
						ㄴ 가장 마지막 검토 옵션. 

			ㄴ upstream 
				ㄴ 거슬러 올라감. 
				ㄴ 소프트웨어 개발에 있어서, 어떤 소프트웨어가 다른 소프트웨어로부터 fork되거나 다른 소프트웨어를 사용하는 경우, 
					그 근원, 발행지 소프트웨어를 의미. 
				ㄴ 버전, 버그, patch 등을 이야기할 때 사용되는 단어. 
			ㄴ OpenSSH?
				ㄴ OpenBSD Secure Shell
				ㄴ ssh protocol을 기반으로하는 네트워크 보안 관련 프로그램들의 집합.
				ㄴ remote 작업 관련 ssh, scp, sftp. 키관리 관련 ssh-add, ssh-keysign, ssh-keyscan, ssh-keygen.
					그 외, sshd, sftp-server, ssh-agent 등이 있음.
				ㄴ OpenBSD Project에 의해 개발.
			ㄴ 데이터 분석?
				ㄴ 단계
					ㄴ 원시 데이터 수집 : 스크래핑, 사내 서비스 내 자체 수집(로그, 이메일, 구매내역 등)
					ㄴ 데이터 정제
						ㄴ 오류 데이터(누락, 오타, 중복, 정상 범주를 벗어난 값 등), 데이터 형식 일치
						ㄴ 일반적으로 가장 많은 시간 할애. 분석 결과 정확성에 직결.
					ㄴ 데이터 분석
						ㄴ ??? 사실 기술, 해석, 의사 결정?
			ㄴ 선점형 멀티테스킹, 협동형 멀티테스킹
				ㄴ 전자는 인터럽트를 사용하여 프로세스를 중단시키고 다음에 실행될 프로세스를 결정하는 방식.
				ㄴ 후자는 프로세스가 리소스가 필요치 않을때 '스스로 양보'하도록 만들어진 멀티테스킹 방식.
			ㄴ coroutine, subroutine
				ㄴ subroutine
					ㄴ 그냥 함수 같은 것. routine이 프로그램이라 하면, 그 하위에서 기능이 나누어져 있는 명령어 조합을 subroutine이라 부름.
					ㄴ routine은 여러 subroutine으로 구성된다 할 수 있고, 여러 subroutine들을 실행시킨다.
				ㄴ coroutine
					ㄴ subroutine과 거의 유사하나, subroutine은 한번 실행되면 종료까지 계속 실행되는 반면,
						coroutine은 시작부터 종료 전까지 계속 실행을 중지하고 재시작하는 것을 선택할 수 있다.
						즉, 중간에 계속 멈췄다 마저 실행되었다를 반복할 수 있는 것.
					ㄴ 협동형 멀티테스킹에 사용된다함.
					ㄴ 함수에서 yield 등을 반환함으로서 코루틴 함수를 만들 수 있다.
						ㄴ ex )

			ㄴ Link
				ㄴ object file들로 executable file을 만들기 위해 링커는 symbol들에 대한 참조를 결정해야 한다.
				ㄴ 이를 위해 링커는 symbol table 사용.
					ㄴ symbol table
						ㄴ 각각의 object file들에서 사용되는 심볼들의 정보를 가지고 있는 테이블.
						ㄴ 심볼 정보란 일반적으로 이름, 타입, 크기, 위치 등.
				ㄴ object file들에서 사용되는 모든 symbol 목록 생성.
					각각의 object file안에서 정의되지 않은 symbol들 필터링.
					필터링된 심볼들을 다른 object file에서 정의되었는지 확인, 발견시, 심볼이 그 정의를 가리키도록 업데이트?
					찾지 못하면 링크프로세스 에러.
				ㄴ Symbol
					ㄴ 소스코드에서 함수명, 변수명 등 프로그램의 요소를 표현하는 것. 이름과 매핑되며 해당하는 정보를 가지고 있다.
				ㄴ 링크 과정에서의 symbol 결정
					ㄴ linker가 파일의 심볼을 보고, 이 심볼이 해당 파일에 정의되어 있는지 확인, 있으면 그 심볼 사용.
						없으면, 다른 오브젝트 파일, 라이브러리 등에 정의되어 있는지 확인. 있으면 그
			ㄴ Emulator
				ㄴ 어떤 컴퓨터 시스템(host라 부른다)이 다른 컴퓨터 시스템(guest라 부른다)처럼 행동할 수 있게 해주는 하드웨어나 소프트웨어를 지칭.
				ㄴ 일반적으로, 특정 소프트웨어를 실행할 수 있게 해주거나, guest 시스템을 위해 설계된 장치를 사용할 수 있게 해준다.
			ㄴ Archive file
				ㄴ 그냥 파일. 파일인데, 메타데이터와 하나 이상의 파일로 구성된 파일을 지칭하는 말.
					여러개의 파일들을 휴대성과 저장의 편리함을 위해 한 파일로 모으거나 압축하기 위해 사용된다.
				ㄴ ex ) jar, zip,
				ㄴ 소프트웨어 배포를 위한 패키징에도 자주 사용된다. 이런 경우, '패키지'라고도 불린다.
					archive format은 동일하되, 관례에 따라 몇가지 파일들이 추가되며 이런 format을'package format'이라 부른다.
					ㄴ ex ) java의 JAR, Debian의 deb, Android의 APK

			*Cookie란?
						ㄴ개요) 서버에서 브라우저로 작은 크기의 정보를 보내는 기술을 말하며, 정보는
						브라우저쪽에 저장된다.
						ㄴ개요) session 기술과 유사하게 클라이언트와 서버간 연결유지기능을 한다
						ㄴ특징) 쿠키 객체는 이름, 값, ㄱ 외 추가적인 속성값들을 가질 수 있으며
						response.addCookie()를 통해 브라우저로 전송되게 된다
						ㄴ쿠키의 개수느 ㄴ약 20개개정도 크기는 4Kb정도이다
						ㄴ이후 브라우저가 서버로 요청을 보낼때 쿠키정보를 같이 보내게 된다
						ㄴ쿠키 메소드)
							new Cookie("--이름--", "--값--")
			*디렉토리 구조?
				ㄴ 이클립스에서 동적 웹프로젝트를 만들면 자동으로 디렉토리 구조가 형성되는데 실무에서는 그 구조를 잘 안쓴다고함.
				ㄴ 이유는 IDE마다 이 디렉토리구조가 다른데 때문에 데이터를 주고받을때 불편하다함.
				ㄴ 그래서 전세계적으로 쓰이는 구조인 Maven(메이븐)구조를 사용한다고한다.
			ㄴ 코딩이 좀만 길어지고 복잡해지니까 가독성좋고 간단,심플,깔끔한 코드의 중요성을 조금 알것같다. 돌아가기만하는데 집중하여 이상한 기교부려가며 코딩하면
				돌아가는건둘째치고 내가알아보기도힘들어서 어디서 오류가났는지, 어떻게 돌아가는지, 어디를 수정해야하는지 모르겟다.
			ㄴ 오류찾기 팁)
				ㄴ 오류내용을 그대로 구글링하는게 좀빠른듯.
			ㄴ MIME 타입)
				ㄴ 웹상에서 텍스트 뿐만 아니라 다른 이미지, 오디오등의 바이너리 파일을 전송하기 위해 파일을 텍스트형식으로 변환(인코딩)하여 송신하고
					인코딩된 파일을 다시 바이너리로 변환(디코딩)하는데 쓰이는 포멧, 형식을  말한다.
			ㄴ 동기적 vs 비동기적)
				ㄴ 동기적 : 어떤 작업을 요청했을 때 그 작업이 종료될 때까지 기다린 후 다음(다른) 작업을 수행하는 방식
				ㄴ 비동기적(Asynchronous) : 어떤 작업을 요청했을 때 그 작업이 종료될 때까지 기다리지 않고 다른 작업을 하고 있다가, 요청했던 작업이
					종료되면 그에 대한 추가 작업을 수행하는 방식

			ㄴ 동기 함수, 비동기 함수)
				ㄴ 동기함수 : 함수 호출부분에서 호출결과가 리턴될때까지 기다려야하는 함수로, 보통 사용하는 대부분의 함수라고 생각하면된다.
				ㄴ 비동기함수 : 호출부에서 실행결과를 기다리지 않아도 되는 함수.
					ex)	js의 setTimeout( (*콜백함수*), (*시간*))메소드. 이 함수실행시, (*시간*)만큼의 시간이 흐른뒤 (*콜백함수*)를
						실행한다. (*시간*)을 기다리는동안 이 호출부에서 계속기다리는게 아니라 다른 작업을 수행한다.
					ㄴ 자바스크립트에서 특히 자주쓰이며, 이런 비동기함수를 많이써야하는 상황에서 콜백함수들이 여러개가 중첩되어 가독성이 심각하게
						안좋아지는 '콜백지옥' 현상이 생긴다고한다. (이에 대한 해결책이 Promise객체)
			ㄴ 공부자료 tip)
				ㄴ MDN페이지에서 설명해주는 페이지들 맨 아래쪽에보면 'Specifications'항목에 'specification'아래에 해당 내용에 관련된 API나
					객체이름을 클릭하면 그 API나 객체의 스펙을 아주 자세히 알려주는 페이지가 나온다.
			ㄴ 자바스크립트 코딩)
				ㄴ 이유는 모르겟지만 js코드를 이클립스에서 돌리면 콘솔창으로 출력한 내용이 어디로 나오는지도모르겟고 오류목록도 잘 안뜨는듯하다.
					해서 자바스크립트는 코딩만 이클립스로하고 실행결과를볼때는 크롬에서 톰켓url로 입력하여 실행하는 방식으로 하자.
			ㄴ 웹 동작 과정)
				ㄴ 웹 페이지는 서버단에서 java, jsp, jstl등이 실행되고 파싱된 페이지가 브라우저로 전달되어 브라우저에서  html,css, js가 파싱되고 실행되는 순서.
				ㄴ 따라서 js의 스크립트 부분안에 jstl등을 넣어도 서버단에서 먼저 처리되긴하므로 사용 '가능'하기는 하다. (순서를 잘고려해 조심해서 코딩해야함)

			* 자바 annotation
				ㄴ 소스코드에 메타데이터를 표현하는게 본질이라함.
				ㄴ 문법)
					ㄴ 선언? : ex)	@(*annotation 이름*)  과 같은 형태로 사용한다. 컴파일러에게 이게 어노테이션임을 알린다.
						위치는 클래스, 인터페이스, 메소드, 메소드파라미터, 필드, 지역변수 위에 위치한다.
						ex)	@(*이름*)
							public class AAA{~~~}
					ㄴ 요소 : 어노테이션은 요소를 가질수있다. setAttribute()같은것.
						형태는 @(*어노테이션이름*)( (*요소이름1*) = " (*요소 값1*) ", (*요소이름2*) = " (*요소 값*) " )
						요소가 하나일경우 @(*어노테이션이름*)( " (*요소 값*) " ) 이렇게쓸수도잇다.

				ㄴ 기본적으로 제공하는 어노테이션)
					ㄴ @Deprecated : 해당 대상은 더이상지원하지않거나, 문제가있거나, 다른 더좋은게있으니 '사용하지 말라는 의미'. 사용하면 컴파일경고.
					ㄴ @Override : 대상이 슈퍼클래스에대해 오버라이드 되었다는걸 알려준다. 매칭되지 않는다면 오류를 날림.
					ㄴ @SuppressWarnings : 해당 메소드에 대해 컴파일러 경고메세지를 없애준다.
				ㄴ 메타 어노테이션)
					ㄴ 커스텀 어노테이션을 만드는데 쓰이는 기본어노테이션 이외의 어노테이션이라하마.
					ㄴ @Retention : 어노테이션 범위. 어떤시점까지 어노테이션이 영향을 미치는지 결정.
					ㄴ @Documented : 문서에도 어노테이션 정보를 표현.
					ㄴ @Target : 적용할 위치결정.
					ㄴ @Inherited : 이 어노테이션을 선언하면 자식클래스가 어노테이션을 상속받을수있음.
					ㄴ @Repeatable : 반복적으로 어노테이션을 선언할수있게함.
				ㄴ 커스텀 어노테이션)
					ㄴ ex)
				import java.lang.annotation.*;

				@Inherited
				@Documented
				@Retention(RetentionPolicy.RUNTIME) // 컴파일 이후에도 JVM에 의해서 참조가 가능합니다.
				//@Retention(RetentionPolicy.CLASS) // 컴파일러가 클래스를 참조할 때까지 유효합니다.
				//@Retention(RetentionPolicy.SOURCE) // 어노테이션 정보는 컴파일 이후 없어집니다.
				@Target({
						ElementType.PACKAGE, // 패키지 선언시
						ElementType.TYPE, // 타입 선언시
						ElementType.CONSTRUCTOR, // 생성자 선언시
						ElementType.FIELD, // 멤버 변수 선언시
						ElementType.METHOD, // 메소드 선언시
						ElementType.ANNOTATION_TYPE, // 어노테이션 타입 선언시
						ElementType.LOCAL_VARIABLE, // 지역 변수 선언시
						ElementType.PARAMETER, // 매개 변수 선언시
						ElementType.TYPE_PARAMETER, // 매개 변수 타입 선언시
						ElementType.TYPE_USE // 타입 사용시
				})
				public @interface MyAnnotation {
					/* enum 타입을 선언할 수 있습니다. */
					public enum Quality {BAD, GOOD, VERYGOOD}
					/* String은 기본 자료형은 아니지만 사용 가능합니다. */
					String value();
					/* 배열 형태로도 사용할 수 있습니다. */
					int[] values();
					/* enum 형태를 사용하는 방법입니다. */
					Quality quality() default Quality.GOOD;
				}
					ㄴ @interface (*커스텀어노테이션 이름*){ ~~~(*내용*)~~~ } 형태로 만든다.
			ㄴ 애자일 설계 방법) (정확하지않음)
				ㄴ 이 방법이란건 일종의 큰 범위이고 이 안에 속하는 대표적 방법으로 '스크럼'이 있다고한다.
				ㄴ 폭포수모델이 경직적인 단점을 해결하려고 나온 방법같으며
				ㄴ 짧은 개발주기를 반복적으로 하는게 특징인것 같다. (프로토타입을 여러번 만든다고 표현한다)
				ㄴ 한 주기안에서 요구사항, 명세, 구현 등 진행과정은 비슷한 듯 싶다.
			ㅇ 컴퓨터 작동의 원리
				ㄴ 컴퓨터 작동의 원리
				ㄴ 무엇이 컴퓨터를 컴퓨터로 만들까요?
					ㄴ 여러 종류가 있겠지만 모든 컴퓨터는 공통적인 네가지 단계를 가진다.
					ㄴ input, storage, processing, output
				ㄴ 이진수와 데이터
					ㄴ 컴퓨터는 전기신호를 통해서만 정보를 사용 할 수 있다.
					ㄴ 전기 신호는 전기가 통하는 전선에서 '켜짐'과 '꺼짐'을 이용하여 0,1로 표현이 가능하며 이것을 '비트'라고 한다.
					ㄴ 이 비트는 0,1 또는 참,거짓 또는 on,off 두가지밖에 표현하지 못하지만 이 비트가 무수히 많아질수록 표현가능한 정보의 종류는 많아진다.
					ㄴ 3비트가 있으면 8가지를 표현할 수 있고 이런식으로.
					ㄴ 이런 무수한 비트들의조합으로 글자, 이미지, 소리 등을 표현할 수 있다.
				ㄴ 회로와 논리
					ㄴ 컴퓨터가 이런 비트정보들로 processing을 하기 위해선 이 비트들을 변경하거나 합치는 등의 작업을 해야한다.
					ㄴ 이를 위해서 필요한 것이 '회로'이다.
					ㄴ 회로란 내가 알고있는 논리 회로를 말하며, XOR, AND연산 등을 해주는 회로를 말함.
					ㄴ 이러한 간단한 회로들을 복잡하게 연결하여 사칙연산과 같은 기능을 하는 회로를 만들수 있으며, 또 이 덧셈 회로를 복잡하게 연결하여
						곱셈연산을 하는 회로를 만들 수 도 있다.
					ㄴ 이런식으로 processing과정의 연산들은 이러한 간단한 연산들의 합이라고 볼 수 있다.
					ㄴ 이런 복잡한 회로, 연산을 통해 프로그램을 만드는것.
				ㄴ cpu, 메모리, 입출력
					ㄴ 위에서 말한 컴퓨터의 공통적인 네단계는 컴퓨터 안에서 각기 다른곳에서 발생한다함.
					ㄴ 데이터를 받거나 내보내거나 이진수로 변환해주는 io, 이 이진데이터를 저장하는 메모리, 이진데이터들을 연산하는 cpu.
			ㄴ 파일질라 )
				ㄴ sftp의 경우는 22번 포트, ftp의 경우는 21번포트로 연결을 시도하면 되는 듯하다.
				ㄴ 계정과 비번은 접속하려는 컴퓨터의 계정을 말하는 것.
					ㄴ 네이버클라우드플랫폼 서버의 경우, ssh연결할때 사용한 root계정을 쓰면되는듯하다. 이게 그컴퓨터의 계정이니까.
			ㄴ BSON <button>more</button>
			<pre>
				ㄴ JSON과 같은 데이터 변환 형태이다. Binary JSON의 약자.
				ㄴ '연관 배열'이나 정수 인덱스 배열과 같은 복잡한 데이터 structure나 단순 데이터를 바이너리 형태로 나타낸다.
			</pre>
			ㄴ 포팅, Porting
				ㄴ 원래 해당 소프트웨어가 실행되도록 고려된 환경이 아닌 다른 환경에서 실행시키기 위해 소프트웨어를 적용시키는 과정
				ㄴ 소프트웨어를 다시 처음부터 만드는 비용보다 소프트웨어를 새 플랫폼 환경으로 포팅하는 비용이 싸다면 그 소프트웨어는
					'portable'하다 한다. 비용이 쌀 수록 더 '휴대성있다'한다.
			ㄴ ORM )
				ㄴ ??? 객체지향 프로그램에서는 주로 객체에 대해서 로직이 짜인다.
					객체에 대한 정보를 db에 저장하려하면, 객체의 데이터를 원자화하여 sql로 작성하거나 sql로부터 가져온 원자 데이터를
					객체로 만드는 등의 작업이 필요한데, 일일히 sql을 작성하여 작업해야 한다.
					ORM은 객체지향 언어에 대해 적절한 api를 제공하여 sql없이 객체만 사용하여 이러한 작업을 할 수 있게 해준다???
				ㄴ persistent, 영속성
					ㄴ 객체를 db에 원자화 하여 저장하고, db로부터 객체를 객체의 속성과 관계를 보존하면서 가져와 쓸 수 있을 때,
						이 객체를 'persistent하다' 라고 한다.
				ㄴ sql 작성 관련 작업의 상당수를 간소화.
					ㄴ '모두'는 아님.
				ㄴ 높은 추상화 수준으로 인한 러닝 커브.
				ㄴ ??? ORM 소프트웨어에 대한 의존성으로 인한 db 설계상의 문제.


		</pre>
		오류내용<button>더보기</button>
		<pre>
			ㅡRequestDispatcher의 forward()를 사용해 페이지를 넘기는게 안됨. 오류가뜨지도않고 그냥 페이지가 멈춤. 콘솔창에는
				ERR_INCOMPLETE_CHUNKED_ENCODING 200 라고뜨며, 인터넷에 처보면 해결책이 먼소린지모르겟음. 간단한 forward는 작동하나
				myBoard에서 문제발생함.

			ㅡa태그로 jsp페이지로 넘어가면 이유는 모르겟지만 스크립틀릿부분이 제대로 실행되지 않는경우가 있다. form을 이용해 넘겨주면 제대로 되긴함.
				이유는 잘모르겟음.

			ㅡ서버가 아예 시작이안되는 경우.  뭐가 중복된다고뜸.오른쪽 프록젝트 목록 다지우니까 됨. 같이컴파일비슷하게 되나봄.

			ㅡ 자바는 함수호출시 값의의한 호출만 지원. 객체도 복사된 참조값이 넘어가기때문에  해당객체의 내용을 바꿀수는 있지만 넘어간 함수안에서 참조값에 null을넣어봤자
				복사본의 참조자에 null을넣는것이므로 원본참조자에는 변동없음.

			ㅡ 서블릿을 어플리케이션의 시작으로 삼을때)
				ㄴ 그 서블릿이 제대로 동작하지않는 경우가 있는것같다. forward()가있었는데 이부분만 동작하고 그 위로는 다 처리되지않았다.

			ㅡ 외부 jar파일이나 라이브러리같은 파일을 추가하고나서 왼쪽탐색기에 추가한 내용이 표시되지않으면 인식이 안되는듯하다. refresh버튼 눌러서 추가되도록하거나
				톰켓 매니저페이지 들어가서 리로드하자.

			ㅡ 보안설정하려고 톰캣에서 "tomcat-users.xml"파일 에서 < role rolename~~~>등 설정하는데 이 파일에 대한 쓰기권한이 없다고한다.

			ㅡ 파일 경로에 한글이 포함되어 있으면 인식하지 못하는 오류가 가끔 있는 듯 하다.

			ㅡ  java.lang.IllegalArgumentException: 메소드 이름에 유효하지 않은 문자가 발견되었습니다. HTTP 메소드 이름은 유효한 토큰이어야 합니다.
				ㄴ 형식이 잘못된 http request로 인해 발생한다함.
				ㄴ 출처 ) https://stackoverrun.com/ko/q/11614574
				ㄴ 내 경우, request를 https에서 http로 변경하여 해결. 이유는 정확히 모르겠으나 이 오류가 https를 못쓰는데 https요청을 보낼때
					생긴다하여 바꿔봤는데 해결됨.
			ㅡ ajax 이용해서 파라미터 보낼시 받는 컨트롤러에서 한글이 깨지는 현상 )
				ㄴ 맨위에 jsp지시자로 아래와같이 설정해주는 문제느 ㄴ아니었고
					ㄴ <%@ page language="java" contentType="text/html; charset=UTF-8"  pageEncoding="UTF-8"%>
				ㄴ ajax사용시 post형태로 보내기위해 	httpRequest.setRequestHeader('Content-Type', 'application/x-www-form-urlencoded; charset=UTF-8'); 를
					추가했는데 여기 맨뒤에 보이는것처럼 charset=UTF-8을 추가해주니 해결되었다.
			ㅡ
		</pre>
		팁<button>더보기</button>
		<pre>
			ㅡ 가장 먼저 스펠링 확인.
			ㅡ 디버깅 모드가 강력. 함수 하나하나 들어가서 살펴 볼 필요 없고(어차피 어려워서 모름), F6으로 넘기면서 값들 확인만으로도 버그찾기 수월.
			ㅡ 퓨어 자바스크립트와 제이쿼리와 같이, 확실히 만들어진 api가 쓰기는 좋지만 섬세한 작업이 필요할때와 커스터마이징이 필요할 때는 근간기술을 사용하는게 더 수월하기도 하다.
				ㄴ 자바로 웹페이지 만드는 거하고 wordpress로 만드려던것 생각해보자.
			ㅡ 되도록 영어로 검색하자. 더 많고 깊은정보가 나오는듯하다. 익숙해져야하기도하고.
			ㅡ 주석달기
				ㄴ 아무리깔끔하게 코딩하고 내가 몇일전에 짠 코드라 해도 다시보면 뭐가뭔지모르거나 헷갈림.
				ㄴ 코드가 아무리 쉽더라도 다시보면서 이해하는데 시간이 걸림. 지금 게시판도 이렇게 복잡하게 느껴지는데 실무의 만줄코드는 서로 얽히고 섥혀 얼마나 복잡할까. 그리고 이걸 아무정리없이 나중에 다시봐야한다고 생각해보자.
					이걸 언제 다시 이해하고있는가.
				ㄴ 성능 약간 좋아지는 것보다 코드 깔끔하고 주석 잘 정리해 두는게 훨씬 더 중요한 것 같다.
			ㅡ 역시 뭔가 처음써보는것을 사용할땐 튜토리얼을 한번쭉훑고 시작하는게 낫다. 여기서 모든걸 알수는 없겠지만 기본적이고 많이쓰이는 내용들은 대부분 담겨있고 구글링으로 검색해서 아는것보다 더깊은 지식이있는경우가 많다.
				기본적인것도 몰라서 삽질하는걸 막을 수도 있고.
			ㅡ 콘솔에 찍히는 예외 스택 트레이스 )
				ㄴ 말그대로 예외 스택 트레이스이므로 가장 밑단에서 예외발생하면 그걸 던지고 던지고 쭉 타고 내 코드부분까지 올라오는것.
		</pre>
		궁금증<button>더보기</button>
		<pre>
			ㅡㅇㅇ 이런 언어들, css,ajax, el 등등 이 어디서왔는지? 어떻게 동작하는지?(사용법말고 내부적으로), 그냥 언어로만들어진 프로그램의 일종이라면 뭘로 만들어졌는지?
				ㄴ 가령 css의 예를들면, computer language의 일종. 그중에서도 Style Sheet Language 의 일종이다.
				ㄴ c언어처럼 문법이 있고 이를 해석하는 컴파일러, 어셈블러, 로더가 있어 해당언어로 작성한 문서를 실행할수있게해주는.
				ㄴ 이것처럼 css도 css의 문법이 html같은 dom문서에서 display부분을 조작하도록 만들어진
				ㄴ 예상했던대로, c같은 언어 그 자체는 일종의 문법, rule이고 이를 컴파일러(어셈블러,로더)가 해석해서 실행가능한 파일로 만들어주는것.
					ㄴ 컴파일러 역시 c코드같은 문자데이터를 해석해주는 프로그램의 일종이고, 어떤언어로든 만들어졌겠지.
					ㄴ 컴파일된걸 어셈블러, 로더 등등의 과정을 거쳐 실행가능한 프로그램이 되는거고.
				ㄴ 그럼 어떤 프로그램이든, 뭐든 어떠한 언어로 만들어져 내부적으로 프로그램된 프로그램의 일종이라고 생각한다면, 굳이 그 내부적으로 어떻게 동작하는지 필요한게 아니면 알 필요가 없지않을까?
					ㄴ 모르긴몰라도 어차피 내가만들거나 다른 만들어진 프로그램들처럼, 똑같이 함수쓰고 알고리즘 만들어서 돌아가는 프로그램일 테니까.
					ㄴ 네트워크, 스레드, 프로세스, 이런 컴구에 나오는 주요한 이슈 아니면 굳이 알필요없지 않을까 싶다.
				ㄴ css도 마찬가지. 모르긴몰라도 사람들에 의해 어떤 문법이 만들어졌고, dom상에 적용되는 언어라니까 dom을 다루는 브라우져같은 프로그램에서 내부적으로 동작하면서 css의 내용중 해당 dom부분에 css rule대로 display를 입혀주는
					그런 프로그램이겠지.
				ㄴ ajax도 마찬가지, el도 마찬가지.
				ㄴ 이렇게 되면 굳이 내부동작원리 알려고 애쓸거없이 그냥 사용법만 잘익혀서 사용하면 되는거 아닌가?
				ㄴ 물론 아예 필요없는건 아니고. 굳이 특별한 이유없으면 하나하나 궁금해할 이유가 없는거니까.

		</pre>
	</pre>

	<br/>
	서비스 기획? 도메인?<button>more</button>
	<pre>
		ㅡ 본인인증?, 인증?
			ㄴ 종류
				ㄴ 휴대폰 본인인증
					ㄴ ??? 당사자의 개인 정보를 가지고 있고, 그 당사자의 휴대폰을 실소유하고 있는지 확인?
						개인정보 입력과 그 사람 소유의 휴대폰으로 sms인증을 통하여?
					ㄴ 휴대폰 통신사를 통하여 진행.
				ㄴ 실명인증
					ㄴ ??? 당사자가 실존하는 사람인지 확인?
						개인정보 입력을 통해 확인?
					ㄴ 신용평가기관을 통하여 진행?
				ㄴ 휴대폰 인증
					ㄴ 실제로 있는 번호인지 확인?
					ㄴ sms 인증번호 확인을 통해 진행?
				ㄴ 이메일 인증
					ㄴ 실제로 있는 이메일인지 확인?
					ㄴ 이메일 인증번호 확인을 통해 진행?
			ㄴ 서비스에서 굳이 본인을 인증할 필요가 없다면 할 필요 없다.
			ㄴ 본인 인증이 필요한 경우
				ㄴ 서비스 특성상 본인 인증이 필요할 때
					ㄴ ex ) 법적인 이유, ???도용 및 부정 거래 방지?
				ㄴ 진정 정보 수집?
					ㄴ 실제 서비스 이용자들에 대한 정보를 수집하고자 하는 것?
			ㄴ 본인인증은 ux관점에서 허들로 작용할 수 있다.
			ㄴ 통상적으로 말하는 본인인증의 필요성 및 장점
				ㄴ 주민등록번호 생성기를 통한 회원가입 및 타인 주민등록번호 도용을 방지할 수 있습니다.
				ㄴ 정보통신망 이용에 관한 법률에 따라 일정규모 이상의 방문자를 가진 인터넷사이트는 의무적으로 실명확인서비스를 도입해야 합니다.
				ㄴ 인터넷 상거래가 일어나는 쇼핑몰, 유료 사이트 등은 회원들의 실명 확인을 통해 명의도용 등의 상거래 상의 문제를 예방할 수 있습니다.
				ㄴ 성인인증이 필요한 사이트는 미성년자의 실명확인을 통해 접근을 사전 차단할 수 있습니다.
				ㄴ 실명이 확인된 고객 데이터를 기반으로 실제 고객에게만 CRM활동을 함으로써 마케팅비용을 절감할 수 있습니다.
				ㄴ 가명을 이용하여 가입한 회원들의 익명성에 의한 허위 사실의 유포 및 무분별한 비방을 막을 수 있습니다
			ㄴ ex )
				ㄴ


	</pre>


	<script src="https://code.jquery.com/jquery-latest.js"></script>
	<script>
		$('button').next('pre').css('display','none');
		$('button').on('click',function(e){
			if($(this).next('pre').css('display')=='none'){
				$(this).next('pre').css('display','block');
				$(this).text('접기');
			}
			else{
				$(this).next('pre').css('display','none');
				$(this).text('펼치기');
			}
		})

		$('#showAll').on('click', function(e){
			$('pre').css('display','block');
		})
	</script>
</body>
</html>
